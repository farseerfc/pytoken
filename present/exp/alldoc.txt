
This is a brief list of all the files in ./linux/Documentation and what
they contain. If you add a documentation file, please list it here in
alphabetical order as well, or risk being hunted down like a rabid dog.
Please try and keep the descriptions small enough to fit on one line.
							 Thanks -- Paul G.

Following translations are available on the WWW:

   - Japanese, maintained by the JF Project (JF@linux.or.jp), at
     http://www.linux.or.jp/JF/

00-INDEX
	- this file.
ABI/
	- info on kernel <-> userspace ABI and relative interface stability.

BUG-HUNTING
	- brute force method of doing binary search of patches to find bug.
Changes
	- list of changes that break older software packages.
CodingStyle
	- how the boss likes the C code in the kernel to look.
development-process/
	- An extended tutorial on how to work with the kernel development
	  process.
DMA-API.txt
	- DMA API, pci_ API & extensions for non-consistent memory machines.
DMA-ISA-LPC.txt
	- How to do DMA with ISA (and LPC) devices.
DocBook/
	- directory with DocBook templates etc. for kernel documentation.
HOWTO
	- the process and procedures of how to do Linux kernel development.
IPMI.txt
	- info on Linux Intelligent Platform Management Interface (IPMI) Driver.
IRQ-affinity.txt
	- how to select which CPU(s) handle which interrupt events on SMP.
IRQ.txt
	- description of what an IRQ is.
ManagementStyle
	- how to (attempt to) manage kernel hackers.
RCU/
	- directory with info on RCU (read-copy update).
SAK.txt
	- info on Secure Attention Keys.
SM501.txt
	- Silicon Motion SM501 multimedia companion chip
SecurityBugs
	- procedure for reporting security bugs found in the kernel.
SubmitChecklist
	- Linux kernel patch submission checklist.
SubmittingDrivers
	- procedure to get a new driver source included into the kernel tree.
SubmittingPatches
	- procedure to get a source patch included into the kernel tree.
VGA-softcursor.txt
	- how to change your VGA cursor from a blinking underscore.
accounting/
	- documentation on accounting and taskstats.
acpi/
	- info on ACPI-specific hooks in the kernel.
aoe/
	- description of AoE (ATA over Ethernet) along with config examples.
applying-patches.txt
	- description of various trees and how to apply their patches.
arm/
	- directory with info about Linux on the ARM architecture.
atomic_ops.txt
	- semantics and behavior of atomic and bitmask operations.
auxdisplay/
	- misc. LCD driver documentation (cfag12864b, ks0108).
basic_profiling.txt
	- basic instructions for those who wants to profile Linux kernel.
binfmt_misc.txt
	- info on the kernel support for extra binary formats.
blackfin/
	- directory with documentation for the Blackfin arch.
block/
	- info on the Block I/O (BIO) layer.
blockdev/
	- info on block devices & drivers
btmrvl.txt
	- info on Marvell Bluetooth driver usage.
bus-virt-phys-mapping.txt
	- how to access I/O mapped memory from within device drivers.
cachetlb.txt
	- describes the cache/TLB flushing interfaces Linux uses.
cdrom/
	- directory with information on the CD-ROM drivers that Linux has.
cgroups/
	- cgroups features, including cpusets and memory controller.
connector/
	- docs on the netlink based userspace<->kernel space communication mod.
console/
	- documentation on Linux console drivers.
cpu-freq/
	- info on CPU frequency and voltage scaling.
cpu-hotplug.txt
	- document describing CPU hotplug support in the Linux kernel.
cpu-load.txt
	- document describing how CPU load statistics are collected.
cpuidle/
	- info on CPU_IDLE, CPU idle state management subsystem.
cputopology.txt
	- documentation on how CPU topology info is exported via sysfs.
cris/
	- directory with info about Linux on CRIS architecture.
crypto/
	- directory with info on the Crypto API.
dcdbas.txt
	- information on the Dell Systems Management Base Driver.
debugging-modules.txt
	- some notes on debugging modules after Linux 2.6.3.
dell_rbu.txt
	- document demonstrating the use of the Dell Remote BIOS Update driver.
device-mapper/
	- directory with info on Device Mapper.
devices.txt
	- plain ASCII listing of all the nodes in /dev/ with major minor #'s.
dontdiff
	- file containing a list of files that should never be diff'ed.
driver-model/
	- directory with info about Linux driver model.
dvb/
	- info on Linux Digital Video Broadcast (DVB) subsystem.
early-userspace/
	- info about initramfs, klibc, and userspace early during boot.
edac.txt
	- information on EDAC - Error Detection And Correction
eisa.txt
	- info on EISA bus support.
fault-injection/
	- dir with docs about the fault injection capabilities infrastructure.
fb/
	- directory with info on the frame buffer graphics abstraction layer.
feature-removal-schedule.txt
	- list of files and features that are going to be removed.
filesystems/
	- info on the vfs and the various filesystems that Linux supports.
firmware_class/
	- request_firmware() hotplug interface info.
frv/
	- Fujitsu FR-V Linux documentation.
gpio.txt
	- overview of GPIO (General Purpose Input/Output) access conventions.
highuid.txt
	- notes on the change from 16 bit to 32 bit user/group IDs.
timers/
	- info on the timer related topics
hw_random.txt
	- info on Linux support for random number generator in i8xx chipsets.
hwmon/
	- directory with docs on various hardware monitoring drivers.
i2c/
	- directory with info about the I2C bus/protocol (2 wire, kHz speed).
i2o/
	- directory with info about the Linux I2O subsystem.
x86/i386/
	- directory with info about Linux on Intel 32 bit architecture.
ia64/
	- directory with info about Linux on Intel 64 bit architecture.
infiniband/
	- directory with documents concerning Linux InfiniBand support.
initrd.txt
	- how to use the RAM disk as an initial/temporary root filesystem.
input/
	- info on Linux input device support.
io-mapping.txt
	- description of io_mapping functions in linux/io-mapping.h
io_ordering.txt
	- info on ordering I/O writes to memory-mapped addresses.
ioctl/
	- directory with documents describing various IOCTL calls.
iostats.txt
	- info on I/O statistics Linux kernel provides.
irqflags-tracing.txt
	- how to use the irq-flags tracing feature.
isapnp.txt
	- info on Linux ISA Plug & Play support.
isdn/
	- directory with info on the Linux ISDN support, and supported cards.
java.txt
	- info on the in-kernel binary support for Java(tm).
kbuild/
	- directory with info about the kernel build process.
kdump/
	- directory with mini HowTo on getting the crash dump code to work.
kernel-doc-nano-HOWTO.txt
	- mini HowTo on generation and location of kernel documentation files.
kernel-docs.txt
	- listing of various WWW + books that document kernel internals.
kernel-parameters.txt
	- summary listing of command line / boot prompt args for the kernel.
kobject.txt
	- info of the kobject infrastructure of the Linux kernel.
kprobes.txt
	- documents the kernel probes debugging feature.
kref.txt
	- docs on adding reference counters (krefs) to kernel objects.
laptops/
	- directory with laptop related info and laptop driver documentation.
ldm.txt
	- a brief description of LDM (Windows Dynamic Disks).
leds/
	- directory with info about LED handling under Linux.
local_ops.txt
	- semantics and behavior of local atomic operations.
lockdep-design.txt
	- documentation on the runtime locking correctness validator.
logo.gif
	- full colour GIF image of Linux logo (penguin - Tux).
logo.txt
	- info on creator of above logo & site to get additional images from.
m68k/
	- directory with info about Linux on Motorola 68k architecture.
magic-number.txt
	- list of magic numbers used to mark/protect kernel data structures.
mca.txt
	- info on supporting Micro Channel Architecture (e.g. PS/2) systems.
md.txt
	- info on boot arguments for the multiple devices driver.
memory-barriers.txt
	- info on Linux kernel memory barriers.
memory-hotplug.txt
	- Hotpluggable memory support, how to use and current status.
memory.txt
	- info on typical Linux memory problems.
mips/
	- directory with info about Linux on MIPS architecture.
mmc/
	- directory with info about the MMC subsystem
mono.txt
	- how to execute Mono-based .NET binaries with the help of BINFMT_MISC.
mutex-design.txt
	- info on the generic mutex subsystem.
namespaces/
	- directory with various information about namespaces
netlabel/
	- directory with information on the NetLabel subsystem.
networking/
	- directory with info on various aspects of networking with Linux.
nmi_watchdog.txt
	- info on NMI watchdog for SMP systems.
nommu-mmap.txt
	- documentation about no-mmu memory mapping support.
numastat.txt
	- info on how to read Numa policy hit/miss statistics in sysfs.
oops-tracing.txt
	- how to decode those nasty internal kernel error dump messages.
padata.txt
	- An introduction to the "padata" parallel execution API
parisc/
	- directory with info on using Linux on PA-RISC architecture.
parport.txt
	- how to use the parallel-port driver.
parport-lowlevel.txt
	- description and usage of the low level parallel port functions.
pcmcia/
	- info on the Linux PCMCIA driver.
pi-futex.txt
	- documentation on lightweight PI-futexes.
pnp.txt
	- Linux Plug and Play documentation.
power/
	- directory with info on Linux PCI power management.
powerpc/
	- directory with info on using Linux with the PowerPC.
preempt-locking.txt
	- info on locking under a preemptive kernel.
printk-formats.txt
	- how to get printk format specifiers right
prio_tree.txt
	- info on radix-priority-search-tree use for indexing vmas.
rbtree.txt
	- info on what red-black trees are and what they are for.
robust-futex-ABI.txt
	- documentation of the robust futex ABI.
robust-futexes.txt
	- a description of what robust futexes are.
rt-mutex-design.txt
	- description of the RealTime mutex implementation design.
rt-mutex.txt
	- desc. of RT-mutex subsystem with PI (Priority Inheritance) support.
rtc.txt
	- notes on how to use the Real Time Clock (aka CMOS clock) driver.
s390/
	- directory with info on using Linux on the IBM S390.
scheduler/
	- directory with info on the scheduler.
scsi/
	- directory with info on Linux scsi support.
security/
	- directory that contains security-related info
serial/
	- directory with info on the low level serial API.
serial-console.txt
	- how to set up Linux with a serial line console as the default.
sgi-ioc4.txt
	- description of the SGI IOC4 PCI (multi function) device.
sgi-visws.txt
	- short blurb on the SGI Visual Workstations.
sh/
	- directory with info on porting Linux to a new architecture.
sound/
	- directory with info on sound card support.
sparc/
	- directory with info on using Linux on Sparc architecture.
sparse.txt
	- info on how to obtain and use the sparse tool for typechecking.
spi/
	- overview of Linux kernel Serial Peripheral Interface (SPI) support.
spinlocks.txt
	- info on using spinlocks to provide exclusive access in kernel.
stable_api_nonsense.txt
	- info on why the kernel does not have a stable in-kernel api or abi.
stable_kernel_rules.txt
	- rules and procedures for the -stable kernel releases.
svga.txt
	- short guide on selecting video modes at boot via VGA BIOS.
sysfs-rules.txt
	- How not to use sysfs.
sysctl/
	- directory with info on the /proc/sys/* files.
sysrq.txt
	- info on the magic SysRq key.
telephony/
	- directory with info on telephony (e.g. voice over IP) support.
unicode.txt
	- info on the Unicode character/font mapping used in Linux.
unshare.txt
	- description of the Linux unshare system call.
usb/
	- directory with info regarding the Universal Serial Bus.
video-output.txt
	- sysfs class driver interface to enable/disable a video output device.
video4linux/
	- directory with info regarding video/TV/radio cards and linux.
vm/
	- directory with info on the Linux vm code.
volatile-considered-harmful.txt
	- Why the "volatile" type class should not be used
w1/
	- directory with documents regarding the 1-wire (w1) subsystem.
watchdog/
	- how to auto-reboot Linux if it has "fallen and can't get up". ;-)
x86/x86_64/
	- directory with info on Linux support for AMD x86-64 (Hammer) machines.
zorro.txt
	- info on writing drivers for Zorro bus devices found on Amigas.

	Applying Patches To The Linux Kernel
	------------------------------------

	Original by: Jesper Juhl, August 2005
	Last update: 2006-01-05


A frequently asked question on the Linux Kernel Mailing List is how to apply
a patch to the kernel or, more specifically, what base kernel a patch for
one of the many trees/branches should be applied to. Hopefully this document
will explain this to you.

In addition to explaining how to apply and revert patches, a brief
description of the different kernel trees (and examples of how to apply
their specific patches) is also provided.


What is a patch?
---
 A patch is a small text document containing a delta of changes between two
different versions of a source tree. Patches are created with the `diff'
program.
To correctly apply a patch you need to know what base it was generated from
and what new version the patch will change the source tree into. These
should both be present in the patch file metadata or be possible to deduce
from the filename.


How do I apply or revert a patch?
---
 You apply a patch with the `patch' program. The patch program reads a diff
(or patch) file and makes the changes to the source tree described in it.

Patches for the Linux kernel are generated relative to the parent directory
holding the kernel source dir.

This means that paths to files inside the patch file contain the name of the
kernel source directories it was generated against (or some other directory
names like "a/" and "b/").
Since this is unlikely to match the name of the kernel source dir on your
local machine (but is often useful info to see what version an otherwise
unlabeled patch was generated against) you should change into your kernel
source directory and then strip the first element of the path from filenames
in the patch file when applying it (the -p1 argument to `patch' does this).

To revert a previously applied patch, use the -R argument to patch.
So, if you applied a patch like this:
	patch -p1 < ../patch-x.y.z

You can revert (undo) it like this:
	patch -R -p1 < ../patch-x.y.z


How do I feed a patch/diff file to `patch'?
---
 This (as usual with Linux and other UNIX like operating systems) can be
done in several different ways.
In all the examples below I feed the file (in uncompressed form) to patch
via stdin using the following syntax:
	patch -p1 < path/to/patch-x.y.z

If you just want to be able to follow the examples below and don't want to
know of more than one way to use patch, then you can stop reading this
section here.

Patch can also get the name of the file to use via the -i argument, like
this:
	patch -p1 -i path/to/patch-x.y.z

If your patch file is compressed with gzip or bzip2 and you don't want to
uncompress it before applying it, then you can feed it to patch like this
instead:
	zcat path/to/patch-x.y.z.gz | patch -p1
	bzcat path/to/patch-x.y.z.bz2 | patch -p1

If you wish to uncompress the patch file by hand first before applying it
(what I assume you've done in the examples below), then you simply run
gunzip or bunzip2 on the file -- like this:
	gunzip patch-x.y.z.gz
	bunzip2 patch-x.y.z.bz2

Which will leave you with a plain text patch-x.y.z file that you can feed to
patch via stdin or the -i argument, as you prefer.

A few other nice arguments for patch are -s which causes patch to be silent
except for errors which is nice to prevent errors from scrolling out of the
screen too fast, and --dry-run which causes patch to just print a listing of
what would happen, but doesn't actually make any changes. Finally --verbose
tells patch to print more information about the work being done.


Common errors when patching
---
 When patch applies a patch file it attempts to verify the sanity of the
file in different ways.
Checking that the file looks like a valid patch file & checking the code
around the bits being modified matches the context provided in the patch are
just two of the basic sanity checks patch does.

If patch encounters something that doesn't look quite right it has two
options. It can either refuse to apply the changes and abort or it can try
to find a way to make the patch apply with a few minor changes.

One example of something that's not 'quite right' that patch will attempt to
fix up is if all the context matches, the lines being changed match, but the
line numbers are different. This can happen, for example, if the patch makes
a change in the middle of the file but for some reasons a few lines have
been added or removed near the beginning of the file. In that case
everything looks good it has just moved up or down a bit, and patch will
usually adjust the line numbers and apply the patch.

Whenever patch applies a patch that it had to modify a bit to make it fit
it'll tell you about it by saying the patch applied with 'fuzz'.
You should be wary of such changes since even though patch probably got it
right it doesn't /always/ get it right, and the result will sometimes be
wrong.

When patch encounters a change that it can't fix up with fuzz it rejects it
outright and leaves a file with a .rej extension (a reject file). You can
read this file to see exactly what change couldn't be applied, so you can
go fix it up by hand if you wish.

If you don't have any third-party patches applied to your kernel source, but
only patches from kernel.org and you apply the patches in the correct order,
and have made no modifications yourself to the source files, then you should
never see a fuzz or reject message from patch. If you do see such messages
anyway, then there's a high risk that either your local source tree or the
patch file is corrupted in some way. In that case you should probably try
re-downloading the patch and if things are still not OK then you'd be advised
to start with a fresh tree downloaded in full from kernel.org.

Let's look a bit more at some of the messages patch can produce.

If patch stops and presents a "File to patch:" prompt, then patch could not
find a file to be patched. Most likely you forgot to specify -p1 or you are
in the wrong directory. Less often, you'll find patches that need to be
applied with -p0 instead of -p1 (reading the patch file should reveal if
this is the case -- if so, then this is an error by the person who created
the patch but is not fatal).

If you get "Hunk #2 succeeded at 1887 with fuzz 2 (offset 7 lines)." or a
message similar to that, then it means that patch had to adjust the location
of the change (in this example it needed to move 7 lines from where it
expected to make the change to make it fit).
The resulting file may or may not be OK, depending on the reason the file
was different than expected.
This often happens if you try to apply a patch that was generated against a
different kernel version than the one you are trying to patch.

If you get a message like "Hunk #3 FAILED at 2387.", then it means that the
patch could not be applied correctly and the patch program was unable to
fuzz its way through. This will generate a .rej file with the change that
caused the patch to fail and also a .orig file showing you the original
content that couldn't be changed.

If you get "Reversed (or previously applied) patch detected!  Assume -R? [n]"
then patch detected that the change contained in the patch seems to have
already been made.
If you actually did apply this patch previously and you just re-applied it
in error, then just say [n]o and abort this patch. If you applied this patch
previously and actually intended to revert it, but forgot to specify -R,
then you can say [y]es here to make patch revert it for you.
This can also happen if the creator of the patch reversed the source and
destination directories when creating the patch, and in that case reverting
the patch will in fact apply it.

A message similar to "patch: **** unexpected end of file in patch" or "patch
unexpectedly ends in middle of line" means that patch could make no sense of
the file you fed to it. Either your download is broken, you tried to feed
patch a compressed patch file without uncompressing it first, or the patch
file that you are using has been mangled by a mail client or mail transfer
agent along the way somewhere, e.g., by splitting a long line into two lines.
Often these warnings can easily be fixed by joining (concatenating) the
two lines that had been split.

As I already mentioned above, these errors should never happen if you apply
a patch from kernel.org to the correct version of an unmodified source tree.
So if you get these errors with kernel.org patches then you should probably
assume that either your patch file or your tree is broken and I'd advise you
to start over with a fresh download of a full kernel tree and the patch you
wish to apply.


Are there any alternatives to `patch'?
---
 Yes there are alternatives.

 You can use the `interdiff' program (http://cyberelk.net/tim/patchutils/) to
generate a patch representing the differences between two patches and then
apply the result.
This will let you move from something like 2.6.12.2 to 2.6.12.3 in a single
step. The -z flag to interdiff will even let you feed it patches in gzip or
bzip2 compressed form directly without the use of zcat or bzcat or manual
decompression.

Here's how you'd go from 2.6.12.2 to 2.6.12.3 in a single step:
	interdiff -z ../patch-2.6.12.2.bz2 ../patch-2.6.12.3.gz | patch -p1

Although interdiff may save you a step or two you are generally advised to
do the additional steps since interdiff can get things wrong in some cases.

 Another alternative is `ketchup', which is a python script for automatic
downloading and applying of patches (http://www.selenic.com/ketchup/).

 Other nice tools are diffstat, which shows a summary of changes made by a
patch; lsdiff, which displays a short listing of affected files in a patch
file, along with (optionally) the line numbers of the start of each patch;
and grepdiff, which displays a list of the files modified by a patch where
the patch contains a given regular expression.


Where can I download the patches?
---
 The patches are available at http://kernel.org/
Most recent patches are linked from the front page, but they also have
specific homes.

The 2.6.x.y (-stable) and 2.6.x patches live at
 ftp://ftp.kernel.org/pub/linux/kernel/v2.6/

The -rc patches live at
 ftp://ftp.kernel.org/pub/linux/kernel/v2.6/testing/

The -git patches live at
 ftp://ftp.kernel.org/pub/linux/kernel/v2.6/snapshots/

The -mm kernels live at
 ftp://ftp.kernel.org/pub/linux/kernel/people/akpm/patches/2.6/

In place of ftp.kernel.org you can use ftp.cc.kernel.org, where cc is a
country code. This way you'll be downloading from a mirror site that's most
likely geographically closer to you, resulting in faster downloads for you,
less bandwidth used globally and less load on the main kernel.org servers --
these are good things, so do use mirrors when possible.


The 2.6.x kernels
---
 These are the base stable releases released by Linus. The highest numbered
release is the most recent.

If regressions or other serious flaws are found, then a -stable fix patch
will be released (see below) on top of this base. Once a new 2.6.x base
kernel is released, a patch is made available that is a delta between the
previous 2.6.x kernel and the new one.

To apply a patch moving from 2.6.11 to 2.6.12, you'd do the following (note
that such patches do *NOT* apply on top of 2.6.x.y kernels but on top of the
base 2.6.x kernel -- if you need to move from 2.6.x.y to 2.6.x+1 you need to
first revert the 2.6.x.y patch).

Here are some examples:

# moving from 2.6.11 to 2.6.12
$ cd ~/linux-2.6.11			# change to kernel source dir
$ patch -p1 < ../patch-2.6.12		# apply the 2.6.12 patch
$ cd ..
$ mv linux-2.6.11 linux-2.6.12		# rename source dir

# moving from 2.6.11.1 to 2.6.12
$ cd ~/linux-2.6.11.1			# change to kernel source dir
$ patch -p1 -R < ../patch-2.6.11.1	# revert the 2.6.11.1 patch
					# source dir is now 2.6.11
$ patch -p1 < ../patch-2.6.12		# apply new 2.6.12 patch
$ cd ..
$ mv linux-2.6.11.1 linux-2.6.12		# rename source dir


The 2.6.x.y kernels
---
 Kernels with 4-digit versions are -stable kernels. They contain small(ish)
critical fixes for security problems or significant regressions discovered
in a given 2.6.x kernel.

This is the recommended branch for users who want the most recent stable
kernel and are not interested in helping test development/experimental
versions.

If no 2.6.x.y kernel is available, then the highest numbered 2.6.x kernel is
the current stable kernel.

 note: the -stable team usually do make incremental patches available as well
 as patches against the latest mainline release, but I only cover the
 non-incremental ones below. The incremental ones can be found at
 ftp://ftp.kernel.org/pub/linux/kernel/v2.6/incr/

These patches are not incremental, meaning that for example the 2.6.12.3
patch does not apply on top of the 2.6.12.2 kernel source, but rather on top
of the base 2.6.12 kernel source .
So, in order to apply the 2.6.12.3 patch to your existing 2.6.12.2 kernel
source you have to first back out the 2.6.12.2 patch (so you are left with a
base 2.6.12 kernel source) and then apply the new 2.6.12.3 patch.

Here's a small example:

$ cd ~/linux-2.6.12.2			# change into the kernel source dir
$ patch -p1 -R < ../patch-2.6.12.2	# revert the 2.6.12.2 patch
$ patch -p1 < ../patch-2.6.12.3		# apply the new 2.6.12.3 patch
$ cd ..
$ mv linux-2.6.12.2 linux-2.6.12.3	# rename the kernel source dir


The -rc kernels
---
 These are release-candidate kernels. These are development kernels released
by Linus whenever he deems the current git (the kernel's source management
tool) tree to be in a reasonably sane state adequate for testing.

These kernels are not stable and you should expect occasional breakage if
you intend to run them. This is however the most stable of the main
development branches and is also what will eventually turn into the next
stable kernel, so it is important that it be tested by as many people as
possible.

This is a good branch to run for people who want to help out testing
development kernels but do not want to run some of the really experimental
stuff (such people should see the sections about -git and -mm kernels below).

The -rc patches are not incremental, they apply to a base 2.6.x kernel, just
like the 2.6.x.y patches described above. The kernel version before the -rcN
suffix denotes the version of the kernel that this -rc kernel will eventually
turn into.
So, 2.6.13-rc5 means that this is the fifth release candidate for the 2.6.13
kernel and the patch should be applied on top of the 2.6.12 kernel source.

Here are 3 examples of how to apply these patches:

# first an example of moving from 2.6.12 to 2.6.13-rc3
$ cd ~/linux-2.6.12			# change into the 2.6.12 source dir
$ patch -p1 < ../patch-2.6.13-rc3	# apply the 2.6.13-rc3 patch
$ cd ..
$ mv linux-2.6.12 linux-2.6.13-rc3	# rename the source dir

# now let's move from 2.6.13-rc3 to 2.6.13-rc5
$ cd ~/linux-2.6.13-rc3			# change into the 2.6.13-rc3 dir
$ patch -p1 -R < ../patch-2.6.13-rc3	# revert the 2.6.13-rc3 patch
$ patch -p1 < ../patch-2.6.13-rc5	# apply the new 2.6.13-rc5 patch
$ cd ..
$ mv linux-2.6.13-rc3 linux-2.6.13-rc5	# rename the source dir

# finally let's try and move from 2.6.12.3 to 2.6.13-rc5
$ cd ~/linux-2.6.12.3			# change to the kernel source dir
$ patch -p1 -R < ../patch-2.6.12.3	# revert the 2.6.12.3 patch
$ patch -p1 < ../patch-2.6.13-rc5	# apply new 2.6.13-rc5 patch
$ cd ..
$ mv linux-2.6.12.3 linux-2.6.13-rc5	# rename the kernel source dir


The -git kernels
---
 These are daily snapshots of Linus' kernel tree (managed in a git
repository, hence the name).

These patches are usually released daily and represent the current state of
Linus's tree. They are more experimental than -rc kernels since they are
generated automatically without even a cursory glance to see if they are
sane.

-git patches are not incremental and apply either to a base 2.6.x kernel or
a base 2.6.x-rc kernel -- you can see which from their name.
A patch named 2.6.12-git1 applies to the 2.6.12 kernel source and a patch
named 2.6.13-rc3-git2 applies to the source of the 2.6.13-rc3 kernel.

Here are some examples of how to apply these patches:

# moving from 2.6.12 to 2.6.12-git1
$ cd ~/linux-2.6.12			# change to the kernel source dir
$ patch -p1 < ../patch-2.6.12-git1	# apply the 2.6.12-git1 patch
$ cd ..
$ mv linux-2.6.12 linux-2.6.12-git1	# rename the kernel source dir

# moving from 2.6.12-git1 to 2.6.13-rc2-git3
$ cd ~/linux-2.6.12-git1		# change to the kernel source dir
$ patch -p1 -R < ../patch-2.6.12-git1	# revert the 2.6.12-git1 patch
					# we now have a 2.6.12 kernel
$ patch -p1 < ../patch-2.6.13-rc2	# apply the 2.6.13-rc2 patch
					# the kernel is now 2.6.13-rc2
$ patch -p1 < ../patch-2.6.13-rc2-git3	# apply the 2.6.13-rc2-git3 patch
					# the kernel is now 2.6.13-rc2-git3
$ cd ..
$ mv linux-2.6.12-git1 linux-2.6.13-rc2-git3	# rename source dir


The -mm kernels
---
 These are experimental kernels released by Andrew Morton.

The -mm tree serves as a sort of proving ground for new features and other
experimental patches.
Once a patch has proved its worth in -mm for a while Andrew pushes it on to
Linus for inclusion in mainline.

Although it's encouraged that patches flow to Linus via the -mm tree, this
is not always enforced.
Subsystem maintainers (or individuals) sometimes push their patches directly
to Linus, even though (or after) they have been merged and tested in -mm (or
sometimes even without prior testing in -mm).

You should generally strive to get your patches into mainline via -mm to
ensure maximum testing.

This branch is in constant flux and contains many experimental features, a
lot of debugging patches not appropriate for mainline etc., and is the most
experimental of the branches described in this document.

These kernels are not appropriate for use on systems that are supposed to be
stable and they are more risky to run than any of the other branches (make
sure you have up-to-date backups -- that goes for any experimental kernel but
even more so for -mm kernels).

These kernels in addition to all the other experimental patches they contain
usually also contain any changes in the mainline -git kernels available at
the time of release.

Testing of -mm kernels is greatly appreciated since the whole point of the
tree is to weed out regressions, crashes, data corruption bugs, build
breakage (and any other bug in general) before changes are merged into the
more stable mainline Linus tree.
But testers of -mm should be aware that breakage in this tree is more common
than in any other tree.

The -mm kernels are not released on a fixed schedule, but usually a few -mm
kernels are released in between each -rc kernel (1 to 3 is common).
The -mm kernels apply to either a base 2.6.x kernel (when no -rc kernels
have been released yet) or to a Linus -rc kernel.

Here are some examples of applying the -mm patches:

# moving from 2.6.12 to 2.6.12-mm1
$ cd ~/linux-2.6.12			# change to the 2.6.12 source dir
$ patch -p1 < ../2.6.12-mm1		# apply the 2.6.12-mm1 patch
$ cd ..
$ mv linux-2.6.12 linux-2.6.12-mm1	# rename the source appropriately

# moving from 2.6.12-mm1 to 2.6.13-rc3-mm3
$ cd ~/linux-2.6.12-mm1
$ patch -p1 -R < ../2.6.12-mm1		# revert the 2.6.12-mm1 patch
					# we now have a 2.6.12 source
$ patch -p1 < ../patch-2.6.13-rc3	# apply the 2.6.13-rc3 patch
					# we now have a 2.6.13-rc3 source
$ patch -p1 < ../2.6.13-rc3-mm3		# apply the 2.6.13-rc3-mm3 patch
$ cd ..
$ mv linux-2.6.12-mm1 linux-2.6.13-rc3-mm3	# rename the source dir


This concludes this list of explanations of the various kernel trees.
I hope you are now clear on how to apply the various patches and help testing
the kernel.

Thank you's to Randy Dunlap, Rolf Eike Beer, Linus Torvalds, Bodo Eggert,
Johannes Stezenbach, Grant Coady, Pavel Machek and others that I may have
forgotten for their reviews and contributions to this document.

March 2008
Jan-Simon Moeller, dl9pf@gmx.de


How to deal with bad memory e.g. reported by memtest86+ ?
#########################################################

There are three possibilities I know of:

1) Reinsert/swap the memory modules

2) Buy new modules (best!) or try to exchange the memory
   if you have spare-parts

3) Use BadRAM or memmap

This Howto is about number 3) .


BadRAM
######
BadRAM is the actively developed and available as kernel-patch
here:  http://rick.vanrein.org/linux/badram/

For more details see the BadRAM documentation.

memmap
######

memmap is already in the kernel and usable as kernel-parameter at
boot-time.  Its syntax is slightly strange and you may need to
calculate the values by yourself!

Syntax to exclude a memory area (see kernel-parameters.txt for details):
memmap=<size>$<address>

Example: memtest86+ reported here errors at address 0x18691458, 0x18698424 and
         some others. All had 0x1869xxxx in common, so I chose a pattern of
         0x18690000,0xffff0000.

With the numbers of the example above:
memmap=64K$0x18690000
 or
memmap=0x10000$0x18690000

These instructions are deliberately very basic. If you want something clever,
go read the real docs ;-) Please don't add more stuff, but feel free to 
correct my mistakes ;-)    (mbligh@aracnet.com)
Thanks to John Levon, Dave Hansen, et al. for help writing this.

<test> is the thing you're trying to measure.
Make sure you have the correct System.map / vmlinux referenced!

It is probably easiest to use "make install" for linux and hack
/sbin/installkernel to copy vmlinux to /boot, in addition to vmlinuz,
config, System.map, which are usually installed by default.

Readprofile
-----------
A recent readprofile command is needed for 2.6, such as found in util-linux
2.12a, which can be downloaded from:

http://www.kernel.org/pub/linux/utils/util-linux/

Most distributions will ship it already.

Add "profile=2" to the kernel command line.

clear		readprofile -r
		<test>
dump output	readprofile -m /boot/System.map > captured_profile

Oprofile
--------

Get the source (see Changes for required version) from
http://oprofile.sourceforge.net/ and add "idle=poll" to the kernel command
line.

Configure with CONFIG_PROFILING=y and CONFIG_OPROFILE=y & reboot on new kernel

./configure --with-kernel-support
make install

For superior results, be sure to enable the local APIC. If opreport sees
a 0Hz CPU, APIC was not on. Be aware that idle=poll may mean a performance
penalty.

One time setup:
		opcontrol --setup --vmlinux=/boot/vmlinux

clear		opcontrol --reset
start		opcontrol --start
		<test>
stop		opcontrol --stop
dump output	opreport >  output_file

To only report on the kernel, run opreport -l /boot/vmlinux > output_file

A reset is needed to clear old statistics, which survive a reboot.

                       Linux Braille Console

To get early boot messages on a braille device (before userspace screen
readers can start), you first need to compile the support for the usual serial
console (see serial-console.txt), and for braille device (in Device Drivers -
Accessibility).

Then you need to specify a console=brl, option on the kernel command line, the
format is:

	console=brl,serial_options...

where serial_options... are the same as described in serial-console.txt

So for instance you can use console=brl,ttyS0 if the braille device is connected
to the first serial port, and console=brl,ttyS0,115200 to override the baud rate
to 115200, etc.

By default, the braille device will just show the last kernel message (console
mode).  To review previous messages, press the Insert key to switch to the VT
review mode.  In review mode, the arrow keys permit to browse in the VT content,
page up/down keys go at the top/bottom of the screen, and the home key goes back
to the cursor, hence providing very basic screen reviewing facility.

Sound feedback can be obtained by adding the braille_console.sound=1 kernel
parameter.

For simplicity, only one braille console can be enabled, other uses of
console=brl,... will be discarded.  Also note that it does not interfere with
the console selection mechanism described in serial-console.txt

For now, only the VisioBraille device is supported.

Samuel Thibault <samuel.thibault@ens-lyon.org>
===============================================================
==  BT8XXGPIO driver                                         ==
==                                                           ==
==  A driver for a selfmade cheap BT8xx based PCI GPIO-card  ==
==                                                           ==
==  For advanced documentation, see                          ==
==  http://www.bu3sch.de/btgpio.php                          ==
===============================================================


A generic digital 24-port PCI GPIO card can be built out of an ordinary
Brooktree bt848, bt849, bt878 or bt879 based analog TV tuner card. The
Brooktree chip is used in old analog Hauppauge WinTV PCI cards. You can easily
find them used for low prices on the net.

The bt8xx chip does have 24 digital GPIO ports.
These ports are accessible via 24 pins on the SMD chip package.


==============================================
==  How to physically access the GPIO pins  ==
==============================================

The are several ways to access these pins. One might unsolder the whole chip
and put it on a custom PCI board, or one might only unsolder each individual
GPIO pin and solder that to some tiny wire. As the chip package really is tiny
there are some advanced soldering skills needed in any case.

The physical pinouts are drawn in the following ASCII art.
The GPIO pins are marked with G00-G23

                                           G G G G G G G G G G G G     G G G G G G
                                           0 0 0 0 0 0 0 0 0 0 1 1     1 1 1 1 1 1
                                           0 1 2 3 4 5 6 7 8 9 0 1     2 3 4 5 6 7
           | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |
           ---------------------------------------------------------------------------
         --|                               ^                                     ^   |--
         --|                               pin 86                           pin 67   |--
         --|                                                                         |--
         --|                                                               pin 61 >  |-- G18
         --|                                                                         |-- G19
         --|                                                                         |-- G20
         --|                                                                         |-- G21
         --|                                                                         |-- G22
         --|                                                               pin 56 >  |-- G23
         --|                                                                         |--
         --|                           Brooktree 878/879                             |--
         --|                                                                         |--
         --|                                                                         |--
         --|                                                                         |--
         --|                                                                         |--
         --|                                                                         |--
         --|                                                                         |--
         --|                                                                         |--
         --|                                                                         |--
         --|                                                                         |--
         --|                                                                         |--
         --|                                                                         |--
         --|                                                                         |--
         --|                                                                         |--
         --|   O                                                                     |--
         --|                                                                         |--
           ---------------------------------------------------------------------------
           | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |
           ^
           This is pin 1

=======================================================================
		README for btmrvl driver
=======================================================================


All commands are used via debugfs interface.

=====================
Set/get driver configurations:

Path:	/debug/btmrvl/config/

gpiogap=[n]
hscfgcmd
	These commands are used to configure the host sleep parameters.
	bit 8:0  -- Gap
	bit 16:8 -- GPIO

	where GPIO is the pin number of GPIO used to wake up the host.
	It could be any valid GPIO pin# (e.g. 0-7) or 0xff (SDIO interface
	wakeup will be used instead).

	where Gap is the gap in milli seconds between wakeup signal and
	wakeup event, or 0xff for special host sleep setting.

	Usage:
		# Use SDIO interface to wake up the host and set GAP to 0x80:
		echo 0xff80 > /debug/btmrvl/config/gpiogap
		echo 1 > /debug/btmrvl/config/hscfgcmd

		# Use GPIO pin #3 to wake up the host and set GAP to 0xff:
		echo 0x03ff >  /debug/btmrvl/config/gpiogap
		echo 1 > /debug/btmrvl/config/hscfgcmd

psmode=[n]
pscmd
	These commands are used to enable/disable auto sleep mode

	where the option is:
			1 	-- Enable auto sleep mode
			0 	-- Disable auto sleep mode

	Usage:
		# Enable auto sleep mode
		echo 1 > /debug/btmrvl/config/psmode
		echo 1 > /debug/btmrvl/config/pscmd

		# Disable auto sleep mode
		echo 0 > /debug/btmrvl/config/psmode
		echo 1 > /debug/btmrvl/config/pscmd


hsmode=[n]
hscmd
	These commands are used to enable host sleep or wake up firmware

	where the option is:
			1	-- Enable host sleep
			0	-- Wake up firmware

	Usage:
		# Enable host sleep
		echo 1 > /debug/btmrvl/config/hsmode
		echo 1 > /debug/btmrvl/config/hscmd

		# Wake up firmware
		echo 0 > /debug/btmrvl/config/hsmode
		echo 1 > /debug/btmrvl/config/hscmd


======================
Get driver status:

Path:	/debug/btmrvl/status/

Usage:
	cat /debug/btmrvl/status/<args>

where the args are:

curpsmode
	This command displays current auto sleep status.

psstate
	This command display the power save state.

hsstate
	This command display the host sleep state.

txdnldrdy
	This command displays the value of Tx download ready flag.


=====================

Use hcitool to issue raw hci command, refer to hcitool manual

	Usage: Hcitool cmd <ogf> <ocf> [Parameters]

	Interface Control Command
	hcitool cmd 0x3f 0x5b 0xf5 0x01 0x00    --Enable All interface
	hcitool cmd 0x3f 0x5b 0xf5 0x01 0x01    --Enable Wlan interface
	hcitool cmd 0x3f 0x5b 0xf5 0x01 0x02    --Enable BT interface
	hcitool cmd 0x3f 0x5b 0xf5 0x00 0x00    --Disable All interface
	hcitool cmd 0x3f 0x5b 0xf5 0x00 0x01    --Disable Wlan interface
	hcitool cmd 0x3f 0x5b 0xf5 0x00 0x02    --Disable BT interface

=======================================================================


SD8688 firmware:

/lib/firmware/sd8688_helper.bin
/lib/firmware/sd8688.bin


The images can be downloaded from:

git.infradead.org/users/dwmw2/linux-firmware.git/libertas/
Table of contents
=================

Last updated: 20 December 2005

Contents
========

- Introduction
- Devices not appearing
- Finding patch that caused a bug
-- Finding using git-bisect
-- Finding it the old way
- Fixing the bug

Introduction
============

Always try the latest kernel from kernel.org and build from source. If you are
not confident in doing that please report the bug to your distribution vendor
instead of to a kernel developer.

Finding bugs is not always easy. Have a go though. If you can't find it don't
give up. Report as much as you have found to the relevant maintainer. See
MAINTAINERS for who that is for the subsystem you have worked on.

Before you submit a bug report read REPORTING-BUGS.

Devices not appearing
=====================

Often this is caused by udev. Check that first before blaming it on the
kernel.

Finding patch that caused a bug
===============================



Finding using git-bisect
------------------------

Using the provided tools with git makes finding bugs easy provided the bug is
reproducible.

Steps to do it:
- start using git for the kernel source
- read the man page for git-bisect
- have fun

Finding it the old way
----------------------

[Sat Mar  2 10:32:33 PST 1996 KERNEL_BUG-HOWTO lm@sgi.com (Larry McVoy)]

This is how to track down a bug if you know nothing about kernel hacking.
It's a brute force approach but it works pretty well.

You need:

        . A reproducible bug - it has to happen predictably (sorry)
        . All the kernel tar files from a revision that worked to the
          revision that doesn't

You will then do:

        . Rebuild a revision that you believe works, install, and verify that.
        . Do a binary search over the kernels to figure out which one
          introduced the bug.  I.e., suppose 1.3.28 didn't have the bug, but
          you know that 1.3.69 does.  Pick a kernel in the middle and build
          that, like 1.3.50.  Build & test; if it works, pick the mid point
          between .50 and .69, else the mid point between .28 and .50.
        . You'll narrow it down to the kernel that introduced the bug.  You
          can probably do better than this but it gets tricky.

        . Narrow it down to a subdirectory

          - Copy kernel that works into "test".  Let's say that 3.62 works,
            but 3.63 doesn't.  So you diff -r those two kernels and come
            up with a list of directories that changed.  For each of those
            directories:

                Copy the non-working directory next to the working directory
                as "dir.63".
                One directory at time, try moving the working directory to
                "dir.62" and mv dir.63 dir"time, try

                        mv dir dir.62
                        mv dir.63 dir
                        find dir -name '*.[oa]' -print | xargs rm -f

                And then rebuild and retest.  Assuming that all related
                changes were contained in the sub directory, this should
                isolate the change to a directory.

                Problems: changes in header files may have occurred; I've
                found in my case that they were self explanatory - you may
                or may not want to give up when that happens.

        . Narrow it down to a file

          - You can apply the same technique to each file in the directory,
            hoping that the changes in that file are self contained.

        . Narrow it down to a routine

          - You can take the old file and the new file and manually create
            a merged file that has

                #ifdef VER62
                routine()
                {
                        ...
                }
                #else
                routine()
                {
                        ...
                }
                #endif

            And then walk through that file, one routine at a time and
            prefix it with

                #define VER62
                /* both routines here */
                #undef VER62

            Then recompile, retest, move the ifdefs until you find the one
            that makes the difference.

Finally, you take all the info that you have, kernel revisions, bug
description, the extent to which you have narrowed it down, and pass
that off to whomever you believe is the maintainer of that section.
A post to linux.dev.kernel isn't such a bad idea if you've done some
work to narrow it down.

If you get it down to a routine, you'll probably get a fix in 24 hours.

My apologies to Linus and the other kernel hackers for describing this
brute force approach, it's hardly what a kernel hacker would do.  However,
it does work and it lets non-hackers help fix bugs.  And it is cool
because Linux snapshots will let you do this - something that you can't
do with vendor supplied releases.

Fixing the bug
==============

Nobody is going to tell you how to fix bugs. Seriously. You need to work it
out. But below are some hints on how to use the tools.

To debug a kernel, use objdump and look for the hex offset from the crash
output to find the valid line of code/assembler. Without debug symbols, you
will see the assembler code for the routine shown, but if your kernel has
debug symbols the C code will also be available. (Debug symbols can be enabled
in the kernel hacking menu of the menu configuration.) For example:

    objdump -r -S -l --disassemble net/dccp/ipv4.o

NB.: you need to be at the top level of the kernel tree for this to pick up
your C files.

If you don't have access to the code you can also debug on some crash dumps
e.g. crash dump output as shown by Dave Miller.

>    EIP is at ip_queue_xmit+0x14/0x4c0
>     ...
>    Code: 44 24 04 e8 6f 05 00 00 e9 e8 fe ff ff 8d 76 00 8d bc 27 00 00
>    00 00 55 57  56 53 81 ec bc 00 00 00 8b ac 24 d0 00 00 00 8b 5d 08
>    <8b> 83 3c 01 00 00 89 44  24 14 8b 45 28 85 c0 89 44 24 18 0f 85
>
>    Put the bytes into a "foo.s" file like this:
>
>           .text
>           .globl foo
>    foo:
>           .byte  .... /* bytes from Code: part of OOPS dump */
>
>    Compile it with "gcc -c -o foo.o foo.s" then look at the output of
>    "objdump --disassemble foo.o".
>
>    Output:
>
>    ip_queue_xmit:
>        push       %ebp
>        push       %edi
>        push       %esi
>        push       %ebx
>        sub        $0xbc, %esp
>        mov        0xd0(%esp), %ebp        ! %ebp = arg0 (skb)
>        mov        0x8(%ebp), %ebx         ! %ebx = skb->sk
>        mov        0x13c(%ebx), %eax       ! %eax = inet_sk(sk)->opt

In addition, you can use GDB to figure out the exact file and line
number of the OOPS from the vmlinux file. If you have
CONFIG_DEBUG_INFO enabled, you can simply copy the EIP value from the
OOPS:

 EIP:    0060:[<c021e50e>]    Not tainted VLI

And use GDB to translate that to human-readable form:

  gdb vmlinux
  (gdb) l *0xc021e50e

If you don't have CONFIG_DEBUG_INFO enabled, you use the function
offset from the OOPS:

 EIP is at vt_ioctl+0xda8/0x1482

And recompile the kernel with CONFIG_DEBUG_INFO enabled:

  make vmlinux
  gdb vmlinux
  (gdb) p vt_ioctl
  (gdb) l *(0x<address of vt_ioctl> + 0xda8)
or, as one command
  (gdb) l *(vt_ioctl + 0xda8)

If you have a call trace, such as :-
>Call Trace:
> [<ffffffff8802c8e9>] :jbd:log_wait_commit+0xa3/0xf5
> [<ffffffff810482d9>] autoremove_wake_function+0x0/0x2e
> [<ffffffff8802770b>] :jbd:journal_stop+0x1be/0x1ee
> ...
this shows the problem in the :jbd: module. You can load that module in gdb
and list the relevant code.
  gdb fs/jbd/jbd.ko
  (gdb) p log_wait_commit
  (gdb) l *(0x<address> + 0xa3)
or
  (gdb) l *(log_wait_commit + 0xa3)


Another very useful option of the Kernel Hacking section in menuconfig is
Debug memory allocations. This will help you see whether data has been
initialised and not set before use etc. To see the values that get assigned
with this look at mm/slab.c and search for POISON_INUSE. When using this an
Oops will often show the poisoned data instead of zero which is the default.

Once you have worked out a fix please submit it upstream. After all open
source is about sharing what you do and don't you want to be recognised for
your genius?

Please do read Documentation/SubmittingPatches though to help your code get
accepted.
[ NOTE: The virt_to_bus() and bus_to_virt() functions have been
	superseded by the functionality provided by the PCI DMA interface
	(see Documentation/PCI/PCI-DMA-mapping.txt).  They continue
	to be documented below for historical purposes, but new code
	must not use them. --davidm 00/12/12 ]

[ This is a mail message in response to a query on IO mapping, thus the
  strange format for a "document" ]

The AHA-1542 is a bus-master device, and your patch makes the driver give the
controller the physical address of the buffers, which is correct on x86
(because all bus master devices see the physical memory mappings directly). 

However, on many setups, there are actually _three_ different ways of looking
at memory addresses, and in this case we actually want the third, the
so-called "bus address". 

Essentially, the three ways of addressing memory are (this is "real memory",
that is, normal RAM--see later about other details): 

 - CPU untranslated.  This is the "physical" address.  Physical address 
   0 is what the CPU sees when it drives zeroes on the memory bus.

 - CPU translated address. This is the "virtual" address, and is 
   completely internal to the CPU itself with the CPU doing the appropriate
   translations into "CPU untranslated". 

 - bus address. This is the address of memory as seen by OTHER devices, 
   not the CPU. Now, in theory there could be many different bus 
   addresses, with each device seeing memory in some device-specific way, but
   happily most hardware designers aren't actually actively trying to make
   things any more complex than necessary, so you can assume that all 
   external hardware sees the memory the same way. 

Now, on normal PCs the bus address is exactly the same as the physical
address, and things are very simple indeed. However, they are that simple
because the memory and the devices share the same address space, and that is
not generally necessarily true on other PCI/ISA setups. 

Now, just as an example, on the PReP (PowerPC Reference Platform), the 
CPU sees a memory map something like this (this is from memory):

	0-2 GB		"real memory"
	2 GB-3 GB	"system IO" (inb/out and similar accesses on x86)
	3 GB-4 GB 	"IO memory" (shared memory over the IO bus)

Now, that looks simple enough. However, when you look at the same thing from
the viewpoint of the devices, you have the reverse, and the physical memory
address 0 actually shows up as address 2 GB for any IO master.

So when the CPU wants any bus master to write to physical memory 0, it 
has to give the master address 0x80000000 as the memory address.

So, for example, depending on how the kernel is actually mapped on the 
PPC, you can end up with a setup like this:

 physical address:	0
 virtual address:	0xC0000000
 bus address:		0x80000000

where all the addresses actually point to the same thing.  It's just seen 
through different translations..

Similarly, on the Alpha, the normal translation is

 physical address:	0
 virtual address:	0xfffffc0000000000
 bus address:		0x40000000

(but there are also Alphas where the physical address and the bus address
are the same). 

Anyway, the way to look up all these translations, you do

	#include <asm/io.h>

	phys_addr = virt_to_phys(virt_addr);
	virt_addr = phys_to_virt(phys_addr);
	 bus_addr = virt_to_bus(virt_addr);
	virt_addr = bus_to_virt(bus_addr);

Now, when do you need these?

You want the _virtual_ address when you are actually going to access that 
pointer from the kernel. So you can have something like this:

	/*
	 * this is the hardware "mailbox" we use to communicate with
	 * the controller. The controller sees this directly.
	 */
	struct mailbox {
		__u32 status;
		__u32 bufstart;
		__u32 buflen;
		..
	} mbox;

		unsigned char * retbuffer;

		/* get the address from the controller */
		retbuffer = bus_to_virt(mbox.bufstart);
		switch (retbuffer[0]) {
			case STATUS_OK:
				...

on the other hand, you want the bus address when you have a buffer that 
you want to give to the controller:

	/* ask the controller to read the sense status into "sense_buffer" */
	mbox.bufstart = virt_to_bus(&sense_buffer);
	mbox.buflen = sizeof(sense_buffer);
	mbox.status = 0;
	notify_controller(&mbox);

And you generally _never_ want to use the physical address, because you can't
use that from the CPU (the CPU only uses translated virtual addresses), and
you can't use it from the bus master. 

So why do we care about the physical address at all? We do need the physical
address in some cases, it's just not very often in normal code.  The physical
address is needed if you use memory mappings, for example, because the
"remap_pfn_range()" mm function wants the physical address of the memory to
be remapped as measured in units of pages, a.k.a. the pfn (the memory
management layer doesn't know about devices outside the CPU, so it
shouldn't need to know about "bus addresses" etc).

NOTE NOTE NOTE! The above is only one part of the whole equation. The above
only talks about "real memory", that is, CPU memory (RAM). 

There is a completely different type of memory too, and that's the "shared
memory" on the PCI or ISA bus. That's generally not RAM (although in the case
of a video graphics card it can be normal DRAM that is just used for a frame
buffer), but can be things like a packet buffer in a network card etc. 

This memory is called "PCI memory" or "shared memory" or "IO memory" or
whatever, and there is only one way to access it: the readb/writeb and
related functions. You should never take the address of such memory, because
there is really nothing you can do with such an address: it's not
conceptually in the same memory space as "real memory" at all, so you cannot
just dereference a pointer. (Sadly, on x86 it _is_ in the same memory space,
so on x86 it actually works to just deference a pointer, but it's not
portable). 

For such memory, you can do things like

 - reading:
	/*
	 * read first 32 bits from ISA memory at 0xC0000, aka
	 * C000:0000 in DOS terms
	 */
	unsigned int signature = isa_readl(0xC0000);

 - remapping and writing:
	/*
	 * remap framebuffer PCI memory area at 0xFC000000,
	 * size 1MB, so that we can access it: We can directly
	 * access only the 640k-1MB area, so anything else
	 * has to be remapped.
	 */
	void __iomem *baseptr = ioremap(0xFC000000, 1024*1024);

	/* write a 'A' to the offset 10 of the area */
	writeb('A',baseptr+10);

	/* unmap when we unload the driver */
	iounmap(baseptr);

 - copying and clearing:
	/* get the 6-byte Ethernet address at ISA address E000:0040 */
	memcpy_fromio(kernel_buffer, 0xE0040, 6);
	/* write a packet to the driver */
	memcpy_toio(0xE1000, skb->data, skb->len);
	/* clear the frame buffer */
	memset_io(0xA0000, 0, 0x10000);

OK, that just about covers the basics of accessing IO portably.  Questions?
Comments? You may think that all the above is overly complex, but one day you
might find yourself with a 500 MHz Alpha in front of you, and then you'll be
happy that your driver works ;)

Note that kernel versions 2.0.x (and earlier) mistakenly called the
ioremap() function "vremap()".  ioremap() is the proper name, but I
didn't think straight when I wrote it originally.  People who have to
support both can do something like:
 
	/* support old naming silliness */
	#if LINUX_VERSION_CODE < 0x020100                                     
	#define ioremap vremap
	#define iounmap vfree                                                     
	#endif
 
at the top of their source files, and then they can use the right names
even on 2.0.x systems. 

And the above sounds worse than it really is.  Most real drivers really
don't do all that complex things (or rather: the complexity is not so
much in the actual IO accesses as in error handling and timeouts etc). 
It's generally not hard to fix drivers, and in many cases the code
actually looks better afterwards:

	unsigned long signature = *(unsigned int *) 0xC0000;
		vs
	unsigned long signature = readl(0xC0000);

I think the second version actually is more readable, no?

		Linus

		Cache and TLB Flushing
		     Under Linux

	    David S. Miller <davem@redhat.com>

This document describes the cache/tlb flushing interfaces called
by the Linux VM subsystem.  It enumerates over each interface,
describes its intended purpose, and what side effect is expected
after the interface is invoked.

The side effects described below are stated for a uniprocessor
implementation, and what is to happen on that single processor.  The
SMP cases are a simple extension, in that you just extend the
definition such that the side effect for a particular interface occurs
on all processors in the system.  Don't let this scare you into
thinking SMP cache/tlb flushing must be so inefficient, this is in
fact an area where many optimizations are possible.  For example,
if it can be proven that a user address space has never executed
on a cpu (see mm_cpumask()), one need not perform a flush
for this address space on that cpu.

First, the TLB flushing interfaces, since they are the simplest.  The
"TLB" is abstracted under Linux as something the cpu uses to cache
virtual-->physical address translations obtained from the software
page tables.  Meaning that if the software page tables change, it is
possible for stale translations to exist in this "TLB" cache.
Therefore when software page table changes occur, the kernel will
invoke one of the following flush methods _after_ the page table
changes occur:

1) void flush_tlb_all(void)

	The most severe flush of all.  After this interface runs,
	any previous page table modification whatsoever will be
	visible to the cpu.

	This is usually invoked when the kernel page tables are
	changed, since such translations are "global" in nature.

2) void flush_tlb_mm(struct mm_struct *mm)

	This interface flushes an entire user address space from
	the TLB.  After running, this interface must make sure that
	any previous page table modifications for the address space
	'mm' will be visible to the cpu.  That is, after running,
	there will be no entries in the TLB for 'mm'.

	This interface is used to handle whole address space
	page table operations such as what happens during
	fork, and exec.

3) void flush_tlb_range(struct vm_area_struct *vma,
			unsigned long start, unsigned long end)

	Here we are flushing a specific range of (user) virtual
	address translations from the TLB.  After running, this
	interface must make sure that any previous page table
	modifications for the address space 'vma->vm_mm' in the range
	'start' to 'end-1' will be visible to the cpu.  That is, after
	running, here will be no entries in the TLB for 'mm' for
	virtual addresses in the range 'start' to 'end-1'.

	The "vma" is the backing store being used for the region.
	Primarily, this is used for munmap() type operations.

	The interface is provided in hopes that the port can find
	a suitably efficient method for removing multiple page
	sized translations from the TLB, instead of having the kernel
	call flush_tlb_page (see below) for each entry which may be
	modified.

4) void flush_tlb_page(struct vm_area_struct *vma, unsigned long addr)

	This time we need to remove the PAGE_SIZE sized translation
	from the TLB.  The 'vma' is the backing structure used by
	Linux to keep track of mmap'd regions for a process, the
	address space is available via vma->vm_mm.  Also, one may
	test (vma->vm_flags & VM_EXEC) to see if this region is
	executable (and thus could be in the 'instruction TLB' in
	split-tlb type setups).

	After running, this interface must make sure that any previous
	page table modification for address space 'vma->vm_mm' for
	user virtual address 'addr' will be visible to the cpu.  That
	is, after running, there will be no entries in the TLB for
	'vma->vm_mm' for virtual address 'addr'.

	This is used primarily during fault processing.

5) void update_mmu_cache(struct vm_area_struct *vma,
			 unsigned long address, pte_t *ptep)

	At the end of every page fault, this routine is invoked to
	tell the architecture specific code that a translation
	now exists at virtual address "address" for address space
	"vma->vm_mm", in the software page tables.

	A port may use this information in any way it so chooses.
	For example, it could use this event to pre-load TLB
	translations for software managed TLB configurations.
	The sparc64 port currently does this.

6) void tlb_migrate_finish(struct mm_struct *mm)

	This interface is called at the end of an explicit
	process migration. This interface provides a hook
	to allow a platform to update TLB or context-specific
	information for the address space.

	The ia64 sn2 platform is one example of a platform
	that uses this interface.

Next, we have the cache flushing interfaces.  In general, when Linux
is changing an existing virtual-->physical mapping to a new value,
the sequence will be in one of the following forms:

	1) flush_cache_mm(mm);
	   change_all_page_tables_of(mm);
	   flush_tlb_mm(mm);

	2) flush_cache_range(vma, start, end);
	   change_range_of_page_tables(mm, start, end);
	   flush_tlb_range(vma, start, end);

	3) flush_cache_page(vma, addr, pfn);
	   set_pte(pte_pointer, new_pte_val);
	   flush_tlb_page(vma, addr);

The cache level flush will always be first, because this allows
us to properly handle systems whose caches are strict and require
a virtual-->physical translation to exist for a virtual address
when that virtual address is flushed from the cache.  The HyperSparc
cpu is one such cpu with this attribute.

The cache flushing routines below need only deal with cache flushing
to the extent that it is necessary for a particular cpu.  Mostly,
these routines must be implemented for cpus which have virtually
indexed caches which must be flushed when virtual-->physical
translations are changed or removed.  So, for example, the physically
indexed physically tagged caches of IA32 processors have no need to
implement these interfaces since the caches are fully synchronized
and have no dependency on translation information.

Here are the routines, one by one:

1) void flush_cache_mm(struct mm_struct *mm)

	This interface flushes an entire user address space from
	the caches.  That is, after running, there will be no cache
	lines associated with 'mm'.

	This interface is used to handle whole address space
	page table operations such as what happens during exit and exec.

2) void flush_cache_dup_mm(struct mm_struct *mm)

	This interface flushes an entire user address space from
	the caches.  That is, after running, there will be no cache
	lines associated with 'mm'.

	This interface is used to handle whole address space
	page table operations such as what happens during fork.

	This option is separate from flush_cache_mm to allow some
	optimizations for VIPT caches.

3) void flush_cache_range(struct vm_area_struct *vma,
			  unsigned long start, unsigned long end)

	Here we are flushing a specific range of (user) virtual
	addresses from the cache.  After running, there will be no
	entries in the cache for 'vma->vm_mm' for virtual addresses in
	the range 'start' to 'end-1'.

	The "vma" is the backing store being used for the region.
	Primarily, this is used for munmap() type operations.

	The interface is provided in hopes that the port can find
	a suitably efficient method for removing multiple page
	sized regions from the cache, instead of having the kernel
	call flush_cache_page (see below) for each entry which may be
	modified.

4) void flush_cache_page(struct vm_area_struct *vma, unsigned long addr, unsigned long pfn)

	This time we need to remove a PAGE_SIZE sized range
	from the cache.  The 'vma' is the backing structure used by
	Linux to keep track of mmap'd regions for a process, the
	address space is available via vma->vm_mm.  Also, one may
	test (vma->vm_flags & VM_EXEC) to see if this region is
	executable (and thus could be in the 'instruction cache' in
	"Harvard" type cache layouts).

	The 'pfn' indicates the physical page frame (shift this value
	left by PAGE_SHIFT to get the physical address) that 'addr'
	translates to.  It is this mapping which should be removed from
	the cache.

	After running, there will be no entries in the cache for
	'vma->vm_mm' for virtual address 'addr' which translates
	to 'pfn'.

	This is used primarily during fault processing.

5) void flush_cache_kmaps(void)

	This routine need only be implemented if the platform utilizes
	highmem.  It will be called right before all of the kmaps
	are invalidated.

	After running, there will be no entries in the cache for
	the kernel virtual address range PKMAP_ADDR(0) to
	PKMAP_ADDR(LAST_PKMAP).

	This routing should be implemented in asm/highmem.h

6) void flush_cache_vmap(unsigned long start, unsigned long end)
   void flush_cache_vunmap(unsigned long start, unsigned long end)

	Here in these two interfaces we are flushing a specific range
	of (kernel) virtual addresses from the cache.  After running,
	there will be no entries in the cache for the kernel address
	space for virtual addresses in the range 'start' to 'end-1'.

	The first of these two routines is invoked after map_vm_area()
	has installed the page table entries.  The second is invoked
	before unmap_kernel_range() deletes the page table entries.

There exists another whole class of cpu cache issues which currently
require a whole different set of interfaces to handle properly.
The biggest problem is that of virtual aliasing in the data cache
of a processor.

Is your port susceptible to virtual aliasing in its D-cache?
Well, if your D-cache is virtually indexed, is larger in size than
PAGE_SIZE, and does not prevent multiple cache lines for the same
physical address from existing at once, you have this problem.

If your D-cache has this problem, first define asm/shmparam.h SHMLBA
properly, it should essentially be the size of your virtually
addressed D-cache (or if the size is variable, the largest possible
size).  This setting will force the SYSv IPC layer to only allow user
processes to mmap shared memory at address which are a multiple of
this value.

NOTE: This does not fix shared mmaps, check out the sparc64 port for
one way to solve this (in particular SPARC_FLAG_MMAPSHARED).

Next, you have to solve the D-cache aliasing issue for all
other cases.  Please keep in mind that fact that, for a given page
mapped into some user address space, there is always at least one more
mapping, that of the kernel in its linear mapping starting at
PAGE_OFFSET.  So immediately, once the first user maps a given
physical page into its address space, by implication the D-cache
aliasing problem has the potential to exist since the kernel already
maps this page at its virtual address.

  void copy_user_page(void *to, void *from, unsigned long addr, struct page *page)
  void clear_user_page(void *to, unsigned long addr, struct page *page)

	These two routines store data in user anonymous or COW
	pages.  It allows a port to efficiently avoid D-cache alias
	issues between userspace and the kernel.

	For example, a port may temporarily map 'from' and 'to' to
	kernel virtual addresses during the copy.  The virtual address
	for these two pages is chosen in such a way that the kernel
	load/store instructions happen to virtual addresses which are
	of the same "color" as the user mapping of the page.  Sparc64
	for example, uses this technique.

	The 'addr' parameter tells the virtual address where the
	user will ultimately have this page mapped, and the 'page'
	parameter gives a pointer to the struct page of the target.

	If D-cache aliasing is not an issue, these two routines may
	simply call memcpy/memset directly and do nothing more.

  void flush_dcache_page(struct page *page)

	Any time the kernel writes to a page cache page, _OR_
	the kernel is about to read from a page cache page and
	user space shared/writable mappings of this page potentially
	exist, this routine is called.

	NOTE: This routine need only be called for page cache pages
	      which can potentially ever be mapped into the address
	      space of a user process.  So for example, VFS layer code
	      handling vfs symlinks in the page cache need not call
	      this interface at all.

	The phrase "kernel writes to a page cache page" means,
	specifically, that the kernel executes store instructions
	that dirty data in that page at the page->virtual mapping
	of that page.  It is important to flush here to handle
	D-cache aliasing, to make sure these kernel stores are
	visible to user space mappings of that page.

	The corollary case is just as important, if there are users
	which have shared+writable mappings of this file, we must make
	sure that kernel reads of these pages will see the most recent
	stores done by the user.

	If D-cache aliasing is not an issue, this routine may
	simply be defined as a nop on that architecture.

        There is a bit set aside in page->flags (PG_arch_1) as
	"architecture private".  The kernel guarantees that,
	for pagecache pages, it will clear this bit when such
	a page first enters the pagecache.

	This allows these interfaces to be implemented much more
	efficiently.  It allows one to "defer" (perhaps indefinitely)
	the actual flush if there are currently no user processes
	mapping this page.  See sparc64's flush_dcache_page and
	update_mmu_cache implementations for an example of how to go
	about doing this.

	The idea is, first at flush_dcache_page() time, if
	page->mapping->i_mmap is an empty tree and ->i_mmap_nonlinear
	an empty list, just mark the architecture private page flag bit.
	Later, in update_mmu_cache(), a check is made of this flag bit,
	and if set the flush is done and the flag bit is cleared.

	IMPORTANT NOTE: It is often important, if you defer the flush,
			that the actual flush occurs on the same CPU
			as did the cpu stores into the page to make it
			dirty.  Again, see sparc64 for examples of how
			to deal with this.

  void copy_to_user_page(struct vm_area_struct *vma, struct page *page,
                         unsigned long user_vaddr,
                         void *dst, void *src, int len)
  void copy_from_user_page(struct vm_area_struct *vma, struct page *page,
                           unsigned long user_vaddr,
                           void *dst, void *src, int len)
	When the kernel needs to copy arbitrary data in and out
	of arbitrary user pages (f.e. for ptrace()) it will use
	these two routines.

	Any necessary cache flushing or other coherency operations
	that need to occur should happen here.  If the processor's
	instruction cache does not snoop cpu stores, it is very
	likely that you will need to flush the instruction cache
	for copy_to_user_page().

  void flush_anon_page(struct vm_area_struct *vma, struct page *page,
                       unsigned long vmaddr)
  	When the kernel needs to access the contents of an anonymous
	page, it calls this function (currently only
	get_user_pages()).  Note: flush_dcache_page() deliberately
	doesn't work for an anonymous page.  The default
	implementation is a nop (and should remain so for all coherent
	architectures).  For incoherent architectures, it should flush
	the cache of the page at vmaddr.

  void flush_kernel_dcache_page(struct page *page)
	When the kernel needs to modify a user page is has obtained
	with kmap, it calls this function after all modifications are
	complete (but before kunmapping it) to bring the underlying
	page up to date.  It is assumed here that the user has no
	incoherent cached copies (i.e. the original page was obtained
	from a mechanism like get_user_pages()).  The default
	implementation is a nop and should remain so on all coherent
	architectures.  On incoherent architectures, this should flush
	the kernel cache for page (using page_address(page)).


  void flush_icache_range(unsigned long start, unsigned long end)
  	When the kernel stores into addresses that it will execute
	out of (eg when loading modules), this function is called.

	If the icache does not snoop stores then this routine will need
	to flush it.

  void flush_icache_page(struct vm_area_struct *vma, struct page *page)
	All the functionality of flush_icache_page can be implemented in
	flush_dcache_page and update_mmu_cache. In 2.7 the hope is to
	remove this interface completely.

The final category of APIs is for I/O to deliberately aliased address
ranges inside the kernel.  Such aliases are set up by use of the
vmap/vmalloc API.  Since kernel I/O goes via physical pages, the I/O
subsystem assumes that the user mapping and kernel offset mapping are
the only aliases.  This isn't true for vmap aliases, so anything in
the kernel trying to do I/O to vmap areas must manually manage
coherency.  It must do this by flushing the vmap range before doing
I/O and invalidating it after the I/O returns.

  void flush_kernel_vmap_range(void *vaddr, int size)
       flushes the kernel cache for a given virtual address range in
       the vmap area.  This is to make sure that any data the kernel
       modified in the vmap range is made visible to the physical
       page.  The design is to make this area safe to perform I/O on.
       Note that this API does *not* also flush the offset map alias
       of the area.

  void invalidate_kernel_vmap_range(void *vaddr, int size) invalidates
       the cache for a given virtual address range in the vmap area
       which prevents the processor from making the cache stale by
       speculatively reading data while the I/O was occurring to the
       physical pages.  This is only necessary for data reads into the
       vmap area.
Intro
=====

This document is designed to provide a list of the minimum levels of
software necessary to run the 3.0 kernels.

This document is originally based on my "Changes" file for 2.0.x kernels
and therefore owes credit to the same people as that file (Jared Mauch,
Axel Boldt, Alessandro Sigala, and countless other users all over the
'net).

Current Minimal Requirements
============================

Upgrade to at *least* these software revisions before thinking you've
encountered a bug!  If you're unsure what version you're currently
running, the suggested command should tell you.

Again, keep in mind that this list assumes you are already functionally
running a Linux kernel.  Also, not all tools are necessary on all
systems; obviously, if you don't have any ISDN hardware, for example,
you probably needn't concern yourself with isdn4k-utils.

o  Gnu C                  3.2                     # gcc --version
o  Gnu make               3.80                    # make --version
o  binutils               2.12                    # ld -v
o  util-linux             2.10o                   # fdformat --version
o  module-init-tools      0.9.10                  # depmod -V
o  e2fsprogs              1.41.4                  # e2fsck -V
o  jfsutils               1.1.3                   # fsck.jfs -V
o  reiserfsprogs          3.6.3                   # reiserfsck -V
o  xfsprogs               2.6.0                   # xfs_db -V
o  squashfs-tools         4.0                     # mksquashfs -version
o  btrfs-progs            0.18                    # btrfsck
o  pcmciautils            004                     # pccardctl -V
o  quota-tools            3.09                    # quota -V
o  PPP                    2.4.0                   # pppd --version
o  isdn4k-utils           3.1pre1                 # isdnctrl 2>&1|grep version
o  nfs-utils              1.0.5                   # showmount --version
o  procps                 3.2.0                   # ps --version
o  oprofile               0.9                     # oprofiled --version
o  udev                   081                     # udevd --version
o  grub                   0.93                    # grub --version || grub-install --version
o  mcelog                 0.6                     # mcelog --version
o  iptables               1.4.2                   # iptables -V


Kernel compilation
==================

GCC
---

The gcc version requirements may vary depending on the type of CPU in your
computer.

Make
----

You will need Gnu make 3.80 or later to build the kernel.

Binutils
--------

Linux on IA-32 has recently switched from using as86 to using gas for
assembling the 16-bit boot code, removing the need for as86 to compile
your kernel.  This change does, however, mean that you need a recent
release of binutils.

Perl
----

You will need perl 5 and the following modules: Getopt::Long, Getopt::Std,
File::Basename, and File::Find to build the kernel.


System utilities
================

Architectural changes
---------------------

DevFS has been obsoleted in favour of udev
(http://www.kernel.org/pub/linux/utils/kernel/hotplug/)

32-bit UID support is now in place.  Have fun!

Linux documentation for functions is transitioning to inline
documentation via specially-formatted comments near their
definitions in the source.  These comments can be combined with the
SGML templates in the Documentation/DocBook directory to make DocBook
files, which can then be converted by DocBook stylesheets to PostScript,
HTML, PDF files, and several other formats.  In order to convert from
DocBook format to a format of your choice, you'll need to install Jade as
well as the desired DocBook stylesheets.

Util-linux
----------

New versions of util-linux provide *fdisk support for larger disks,
support new options to mount, recognize more supported partition
types, have a fdformat which works with 2.4 kernels, and similar goodies.
You'll probably want to upgrade.

Ksymoops
--------

If the unthinkable happens and your kernel oopses, you may need the
ksymoops tool to decode it, but in most cases you don't.
It is generally preferred to build the kernel with CONFIG_KALLSYMS so
that it produces readable dumps that can be used as-is (this also
produces better output than ksymoops).  If for some reason your kernel
is not build with CONFIG_KALLSYMS and you have no way to rebuild and
reproduce the Oops with that option, then you can still decode that Oops
with ksymoops.

Module-Init-Tools
-----------------

A new module loader is now in the kernel that requires module-init-tools
to use.  It is backward compatible with the 2.4.x series kernels.

Mkinitrd
--------

These changes to the /lib/modules file tree layout also require that
mkinitrd be upgraded.

E2fsprogs
---------

The latest version of e2fsprogs fixes several bugs in fsck and
debugfs.  Obviously, it's a good idea to upgrade.

JFSutils
--------

The jfsutils package contains the utilities for the file system.
The following utilities are available:
o fsck.jfs - initiate replay of the transaction log, and check
  and repair a JFS formatted partition.
o mkfs.jfs - create a JFS formatted partition.
o other file system utilities are also available in this package.

Reiserfsprogs
-------------

The reiserfsprogs package should be used for reiserfs-3.6.x
(Linux kernels 2.4.x). It is a combined package and contains working
versions of mkreiserfs, resize_reiserfs, debugreiserfs and
reiserfsck. These utils work on both i386 and alpha platforms.

Xfsprogs
--------

The latest version of xfsprogs contains mkfs.xfs, xfs_db, and the
xfs_repair utilities, among others, for the XFS filesystem.  It is
architecture independent and any version from 2.0.0 onward should
work correctly with this version of the XFS kernel code (2.6.0 or
later is recommended, due to some significant improvements).

PCMCIAutils
-----------

PCMCIAutils replaces pcmcia-cs (see below). It properly sets up
PCMCIA sockets at system startup and loads the appropriate modules
for 16-bit PCMCIA devices if the kernel is modularized and the hotplug
subsystem is used.

Pcmcia-cs
---------

PCMCIA (PC Card) support is now partially implemented in the main
kernel source. The "pcmciautils" package (see above) replaces pcmcia-cs
for newest kernels.

Quota-tools
-----------

Support for 32 bit uid's and gid's is required if you want to use
the newer version 2 quota format.  Quota-tools version 3.07 and
newer has this support.  Use the recommended version or newer
from the table above.

Intel IA32 microcode
--------------------

A driver has been added to allow updating of Intel IA32 microcode,
accessible as a normal (misc) character device.  If you are not using
udev you may need to:

mkdir /dev/cpu
mknod /dev/cpu/microcode c 10 184
chmod 0644 /dev/cpu/microcode

as root before you can use this.  You'll probably also want to
get the user-space microcode_ctl utility to use with this.

Powertweak
----------

If you are running v0.1.17 or earlier, you should upgrade to
version v0.99.0 or higher. Running old versions may cause problems
with programs using shared memory.

udev
----
udev is a userspace application for populating /dev dynamically with
only entries for devices actually present.  udev replaces the basic
functionality of devfs, while allowing persistent device naming for
devices.

FUSE
----

Needs libfuse 2.4.0 or later.  Absolute minimum is 2.3.0 but mount
options 'direct_io' and 'kernel_cache' won't work.

Networking
==========

General changes
---------------

If you have advanced network configuration needs, you should probably
consider using the network tools from ip-route2.

Packet Filter / NAT
-------------------
The packet filtering and NAT code uses the same tools like the previous 2.4.x
kernel series (iptables).  It still includes backwards-compatibility modules
for 2.2.x-style ipchains and 2.0.x-style ipfwadm.

PPP
---

The PPP driver has been restructured to support multilink and to
enable it to operate over diverse media layers.  If you use PPP,
upgrade pppd to at least 2.4.0.

If you are not using udev, you must have the device file /dev/ppp
which can be made by:

mknod /dev/ppp c 108 0

as root.

Isdn4k-utils
------------

Due to changes in the length of the phone number field, isdn4k-utils
needs to be recompiled or (preferably) upgraded.

NFS-utils
---------

In ancient (2.4 and earlier) kernels, the nfs server needed to know
about any client that expected to be able to access files via NFS.  This
information would be given to the kernel by "mountd" when the client
mounted the filesystem, or by "exportfs" at system startup.  exportfs
would take information about active clients from /var/lib/nfs/rmtab.

This approach is quite fragile as it depends on rmtab being correct
which is not always easy, particularly when trying to implement
fail-over.  Even when the system is working well, rmtab suffers from
getting lots of old entries that never get removed.

With modern kernels we have the option of having the kernel tell mountd
when it gets a request from an unknown host, and mountd can give
appropriate export information to the kernel.  This removes the
dependency on rmtab and means that the kernel only needs to know about
currently active clients.

To enable this new functionality, you need to:

  mount -t nfsd nfsd /proc/fs/nfsd

before running exportfs or mountd.  It is recommended that all NFS
services be protected from the internet-at-large by a firewall where
that is possible.

mcelog
------

In Linux 2.6.31+ the i386 kernel needs to run the mcelog utility
as a regular cronjob similar to the x86-64 kernel to process and log
machine check events when CONFIG_X86_NEW_MCE is enabled. Machine check
events are errors reported by the CPU. Processing them is strongly encouraged.
All x86-64 kernels since 2.6.4 require the mcelog utility to
process machine checks.

Getting updated software
========================

Kernel compilation
******************

gcc
---
o  <ftp://ftp.gnu.org/gnu/gcc/>

Make
----
o  <ftp://ftp.gnu.org/gnu/make/>

Binutils
--------
o  <ftp://ftp.kernel.org/pub/linux/devel/binutils/>

System utilities
****************

Util-linux
----------
o  <ftp://ftp.kernel.org/pub/linux/utils/util-linux/>

Ksymoops
--------
o  <ftp://ftp.kernel.org/pub/linux/utils/kernel/ksymoops/v2.4/>

Module-Init-Tools
-----------------
o  <ftp://ftp.kernel.org/pub/linux/kernel/people/rusty/modules/>

Mkinitrd
--------
o  <https://code.launchpad.net/initrd-tools/main>

E2fsprogs
---------
o  <http://prdownloads.sourceforge.net/e2fsprogs/e2fsprogs-1.29.tar.gz>

JFSutils
--------
o  <http://jfs.sourceforge.net/>

Reiserfsprogs
-------------
o  <http://www.kernel.org/pub/linux/utils/fs/reiserfs/>

Xfsprogs
--------
o  <ftp://oss.sgi.com/projects/xfs/>

Pcmciautils
-----------
o  <ftp://ftp.kernel.org/pub/linux/utils/kernel/pcmcia/>

Pcmcia-cs
---------
o  <http://pcmcia-cs.sourceforge.net/>

Quota-tools
----------
o  <http://sourceforge.net/projects/linuxquota/>

DocBook Stylesheets
-------------------
o  <http://nwalsh.com/docbook/dsssl/>

XMLTO XSLT Frontend
-------------------
o  <http://cyberelk.net/tim/xmlto/>

Intel P6 microcode
------------------
o  <http://www.urbanmyth.org/microcode/>

Powertweak
----------
o  <http://powertweak.sourceforge.net/>

udev
----
o <http://www.kernel.org/pub/linux/utils/kernel/hotplug/udev.html>

FUSE
----
o <http://sourceforge.net/projects/fuse>

mcelog
------
o <ftp://ftp.kernel.org/pub/linux/utils/cpu/mce/>

Networking
**********

PPP
---
o  <ftp://ftp.samba.org/pub/ppp/>

Isdn4k-utils
------------
o  <ftp://ftp.isdn4linux.de/pub/isdn4linux/utils/>

NFS-utils
---------
o  <http://sourceforge.net/project/showfiles.php?group_id=14>

Iptables
--------
o  <http://www.iptables.org/downloads.html>

Ip-route2
---------
o  <ftp://ftp.tux.org/pub/net/ip-routing/iproute2-2.2.4-now-ss991023.tar.gz>

OProfile
--------
o  <http://oprofile.sf.net/download/>

NFS-Utils
---------
o  <http://nfs.sourceforge.net/>

			       ================
			       CIRCULAR BUFFERS
			       ================

By: David Howells <dhowells@redhat.com>
    Paul E. McKenney <paulmck@linux.vnet.ibm.com>


Linux provides a number of features that can be used to implement circular
buffering.  There are two sets of such features:

 (1) Convenience functions for determining information about power-of-2 sized
     buffers.

 (2) Memory barriers for when the producer and the consumer of objects in the
     buffer don't want to share a lock.

To use these facilities, as discussed below, there needs to be just one
producer and just one consumer.  It is possible to handle multiple producers by
serialising them, and to handle multiple consumers by serialising them.


Contents:

 (*) What is a circular buffer?

 (*) Measuring power-of-2 buffers.

 (*) Using memory barriers with circular buffers.
     - The producer.
     - The consumer.


==========================
WHAT IS A CIRCULAR BUFFER?
==========================

First of all, what is a circular buffer?  A circular buffer is a buffer of
fixed, finite size into which there are two indices:

 (1) A 'head' index - the point at which the producer inserts items into the
     buffer.

 (2) A 'tail' index - the point at which the consumer finds the next item in
     the buffer.

Typically when the tail pointer is equal to the head pointer, the buffer is
empty; and the buffer is full when the head pointer is one less than the tail
pointer.

The head index is incremented when items are added, and the tail index when
items are removed.  The tail index should never jump the head index, and both
indices should be wrapped to 0 when they reach the end of the buffer, thus
allowing an infinite amount of data to flow through the buffer.

Typically, items will all be of the same unit size, but this isn't strictly
required to use the techniques below.  The indices can be increased by more
than 1 if multiple items or variable-sized items are to be included in the
buffer, provided that neither index overtakes the other.  The implementer must
be careful, however, as a region more than one unit in size may wrap the end of
the buffer and be broken into two segments.


============================
MEASURING POWER-OF-2 BUFFERS
============================

Calculation of the occupancy or the remaining capacity of an arbitrarily sized
circular buffer would normally be a slow operation, requiring the use of a
modulus (divide) instruction.  However, if the buffer is of a power-of-2 size,
then a much quicker bitwise-AND instruction can be used instead.

Linux provides a set of macros for handling power-of-2 circular buffers.  These
can be made use of by:

	#include <linux/circ_buf.h>

The macros are:

 (*) Measure the remaining capacity of a buffer:

	CIRC_SPACE(head_index, tail_index, buffer_size);

     This returns the amount of space left in the buffer[1] into which items
     can be inserted.


 (*) Measure the maximum consecutive immediate space in a buffer:

	CIRC_SPACE_TO_END(head_index, tail_index, buffer_size);

     This returns the amount of consecutive space left in the buffer[1] into
     which items can be immediately inserted without having to wrap back to the
     beginning of the buffer.


 (*) Measure the occupancy of a buffer:

	CIRC_CNT(head_index, tail_index, buffer_size);

     This returns the number of items currently occupying a buffer[2].


 (*) Measure the non-wrapping occupancy of a buffer:

	CIRC_CNT_TO_END(head_index, tail_index, buffer_size);

     This returns the number of consecutive items[2] that can be extracted from
     the buffer without having to wrap back to the beginning of the buffer.


Each of these macros will nominally return a value between 0 and buffer_size-1,
however:

 [1] CIRC_SPACE*() are intended to be used in the producer.  To the producer
     they will return a lower bound as the producer controls the head index,
     but the consumer may still be depleting the buffer on another CPU and
     moving the tail index.

     To the consumer it will show an upper bound as the producer may be busy
     depleting the space.

 [2] CIRC_CNT*() are intended to be used in the consumer.  To the consumer they
     will return a lower bound as the consumer controls the tail index, but the
     producer may still be filling the buffer on another CPU and moving the
     head index.

     To the producer it will show an upper bound as the consumer may be busy
     emptying the buffer.

 [3] To a third party, the order in which the writes to the indices by the
     producer and consumer become visible cannot be guaranteed as they are
     independent and may be made on different CPUs - so the result in such a
     situation will merely be a guess, and may even be negative.


===========================================
USING MEMORY BARRIERS WITH CIRCULAR BUFFERS
===========================================

By using memory barriers in conjunction with circular buffers, you can avoid
the need to:

 (1) use a single lock to govern access to both ends of the buffer, thus
     allowing the buffer to be filled and emptied at the same time; and

 (2) use atomic counter operations.

There are two sides to this: the producer that fills the buffer, and the
consumer that empties it.  Only one thing should be filling a buffer at any one
time, and only one thing should be emptying a buffer at any one time, but the
two sides can operate simultaneously.


THE PRODUCER
------------

The producer will look something like this:

	spin_lock(&producer_lock);

	unsigned long head = buffer->head;
	unsigned long tail = ACCESS_ONCE(buffer->tail);

	if (CIRC_SPACE(head, tail, buffer->size) >= 1) {
		/* insert one item into the buffer */
		struct item *item = buffer[head];

		produce_item(item);

		smp_wmb(); /* commit the item before incrementing the head */

		buffer->head = (head + 1) & (buffer->size - 1);

		/* wake_up() will make sure that the head is committed before
		 * waking anyone up */
		wake_up(consumer);
	}

	spin_unlock(&producer_lock);

This will instruct the CPU that the contents of the new item must be written
before the head index makes it available to the consumer and then instructs the
CPU that the revised head index must be written before the consumer is woken.

Note that wake_up() doesn't have to be the exact mechanism used, but whatever
is used must guarantee a (write) memory barrier between the update of the head
index and the change of state of the consumer, if a change of state occurs.


THE CONSUMER
------------

The consumer will look something like this:

	spin_lock(&consumer_lock);

	unsigned long head = ACCESS_ONCE(buffer->head);
	unsigned long tail = buffer->tail;

	if (CIRC_CNT(head, tail, buffer->size) >= 1) {
		/* read index before reading contents at that index */
		smp_read_barrier_depends();

		/* extract one item from the buffer */
		struct item *item = buffer[tail];

		consume_item(item);

		smp_mb(); /* finish reading descriptor before incrementing tail */

		buffer->tail = (tail + 1) & (buffer->size - 1);
	}

	spin_unlock(&consumer_lock);

This will instruct the CPU to make sure the index is up to date before reading
the new item, and then it shall make sure the CPU has finished reading the item
before it writes the new tail pointer, which will erase the item.


Note the use of ACCESS_ONCE() in both algorithms to read the opposition index.
This prevents the compiler from discarding and reloading its cached value -
which some compilers will do across smp_read_barrier_depends().  This isn't
strictly needed if you can be sure that the opposition index will _only_ be
used the once.


===============
FURTHER READING
===============

See also Documentation/memory-barriers.txt for a description of Linux's memory
barrier facilities.
Copyright 2010 Nicolas Palix <npalix@diku.dk>
Copyright 2010 Julia Lawall <julia@diku.dk>
Copyright 2010 Gilles Muller <Gilles.Muller@lip6.fr>


 Getting Coccinelle
~~~~~~~~~~~~~~~~~~~~

The semantic patches included in the kernel use the 'virtual rule'
feature which was introduced in Coccinelle version 0.1.11.

Coccinelle (>=0.2.0) is available through the package manager
of many distributions, e.g. :

 - Debian (>=squeeze)
 - Fedora (>=13)
 - Ubuntu (>=10.04 Lucid Lynx)
 - OpenSUSE
 - Arch Linux
 - NetBSD
 - FreeBSD


You can get the latest version released from the Coccinelle homepage at
http://coccinelle.lip6.fr/

Information and tips about Coccinelle are also provided on the wiki
pages at http://cocci.ekstranet.diku.dk/wiki/doku.php

Once you have it, run the following command:

     	./configure
        make

as a regular user, and install it with

        sudo make install

The semantic patches in the kernel will work best with Coccinelle version
0.2.4 or later.  Using earlier versions may incur some parse errors in the
semantic patch code, but any results that are obtained should still be
correct.

 Using Coccinelle on the Linux kernel
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A Coccinelle-specific target is defined in the top level
Makefile. This target is named 'coccicheck' and calls the 'coccicheck'
front-end in the 'scripts' directory.

Four modes are defined: patch, report, context, and org. The mode to
use is specified by setting the MODE variable with 'MODE=<mode>'.

'patch' proposes a fix, when possible.

'report' generates a list in the following format:
  file:line:column-column: message

'context' highlights lines of interest and their context in a
diff-like style.Lines of interest are indicated with '-'.

'org' generates a report in the Org mode format of Emacs.

Note that not all semantic patches implement all modes. For easy use
of Coccinelle, the default mode is "chain" which tries the previous
modes in the order above until one succeeds.

To make a report for every semantic patch, run the following command:

	make coccicheck MODE=report

NB: The 'report' mode is the default one.

To produce patches, run:

	make coccicheck MODE=patch


The coccicheck target applies every semantic patch available in the
sub-directories of 'scripts/coccinelle' to the entire Linux kernel.

For each semantic patch, a commit message is proposed.  It gives a
description of the problem being checked by the semantic patch, and
includes a reference to Coccinelle.

As any static code analyzer, Coccinelle produces false
positives. Thus, reports must be carefully checked, and patches
reviewed.


 Using Coccinelle with a single semantic patch
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The optional make variable COCCI can be used to check a single
semantic patch. In that case, the variable must be initialized with
the name of the semantic patch to apply.

For instance:

	make coccicheck COCCI=<my_SP.cocci> MODE=patch
or
	make coccicheck COCCI=<my_SP.cocci> MODE=report


 Using Coccinelle on (modified) files
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To apply Coccinelle on a file basis, instead of a directory basis, the
following command may be used:

    make C=1 CHECK="scripts/coccicheck"

To check only newly edited code, use the value 2 for the C flag, i.e.

    make C=2 CHECK="scripts/coccicheck"

This runs every semantic patch in scripts/coccinelle by default. The
COCCI variable may additionally be used to only apply a single
semantic patch as shown in the previous section.

The "chain" mode is the default. You can select another one with the
MODE variable explained above.

In this mode, there is no information about semantic patches
displayed, and no commit message proposed.


 Proposing new semantic patches
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

New semantic patches can be proposed and submitted by kernel
developers. For sake of clarity, they should be organized in the
sub-directories of 'scripts/coccinelle/'.


 Detailed description of the 'report' mode
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

'report' generates a list in the following format:
  file:line:column-column: message

Example:

Running

	make coccicheck MODE=report COCCI=scripts/coccinelle/api/err_cast.cocci

will execute the following part of the SmPL script.

<smpl>
@r depends on !context && !patch && (org || report)@
expression x;
position p;
@@

 ERR_PTR@p(PTR_ERR(x))

@script:python depends on report@
p << r.p;
x << r.x;
@@

msg="ERR_CAST can be used with %s" % (x)
coccilib.report.print_report(p[0], msg)
</smpl>

This SmPL excerpt generates entries on the standard output, as
illustrated below:

/home/user/linux/crypto/ctr.c:188:9-16: ERR_CAST can be used with alg
/home/user/linux/crypto/authenc.c:619:9-16: ERR_CAST can be used with auth
/home/user/linux/crypto/xts.c:227:9-16: ERR_CAST can be used with alg


 Detailed description of the 'patch' mode
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When the 'patch' mode is available, it proposes a fix for each problem
identified.

Example:

Running
	make coccicheck MODE=patch COCCI=scripts/coccinelle/api/err_cast.cocci

will execute the following part of the SmPL script.

<smpl>
@ depends on !context && patch && !org && !report @
expression x;
@@

- ERR_PTR(PTR_ERR(x))
+ ERR_CAST(x)
</smpl>

This SmPL excerpt generates patch hunks on the standard output, as
illustrated below:

diff -u -p a/crypto/ctr.c b/crypto/ctr.c
--- a/crypto/ctr.c 2010-05-26 10:49:38.000000000 +0200
+++ b/crypto/ctr.c 2010-06-03 23:44:49.000000000 +0200
@@ -185,7 +185,7 @@ static struct crypto_instance *crypto_ct
 	alg = crypto_attr_alg(tb[1], CRYPTO_ALG_TYPE_CIPHER,
 				  CRYPTO_ALG_TYPE_MASK);
 	if (IS_ERR(alg))
-		return ERR_PTR(PTR_ERR(alg));
+		return ERR_CAST(alg);
 
 	/* Block size must be >= 4 bytes. */
 	err = -EINVAL;

 Detailed description of the 'context' mode
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

'context' highlights lines of interest and their context
in a diff-like style.

NOTE: The diff-like output generated is NOT an applicable patch. The
      intent of the 'context' mode is to highlight the important lines
      (annotated with minus, '-') and gives some surrounding context
      lines around. This output can be used with the diff mode of
      Emacs to review the code.

Example:

Running
	make coccicheck MODE=context COCCI=scripts/coccinelle/api/err_cast.cocci

will execute the following part of the SmPL script.

<smpl>
@ depends on context && !patch && !org && !report@
expression x;
@@

* ERR_PTR(PTR_ERR(x))
</smpl>

This SmPL excerpt generates diff hunks on the standard output, as
illustrated below:

diff -u -p /home/user/linux/crypto/ctr.c /tmp/nothing
--- /home/user/linux/crypto/ctr.c	2010-05-26 10:49:38.000000000 +0200
+++ /tmp/nothing
@@ -185,7 +185,6 @@ static struct crypto_instance *crypto_ct
 	alg = crypto_attr_alg(tb[1], CRYPTO_ALG_TYPE_CIPHER,
 				  CRYPTO_ALG_TYPE_MASK);
 	if (IS_ERR(alg))
-		return ERR_PTR(PTR_ERR(alg));
 
 	/* Block size must be >= 4 bytes. */
 	err = -EINVAL;

 Detailed description of the 'org' mode
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

'org' generates a report in the Org mode format of Emacs.

Example:

Running
	make coccicheck MODE=org COCCI=scripts/coccinelle/api/err_cast.cocci

will execute the following part of the SmPL script.

<smpl>
@r depends on !context && !patch && (org || report)@
expression x;
position p;
@@

 ERR_PTR@p(PTR_ERR(x))

@script:python depends on org@
p << r.p;
x << r.x;
@@

msg="ERR_CAST can be used with %s" % (x)
msg_safe=msg.replace("[","@(").replace("]",")")
coccilib.org.print_todo(p[0], msg_safe)
</smpl>

This SmPL excerpt generates Org entries on the standard output, as
illustrated below:

* TODO [[view:/home/user/linux/crypto/ctr.c::face=ovl-face1::linb=188::colb=9::cole=16][ERR_CAST can be used with alg]]
* TODO [[view:/home/user/linux/crypto/authenc.c::face=ovl-face1::linb=619::colb=9::cole=16][ERR_CAST can be used with auth]]
* TODO [[view:/home/user/linux/crypto/xts.c::face=ovl-face1::linb=227::colb=9::cole=16][ERR_CAST can be used with alg]]

		Linux kernel coding style

This is a short document describing the preferred coding style for the
linux kernel.  Coding style is very personal, and I won't _force_ my
views on anybody, but this is what goes for anything that I have to be
able to maintain, and I'd prefer it for most other things too.  Please
at least consider the points made here.

First off, I'd suggest printing out a copy of the GNU coding standards,
and NOT read it.  Burn them, it's a great symbolic gesture.

Anyway, here goes:


	 	Chapter 1: Indentation

Tabs are 8 characters, and thus indentations are also 8 characters.
There are heretic movements that try to make indentations 4 (or even 2!)
characters deep, and that is akin to trying to define the value of PI to
be 3.

Rationale: The whole idea behind indentation is to clearly define where
a block of control starts and ends.  Especially when you've been looking
at your screen for 20 straight hours, you'll find it a lot easier to see
how the indentation works if you have large indentations.

Now, some people will claim that having 8-character indentations makes
the code move too far to the right, and makes it hard to read on a
80-character terminal screen.  The answer to that is that if you need
more than 3 levels of indentation, you're screwed anyway, and should fix
your program.

In short, 8-char indents make things easier to read, and have the added
benefit of warning you when you're nesting your functions too deep.
Heed that warning.

The preferred way to ease multiple indentation levels in a switch statement is
to align the "switch" and its subordinate "case" labels in the same column
instead of "double-indenting" the "case" labels.  E.g.:

	switch (suffix) {
	case 'G':
	case 'g':
		mem <<= 30;
		break;
	case 'M':
	case 'm':
		mem <<= 20;
		break;
	case 'K':
	case 'k':
		mem <<= 10;
		/* fall through */
	default:
		break;
	}


Don't put multiple statements on a single line unless you have
something to hide:

	if (condition) do_this;
	  do_something_everytime;

Don't put multiple assignments on a single line either.  Kernel coding style
is super simple.  Avoid tricky expressions.

Outside of comments, documentation and except in Kconfig, spaces are never
used for indentation, and the above example is deliberately broken.

Get a decent editor and don't leave whitespace at the end of lines.


		Chapter 2: Breaking long lines and strings

Coding style is all about readability and maintainability using commonly
available tools.

The limit on the length of lines is 80 columns and this is a strongly
preferred limit.

Statements longer than 80 columns will be broken into sensible chunks.
Descendants are always substantially shorter than the parent and are placed
substantially to the right. The same applies to function headers with a long
argument list. Long strings are as well broken into shorter strings. The
only exception to this is where exceeding 80 columns significantly increases
readability and does not hide information.

void fun(int a, int b, int c)
{
	if (condition)
		printk(KERN_WARNING "Warning this is a long printk with "
						"3 parameters a: %u b: %u "
						"c: %u \n", a, b, c);
	else
		next_statement;
}

		Chapter 3: Placing Braces and Spaces

The other issue that always comes up in C styling is the placement of
braces.  Unlike the indent size, there are few technical reasons to
choose one placement strategy over the other, but the preferred way, as
shown to us by the prophets Kernighan and Ritchie, is to put the opening
brace last on the line, and put the closing brace first, thusly:

	if (x is true) {
		we do y
	}

This applies to all non-function statement blocks (if, switch, for,
while, do).  E.g.:

	switch (action) {
	case KOBJ_ADD:
		return "add";
	case KOBJ_REMOVE:
		return "remove";
	case KOBJ_CHANGE:
		return "change";
	default:
		return NULL;
	}

However, there is one special case, namely functions: they have the
opening brace at the beginning of the next line, thus:

	int function(int x)
	{
		body of function
	}

Heretic people all over the world have claimed that this inconsistency
is ...  well ...  inconsistent, but all right-thinking people know that
(a) K&R are _right_ and (b) K&R are right.  Besides, functions are
special anyway (you can't nest them in C).

Note that the closing brace is empty on a line of its own, _except_ in
the cases where it is followed by a continuation of the same statement,
ie a "while" in a do-statement or an "else" in an if-statement, like
this:

	do {
		body of do-loop
	} while (condition);

and

	if (x == y) {
		..
	} else if (x > y) {
		...
	} else {
		....
	}

Rationale: K&R.

Also, note that this brace-placement also minimizes the number of empty
(or almost empty) lines, without any loss of readability.  Thus, as the
supply of new-lines on your screen is not a renewable resource (think
25-line terminal screens here), you have more empty lines to put
comments on.

Do not unnecessarily use braces where a single statement will do.

if (condition)
	action();

and

if (condition)
	do_this();
else
	do_that();

This does not apply if one branch of a conditional statement is a single
statement. Use braces in both branches.

if (condition) {
	do_this();
	do_that();
} else {
	otherwise();
}

		3.1:  Spaces

Linux kernel style for use of spaces depends (mostly) on
function-versus-keyword usage.  Use a space after (most) keywords.  The
notable exceptions are sizeof, typeof, alignof, and __attribute__, which look
somewhat like functions (and are usually used with parentheses in Linux,
although they are not required in the language, as in: "sizeof info" after
"struct fileinfo info;" is declared).

So use a space after these keywords:
	if, switch, case, for, do, while
but not with sizeof, typeof, alignof, or __attribute__.  E.g.,
	s = sizeof(struct file);

Do not add spaces around (inside) parenthesized expressions.  This example is
*bad*:

	s = sizeof( struct file );

When declaring pointer data or a function that returns a pointer type, the
preferred use of '*' is adjacent to the data name or function name and not
adjacent to the type name.  Examples:

	char *linux_banner;
	unsigned long long memparse(char *ptr, char **retptr);
	char *match_strdup(substring_t *s);

Use one space around (on each side of) most binary and ternary operators,
such as any of these:

	=  +  -  <  >  *  /  %  |  &  ^  <=  >=  ==  !=  ?  :

but no space after unary operators:
	&  *  +  -  ~  !  sizeof  typeof  alignof  __attribute__  defined

no space before the postfix increment & decrement unary operators:
	++  --

no space after the prefix increment & decrement unary operators:
	++  --

and no space around the '.' and "->" structure member operators.

Do not leave trailing whitespace at the ends of lines.  Some editors with
"smart" indentation will insert whitespace at the beginning of new lines as
appropriate, so you can start typing the next line of code right away.
However, some such editors do not remove the whitespace if you end up not
putting a line of code there, such as if you leave a blank line.  As a result,
you end up with lines containing trailing whitespace.

Git will warn you about patches that introduce trailing whitespace, and can
optionally strip the trailing whitespace for you; however, if applying a series
of patches, this may make later patches in the series fail by changing their
context lines.


		Chapter 4: Naming

C is a Spartan language, and so should your naming be.  Unlike Modula-2
and Pascal programmers, C programmers do not use cute names like
ThisVariableIsATemporaryCounter.  A C programmer would call that
variable "tmp", which is much easier to write, and not the least more
difficult to understand.

HOWEVER, while mixed-case names are frowned upon, descriptive names for
global variables are a must.  To call a global function "foo" is a
shooting offense.

GLOBAL variables (to be used only if you _really_ need them) need to
have descriptive names, as do global functions.  If you have a function
that counts the number of active users, you should call that
"count_active_users()" or similar, you should _not_ call it "cntusr()".

Encoding the type of a function into the name (so-called Hungarian
notation) is brain damaged - the compiler knows the types anyway and can
check those, and it only confuses the programmer.  No wonder MicroSoft
makes buggy programs.

LOCAL variable names should be short, and to the point.  If you have
some random integer loop counter, it should probably be called "i".
Calling it "loop_counter" is non-productive, if there is no chance of it
being mis-understood.  Similarly, "tmp" can be just about any type of
variable that is used to hold a temporary value.

If you are afraid to mix up your local variable names, you have another
problem, which is called the function-growth-hormone-imbalance syndrome.
See chapter 6 (Functions).


		Chapter 5: Typedefs

Please don't use things like "vps_t".

It's a _mistake_ to use typedef for structures and pointers. When you see a

	vps_t a;

in the source, what does it mean?

In contrast, if it says

	struct virtual_container *a;

you can actually tell what "a" is.

Lots of people think that typedefs "help readability". Not so. They are
useful only for:

 (a) totally opaque objects (where the typedef is actively used to _hide_
     what the object is).

     Example: "pte_t" etc. opaque objects that you can only access using
     the proper accessor functions.

     NOTE! Opaqueness and "accessor functions" are not good in themselves.
     The reason we have them for things like pte_t etc. is that there
     really is absolutely _zero_ portably accessible information there.

 (b) Clear integer types, where the abstraction _helps_ avoid confusion
     whether it is "int" or "long".

     u8/u16/u32 are perfectly fine typedefs, although they fit into
     category (d) better than here.

     NOTE! Again - there needs to be a _reason_ for this. If something is
     "unsigned long", then there's no reason to do

	typedef unsigned long myflags_t;

     but if there is a clear reason for why it under certain circumstances
     might be an "unsigned int" and under other configurations might be
     "unsigned long", then by all means go ahead and use a typedef.

 (c) when you use sparse to literally create a _new_ type for
     type-checking.

 (d) New types which are identical to standard C99 types, in certain
     exceptional circumstances.

     Although it would only take a short amount of time for the eyes and
     brain to become accustomed to the standard types like 'uint32_t',
     some people object to their use anyway.

     Therefore, the Linux-specific 'u8/u16/u32/u64' types and their
     signed equivalents which are identical to standard types are
     permitted -- although they are not mandatory in new code of your
     own.

     When editing existing code which already uses one or the other set
     of types, you should conform to the existing choices in that code.

 (e) Types safe for use in userspace.

     In certain structures which are visible to userspace, we cannot
     require C99 types and cannot use the 'u32' form above. Thus, we
     use __u32 and similar types in all structures which are shared
     with userspace.

Maybe there are other cases too, but the rule should basically be to NEVER
EVER use a typedef unless you can clearly match one of those rules.

In general, a pointer, or a struct that has elements that can reasonably
be directly accessed should _never_ be a typedef.


		Chapter 6: Functions

Functions should be short and sweet, and do just one thing.  They should
fit on one or two screenfuls of text (the ISO/ANSI screen size is 80x24,
as we all know), and do one thing and do that well.

The maximum length of a function is inversely proportional to the
complexity and indentation level of that function.  So, if you have a
conceptually simple function that is just one long (but simple)
case-statement, where you have to do lots of small things for a lot of
different cases, it's OK to have a longer function.

However, if you have a complex function, and you suspect that a
less-than-gifted first-year high-school student might not even
understand what the function is all about, you should adhere to the
maximum limits all the more closely.  Use helper functions with
descriptive names (you can ask the compiler to in-line them if you think
it's performance-critical, and it will probably do a better job of it
than you would have done).

Another measure of the function is the number of local variables.  They
shouldn't exceed 5-10, or you're doing something wrong.  Re-think the
function, and split it into smaller pieces.  A human brain can
generally easily keep track of about 7 different things, anything more
and it gets confused.  You know you're brilliant, but maybe you'd like
to understand what you did 2 weeks from now.

In source files, separate functions with one blank line.  If the function is
exported, the EXPORT* macro for it should follow immediately after the closing
function brace line.  E.g.:

int system_is_up(void)
{
	return system_state == SYSTEM_RUNNING;
}
EXPORT_SYMBOL(system_is_up);

In function prototypes, include parameter names with their data types.
Although this is not required by the C language, it is preferred in Linux
because it is a simple way to add valuable information for the reader.


		Chapter 7: Centralized exiting of functions

Albeit deprecated by some people, the equivalent of the goto statement is
used frequently by compilers in form of the unconditional jump instruction.

The goto statement comes in handy when a function exits from multiple
locations and some common work such as cleanup has to be done.

The rationale is:

- unconditional statements are easier to understand and follow
- nesting is reduced
- errors by not updating individual exit points when making
    modifications are prevented
- saves the compiler work to optimize redundant code away ;)

int fun(int a)
{
	int result = 0;
	char *buffer = kmalloc(SIZE);

	if (buffer == NULL)
		return -ENOMEM;

	if (condition1) {
		while (loop1) {
			...
		}
		result = 1;
		goto out;
	}
	...
out:
	kfree(buffer);
	return result;
}

		Chapter 8: Commenting

Comments are good, but there is also a danger of over-commenting.  NEVER
try to explain HOW your code works in a comment: it's much better to
write the code so that the _working_ is obvious, and it's a waste of
time to explain badly written code.

Generally, you want your comments to tell WHAT your code does, not HOW.
Also, try to avoid putting comments inside a function body: if the
function is so complex that you need to separately comment parts of it,
you should probably go back to chapter 6 for a while.  You can make
small comments to note or warn about something particularly clever (or
ugly), but try to avoid excess.  Instead, put the comments at the head
of the function, telling people what it does, and possibly WHY it does
it.

When commenting the kernel API functions, please use the kernel-doc format.
See the files Documentation/kernel-doc-nano-HOWTO.txt and scripts/kernel-doc
for details.

Linux style for comments is the C89 "/* ... */" style.
Don't use C99-style "// ..." comments.

The preferred style for long (multi-line) comments is:

	/*
	 * This is the preferred style for multi-line
	 * comments in the Linux kernel source code.
	 * Please use it consistently.
	 *
	 * Description:  A column of asterisks on the left side,
	 * with beginning and ending almost-blank lines.
	 */

It's also important to comment data, whether they are basic types or derived
types.  To this end, use just one data declaration per line (no commas for
multiple data declarations).  This leaves you room for a small comment on each
item, explaining its use.


		Chapter 9: You've made a mess of it

That's OK, we all do.  You've probably been told by your long-time Unix
user helper that "GNU emacs" automatically formats the C sources for
you, and you've noticed that yes, it does do that, but the defaults it
uses are less than desirable (in fact, they are worse than random
typing - an infinite number of monkeys typing into GNU emacs would never
make a good program).

So, you can either get rid of GNU emacs, or change it to use saner
values.  To do the latter, you can stick the following in your .emacs file:

(defun c-lineup-arglist-tabs-only (ignored)
  "Line up argument lists by tabs, not spaces"
  (let* ((anchor (c-langelem-pos c-syntactic-element))
	 (column (c-langelem-2nd-pos c-syntactic-element))
	 (offset (- (1+ column) anchor))
	 (steps (floor offset c-basic-offset)))
    (* (max steps 1)
       c-basic-offset)))

(add-hook 'c-mode-common-hook
          (lambda ()
            ;; Add kernel style
            (c-add-style
             "linux-tabs-only"
             '("linux" (c-offsets-alist
                        (arglist-cont-nonempty
                         c-lineup-gcc-asm-reg
                         c-lineup-arglist-tabs-only))))))

(add-hook 'c-mode-hook
          (lambda ()
            (let ((filename (buffer-file-name)))
              ;; Enable kernel mode for the appropriate files
              (when (and filename
                         (string-match (expand-file-name "~/src/linux-trees")
                                       filename))
                (setq indent-tabs-mode t)
                (c-set-style "linux-tabs-only")))))

This will make emacs go better with the kernel coding style for C
files below ~/src/linux-trees.

But even if you fail in getting emacs to do sane formatting, not
everything is lost: use "indent".

Now, again, GNU indent has the same brain-dead settings that GNU emacs
has, which is why you need to give it a few command line options.
However, that's not too bad, because even the makers of GNU indent
recognize the authority of K&R (the GNU people aren't evil, they are
just severely misguided in this matter), so you just give indent the
options "-kr -i8" (stands for "K&R, 8 character indents"), or use
"scripts/Lindent", which indents in the latest style.

"indent" has a lot of options, and especially when it comes to comment
re-formatting you may want to take a look at the man page.  But
remember: "indent" is not a fix for bad programming.


		Chapter 10: Kconfig configuration files

For all of the Kconfig* configuration files throughout the source tree,
the indentation is somewhat different.  Lines under a "config" definition
are indented with one tab, while help text is indented an additional two
spaces.  Example:

config AUDIT
	bool "Auditing support"
	depends on NET
	help
	  Enable auditing infrastructure that can be used with another
	  kernel subsystem, such as SELinux (which requires this for
	  logging of avc messages output).  Does not do system-call
	  auditing without CONFIG_AUDITSYSCALL.

Features that might still be considered unstable should be defined as
dependent on "EXPERIMENTAL":

config SLUB
	depends on EXPERIMENTAL && !ARCH_USES_SLAB_PAGE_STRUCT
	bool "SLUB (Unqueued Allocator)"
	...

while seriously dangerous features (such as write support for certain
filesystems) should advertise this prominently in their prompt string:

config ADFS_FS_RW
	bool "ADFS write support (DANGEROUS)"
	depends on ADFS_FS
	...

For full documentation on the configuration files, see the file
Documentation/kbuild/kconfig-language.txt.


		Chapter 11: Data structures

Data structures that have visibility outside the single-threaded
environment they are created and destroyed in should always have
reference counts.  In the kernel, garbage collection doesn't exist (and
outside the kernel garbage collection is slow and inefficient), which
means that you absolutely _have_ to reference count all your uses.

Reference counting means that you can avoid locking, and allows multiple
users to have access to the data structure in parallel - and not having
to worry about the structure suddenly going away from under them just
because they slept or did something else for a while.

Note that locking is _not_ a replacement for reference counting.
Locking is used to keep data structures coherent, while reference
counting is a memory management technique.  Usually both are needed, and
they are not to be confused with each other.

Many data structures can indeed have two levels of reference counting,
when there are users of different "classes".  The subclass count counts
the number of subclass users, and decrements the global count just once
when the subclass count goes to zero.

Examples of this kind of "multi-level-reference-counting" can be found in
memory management ("struct mm_struct": mm_users and mm_count), and in
filesystem code ("struct super_block": s_count and s_active).

Remember: if another thread can find your data structure, and you don't
have a reference count on it, you almost certainly have a bug.


		Chapter 12: Macros, Enums and RTL

Names of macros defining constants and labels in enums are capitalized.

#define CONSTANT 0x12345

Enums are preferred when defining several related constants.

CAPITALIZED macro names are appreciated but macros resembling functions
may be named in lower case.

Generally, inline functions are preferable to macros resembling functions.

Macros with multiple statements should be enclosed in a do - while block:

#define macrofun(a, b, c) 			\
	do {					\
		if (a == 5)			\
			do_this(b, c);		\
	} while (0)

Things to avoid when using macros:

1) macros that affect control flow:

#define FOO(x)					\
	do {					\
		if (blah(x) < 0)		\
			return -EBUGGERED;	\
	} while(0)

is a _very_ bad idea.  It looks like a function call but exits the "calling"
function; don't break the internal parsers of those who will read the code.

2) macros that depend on having a local variable with a magic name:

#define FOO(val) bar(index, val)

might look like a good thing, but it's confusing as hell when one reads the
code and it's prone to breakage from seemingly innocent changes.

3) macros with arguments that are used as l-values: FOO(x) = y; will
bite you if somebody e.g. turns FOO into an inline function.

4) forgetting about precedence: macros defining constants using expressions
must enclose the expression in parentheses. Beware of similar issues with
macros using parameters.

#define CONSTANT 0x4000
#define CONSTEXP (CONSTANT | 3)

The cpp manual deals with macros exhaustively. The gcc internals manual also
covers RTL which is used frequently with assembly language in the kernel.


		Chapter 13: Printing kernel messages

Kernel developers like to be seen as literate. Do mind the spelling
of kernel messages to make a good impression. Do not use crippled
words like "dont"; use "do not" or "don't" instead.  Make the messages
concise, clear, and unambiguous.

Kernel messages do not have to be terminated with a period.

Printing numbers in parentheses (%d) adds no value and should be avoided.

There are a number of driver model diagnostic macros in <linux/device.h>
which you should use to make sure messages are matched to the right device
and driver, and are tagged with the right level:  dev_err(), dev_warn(),
dev_info(), and so forth.  For messages that aren't associated with a
particular device, <linux/printk.h> defines pr_debug() and pr_info().

Coming up with good debugging messages can be quite a challenge; and once
you have them, they can be a huge help for remote troubleshooting.  Such
messages should be compiled out when the DEBUG symbol is not defined (that
is, by default they are not included).  When you use dev_dbg() or pr_debug(),
that's automatic.  Many subsystems have Kconfig options to turn on -DDEBUG.
A related convention uses VERBOSE_DEBUG to add dev_vdbg() messages to the
ones already enabled by DEBUG.


		Chapter 14: Allocating memory

The kernel provides the following general purpose memory allocators:
kmalloc(), kzalloc(), kcalloc(), vmalloc(), and vzalloc().  Please refer to
the API documentation for further information about them.

The preferred form for passing a size of a struct is the following:

	p = kmalloc(sizeof(*p), ...);

The alternative form where struct name is spelled out hurts readability and
introduces an opportunity for a bug when the pointer variable type is changed
but the corresponding sizeof that is passed to a memory allocator is not.

Casting the return value which is a void pointer is redundant. The conversion
from void pointer to any other pointer type is guaranteed by the C programming
language.


		Chapter 15: The inline disease

There appears to be a common misperception that gcc has a magic "make me
faster" speedup option called "inline". While the use of inlines can be
appropriate (for example as a means of replacing macros, see Chapter 12), it
very often is not. Abundant use of the inline keyword leads to a much bigger
kernel, which in turn slows the system as a whole down, due to a bigger
icache footprint for the CPU and simply because there is less memory
available for the pagecache. Just think about it; a pagecache miss causes a
disk seek, which easily takes 5 milliseconds. There are a LOT of cpu cycles
that can go into these 5 milliseconds.

A reasonable rule of thumb is to not put inline at functions that have more
than 3 lines of code in them. An exception to this rule are the cases where
a parameter is known to be a compiletime constant, and as a result of this
constantness you *know* the compiler will be able to optimize most of your
function away at compile time. For a good example of this later case, see
the kmalloc() inline function.

Often people argue that adding inline to functions that are static and used
only once is always a win since there is no space tradeoff. While this is
technically correct, gcc is capable of inlining these automatically without
help, and the maintenance issue of removing the inline when a second user
appears outweighs the potential value of the hint that tells gcc to do
something it would have done anyway.


		Chapter 16: Function return values and names

Functions can return values of many different kinds, and one of the
most common is a value indicating whether the function succeeded or
failed.  Such a value can be represented as an error-code integer
(-Exxx = failure, 0 = success) or a "succeeded" boolean (0 = failure,
non-zero = success).

Mixing up these two sorts of representations is a fertile source of
difficult-to-find bugs.  If the C language included a strong distinction
between integers and booleans then the compiler would find these mistakes
for us... but it doesn't.  To help prevent such bugs, always follow this
convention:

	If the name of a function is an action or an imperative command,
	the function should return an error-code integer.  If the name
	is a predicate, the function should return a "succeeded" boolean.

For example, "add work" is a command, and the add_work() function returns 0
for success or -EBUSY for failure.  In the same way, "PCI device present" is
a predicate, and the pci_dev_present() function returns 1 if it succeeds in
finding a matching device or 0 if it doesn't.

All EXPORTed functions must respect this convention, and so should all
public functions.  Private (static) functions need not, but it is
recommended that they do.

Functions whose return value is the actual result of a computation, rather
than an indication of whether the computation succeeded, are not subject to
this rule.  Generally they indicate failure by returning some out-of-range
result.  Typical examples would be functions that return pointers; they use
NULL or the ERR_PTR mechanism to report failure.


		Chapter 17:  Don't re-invent the kernel macros

The header file include/linux/kernel.h contains a number of macros that
you should use, rather than explicitly coding some variant of them yourself.
For example, if you need to calculate the length of an array, take advantage
of the macro

  #define ARRAY_SIZE(x) (sizeof(x) / sizeof((x)[0]))

Similarly, if you need to calculate the size of some structure member, use

  #define FIELD_SIZEOF(t, f) (sizeof(((t*)0)->f))

There are also min() and max() macros that do strict type checking if you
need them.  Feel free to peruse that header file to see what else is already
defined that you shouldn't reproduce in your code.


		Chapter 18:  Editor modelines and other cruft

Some editors can interpret configuration information embedded in source files,
indicated with special markers.  For example, emacs interprets lines marked
like this:

-*- mode: c -*-

Or like this:

/*
Local Variables:
compile-command: "gcc -DMAGIC_DEBUG_FLAG foo.c"
End:
*/

Vim interprets markers that look like this:

/* vim:set sw=8 noet */

Do not include any of these in source files.  People have their own personal
editor configurations, and your source files should not override them.  This
includes markers for indentation and mode configuration.  People may use their
own custom mode, or may have some other magic method for making indentation
work correctly.



		Appendix I: References

The C Programming Language, Second Edition
by Brian W. Kernighan and Dennis M. Ritchie.
Prentice Hall, Inc., 1988.
ISBN 0-13-110362-8 (paperback), 0-13-110370-9 (hardback).
URL: http://cm.bell-labs.com/cm/cs/cbook/

The Practice of Programming
by Brian W. Kernighan and Rob Pike.
Addison-Wesley, Inc., 1999.
ISBN 0-201-61586-X.
URL: http://cm.bell-labs.com/cm/cs/tpop/

GNU manuals - where in compliance with K&R and this text - for cpp, gcc,
gcc internals and indent, all available from http://www.gnu.org/manual/

WG14 is the international standardization working group for the programming
language C, URL: http://www.open-std.org/JTC1/SC22/WG14/

Kernel CodingStyle, by greg@kroah.com at OLS 2002:
http://www.kroah.com/linux/talks/ols_2002_kernel_codingstyle_talk/html/

		CPU hotplug Support in Linux(tm) Kernel

		Maintainers:
		CPU Hotplug Core:
			Rusty Russell <rusty@rustcorp.com.au>
			Srivatsa Vaddagiri <vatsa@in.ibm.com>
		i386:
			Zwane Mwaikambo <zwane@arm.linux.org.uk>
		ppc64:
			Nathan Lynch <nathanl@austin.ibm.com>
			Joel Schopp <jschopp@austin.ibm.com>
		ia64/x86_64:
			Ashok Raj <ashok.raj@intel.com>
		s390:
			Heiko Carstens <heiko.carstens@de.ibm.com>

Authors: Ashok Raj <ashok.raj@intel.com>
Lots of feedback: Nathan Lynch <nathanl@austin.ibm.com>,
	     Joel Schopp <jschopp@austin.ibm.com>

Introduction

Modern advances in system architectures have introduced advanced error
reporting and correction capabilities in processors. CPU architectures permit
partitioning support, where compute resources of a single CPU could be made
available to virtual machine environments. There are couple OEMS that
support NUMA hardware which are hot pluggable as well, where physical
node insertion and removal require support for CPU hotplug.

Such advances require CPUs available to a kernel to be removed either for
provisioning reasons, or for RAS purposes to keep an offending CPU off
system execution path. Hence the need for CPU hotplug support in the
Linux kernel.

A more novel use of CPU-hotplug support is its use today in suspend
resume support for SMP. Dual-core and HT support makes even
a laptop run SMP kernels which didn't support these methods. SMP support
for suspend/resume is a work in progress.

General Stuff about CPU Hotplug
--------------------------------

Command Line Switches
---------------------
maxcpus=n    Restrict boot time cpus to n. Say if you have 4 cpus, using
             maxcpus=2 will only boot 2. You can choose to bring the
             other cpus later online, read FAQ's for more info.

additional_cpus=n (*)	Use this to limit hotpluggable cpus. This option sets
  			cpu_possible_map = cpu_present_map + additional_cpus

cede_offline={"off","on"}  Use this option to disable/enable putting offlined
		            processors to an extended H_CEDE state on
			    supported pseries platforms.
			    If nothing is specified,
			    cede_offline is set to "on".

(*) Option valid only for following architectures
- ia64

ia64 uses the number of disabled local apics in ACPI tables MADT to
determine the number of potentially hot-pluggable cpus. The implementation
should only rely on this to count the # of cpus, but *MUST* not rely
on the apicid values in those tables for disabled apics. In the event
BIOS doesn't mark such hot-pluggable cpus as disabled entries, one could
use this parameter "additional_cpus=x" to represent those cpus in the
cpu_possible_map.

possible_cpus=n		[s390,x86_64] use this to set hotpluggable cpus.
			This option sets possible_cpus bits in
			cpu_possible_map. Thus keeping the numbers of bits set
			constant even if the machine gets rebooted.

CPU maps and such
-----------------
[More on cpumaps and primitive to manipulate, please check
include/linux/cpumask.h that has more descriptive text.]

cpu_possible_map: Bitmap of possible CPUs that can ever be available in the
system. This is used to allocate some boot time memory for per_cpu variables
that aren't designed to grow/shrink as CPUs are made available or removed.
Once set during boot time discovery phase, the map is static, i.e no bits
are added or removed anytime.  Trimming it accurately for your system needs
upfront can save some boot time memory. See below for how we use heuristics
in x86_64 case to keep this under check.

cpu_online_map: Bitmap of all CPUs currently online. Its set in __cpu_up()
after a cpu is available for kernel scheduling and ready to receive
interrupts from devices. Its cleared when a cpu is brought down using
__cpu_disable(), before which all OS services including interrupts are
migrated to another target CPU.

cpu_present_map: Bitmap of CPUs currently present in the system. Not all
of them may be online. When physical hotplug is processed by the relevant
subsystem (e.g ACPI) can change and new bit either be added or removed
from the map depending on the event is hot-add/hot-remove. There are currently
no locking rules as of now. Typical usage is to init topology during boot,
at which time hotplug is disabled.

You really dont need to manipulate any of the system cpu maps. They should
be read-only for most use. When setting up per-cpu resources almost always use
cpu_possible_map/for_each_possible_cpu() to iterate.

Never use anything other than cpumask_t to represent bitmap of CPUs.

	#include <linux/cpumask.h>

	for_each_possible_cpu     - Iterate over cpu_possible_map
	for_each_online_cpu       - Iterate over cpu_online_map
	for_each_present_cpu      - Iterate over cpu_present_map
	for_each_cpu_mask(x,mask) - Iterate over some random collection of cpu mask.

	#include <linux/cpu.h>
	get_online_cpus() and put_online_cpus():

The above calls are used to inhibit cpu hotplug operations. While the
cpu_hotplug.refcount is non zero, the cpu_online_map will not change.
If you merely need to avoid cpus going away, you could also use
preempt_disable() and preempt_enable() for those sections.
Just remember the critical section cannot call any
function that can sleep or schedule this process away. The preempt_disable()
will work as long as stop_machine_run() is used to take a cpu down.

CPU Hotplug - Frequently Asked Questions.

Q: How to enable my kernel to support CPU hotplug?
A: When doing make defconfig, Enable CPU hotplug support

   "Processor type and Features" -> Support for Hotpluggable CPUs

Make sure that you have CONFIG_HOTPLUG, and CONFIG_SMP turned on as well.

You would need to enable CONFIG_HOTPLUG_CPU for SMP suspend/resume support
as well.

Q: What architectures support CPU hotplug?
A: As of 2.6.14, the following architectures support CPU hotplug.

i386 (Intel), ppc, ppc64, parisc, s390, ia64 and x86_64

Q: How to test if hotplug is supported on the newly built kernel?
A: You should now notice an entry in sysfs.

Check if sysfs is mounted, using the "mount" command. You should notice
an entry as shown below in the output.

	....
	none on /sys type sysfs (rw)
	....

If this is not mounted, do the following.

	 #mkdir /sysfs
	#mount -t sysfs sys /sys

Now you should see entries for all present cpu, the following is an example
in a 8-way system.

	#pwd
	#/sys/devices/system/cpu
	#ls -l
	total 0
	drwxr-xr-x  10 root root 0 Sep 19 07:44 .
	drwxr-xr-x  13 root root 0 Sep 19 07:45 ..
	drwxr-xr-x   3 root root 0 Sep 19 07:44 cpu0
	drwxr-xr-x   3 root root 0 Sep 19 07:44 cpu1
	drwxr-xr-x   3 root root 0 Sep 19 07:44 cpu2
	drwxr-xr-x   3 root root 0 Sep 19 07:44 cpu3
	drwxr-xr-x   3 root root 0 Sep 19 07:44 cpu4
	drwxr-xr-x   3 root root 0 Sep 19 07:44 cpu5
	drwxr-xr-x   3 root root 0 Sep 19 07:44 cpu6
	drwxr-xr-x   3 root root 0 Sep 19 07:48 cpu7

Under each directory you would find an "online" file which is the control
file to logically online/offline a processor.

Q: Does hot-add/hot-remove refer to physical add/remove of cpus?
A: The usage of hot-add/remove may not be very consistently used in the code.
CONFIG_HOTPLUG_CPU enables logical online/offline capability in the kernel.
To support physical addition/removal, one would need some BIOS hooks and
the platform should have something like an attention button in PCI hotplug.
CONFIG_ACPI_HOTPLUG_CPU enables ACPI support for physical add/remove of CPUs.

Q: How do i logically offline a CPU?
A: Do the following.

	#echo 0 > /sys/devices/system/cpu/cpuX/online

Once the logical offline is successful, check

	#cat /proc/interrupts

You should now not see the CPU that you removed. Also online file will report
the state as 0 when a cpu if offline and 1 when its online.

	#To display the current cpu state.
	#cat /sys/devices/system/cpu/cpuX/online

Q: Why can't i remove CPU0 on some systems?
A: Some architectures may have some special dependency on a certain CPU.

For e.g in IA64 platforms we have ability to sent platform interrupts to the
OS. a.k.a Corrected Platform Error Interrupts (CPEI). In current ACPI
specifications, we didn't have a way to change the target CPU. Hence if the
current ACPI version doesn't support such re-direction, we disable that CPU
by making it not-removable.

In such cases you will also notice that the online file is missing under cpu0.

Q: How do i find out if a particular CPU is not removable?
A: Depending on the implementation, some architectures may show this by the
absence of the "online" file. This is done if it can be determined ahead of
time that this CPU cannot be removed.

In some situations, this can be a run time check, i.e if you try to remove the
last CPU, this will not be permitted. You can find such failures by
investigating the return value of the "echo" command.

Q: What happens when a CPU is being logically offlined?
A: The following happen, listed in no particular order :-)

- A notification is sent to in-kernel registered modules by sending an event
  CPU_DOWN_PREPARE or CPU_DOWN_PREPARE_FROZEN, depending on whether or not the
  CPU is being offlined while tasks are frozen due to a suspend operation in
  progress
- All processes are migrated away from this outgoing CPU to new CPUs.
  The new CPU is chosen from each process' current cpuset, which may be
  a subset of all online CPUs.
- All interrupts targeted to this CPU is migrated to a new CPU
- timers/bottom half/task lets are also migrated to a new CPU
- Once all services are migrated, kernel calls an arch specific routine
  __cpu_disable() to perform arch specific cleanup.
- Once this is successful, an event for successful cleanup is sent by an event
  CPU_DEAD (or CPU_DEAD_FROZEN if tasks are frozen due to a suspend while the
  CPU is being offlined).

  "It is expected that each service cleans up when the CPU_DOWN_PREPARE
  notifier is called, when CPU_DEAD is called its expected there is nothing
  running on behalf of this CPU that was offlined"

Q: If i have some kernel code that needs to be aware of CPU arrival and
   departure, how to i arrange for proper notification?
A: This is what you would need in your kernel code to receive notifications.

	#include <linux/cpu.h>
	static int __cpuinit foobar_cpu_callback(struct notifier_block *nfb,
					    unsigned long action, void *hcpu)
	{
		unsigned int cpu = (unsigned long)hcpu;

		switch (action) {
		case CPU_ONLINE:
		case CPU_ONLINE_FROZEN:
			foobar_online_action(cpu);
			break;
		case CPU_DEAD:
		case CPU_DEAD_FROZEN:
			foobar_dead_action(cpu);
			break;
		}
		return NOTIFY_OK;
	}

	static struct notifier_block __cpuinitdata foobar_cpu_notifer =
	{
	   .notifier_call = foobar_cpu_callback,
	};

You need to call register_cpu_notifier() from your init function.
Init functions could be of two types:
1. early init (init function called when only the boot processor is online).
2. late init (init function called _after_ all the CPUs are online).

For the first case, you should add the following to your init function

	register_cpu_notifier(&foobar_cpu_notifier);

For the second case, you should add the following to your init function

	register_hotcpu_notifier(&foobar_cpu_notifier);

You can fail PREPARE notifiers if something doesn't work to prepare resources.
This will stop the activity and send a following CANCELED event back.

CPU_DEAD should not be failed, its just a goodness indication, but bad
things will happen if a notifier in path sent a BAD notify code.

Q: I don't see my action being called for all CPUs already up and running?
A: Yes, CPU notifiers are called only when new CPUs are on-lined or offlined.
   If you need to perform some action for each cpu already in the system, then

	for_each_online_cpu(i) {
		foobar_cpu_callback(&foobar_cpu_notifier, CPU_UP_PREPARE, i);
		foobar_cpu_callback(&foobar_cpu_notifier, CPU_ONLINE, i);
	}

Q: If i would like to develop cpu hotplug support for a new architecture,
   what do i need at a minimum?
A: The following are what is required for CPU hotplug infrastructure to work
   correctly.

    - Make sure you have an entry in Kconfig to enable CONFIG_HOTPLUG_CPU
    - __cpu_up()        - Arch interface to bring up a CPU
    - __cpu_disable()   - Arch interface to shutdown a CPU, no more interrupts
                          can be handled by the kernel after the routine
                          returns. Including local APIC timers etc are
                          shutdown.
     - __cpu_die()      - This actually supposed to ensure death of the CPU.
                          Actually look at some example code in other arch
                          that implement CPU hotplug. The processor is taken
                          down from the idle() loop for that specific
                          architecture. __cpu_die() typically waits for some
                          per_cpu state to be set, to ensure the processor
                          dead routine is called to be sure positively.

Q: I need to ensure that a particular cpu is not removed when there is some
   work specific to this cpu is in progress.
A: There are two ways.  If your code can be run in interrupt context, use
   smp_call_function_single(), otherwise use work_on_cpu().  Note that
   work_on_cpu() is slow, and can fail due to out of memory:

	int my_func_on_cpu(int cpu)
	{
		int err;
		get_online_cpus();
		if (!cpu_online(cpu))
			err = -EINVAL;
		else
#if NEEDS_BLOCKING
			err = work_on_cpu(cpu, __my_func_on_cpu, NULL);
#else
			smp_call_function_single(cpu, __my_func_on_cpu, &err,
						 true);
#endif
		put_online_cpus();
		return err;
	}

Q: How do we determine how many CPUs are available for hotplug.
A: There is no clear spec defined way from ACPI that can give us that
   information today. Based on some input from Natalie of Unisys,
   that the ACPI MADT (Multiple APIC Description Tables) marks those possible
   CPUs in a system with disabled status.

   Andi implemented some simple heuristics that count the number of disabled
   CPUs in MADT as hotpluggable CPUS.  In the case there are no disabled CPUS
   we assume 1/2 the number of CPUs currently present can be hotplugged.

   Caveat: Today's ACPI MADT can only provide 256 entries since the apicid field
   in MADT is only 8 bits.

User Space Notification

Hotplug support for devices is common in Linux today. Its being used today to
support automatic configuration of network, usb and pci devices. A hotplug
event can be used to invoke an agent script to perform the configuration task.

You can add /etc/hotplug/cpu.agent to handle hotplug notification user space
scripts.

	#!/bin/bash
	# $Id: cpu.agent
	# Kernel hotplug params include:
	#ACTION=%s [online or offline]
	#DEVPATH=%s
	#
	cd /etc/hotplug
	. ./hotplug.functions

	case $ACTION in
		online)
			echo `date` ":cpu.agent" add cpu >> /tmp/hotplug.txt
			;;
		offline)
			echo `date` ":cpu.agent" remove cpu >>/tmp/hotplug.txt
			;;
		*)
			debug_mesg CPU $ACTION event not supported
        exit 1
        ;;
	esac
CPU load
--------

Linux exports various bits of information via `/proc/stat' and
`/proc/uptime' that userland tools, such as top(1), use to calculate
the average time system spent in a particular state, for example:

    $ iostat
    Linux 2.6.18.3-exp (linmac)     02/20/2007

    avg-cpu:  %user   %nice %system %iowait  %steal   %idle
              10.01    0.00    2.92    5.44    0.00   81.63

    ...

Here the system thinks that over the default sampling period the
system spent 10.01% of the time doing work in user space, 2.92% in the
kernel, and was overall 81.63% of the time idle.

In most cases the `/proc/stat' information reflects the reality quite
closely, however due to the nature of how/when the kernel collects
this data sometimes it can not be trusted at all.

So how is this information collected?  Whenever timer interrupt is
signalled the kernel looks what kind of task was running at this
moment and increments the counter that corresponds to this tasks
kind/state.  The problem with this is that the system could have
switched between various states multiple times between two timer
interrupts yet the counter is incremented only for the last state.


Example
-------

If we imagine the system with one task that periodically burns cycles
in the following manner:

 time line between two timer interrupts
|--------------------------------------|
 ^                                    ^
 |_ something begins working          |
                                      |_ something goes to sleep
                                     (only to be awaken quite soon)

In the above situation the system will be 0% loaded according to the
`/proc/stat' (since the timer interrupt will always happen when the
system is executing the idle handler), but in reality the load is
closer to 99%.

One can imagine many more situations where this behavior of the kernel
will lead to quite erratic information inside `/proc/stat'.


/* gcc -o hog smallhog.c */
#include <time.h>
#include <limits.h>
#include <signal.h>
#include <sys/time.h>
#define HIST 10

static volatile sig_atomic_t stop;

static void sighandler (int signr)
{
     (void) signr;
     stop = 1;
}
static unsigned long hog (unsigned long niters)
{
     stop = 0;
     while (!stop && --niters);
     return niters;
}
int main (void)
{
     int i;
     struct itimerval it = { .it_interval = { .tv_sec = 0, .tv_usec = 1 },
                             .it_value = { .tv_sec = 0, .tv_usec = 1 } };
     sigset_t set;
     unsigned long v[HIST];
     double tmp = 0.0;
     unsigned long n;
     signal (SIGALRM, &sighandler);
     setitimer (ITIMER_REAL, &it, NULL);

     hog (ULONG_MAX);
     for (i = 0; i < HIST; ++i) v[i] = ULONG_MAX - hog (ULONG_MAX);
     for (i = 0; i < HIST; ++i) tmp += v[i];
     tmp /= HIST;
     n = tmp - (tmp / 3.0);

     sigemptyset (&set);
     sigaddset (&set, SIGALRM);

     for (;;) {
         hog (n);
         sigwait (&set, &i);
     }
     return 0;
}


References
----------

http://lkml.org/lkml/2007/2/12/6
Documentation/filesystems/proc.txt (1.8)


Thanks
------

Con Kolivas, Pavel Machek

Export CPU topology info via sysfs. Items (attributes) are similar
to /proc/cpuinfo.

1) /sys/devices/system/cpu/cpuX/topology/physical_package_id:

	physical package id of cpuX. Typically corresponds to a physical
	socket number, but the actual value is architecture and platform
	dependent.

2) /sys/devices/system/cpu/cpuX/topology/core_id:

	the CPU core ID of cpuX. Typically it is the hardware platform's
	identifier (rather than the kernel's).  The actual value is
	architecture and platform dependent.

3) /sys/devices/system/cpu/cpuX/topology/book_id:

	the book ID of cpuX. Typically it is the hardware platform's
	identifier (rather than the kernel's).	The actual value is
	architecture and platform dependent.

4) /sys/devices/system/cpu/cpuX/topology/thread_siblings:

	internel kernel map of cpuX's hardware threads within the same
	core as cpuX

5) /sys/devices/system/cpu/cpuX/topology/core_siblings:

	internal kernel map of cpuX's hardware threads within the same
	physical_package_id.

6) /sys/devices/system/cpu/cpuX/topology/book_siblings:

	internal kernel map of cpuX's hardware threads within the same
	book_id.

To implement it in an architecture-neutral way, a new source file,
drivers/base/topology.c, is to export the 4 or 6 attributes. The two book
related sysfs files will only be created if CONFIG_SCHED_BOOK is selected.

For an architecture to support this feature, it must define some of
these macros in include/asm-XXX/topology.h:
#define topology_physical_package_id(cpu)
#define topology_core_id(cpu)
#define topology_book_id(cpu)
#define topology_thread_cpumask(cpu)
#define topology_core_cpumask(cpu)
#define topology_book_cpumask(cpu)

The type of **_id is int.
The type of siblings is (const) struct cpumask *.

To be consistent on all architectures, include/linux/topology.h
provides default definitions for any of the above macros that are
not defined by include/asm-XXX/topology.h:
1) physical_package_id: -1
2) core_id: 0
3) thread_siblings: just the given CPU
4) core_siblings: just the given CPU

For architectures that don't support books (CONFIG_SCHED_BOOK) there are no
default definitions for topology_book_id() and topology_book_cpumask().

Additionally, CPU topology information is provided under
/sys/devices/system/cpu and includes these files.  The internal
source for the output is in brackets ("[]").

    kernel_max: the maximum CPU index allowed by the kernel configuration.
		[NR_CPUS-1]

    offline:	CPUs that are not online because they have been
		HOTPLUGGED off (see cpu-hotplug.txt) or exceed the limit
		of CPUs allowed by the kernel configuration (kernel_max
		above). [~cpu_online_mask + cpus >= NR_CPUS]

    online:	CPUs that are online and being scheduled [cpu_online_mask]

    possible:	CPUs that have been allocated resources and can be
		brought online if they are present. [cpu_possible_mask]

    present:	CPUs that have been identified as being present in the
		system. [cpu_present_mask]

The format for the above output is compatible with cpulist_parse()
[see <linux/cpumask.h>].  Some examples follow.

In this example, there are 64 CPUs in the system but cpus 32-63 exceed
the kernel max which is limited to 0..31 by the NR_CPUS config option
being 32.  Note also that CPUs 2 and 4-31 are not online but could be
brought online as they are both present and possible.

     kernel_max: 31
        offline: 2,4-31,32-63
         online: 0-1,3
       possible: 0-31
        present: 0-31

In this example, the NR_CPUS config option is 128, but the kernel was
started with possible_cpus=144.  There are 4 CPUs in the system and cpu2
was manually taken offline (and is the only CPU that can be brought
online.)

     kernel_max: 127
        offline: 2,4-127,128-143
         online: 0-1,3
       possible: 0-127
        present: 0-3

See cpu-hotplug.txt for the possible_cpus=NUM kernel start parameter
as well as more information on the various cpumasks.
Overview

The Dell Systems Management Base Driver provides a sysfs interface for
systems management software such as Dell OpenManage to perform system
management interrupts and host control actions (system power cycle or
power off after OS shutdown) on certain Dell systems.

Dell OpenManage requires this driver on the following Dell PowerEdge systems:
300, 1300, 1400, 400SC, 500SC, 1500SC, 1550, 600SC, 1600SC, 650, 1655MC,
700, and 750.  Other Dell software such as the open source libsmbios project
is expected to make use of this driver, and it may include the use of this
driver on other Dell systems.

The Dell libsmbios project aims towards providing access to as much BIOS
information as possible.  See http://linux.dell.com/libsmbios/main/ for
more information about the libsmbios project.


System Management Interrupt

On some Dell systems, systems management software must access certain
management information via a system management interrupt (SMI).  The SMI data
buffer must reside in 32-bit address space, and the physical address of the
buffer is required for the SMI.  The driver maintains the memory required for
the SMI and provides a way for the application to generate the SMI.
The driver creates the following sysfs entries for systems management
software to perform these system management interrupts:

/sys/devices/platform/dcdbas/smi_data
/sys/devices/platform/dcdbas/smi_data_buf_phys_addr
/sys/devices/platform/dcdbas/smi_data_buf_size
/sys/devices/platform/dcdbas/smi_request

Systems management software must perform the following steps to execute
a SMI using this driver:

1) Lock smi_data.
2) Write system management command to smi_data.
3) Write "1" to smi_request to generate a calling interface SMI or
   "2" to generate a raw SMI.
4) Read system management command response from smi_data.
5) Unlock smi_data.


Host Control Action

Dell OpenManage supports a host control feature that allows the administrator
to perform a power cycle or power off of the system after the OS has finished
shutting down.  On some Dell systems, this host control feature requires that
a driver perform a SMI after the OS has finished shutting down.

The driver creates the following sysfs entries for systems management software
to schedule the driver to perform a power cycle or power off host control
action after the system has finished shutting down:

/sys/devices/platform/dcdbas/host_control_action
/sys/devices/platform/dcdbas/host_control_smi_type
/sys/devices/platform/dcdbas/host_control_on_shutdown

Dell OpenManage performs the following steps to execute a power cycle or
power off host control action using this driver:

1) Write host control action to be performed to host_control_action.
2) Write type of SMI that driver needs to perform to host_control_smi_type.
3) Write "1" to host_control_on_shutdown to enable host control action.
4) Initiate OS shutdown.
   (Driver will perform host control SMI when it is notified that the OS
   has finished shutting down.)


Host Control SMI Type

The following table shows the value to write to host_control_smi_type to
perform a power cycle or power off host control action:

PowerEdge System    Host Control SMI Type
----------------    ---------------------
      300             HC_SMITYPE_TYPE1
     1300             HC_SMITYPE_TYPE1
     1400             HC_SMITYPE_TYPE2
      500SC           HC_SMITYPE_TYPE2
     1500SC           HC_SMITYPE_TYPE2
     1550             HC_SMITYPE_TYPE2
      600SC           HC_SMITYPE_TYPE2
     1600SC           HC_SMITYPE_TYPE2
      650             HC_SMITYPE_TYPE2
     1655MC           HC_SMITYPE_TYPE2
      700             HC_SMITYPE_TYPE3
      750             HC_SMITYPE_TYPE3


Debugging Modules after 2.6.3
-----------------------------

In almost all distributions, the kernel asks for modules which don't
exist, such as "net-pf-10" or whatever.  Changing "modprobe -q" to
"succeed" in this case is hacky and breaks some setups, and also we
want to know if it failed for the fallback code for old aliases in
fs/char_dev.c, for example.

In the past a debugging message which would fill people's logs was
emitted.  This debugging message has been removed.  The correct way
of debugging module problems is something like this:

echo '#! /bin/sh' > /tmp/modprobe
echo 'echo "$@" >> /tmp/modprobe.log' >> /tmp/modprobe
echo 'exec /sbin/modprobe "$@"' >> /tmp/modprobe
chmod a+x /tmp/modprobe
echo /tmp/modprobe > /proc/sys/kernel/modprobe

Note that the above applies only when the *kernel* is requesting
that the module be loaded -- it won't have any effect if that module
is being loaded explicitly using "modprobe" from userspace.

  Using physical DMA provided by OHCI-1394 FireWire controllers for debugging
  ---------------------------------------------------------------------------

Introduction
------------

Basically all FireWire controllers which are in use today are compliant
to the OHCI-1394 specification which defines the controller to be a PCI
bus master which uses DMA to offload data transfers from the CPU and has
a "Physical Response Unit" which executes specific requests by employing
PCI-Bus master DMA after applying filters defined by the OHCI-1394 driver.

Once properly configured, remote machines can send these requests to
ask the OHCI-1394 controller to perform read and write requests on
physical system memory and, for read requests, send the result of
the physical memory read back to the requester.

With that, it is possible to debug issues by reading interesting memory
locations such as buffers like the printk buffer or the process table.

Retrieving a full system memory dump is also possible over the FireWire,
using data transfer rates in the order of 10MB/s or more.

Memory access is currently limited to the low 4G of physical address
space which can be a problem on IA64 machines where memory is located
mostly above that limit, but it is rarely a problem on more common
hardware such as hardware based on x86, x86-64 and PowerPC.

Together with a early initialization of the OHCI-1394 controller for debugging,
this facility proved most useful for examining long debugs logs in the printk
buffer on to debug early boot problems in areas like ACPI where the system
fails to boot and other means for debugging (serial port) are either not
available (notebooks) or too slow for extensive debug information (like ACPI).

Drivers
-------

The ohci1394 driver in drivers/ieee1394 initializes the OHCI-1394 controllers
to a working state and enables physical DMA by default for all remote nodes.
This can be turned off by ohci1394's module parameter phys_dma=0.

The alternative firewire-ohci driver in drivers/firewire uses filtered physical
DMA by default, which is more secure but not suitable for remote debugging.
Compile the driver with CONFIG_FIREWIRE_OHCI_REMOTE_DMA (Kernel hacking menu:
Remote debugging over FireWire with firewire-ohci) to get unfiltered physical
DMA.

Because ohci1394 and firewire-ohci depend on the PCI enumeration to be
completed, an initialization routine which runs pretty early has been
implemented for x86.  This routine runs long before console_init() can be
called, i.e. before the printk buffer appears on the console.

To activate it, enable CONFIG_PROVIDE_OHCI1394_DMA_INIT (Kernel hacking menu:
Remote debugging over FireWire early on boot) and pass the parameter
"ohci1394_dma=early" to the recompiled kernel on boot.

Tools
-----

firescope - Originally developed by Benjamin Herrenschmidt, Andi Kleen ported
it from PowerPC to x86 and x86_64 and added functionality, firescope can now
be used to view the printk buffer of a remote machine, even with live update.

Bernhard Kaindl enhanced firescope to support accessing 64-bit machines
from 32-bit firescope and vice versa:
- http://halobates.de/firewire/firescope-0.2.2.tar.bz2

and he implemented fast system dump (alpha version - read README.txt):
- http://halobates.de/firewire/firedump-0.1.tar.bz2

There is also a gdb proxy for firewire which allows to use gdb to access
data which can be referenced from symbols found by gdb in vmlinux:
- http://halobates.de/firewire/fireproxy-0.33.tar.bz2

The latest version of this gdb proxy (fireproxy-0.34) can communicate (not
yet stable) with kgdb over an memory-based communication module (kgdbom).

Getting Started
---------------

The OHCI-1394 specification regulates that the OHCI-1394 controller must
disable all physical DMA on each bus reset.

This means that if you want to debug an issue in a system state where
interrupts are disabled and where no polling of the OHCI-1394 controller
for bus resets takes place, you have to establish any FireWire cable
connections and fully initialize all FireWire hardware __before__ the
system enters such state.

Step-by-step instructions for using firescope with early OHCI initialization:

1) Verify that your hardware is supported:

   Load the ohci1394 or the fw-ohci module and check your kernel logs.
   You should see a line similar to

   ohci1394: fw-host0: OHCI-1394 1.1 (PCI): IRQ=[18]  MMIO=[fe9ff800-fe9fffff]
   ... Max Packet=[2048]  IR/IT contexts=[4/8]

   when loading the driver. If you have no supported controller, many PCI,
   CardBus and even some Express cards which are fully compliant to OHCI-1394
   specification are available. If it requires no driver for Windows operating
   systems, it most likely is. Only specialized shops have cards which are not
   compliant, they are based on TI PCILynx chips and require drivers for Win-
   dows operating systems.

2) Establish a working FireWire cable connection:

   Any FireWire cable, as long at it provides electrically and mechanically
   stable connection and has matching connectors (there are small 4-pin and
   large 6-pin FireWire ports) will do.

   If an driver is running on both machines you should see a line like

   ieee1394: Node added: ID:BUS[0-01:1023]  GUID[0090270001b84bba]

   on both machines in the kernel log when the cable is plugged in
   and connects the two machines.

3) Test physical DMA using firescope:

   On the debug host,
	- load the raw1394 module,
	- make sure that /dev/raw1394 is accessible,
   then start firescope:

	$ firescope
	Port 0 (ohci1394) opened, 2 nodes detected

	FireScope
	---------
	Target : <unspecified>
	Gen    : 1
	[Ctrl-T] choose target
	[Ctrl-H] this menu
	[Ctrl-Q] quit

    ------> Press Ctrl-T now, the output should be similar to:

	2 nodes available, local node is: 0
	 0: ffc0, uuid: 00000000 00000000 [LOCAL]
	 1: ffc1, uuid: 00279000 ba4bb801

   Besides the [LOCAL] node, it must show another node without error message.

4) Prepare for debugging with early OHCI-1394 initialization:

   4.1) Kernel compilation and installation on debug target

   Compile the kernel to be debugged with CONFIG_PROVIDE_OHCI1394_DMA_INIT
   (Kernel hacking: Provide code for enabling DMA over FireWire early on boot)
   enabled and install it on the machine to be debugged (debug target).

   4.2) Transfer the System.map of the debugged kernel to the debug host

   Copy the System.map of the kernel be debugged to the debug host (the host
   which is connected to the debugged machine over the FireWire cable).

5) Retrieving the printk buffer contents:

   With the FireWire cable connected, the OHCI-1394 driver on the debugging
   host loaded, reboot the debugged machine, booting the kernel which has
   CONFIG_PROVIDE_OHCI1394_DMA_INIT enabled, with the option ohci1394_dma=early.

   Then, on the debugging host, run firescope, for example by using -A:

	firescope -A System.map-of-debug-target-kernel

   Note: -A automatically attaches to the first non-local node. It only works
   reliably if only connected two machines are connected using FireWire.

   After having attached to the debug target, press Ctrl-D to view the
   complete printk buffer or Ctrl-U to enter auto update mode and get an
   updated live view of recent kernel messages logged on the debug target.

   Call "firescope -h" to get more information on firescope's options.

Notes
-----
Documentation and specifications: http://halobates.de/firewire/

FireWire is a trademark of Apple Inc. - for more information please refer to:
http://en.wikipedia.org/wiki/FireWire
Purpose:
Demonstrate the usage of the new open sourced rbu (Remote BIOS Update) driver
for updating BIOS images on Dell servers and desktops.

Scope:
This document discusses the functionality of the rbu driver only.
It does not cover the support needed from applications to enable the BIOS to
update itself with the image downloaded in to the memory.

Overview:
This driver works with Dell OpenManage or Dell Update Packages for updating
the BIOS on Dell servers (starting from servers sold since 1999), desktops
and notebooks (starting from those sold in 2005).
Please go to  http://support.dell.com register and you can find info on
OpenManage and Dell Update packages (DUP).
Libsmbios can also be used to update BIOS on Dell systems go to
http://linux.dell.com/libsmbios/ for details.

Dell_RBU driver supports BIOS update using the monolithic image and packetized
image methods. In case of monolithic the driver allocates a contiguous chunk
of physical pages having the BIOS image. In case of packetized the app
using the driver breaks the image in to packets of fixed sizes and the driver
would place each packet in contiguous physical memory. The driver also
maintains a link list of packets for reading them back.
If the dell_rbu driver is unloaded all the allocated memory is freed.

The rbu driver needs to have an application (as mentioned above)which will
inform the BIOS to enable the update in the next system reboot.

The user should not unload the rbu driver after downloading the BIOS image
or updating.

The driver load creates the following directories under the /sys file system.
/sys/class/firmware/dell_rbu/loading
/sys/class/firmware/dell_rbu/data
/sys/devices/platform/dell_rbu/image_type
/sys/devices/platform/dell_rbu/data
/sys/devices/platform/dell_rbu/packet_size

The driver supports two types of update mechanism; monolithic and packetized.
These update mechanism depends upon the BIOS currently running on the system.
Most of the Dell systems support a monolithic update where the BIOS image is
copied to a single contiguous block of physical memory.
In case of packet mechanism the single memory can be broken in smaller chunks
of contiguous memory and the BIOS image is scattered in these packets.

By default the driver uses monolithic memory for the update type. This can be
changed to packets during the driver load time by specifying the load
parameter image_type=packet.  This can also be changed later as below
echo packet > /sys/devices/platform/dell_rbu/image_type

In packet update mode the packet size has to be given before any packets can
be downloaded. It is done as below
echo XXXX > /sys/devices/platform/dell_rbu/packet_size
In the packet update mechanism, the user needs to create a new file having
packets of data arranged back to back. It can be done as follows
The user creates packets header, gets the chunk of the BIOS image and
places it next to the packetheader; now, the packetheader + BIOS image chunk
added together should match the specified packet_size. This makes one
packet, the user needs to create more such packets out of the entire BIOS
image file and then arrange all these packets back to back in to one single
file.
This file is then copied to /sys/class/firmware/dell_rbu/data.
Once this file gets to the driver, the driver extracts packet_size data from
the file and spreads it across the physical memory in contiguous packet_sized
space.
This method makes sure that all the packets get to the driver in a single operation.

In monolithic update the user simply get the BIOS image (.hdr file) and copies
to the data file as is without any change to the BIOS image itself.

Do the steps below to download the BIOS image.
1) echo 1 > /sys/class/firmware/dell_rbu/loading
2) cp bios_image.hdr /sys/class/firmware/dell_rbu/data
3) echo 0 > /sys/class/firmware/dell_rbu/loading

The /sys/class/firmware/dell_rbu/ entries will remain till the following is
done.
echo -1 > /sys/class/firmware/dell_rbu/loading
Until this step is completed the driver cannot be unloaded.
Also echoing either mono, packet or init in to image_type will free up the
memory allocated by the driver.

If a user by accident executes steps 1 and 3 above without executing step 2;
it will make the /sys/class/firmware/dell_rbu/ entries disappear.
The entries can be recreated by doing the following
echo init > /sys/devices/platform/dell_rbu/image_type
NOTE: echoing init in image_type does not change it original value.

Also the driver provides /sys/devices/platform/dell_rbu/data readonly file to
read back the image downloaded.

NOTE:
This driver requires a patch for firmware_class.c which has the modified
request_firmware_nowait function.
Also after updating the BIOS image a user mode application needs to execute
code which sends the BIOS update request to the BIOS. So on the next reboot
the BIOS knows about the new image downloaded and it updates itself.
Also don't unload the rbu driver if the image has to be updated.


		    LINUX ALLOCATED DEVICES (2.6+ version)

	     Maintained by Alan Cox <device@lanana.org>

		      Last revised: 6th April 2009

This list is the Linux Device List, the official registry of allocated
device numbers and /dev directory nodes for the Linux operating
system.

The latest version of this list is available from
http://www.lanana.org/docs/device-list/ or
ftp://ftp.kernel.org/pub/linux/docs/device-list/.  This version may be
newer than the one distributed with the Linux kernel.

The LaTeX version of this document is no longer maintained.

This document is included by reference into the Filesystem Hierarchy
Standard (FHS).	 The FHS is available from http://www.pathname.com/fhs/.

Allocations marked (68k/Amiga) apply to Linux/68k on the Amiga
platform only.	Allocations marked (68k/Atari) apply to Linux/68k on
the Atari platform only.

The symbol {2.6} means the allocation is obsolete and scheduled for
removal once kernel version 2.6 (or equivalent) is released. Some of these
allocations have already been removed.

This document is in the public domain.	The author requests, however,
that semantically altered versions are not distributed without
permission of the author, assuming the author can be contacted without
an unreasonable effort.

In particular, please don't sent patches for this list to Linus, at
least not without contacting me first.

I do not have any information about these devices beyond what appears
on this list.  Any such information requests will be deleted without
reply.


	  **** DEVICE DRIVERS AUTHORS PLEASE READ THIS ****

To have a major number allocated, or a minor number in situations
where that applies (e.g. busmice), please contact me with the
appropriate device information.	 Also, if you have additional
information regarding any of the devices listed below, or if I have
made a mistake, I would greatly appreciate a note.

I do, however, make a few requests about the nature of your report.
This is necessary for me to be able to keep this list up to date and
correct in a timely manner.  First of all, *please* send it to the
correct address... <device@lanana.org>.  I receive hundreds of email
messages a day, so mail sent to other addresses may very well get lost
in the avalanche.  Please put in a descriptive subject, so I can find
your mail again should I need to.  Too many people send me email
saying just "device number request" in the subject.

Second, please include a description of the device *in the same format
as this list*.	The reason for this is that it is the only way I have
found to ensure I have all the requisite information to publish your
device and avoid conflicts.

Third, please don't assume that the distributed version of the list is
up to date.  Due to the number of registrations I have to maintain it
in "batch mode", so there is likely additional registrations that
haven't been listed yet.

Fourth, remember that Linux now has extensive support for dynamic allocation
of device numbering and can use sysfs and udev to handle the naming needs.
There are still some exceptions in the serial and boot device area. Before
asking for a device number make sure you actually need one.

Finally, sometimes I have to play "namespace police."  Please don't be
offended.  I often get submissions for /dev names that would be bound
to cause conflicts down the road.  I am trying to avoid getting in a
situation where we would have to suffer an incompatible forward
change.  Therefore, please consult with me *before* you make your
device names and numbers in any way public, at least to the point
where it would be at all difficult to get them changed.

Your cooperation is appreciated.


  0		Unnamed devices (e.g. non-device mounts)
		  0 = reserved as null device number
		See block major 144, 145, 146 for expansion areas.

  1 char	Memory devices
		  1 = /dev/mem		Physical memory access
		  2 = /dev/kmem		Kernel virtual memory access
		  3 = /dev/null		Null device
		  4 = /dev/port		I/O port access
		  5 = /dev/zero		Null byte source
		  6 = /dev/core		OBSOLETE - replaced by /proc/kcore
		  7 = /dev/full		Returns ENOSPC on write
		  8 = /dev/random	Nondeterministic random number gen.
		  9 = /dev/urandom	Faster, less secure random number gen.
		 10 = /dev/aio		Asynchronous I/O notification interface
		 11 = /dev/kmsg		Writes to this come out as printk's
		 12 = /dev/oldmem	Used by crashdump kernels to access
					the memory of the kernel that crashed.

  1 block	RAM disk
		  0 = /dev/ram0		First RAM disk
		  1 = /dev/ram1		Second RAM disk
		    ...
		250 = /dev/initrd	Initial RAM disk

		Older kernels had /dev/ramdisk (1, 1) here.
		/dev/initrd refers to a RAM disk which was preloaded
		by the boot loader; newer kernels use /dev/ram0 for
		the initrd.

  2 char	Pseudo-TTY masters
		  0 = /dev/ptyp0	First PTY master
		  1 = /dev/ptyp1	Second PTY master
		    ...
		255 = /dev/ptyef	256th PTY master

		Pseudo-tty's are named as follows:
		* Masters are "pty", slaves are "tty";
		* the fourth letter is one of pqrstuvwxyzabcde indicating
		  the 1st through 16th series of 16 pseudo-ttys each, and
		* the fifth letter is one of 0123456789abcdef indicating
		  the position within the series.

		These are the old-style (BSD) PTY devices; Unix98
		devices are on major 128 and above and use the PTY
		master multiplex (/dev/ptmx) to acquire a PTY on
		demand.

  2 block	Floppy disks
		  0 = /dev/fd0		Controller 0, drive 0, autodetect
		  1 = /dev/fd1		Controller 0, drive 1, autodetect
		  2 = /dev/fd2		Controller 0, drive 2, autodetect
		  3 = /dev/fd3		Controller 0, drive 3, autodetect
		128 = /dev/fd4		Controller 1, drive 0, autodetect
		129 = /dev/fd5		Controller 1, drive 1, autodetect
		130 = /dev/fd6		Controller 1, drive 2, autodetect
		131 = /dev/fd7		Controller 1, drive 3, autodetect

		To specify format, add to the autodetect device number:
		  0 = /dev/fd?		Autodetect format
		  4 = /dev/fd?d360	5.25"  360K in a 360K  drive(1)
		 20 = /dev/fd?h360	5.25"  360K in a 1200K drive(1)
		 48 = /dev/fd?h410	5.25"  410K in a 1200K drive
		 64 = /dev/fd?h420	5.25"  420K in a 1200K drive
		 24 = /dev/fd?h720	5.25"  720K in a 1200K drive
		 80 = /dev/fd?h880	5.25"  880K in a 1200K drive(1)
		  8 = /dev/fd?h1200	5.25" 1200K in a 1200K drive(1)
		 40 = /dev/fd?h1440	5.25" 1440K in a 1200K drive(1)
		 56 = /dev/fd?h1476	5.25" 1476K in a 1200K drive
		 72 = /dev/fd?h1494	5.25" 1494K in a 1200K drive
		 92 = /dev/fd?h1600	5.25" 1600K in a 1200K drive(1)

		 12 = /dev/fd?u360	3.5"   360K Double Density(2)
		 16 = /dev/fd?u720	3.5"   720K Double Density(1)
		120 = /dev/fd?u800	3.5"   800K Double Density(2)
		 52 = /dev/fd?u820	3.5"   820K Double Density
		 68 = /dev/fd?u830	3.5"   830K Double Density
		 84 = /dev/fd?u1040	3.5"  1040K Double Density(1)
		 88 = /dev/fd?u1120	3.5"  1120K Double Density(1)
		 28 = /dev/fd?u1440	3.5"  1440K High Density(1)
		124 = /dev/fd?u1600	3.5"  1600K High Density(1)
		 44 = /dev/fd?u1680	3.5"  1680K High Density(3)
		 60 = /dev/fd?u1722	3.5"  1722K High Density
		 76 = /dev/fd?u1743	3.5"  1743K High Density
		 96 = /dev/fd?u1760	3.5"  1760K High Density
		116 = /dev/fd?u1840	3.5"  1840K High Density(3)
		100 = /dev/fd?u1920	3.5"  1920K High Density(1)
		 32 = /dev/fd?u2880	3.5"  2880K Extra Density(1)
		104 = /dev/fd?u3200	3.5"  3200K Extra Density
		108 = /dev/fd?u3520	3.5"  3520K Extra Density
		112 = /dev/fd?u3840	3.5"  3840K Extra Density(1)

		 36 = /dev/fd?CompaQ	Compaq 2880K drive; obsolete?

		(1) Autodetectable format
		(2) Autodetectable format in a Double Density (720K) drive only
		(3) Autodetectable format in a High Density (1440K) drive only

		NOTE: The letter in the device name (d, q, h or u)
		signifies the type of drive: 5.25" Double Density (d),
		5.25" Quad Density (q), 5.25" High Density (h) or 3.5"
		(any model, u).	 The use of the capital letters D, H
		and E for the 3.5" models have been deprecated, since
		the drive type is insignificant for these devices.

  3 char	Pseudo-TTY slaves
		  0 = /dev/ttyp0	First PTY slave
		  1 = /dev/ttyp1	Second PTY slave
		    ...
		255 = /dev/ttyef	256th PTY slave

		These are the old-style (BSD) PTY devices; Unix98
		devices are on major 136 and above.

  3 block	First MFM, RLL and IDE hard disk/CD-ROM interface
		  0 = /dev/hda		Master: whole disk (or CD-ROM)
		 64 = /dev/hdb		Slave: whole disk (or CD-ROM)

		For partitions, add to the whole disk device number:
		  0 = /dev/hd?		Whole disk
		  1 = /dev/hd?1		First partition
		  2 = /dev/hd?2		Second partition
		    ...
		 63 = /dev/hd?63	63rd partition

		For Linux/i386, partitions 1-4 are the primary
		partitions, and 5 and above are logical partitions.
		Other versions of Linux use partitioning schemes
		appropriate to their respective architectures.

  4 char	TTY devices
		  0 = /dev/tty0		Current virtual console

		  1 = /dev/tty1		First virtual console
		    ...
		 63 = /dev/tty63	63rd virtual console
		 64 = /dev/ttyS0	First UART serial port
		    ...
		255 = /dev/ttyS191	192nd UART serial port

		UART serial ports refer to 8250/16450/16550 series devices.

		Older versions of the Linux kernel used this major
		number for BSD PTY devices.  As of Linux 2.1.115, this
		is no longer supported.	 Use major numbers 2 and 3.

  4 block	Aliases for dynamically allocated major devices to be used
		when its not possible to create the real device nodes
		because the root filesystem is mounted read-only.

                  0 = /dev/root

  5 char	Alternate TTY devices
		  0 = /dev/tty		Current TTY device
		  1 = /dev/console	System console
		  2 = /dev/ptmx		PTY master multiplex
		  3 = /dev/ttyprintk	User messages via printk TTY device
		 64 = /dev/cua0		Callout device for ttyS0
		    ...
		255 = /dev/cua191	Callout device for ttyS191

		(5,1) is /dev/console starting with Linux 2.1.71.  See
		the section on terminal devices for more information
		on /dev/console.

  6 char	Parallel printer devices
		  0 = /dev/lp0		Parallel printer on parport0
		  1 = /dev/lp1		Parallel printer on parport1
		    ...

		Current Linux kernels no longer have a fixed mapping
		between parallel ports and I/O addresses.  Instead,
		they are redirected through the parport multiplex layer.

  7 char	Virtual console capture devices
		  0 = /dev/vcs		Current vc text contents
		  1 = /dev/vcs1		tty1 text contents
		    ...
		 63 = /dev/vcs63	tty63 text contents
		128 = /dev/vcsa		Current vc text/attribute contents
		129 = /dev/vcsa1	tty1 text/attribute contents
		    ...
		191 = /dev/vcsa63	tty63 text/attribute contents

		NOTE: These devices permit both read and write access.

  7 block	Loopback devices
		  0 = /dev/loop0	First loop device
		  1 = /dev/loop1	Second loop device
		    ...

		The loop devices are used to mount filesystems not
		associated with block devices.	The binding to the
		loop devices is handled by mount(8) or losetup(8).

  8 block	SCSI disk devices (0-15)
		  0 = /dev/sda		First SCSI disk whole disk
		 16 = /dev/sdb		Second SCSI disk whole disk
		 32 = /dev/sdc		Third SCSI disk whole disk
		    ...
		240 = /dev/sdp		Sixteenth SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

  9 char	SCSI tape devices
		  0 = /dev/st0		First SCSI tape, mode 0
		  1 = /dev/st1		Second SCSI tape, mode 0
		    ...
		 32 = /dev/st0l		First SCSI tape, mode 1
		 33 = /dev/st1l		Second SCSI tape, mode 1
		    ...
		 64 = /dev/st0m		First SCSI tape, mode 2
		 65 = /dev/st1m		Second SCSI tape, mode 2
		    ...
		 96 = /dev/st0a		First SCSI tape, mode 3
		 97 = /dev/st1a		Second SCSI tape, mode 3
		      ...
		128 = /dev/nst0		First SCSI tape, mode 0, no rewind
		129 = /dev/nst1		Second SCSI tape, mode 0, no rewind
		    ...
		160 = /dev/nst0l	First SCSI tape, mode 1, no rewind
		161 = /dev/nst1l	Second SCSI tape, mode 1, no rewind
		    ...
		192 = /dev/nst0m	First SCSI tape, mode 2, no rewind
		193 = /dev/nst1m	Second SCSI tape, mode 2, no rewind
		    ...
		224 = /dev/nst0a	First SCSI tape, mode 3, no rewind
		225 = /dev/nst1a	Second SCSI tape, mode 3, no rewind
		    ...

		"No rewind" refers to the omission of the default
		automatic rewind on device close.  The MTREW or MTOFFL
		ioctl()'s can be used to rewind the tape regardless of
		the device used to access it.

  9 block	Metadisk (RAID) devices
		  0 = /dev/md0		First metadisk group
		  1 = /dev/md1		Second metadisk group
		    ...

		The metadisk driver is used to span a
		filesystem across multiple physical disks.

 10 char	Non-serial mice, misc features
		  0 = /dev/logibm	Logitech bus mouse
		  1 = /dev/psaux	PS/2-style mouse port
		  2 = /dev/inportbm	Microsoft Inport bus mouse
		  3 = /dev/atibm	ATI XL bus mouse
		  4 = /dev/jbm		J-mouse
		  4 = /dev/amigamouse	Amiga mouse (68k/Amiga)
		  5 = /dev/atarimouse	Atari mouse
		  6 = /dev/sunmouse	Sun mouse
		  7 = /dev/amigamouse1	Second Amiga mouse
		  8 = /dev/smouse	Simple serial mouse driver
		  9 = /dev/pc110pad	IBM PC-110 digitizer pad
		 10 = /dev/adbmouse	Apple Desktop Bus mouse
		 11 = /dev/vrtpanel	Vr41xx embedded touch panel
		 13 = /dev/vpcmouse	Connectix Virtual PC Mouse
		 14 = /dev/touchscreen/ucb1x00  UCB 1x00 touchscreen
		 15 = /dev/touchscreen/mk712	MK712 touchscreen
		128 = /dev/beep		Fancy beep device
		129 =
		130 = /dev/watchdog	Watchdog timer port
		131 = /dev/temperature	Machine internal temperature
		132 = /dev/hwtrap	Hardware fault trap
		133 = /dev/exttrp	External device trap
		134 = /dev/apm_bios	Advanced Power Management BIOS
		135 = /dev/rtc		Real Time Clock
		139 = /dev/openprom	SPARC OpenBoot PROM
		140 = /dev/relay8	Berkshire Products Octal relay card
		141 = /dev/relay16	Berkshire Products ISO-16 relay card
		142 =
		143 = /dev/pciconf	PCI configuration space
		144 = /dev/nvram	Non-volatile configuration RAM
		145 = /dev/hfmodem	Soundcard shortwave modem control
		146 = /dev/graphics	Linux/SGI graphics device
		147 = /dev/opengl	Linux/SGI OpenGL pipe
		148 = /dev/gfx		Linux/SGI graphics effects device
		149 = /dev/input/mouse	Linux/SGI Irix emulation mouse
		150 = /dev/input/keyboard Linux/SGI Irix emulation keyboard
		151 = /dev/led		Front panel LEDs
		152 = /dev/kpoll	Kernel Poll Driver
		153 = /dev/mergemem	Memory merge device
		154 = /dev/pmu		Macintosh PowerBook power manager
		155 = /dev/isictl	MultiTech ISICom serial control
		156 = /dev/lcd		Front panel LCD display
		157 = /dev/ac		Applicom Intl Profibus card
		158 = /dev/nwbutton	Netwinder external button
		159 = /dev/nwdebug	Netwinder debug interface
		160 = /dev/nwflash	Netwinder flash memory
		161 = /dev/userdma	User-space DMA access
		162 = /dev/smbus	System Management Bus
		163 = /dev/lik		Logitech Internet Keyboard
		164 = /dev/ipmo		Intel Intelligent Platform Management
		165 = /dev/vmmon	VMWare virtual machine monitor
		166 = /dev/i2o/ctl	I2O configuration manager
		167 = /dev/specialix_sxctl Specialix serial control
		168 = /dev/tcldrv	Technology Concepts serial control
		169 = /dev/specialix_rioctl Specialix RIO serial control
		170 = /dev/thinkpad/thinkpad	IBM Thinkpad devices
		171 = /dev/srripc	QNX4 API IPC manager
		172 = /dev/usemaclone	Semaphore clone device
		173 = /dev/ipmikcs	Intelligent Platform Management
		174 = /dev/uctrl	SPARCbook 3 microcontroller
		175 = /dev/agpgart	AGP Graphics Address Remapping Table
		176 = /dev/gtrsc	Gorgy Timing radio clock
		177 = /dev/cbm		Serial CBM bus
		178 = /dev/jsflash	JavaStation OS flash SIMM
		179 = /dev/xsvc		High-speed shared-mem/semaphore service
		180 = /dev/vrbuttons	Vr41xx button input device
		181 = /dev/toshiba	Toshiba laptop SMM support
		182 = /dev/perfctr	Performance-monitoring counters
		183 = /dev/hwrng	Generic random number generator
		184 = /dev/cpu/microcode CPU microcode update interface
		186 = /dev/atomicps	Atomic shapshot of process state data
		187 = /dev/irnet	IrNET device
		188 = /dev/smbusbios	SMBus BIOS
		189 = /dev/ussp_ctl	User space serial port control
		190 = /dev/crash	Mission Critical Linux crash dump facility
		191 = /dev/pcl181	<information missing>
		192 = /dev/nas_xbus	NAS xbus LCD/buttons access
		193 = /dev/d7s		SPARC 7-segment display
		194 = /dev/zkshim	Zero-Knowledge network shim control
		195 = /dev/elographics/e2201	Elographics touchscreen E271-2201
		198 = /dev/sexec	Signed executable interface
		199 = /dev/scanners/cuecat :CueCat barcode scanner
		200 = /dev/net/tun	TAP/TUN network device
		201 = /dev/button/gulpb	Transmeta GULP-B buttons
		202 = /dev/emd/ctl	Enhanced Metadisk RAID (EMD) control
		204 = /dev/video/em8300		EM8300 DVD decoder control
		205 = /dev/video/em8300_mv	EM8300 DVD decoder video
		206 = /dev/video/em8300_ma	EM8300 DVD decoder audio
		207 = /dev/video/em8300_sp	EM8300 DVD decoder subpicture
		208 = /dev/compaq/cpqphpc	Compaq PCI Hot Plug Controller
		209 = /dev/compaq/cpqrid	Compaq Remote Insight Driver
		210 = /dev/impi/bt	IMPI coprocessor block transfer
		211 = /dev/impi/smic	IMPI coprocessor stream interface
		212 = /dev/watchdogs/0	First watchdog device
		213 = /dev/watchdogs/1	Second watchdog device
		214 = /dev/watchdogs/2	Third watchdog device
		215 = /dev/watchdogs/3	Fourth watchdog device
		216 = /dev/fujitsu/apanel	Fujitsu/Siemens application panel
		217 = /dev/ni/natmotn		National Instruments Motion
		218 = /dev/kchuid	Inter-process chuid control
		219 = /dev/modems/mwave	MWave modem firmware upload
		220 = /dev/mptctl	Message passing technology (MPT) control
		221 = /dev/mvista/hssdsi	Montavista PICMG hot swap system driver
		222 = /dev/mvista/hasi		Montavista PICMG high availability
		223 = /dev/input/uinput		User level driver support for input
		224 = /dev/tpm		TCPA TPM driver
		225 = /dev/pps		Pulse Per Second driver
		226 = /dev/systrace	Systrace device
		227 = /dev/mcelog	X86_64 Machine Check Exception driver
		228 = /dev/hpet		HPET driver
		229 = /dev/fuse		Fuse (virtual filesystem in user-space)
		230 = /dev/midishare	MidiShare driver
		231 = /dev/snapshot	System memory snapshot device
		232 = /dev/kvm		Kernel-based virtual machine (hardware virtualization extensions)
		233 = /dev/kmview	View-OS A process with a view
		234 = /dev/btrfs-control	Btrfs control device
		235 = /dev/autofs	Autofs control device
		236 = /dev/mapper/control	Device-Mapper control device
		240-254			Reserved for local use
		255			Reserved for MISC_DYNAMIC_MINOR

 11 char	Raw keyboard device	(Linux/SPARC only)
		  0 = /dev/kbd		Raw keyboard device

 11 char	Serial Mux device	(Linux/PA-RISC only)
		  0 = /dev/ttyB0	First mux port
		  1 = /dev/ttyB1	Second mux port
		    ...

 11 block	SCSI CD-ROM devices
		  0 = /dev/scd0		First SCSI CD-ROM
		  1 = /dev/scd1		Second SCSI CD-ROM
		    ...

		The prefix /dev/sr (instead of /dev/scd) has been deprecated.

 12 char	QIC-02 tape
		  2 = /dev/ntpqic11	QIC-11, no rewind-on-close
		  3 = /dev/tpqic11	QIC-11, rewind-on-close
		  4 = /dev/ntpqic24	QIC-24, no rewind-on-close
		  5 = /dev/tpqic24	QIC-24, rewind-on-close
		  6 = /dev/ntpqic120	QIC-120, no rewind-on-close
		  7 = /dev/tpqic120	QIC-120, rewind-on-close
		  8 = /dev/ntpqic150	QIC-150, no rewind-on-close
		  9 = /dev/tpqic150	QIC-150, rewind-on-close

		The device names specified are proposed -- if there
		are "standard" names for these devices, please let me know.

 12 block

 13 char	Input core
		  0 = /dev/input/js0	First joystick
		  1 = /dev/input/js1	Second joystick
		    ...
		 32 = /dev/input/mouse0	First mouse
		 33 = /dev/input/mouse1	Second mouse
		    ...
		 63 = /dev/input/mice	Unified mouse
		 64 = /dev/input/event0	First event queue
		 65 = /dev/input/event1	Second event queue
		    ...

		Each device type has 5 bits (32 minors).

 13 block	8-bit MFM/RLL/IDE controller
		  0 = /dev/xda		First XT disk whole disk
		 64 = /dev/xdb		Second XT disk whole disk

		Partitions are handled in the same way as IDE disks
		(see major number 3).

 14 char	Open Sound System (OSS)
		  0 = /dev/mixer	Mixer control
		  1 = /dev/sequencer	Audio sequencer
		  2 = /dev/midi00	First MIDI port
		  3 = /dev/dsp		Digital audio
		  4 = /dev/audio	Sun-compatible digital audio
		  6 =
		  7 = /dev/audioctl	SPARC audio control device
		  8 = /dev/sequencer2	Sequencer -- alternate device
		 16 = /dev/mixer1	Second soundcard mixer control
		 17 = /dev/patmgr0	Sequencer patch manager
		 18 = /dev/midi01	Second MIDI port
		 19 = /dev/dsp1		Second soundcard digital audio
		 20 = /dev/audio1	Second soundcard Sun digital audio
		 33 = /dev/patmgr1	Sequencer patch manager
		 34 = /dev/midi02	Third MIDI port
		 50 = /dev/midi03	Fourth MIDI port

 14 block

 15 char	Joystick
		  0 = /dev/js0		First analog joystick
		  1 = /dev/js1		Second analog joystick
		    ...
		128 = /dev/djs0		First digital joystick
		129 = /dev/djs1		Second digital joystick
		    ...
 15 block	Sony CDU-31A/CDU-33A CD-ROM
		  0 = /dev/sonycd	Sony CDU-31a CD-ROM

 16 char	Non-SCSI scanners
		  0 = /dev/gs4500	Genius 4500 handheld scanner

 16 block	GoldStar CD-ROM
		  0 = /dev/gscd		GoldStar CD-ROM

 17 char	OBSOLETE (was Chase serial card)
		  0 = /dev/ttyH0	First Chase port
		  1 = /dev/ttyH1	Second Chase port
		    ...
 17 block	Optics Storage CD-ROM
		  0 = /dev/optcd	Optics Storage CD-ROM

 18 char	OBSOLETE (was Chase serial card - alternate devices)
		  0 = /dev/cuh0		Callout device for ttyH0
		  1 = /dev/cuh1		Callout device for ttyH1
		    ...
 18 block	Sanyo CD-ROM
		  0 = /dev/sjcd		Sanyo CD-ROM

 19 char	Cyclades serial card
		  0 = /dev/ttyC0	First Cyclades port
		    ...
		 31 = /dev/ttyC31	32nd Cyclades port

 19 block	"Double" compressed disk
		  0 = /dev/double0	First compressed disk
		    ...
		  7 = /dev/double7	Eighth compressed disk
		128 = /dev/cdouble0	Mirror of first compressed disk
		    ...
		135 = /dev/cdouble7	Mirror of eighth compressed disk

		See the Double documentation for the meaning of the
		mirror devices.

 20 char	Cyclades serial card - alternate devices
		  0 = /dev/cub0		Callout device for ttyC0
		    ...
		 31 = /dev/cub31	Callout device for ttyC31

 20 block	Hitachi CD-ROM (under development)
		  0 = /dev/hitcd	Hitachi CD-ROM

 21 char	Generic SCSI access
		  0 = /dev/sg0		First generic SCSI device
		  1 = /dev/sg1		Second generic SCSI device
		    ...

		Most distributions name these /dev/sga, /dev/sgb...;
		this sets an unnecessary limit of 26 SCSI devices in
		the system and is counter to standard Linux
		device-naming practice.

 21 block	Acorn MFM hard drive interface
		  0 = /dev/mfma		First MFM drive whole disk
		 64 = /dev/mfmb		Second MFM drive whole disk

		This device is used on the ARM-based Acorn RiscPC.
		Partitions are handled the same way as for IDE disks
		(see major number 3).

 22 char	Digiboard serial card
		  0 = /dev/ttyD0	First Digiboard port
		  1 = /dev/ttyD1	Second Digiboard port
		    ...
 22 block	Second IDE hard disk/CD-ROM interface
		  0 = /dev/hdc		Master: whole disk (or CD-ROM)
		 64 = /dev/hdd		Slave: whole disk (or CD-ROM)

		Partitions are handled the same way as for the first
		interface (see major number 3).

 23 char	Digiboard serial card - alternate devices
		  0 = /dev/cud0		Callout device for ttyD0
		  1 = /dev/cud1		Callout device for ttyD1
		      ...
 23 block	Mitsumi proprietary CD-ROM
		  0 = /dev/mcd		Mitsumi CD-ROM

 24 char	Stallion serial card
		  0 = /dev/ttyE0	Stallion port 0 card 0
		  1 = /dev/ttyE1	Stallion port 1 card 0
		    ...
		 64 = /dev/ttyE64	Stallion port 0 card 1
		 65 = /dev/ttyE65	Stallion port 1 card 1
		      ...
		128 = /dev/ttyE128	Stallion port 0 card 2
		129 = /dev/ttyE129	Stallion port 1 card 2
		    ...
		192 = /dev/ttyE192	Stallion port 0 card 3
		193 = /dev/ttyE193	Stallion port 1 card 3
		    ...
 24 block	Sony CDU-535 CD-ROM
		  0 = /dev/cdu535	Sony CDU-535 CD-ROM

 25 char	Stallion serial card - alternate devices
		  0 = /dev/cue0		Callout device for ttyE0
		  1 = /dev/cue1		Callout device for ttyE1
		    ...
		 64 = /dev/cue64	Callout device for ttyE64
		 65 = /dev/cue65	Callout device for ttyE65
		    ...
		128 = /dev/cue128	Callout device for ttyE128
		129 = /dev/cue129	Callout device for ttyE129
		    ...
		192 = /dev/cue192	Callout device for ttyE192
		193 = /dev/cue193	Callout device for ttyE193
		      ...
 25 block	First Matsushita (Panasonic/SoundBlaster) CD-ROM
		  0 = /dev/sbpcd0	Panasonic CD-ROM controller 0 unit 0
		  1 = /dev/sbpcd1	Panasonic CD-ROM controller 0 unit 1
		  2 = /dev/sbpcd2	Panasonic CD-ROM controller 0 unit 2
		  3 = /dev/sbpcd3	Panasonic CD-ROM controller 0 unit 3

 26 char

 26 block	Second Matsushita (Panasonic/SoundBlaster) CD-ROM
		  0 = /dev/sbpcd4	Panasonic CD-ROM controller 1 unit 0
		  1 = /dev/sbpcd5	Panasonic CD-ROM controller 1 unit 1
		  2 = /dev/sbpcd6	Panasonic CD-ROM controller 1 unit 2
		  3 = /dev/sbpcd7	Panasonic CD-ROM controller 1 unit 3

 27 char	QIC-117 tape
		  0 = /dev/qft0		Unit 0, rewind-on-close
		  1 = /dev/qft1		Unit 1, rewind-on-close
		  2 = /dev/qft2		Unit 2, rewind-on-close
		  3 = /dev/qft3		Unit 3, rewind-on-close
		  4 = /dev/nqft0	Unit 0, no rewind-on-close
		  5 = /dev/nqft1	Unit 1, no rewind-on-close
		  6 = /dev/nqft2	Unit 2, no rewind-on-close
		  7 = /dev/nqft3	Unit 3, no rewind-on-close
		 16 = /dev/zqft0	Unit 0, rewind-on-close, compression
		 17 = /dev/zqft1	Unit 1, rewind-on-close, compression
		 18 = /dev/zqft2	Unit 2, rewind-on-close, compression
		 19 = /dev/zqft3	Unit 3, rewind-on-close, compression
		 20 = /dev/nzqft0	Unit 0, no rewind-on-close, compression
		 21 = /dev/nzqft1	Unit 1, no rewind-on-close, compression
		 22 = /dev/nzqft2	Unit 2, no rewind-on-close, compression
		 23 = /dev/nzqft3	Unit 3, no rewind-on-close, compression
		 32 = /dev/rawqft0	Unit 0, rewind-on-close, no file marks
		 33 = /dev/rawqft1	Unit 1, rewind-on-close, no file marks
		 34 = /dev/rawqft2	Unit 2, rewind-on-close, no file marks
		 35 = /dev/rawqft3	Unit 3, rewind-on-close, no file marks
		 36 = /dev/nrawqft0	Unit 0, no rewind-on-close, no file marks
		 37 = /dev/nrawqft1	Unit 1, no rewind-on-close, no file marks
		 38 = /dev/nrawqft2	Unit 2, no rewind-on-close, no file marks
		 39 = /dev/nrawqft3	Unit 3, no rewind-on-close, no file marks

 27 block	Third Matsushita (Panasonic/SoundBlaster) CD-ROM
		  0 = /dev/sbpcd8	Panasonic CD-ROM controller 2 unit 0
		  1 = /dev/sbpcd9	Panasonic CD-ROM controller 2 unit 1
		  2 = /dev/sbpcd10	Panasonic CD-ROM controller 2 unit 2
		  3 = /dev/sbpcd11	Panasonic CD-ROM controller 2 unit 3

 28 char	Stallion serial card - card programming
		  0 = /dev/staliomem0	First Stallion card I/O memory
		  1 = /dev/staliomem1	Second Stallion card I/O memory
		  2 = /dev/staliomem2	Third Stallion card I/O memory
		  3 = /dev/staliomem3	Fourth Stallion card I/O memory

 28 char	Atari SLM ACSI laser printer (68k/Atari)
		  0 = /dev/slm0		First SLM laser printer
		  1 = /dev/slm1		Second SLM laser printer
		    ...
 28 block	Fourth Matsushita (Panasonic/SoundBlaster) CD-ROM
		  0 = /dev/sbpcd12	Panasonic CD-ROM controller 3 unit 0
		  1 = /dev/sbpcd13	Panasonic CD-ROM controller 3 unit 1
		  2 = /dev/sbpcd14	Panasonic CD-ROM controller 3 unit 2
		  3 = /dev/sbpcd15	Panasonic CD-ROM controller 3 unit 3

 28 block	ACSI disk (68k/Atari)
		  0 = /dev/ada		First ACSI disk whole disk
		 16 = /dev/adb		Second ACSI disk whole disk
		 32 = /dev/adc		Third ACSI disk whole disk
		    ...
		240 = /dev/adp		16th ACSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15, like SCSI.

 29 char	Universal frame buffer
		  0 = /dev/fb0		First frame buffer
		  1 = /dev/fb1		Second frame buffer
		    ...
		 31 = /dev/fb31		32nd frame buffer

 29 block	Aztech/Orchid/Okano/Wearnes CD-ROM
		  0 = /dev/aztcd	Aztech CD-ROM

 30 char	iBCS-2 compatibility devices
		  0 = /dev/socksys	Socket access
		  1 = /dev/spx		SVR3 local X interface
		 32 = /dev/inet/ip	Network access
		 33 = /dev/inet/icmp
		 34 = /dev/inet/ggp
		 35 = /dev/inet/ipip
		 36 = /dev/inet/tcp
		 37 = /dev/inet/egp
		 38 = /dev/inet/pup
		 39 = /dev/inet/udp
		 40 = /dev/inet/idp
		 41 = /dev/inet/rawip

		Additionally, iBCS-2 requires the following links:

		/dev/ip -> /dev/inet/ip
		/dev/icmp -> /dev/inet/icmp
		/dev/ggp -> /dev/inet/ggp
		/dev/ipip -> /dev/inet/ipip
		/dev/tcp -> /dev/inet/tcp
		/dev/egp -> /dev/inet/egp
		/dev/pup -> /dev/inet/pup
		/dev/udp -> /dev/inet/udp
		/dev/idp -> /dev/inet/idp
		/dev/rawip -> /dev/inet/rawip
		/dev/inet/arp -> /dev/inet/udp
		/dev/inet/rip -> /dev/inet/udp
		/dev/nfsd -> /dev/socksys
		/dev/X0R -> /dev/null (? apparently not required ?)

 30 block	Philips LMS CM-205 CD-ROM
		  0 = /dev/cm205cd	Philips LMS CM-205 CD-ROM

		/dev/lmscd is an older name for this device.  This
		driver does not work with the CM-205MS CD-ROM.

 31 char	MPU-401 MIDI
		  0 = /dev/mpu401data	MPU-401 data port
		  1 = /dev/mpu401stat	MPU-401 status port

 31 block	ROM/flash memory card
		  0 = /dev/rom0		First ROM card (rw)
		      ...
		  7 = /dev/rom7		Eighth ROM card (rw)
		  8 = /dev/rrom0	First ROM card (ro)
		    ...
		 15 = /dev/rrom7	Eighth ROM card (ro)
		 16 = /dev/flash0	First flash memory card (rw)
		    ...
		 23 = /dev/flash7	Eighth flash memory card (rw)
		 24 = /dev/rflash0	First flash memory card (ro)
		    ...
		 31 = /dev/rflash7	Eighth flash memory card (ro)

		The read-write (rw) devices support back-caching
		written data in RAM, as well as writing to flash RAM
		devices.  The read-only devices (ro) support reading
		only.

 32 char	Specialix serial card
		  0 = /dev/ttyX0	First Specialix port
		  1 = /dev/ttyX1	Second Specialix port
		    ...
 32 block	Philips LMS CM-206 CD-ROM
		  0 = /dev/cm206cd	Philips LMS CM-206 CD-ROM

 33 char	Specialix serial card - alternate devices
		  0 = /dev/cux0		Callout device for ttyX0
		  1 = /dev/cux1		Callout device for ttyX1
		    ...
 33 block	Third IDE hard disk/CD-ROM interface
		  0 = /dev/hde		Master: whole disk (or CD-ROM)
		 64 = /dev/hdf		Slave: whole disk (or CD-ROM)

		Partitions are handled the same way as for the first
		interface (see major number 3).

 34 char	Z8530 HDLC driver
		  0 = /dev/scc0		First Z8530, first port
		  1 = /dev/scc1		First Z8530, second port
		  2 = /dev/scc2		Second Z8530, first port
		  3 = /dev/scc3		Second Z8530, second port
		    ...

		In a previous version these devices were named
		/dev/sc1 for /dev/scc0, /dev/sc2 for /dev/scc1, and so
		on.

 34 block	Fourth IDE hard disk/CD-ROM interface
		  0 = /dev/hdg		Master: whole disk (or CD-ROM)
		 64 = /dev/hdh		Slave: whole disk (or CD-ROM)

		Partitions are handled the same way as for the first
		interface (see major number 3).

 35 char	tclmidi MIDI driver
		  0 = /dev/midi0	First MIDI port, kernel timed
		  1 = /dev/midi1	Second MIDI port, kernel timed
		  2 = /dev/midi2	Third MIDI port, kernel timed
		  3 = /dev/midi3	Fourth MIDI port, kernel timed
		 64 = /dev/rmidi0	First MIDI port, untimed
		 65 = /dev/rmidi1	Second MIDI port, untimed
		 66 = /dev/rmidi2	Third MIDI port, untimed
		 67 = /dev/rmidi3	Fourth MIDI port, untimed
		128 = /dev/smpte0	First MIDI port, SMPTE timed
		129 = /dev/smpte1	Second MIDI port, SMPTE timed
		130 = /dev/smpte2	Third MIDI port, SMPTE timed
		131 = /dev/smpte3	Fourth MIDI port, SMPTE timed

 35 block	Slow memory ramdisk
		  0 = /dev/slram	Slow memory ramdisk

 36 char	Netlink support
		  0 = /dev/route	Routing, device updates, kernel to user
		  1 = /dev/skip		enSKIP security cache control
		  3 = /dev/fwmonitor	Firewall packet copies
		 16 = /dev/tap0		First Ethertap device
		    ...
		 31 = /dev/tap15	16th Ethertap device

 36 block	MCA ESDI hard disk
		  0 = /dev/eda		First ESDI disk whole disk
		 64 = /dev/edb		Second ESDI disk whole disk
		    ...

		Partitions are handled in the same way as IDE disks
		(see major number 3).

 37 char	IDE tape
		  0 = /dev/ht0		First IDE tape
		  1 = /dev/ht1		Second IDE tape
		    ...
		128 = /dev/nht0		First IDE tape, no rewind-on-close
		129 = /dev/nht1		Second IDE tape, no rewind-on-close
		    ...

		Currently, only one IDE tape drive is supported.

 37 block	Zorro II ramdisk
		  0 = /dev/z2ram	Zorro II ramdisk

 38 char	Myricom PCI Myrinet board
		  0 = /dev/mlanai0	First Myrinet board
		  1 = /dev/mlanai1	Second Myrinet board
		    ...

		This device is used for status query, board control
		and "user level packet I/O."  This board is also
		accessible as a standard networking "eth" device.

 38 block	OBSOLETE (was Linux/AP+)

 39 char	ML-16P experimental I/O board
		  0 = /dev/ml16pa-a0	First card, first analog channel
		  1 = /dev/ml16pa-a1	First card, second analog channel
		    ...
		 15 = /dev/ml16pa-a15	First card, 16th analog channel
		 16 = /dev/ml16pa-d	First card, digital lines
		 17 = /dev/ml16pa-c0	First card, first counter/timer
		 18 = /dev/ml16pa-c1	First card, second counter/timer
		 19 = /dev/ml16pa-c2	First card, third counter/timer
		 32 = /dev/ml16pb-a0	Second card, first analog channel
		 33 = /dev/ml16pb-a1	Second card, second analog channel
		    ...
		 47 = /dev/ml16pb-a15	Second card, 16th analog channel
		 48 = /dev/ml16pb-d	Second card, digital lines
		 49 = /dev/ml16pb-c0	Second card, first counter/timer
		 50 = /dev/ml16pb-c1	Second card, second counter/timer
		 51 = /dev/ml16pb-c2	Second card, third counter/timer
		      ...
 39 block

 40 char

 40 block

 41 char	Yet Another Micro Monitor
		  0 = /dev/yamm		Yet Another Micro Monitor

 41 block

 42 char	Demo/sample use

 42 block	Demo/sample use

		This number is intended for use in sample code, as
		well as a general "example" device number.  It
		should never be used for a device driver that is being
		distributed; either obtain an official number or use
		the local/experimental range.  The sudden addition or
		removal of a driver with this number should not cause
		ill effects to the system (bugs excepted.)

		IN PARTICULAR, ANY DISTRIBUTION WHICH CONTAINS A
		DEVICE DRIVER USING MAJOR NUMBER 42 IS NONCOMPLIANT.

 43 char	isdn4linux virtual modem
		  0 = /dev/ttyI0	First virtual modem
		    ...
		 63 = /dev/ttyI63	64th virtual modem

 43 block	Network block devices
		  0 = /dev/nb0		First network block device
		  1 = /dev/nb1		Second network block device
		    ...

		Network Block Device is somehow similar to loopback
		devices: If you read from it, it sends packet across
		network asking server for data. If you write to it, it
		sends packet telling server to write. It could be used
		to mounting filesystems over the net, swapping over
		the net, implementing block device in userland etc.

 44 char	isdn4linux virtual modem - alternate devices
		  0 = /dev/cui0		Callout device for ttyI0
		    ...
		 63 = /dev/cui63	Callout device for ttyI63

 44 block	Flash Translation Layer (FTL) filesystems
		  0 = /dev/ftla		FTL on first Memory Technology Device
		 16 = /dev/ftlb		FTL on second Memory Technology Device
		 32 = /dev/ftlc		FTL on third Memory Technology Device
		    ...
		240 = /dev/ftlp		FTL on 16th Memory Technology Device

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the partition
		limit is 15 rather than 63 per disk (same as SCSI.)

 45 char	isdn4linux ISDN BRI driver
		  0 = /dev/isdn0	First virtual B channel raw data
		    ...
		 63 = /dev/isdn63	64th virtual B channel raw data
		 64 = /dev/isdnctrl0	First channel control/debug
		    ...
		127 = /dev/isdnctrl63	64th channel control/debug

		128 = /dev/ippp0	First SyncPPP device
		    ...
		191 = /dev/ippp63	64th SyncPPP device

		255 = /dev/isdninfo	ISDN monitor interface

 45 block	Parallel port IDE disk devices
		  0 = /dev/pda		First parallel port IDE disk
		 16 = /dev/pdb		Second parallel port IDE disk
		 32 = /dev/pdc		Third parallel port IDE disk
		 48 = /dev/pdd		Fourth parallel port IDE disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the partition
		limit is 15 rather than 63 per disk.

 46 char	Comtrol Rocketport serial card
		  0 = /dev/ttyR0	First Rocketport port
		  1 = /dev/ttyR1	Second Rocketport port
		    ...
 46 block	Parallel port ATAPI CD-ROM devices
		  0 = /dev/pcd0		First parallel port ATAPI CD-ROM
		  1 = /dev/pcd1		Second parallel port ATAPI CD-ROM
		  2 = /dev/pcd2		Third parallel port ATAPI CD-ROM
		  3 = /dev/pcd3		Fourth parallel port ATAPI CD-ROM

 47 char	Comtrol Rocketport serial card - alternate devices
		  0 = /dev/cur0		Callout device for ttyR0
		  1 = /dev/cur1		Callout device for ttyR1
		    ...
 47 block	Parallel port ATAPI disk devices
		  0 = /dev/pf0		First parallel port ATAPI disk
		  1 = /dev/pf1		Second parallel port ATAPI disk
		  2 = /dev/pf2		Third parallel port ATAPI disk
		  3 = /dev/pf3		Fourth parallel port ATAPI disk

		This driver is intended for floppy disks and similar
		devices and hence does not support partitioning.

 48 char	SDL RISCom serial card
		  0 = /dev/ttyL0	First RISCom port
		  1 = /dev/ttyL1	Second RISCom port
		    ...
 48 block	Mylex DAC960 PCI RAID controller; first controller
		  0 = /dev/rd/c0d0	First disk, whole disk
		  8 = /dev/rd/c0d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c0d31	32nd disk, whole disk

		For partitions add:
		  0 = /dev/rd/c?d?	Whole disk
		  1 = /dev/rd/c?d?p1	First partition
		    ...
		  7 = /dev/rd/c?d?p7	Seventh partition

 49 char	SDL RISCom serial card - alternate devices
		  0 = /dev/cul0		Callout device for ttyL0
		  1 = /dev/cul1		Callout device for ttyL1
		    ...
 49 block	Mylex DAC960 PCI RAID controller; second controller
		  0 = /dev/rd/c1d0	First disk, whole disk
		  8 = /dev/rd/c1d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c1d31	32nd disk, whole disk

		Partitions are handled as for major 48.

 50 char	Reserved for GLINT

 50 block	Mylex DAC960 PCI RAID controller; third controller
		  0 = /dev/rd/c2d0	First disk, whole disk
		  8 = /dev/rd/c2d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c2d31	32nd disk, whole disk

 51 char	Baycom radio modem OR Radio Tech BIM-XXX-RS232 radio modem
		  0 = /dev/bc0		First Baycom radio modem
		  1 = /dev/bc1		Second Baycom radio modem
		    ...
 51 block	Mylex DAC960 PCI RAID controller; fourth controller
		  0 = /dev/rd/c3d0	First disk, whole disk
		  8 = /dev/rd/c3d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c3d31	32nd disk, whole disk

		Partitions are handled as for major 48.

 52 char	Spellcaster DataComm/BRI ISDN card
		  0 = /dev/dcbri0	First DataComm card
		  1 = /dev/dcbri1	Second DataComm card
		  2 = /dev/dcbri2	Third DataComm card
		  3 = /dev/dcbri3	Fourth DataComm card

 52 block	Mylex DAC960 PCI RAID controller; fifth controller
		  0 = /dev/rd/c4d0	First disk, whole disk
		  8 = /dev/rd/c4d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c4d31	32nd disk, whole disk

		Partitions are handled as for major 48.

 53 char	BDM interface for remote debugging MC683xx microcontrollers
		  0 = /dev/pd_bdm0	PD BDM interface on lp0
		  1 = /dev/pd_bdm1	PD BDM interface on lp1
		  2 = /dev/pd_bdm2	PD BDM interface on lp2
		  4 = /dev/icd_bdm0	ICD BDM interface on lp0
		  5 = /dev/icd_bdm1	ICD BDM interface on lp1
		  6 = /dev/icd_bdm2	ICD BDM interface on lp2

		This device is used for the interfacing to the MC683xx
		microcontrollers via Background Debug Mode by use of a
		Parallel Port interface. PD is the Motorola Public
		Domain Interface and ICD is the commercial interface
		by P&E.

 53 block	Mylex DAC960 PCI RAID controller; sixth controller
		  0 = /dev/rd/c5d0	First disk, whole disk
		  8 = /dev/rd/c5d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c5d31	32nd disk, whole disk

		Partitions are handled as for major 48.

 54 char	Electrocardiognosis Holter serial card
		  0 = /dev/holter0	First Holter port
		  1 = /dev/holter1	Second Holter port
		  2 = /dev/holter2	Third Holter port

		A custom serial card used by Electrocardiognosis SRL
		<mseritan@ottonel.pub.ro> to transfer data from Holter
		24-hour heart monitoring equipment.

 54 block	Mylex DAC960 PCI RAID controller; seventh controller
		  0 = /dev/rd/c6d0	First disk, whole disk
		  8 = /dev/rd/c6d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c6d31	32nd disk, whole disk

		Partitions are handled as for major 48.

 55 char	DSP56001 digital signal processor
		  0 = /dev/dsp56k	First DSP56001

 55 block	Mylex DAC960 PCI RAID controller; eighth controller
		  0 = /dev/rd/c7d0	First disk, whole disk
		  8 = /dev/rd/c7d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c7d31	32nd disk, whole disk

		Partitions are handled as for major 48.

 56 char	Apple Desktop Bus
		  0 = /dev/adb		ADB bus control

		Additional devices will be added to this number, all
		starting with /dev/adb.

 56 block	Fifth IDE hard disk/CD-ROM interface
		  0 = /dev/hdi		Master: whole disk (or CD-ROM)
		 64 = /dev/hdj		Slave: whole disk (or CD-ROM)

		Partitions are handled the same way as for the first
		interface (see major number 3).

 57 char	Hayes ESP serial card
		  0 = /dev/ttyP0	First ESP port
		  1 = /dev/ttyP1	Second ESP port
		    ...

 57 block	Sixth IDE hard disk/CD-ROM interface
		  0 = /dev/hdk		Master: whole disk (or CD-ROM)
		 64 = /dev/hdl		Slave: whole disk (or CD-ROM)

		Partitions are handled the same way as for the first
		interface (see major number 3).

 58 char	Hayes ESP serial card - alternate devices
		  0 = /dev/cup0		Callout device for ttyP0
		  1 = /dev/cup1		Callout device for ttyP1
		    ...

 58 block	Reserved for logical volume manager

 59 char	sf firewall package
		  0 = /dev/firewall	Communication with sf kernel module

 59 block	Generic PDA filesystem device
		  0 = /dev/pda0		First PDA device
		  1 = /dev/pda1		Second PDA device
		    ...

		The pda devices are used to mount filesystems on
		remote pda's (basically slow handheld machines with
		proprietary OS's and limited memory and storage
		running small fs translation drivers) through serial /
		IRDA / parallel links.

		NAMING CONFLICT -- PROPOSED REVISED NAME /dev/rpda0 etc

 60-63 char	LOCAL/EXPERIMENTAL USE

 60-63 block	LOCAL/EXPERIMENTAL USE
		Allocated for local/experimental use.  For devices not
		assigned official numbers, these ranges should be
		used in order to avoid conflicting with future assignments.

 64 char	ENskip kernel encryption package
		  0 = /dev/enskip	Communication with ENskip kernel module

 64 block	Scramdisk/DriveCrypt encrypted devices
		  0 = /dev/scramdisk/master    Master node for ioctls
		  1 = /dev/scramdisk/1         First encrypted device
		  2 = /dev/scramdisk/2         Second encrypted device
		  ...
		255 = /dev/scramdisk/255       255th encrypted device

		The filename of the encrypted container and the passwords
		are sent via ioctls (using the sdmount tool) to the master
		node which then activates them via one of the
		/dev/scramdisk/x nodes for loop mounting (all handled
		through the sdmount tool).

		Requested by: andy@scramdisklinux.org

 65 char	Sundance "plink" Transputer boards (obsolete, unused)
		  0 = /dev/plink0	First plink device
		  1 = /dev/plink1	Second plink device
		  2 = /dev/plink2	Third plink device
		  3 = /dev/plink3	Fourth plink device
		 64 = /dev/rplink0	First plink device, raw
		 65 = /dev/rplink1	Second plink device, raw
		 66 = /dev/rplink2	Third plink device, raw
		 67 = /dev/rplink3	Fourth plink device, raw
		128 = /dev/plink0d	First plink device, debug
		129 = /dev/plink1d	Second plink device, debug
		130 = /dev/plink2d	Third plink device, debug
		131 = /dev/plink3d	Fourth plink device, debug
		192 = /dev/rplink0d	First plink device, raw, debug
		193 = /dev/rplink1d	Second plink device, raw, debug
		194 = /dev/rplink2d	Third plink device, raw, debug
		195 = /dev/rplink3d	Fourth plink device, raw, debug

		This is a commercial driver; contact James Howes
		<jth@prosig.demon.co.uk> for information.

 65 block	SCSI disk devices (16-31)
		  0 = /dev/sdq		17th SCSI disk whole disk
		 16 = /dev/sdr		18th SCSI disk whole disk
		 32 = /dev/sds		19th SCSI disk whole disk
		    ...
		240 = /dev/sdaf		32nd SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 66 char	YARC PowerPC PCI coprocessor card
		  0 = /dev/yppcpci0	First YARC card
		  1 = /dev/yppcpci1	Second YARC card
		    ...

 66 block	SCSI disk devices (32-47)
		  0 = /dev/sdag		33th SCSI disk whole disk
		 16 = /dev/sdah		34th SCSI disk whole disk
		 32 = /dev/sdai		35th SCSI disk whole disk
		    ...
		240 = /dev/sdav		48nd SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 67 char	Coda network file system
		  0 = /dev/cfs0		Coda cache manager

		See http://www.coda.cs.cmu.edu for information about Coda.

 67 block	SCSI disk devices (48-63)
		  0 = /dev/sdaw		49th SCSI disk whole disk
		 16 = /dev/sdax		50th SCSI disk whole disk
		 32 = /dev/sday		51st SCSI disk whole disk
		    ...
		240 = /dev/sdbl		64th SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 68 char	CAPI 2.0 interface
		  0 = /dev/capi20	Control device
		  1 = /dev/capi20.00	First CAPI 2.0 application
		  2 = /dev/capi20.01	Second CAPI 2.0 application
		    ...
		 20 = /dev/capi20.19	19th CAPI 2.0 application

		ISDN CAPI 2.0 driver for use with CAPI 2.0
		applications; currently supports the AVM B1 card.

 68 block	SCSI disk devices (64-79)
		  0 = /dev/sdbm		65th SCSI disk whole disk
		 16 = /dev/sdbn		66th SCSI disk whole disk
		 32 = /dev/sdbo		67th SCSI disk whole disk
		    ...
		240 = /dev/sdcb		80th SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 69 char	MA16 numeric accelerator card
		  0 = /dev/ma16		Board memory access

 69 block	SCSI disk devices (80-95)
		  0 = /dev/sdcc		81st SCSI disk whole disk
		 16 = /dev/sdcd		82nd SCSI disk whole disk
		 32 = /dev/sdce		83th SCSI disk whole disk
		    ...
		240 = /dev/sdcr		96th SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 70 char	SpellCaster Protocol Services Interface
		  0 = /dev/apscfg	Configuration interface
		  1 = /dev/apsauth	Authentication interface
		  2 = /dev/apslog	Logging interface
		  3 = /dev/apsdbg	Debugging interface
		 64 = /dev/apsisdn	ISDN command interface
		 65 = /dev/apsasync	Async command interface
		128 = /dev/apsmon	Monitor interface

 70 block	SCSI disk devices (96-111)
		  0 = /dev/sdcs		97th SCSI disk whole disk
		 16 = /dev/sdct		98th SCSI disk whole disk
		 32 = /dev/sdcu		99th SCSI disk whole disk
		    ...
		240 = /dev/sddh		112nd SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 71 char	Computone IntelliPort II serial card
		  0 = /dev/ttyF0	IntelliPort II board 0, port 0
		  1 = /dev/ttyF1	IntelliPort II board 0, port 1
		    ...
		 63 = /dev/ttyF63	IntelliPort II board 0, port 63
		 64 = /dev/ttyF64	IntelliPort II board 1, port 0
		 65 = /dev/ttyF65	IntelliPort II board 1, port 1
		    ...
		127 = /dev/ttyF127	IntelliPort II board 1, port 63
		128 = /dev/ttyF128	IntelliPort II board 2, port 0
		129 = /dev/ttyF129	IntelliPort II board 2, port 1
		    ...
		191 = /dev/ttyF191	IntelliPort II board 2, port 63
		192 = /dev/ttyF192	IntelliPort II board 3, port 0
		193 = /dev/ttyF193	IntelliPort II board 3, port 1
		    ...
		255 = /dev/ttyF255	IntelliPort II board 3, port 63

 71 block	SCSI disk devices (112-127)
		  0 = /dev/sddi		113th SCSI disk whole disk
		 16 = /dev/sddj		114th SCSI disk whole disk
		 32 = /dev/sddk		115th SCSI disk whole disk
		    ...
		240 = /dev/sddx		128th SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 72 char	Computone IntelliPort II serial card - alternate devices
		  0 = /dev/cuf0		Callout device for ttyF0
		  1 = /dev/cuf1		Callout device for ttyF1
		    ...
		 63 = /dev/cuf63	Callout device for ttyF63
		 64 = /dev/cuf64	Callout device for ttyF64
		 65 = /dev/cuf65	Callout device for ttyF65
		    ...
		127 = /dev/cuf127	Callout device for ttyF127
		128 = /dev/cuf128	Callout device for ttyF128
		129 = /dev/cuf129	Callout device for ttyF129
		    ...
		191 = /dev/cuf191	Callout device for ttyF191
		192 = /dev/cuf192	Callout device for ttyF192
		193 = /dev/cuf193	Callout device for ttyF193
		    ...
		255 = /dev/cuf255	Callout device for ttyF255

 72 block	Compaq Intelligent Drive Array, first controller
		  0 = /dev/ida/c0d0	First logical drive whole disk
		 16 = /dev/ida/c0d1	Second logical drive whole disk
		    ...
		240 = /dev/ida/c0d15	16th logical drive whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

 73 char	Computone IntelliPort II serial card - control devices
		  0 = /dev/ip2ipl0	Loadware device for board 0
		  1 = /dev/ip2stat0	Status device for board 0
		  4 = /dev/ip2ipl1	Loadware device for board 1
		  5 = /dev/ip2stat1	Status device for board 1
		  8 = /dev/ip2ipl2	Loadware device for board 2
		  9 = /dev/ip2stat2	Status device for board 2
		 12 = /dev/ip2ipl3	Loadware device for board 3
		 13 = /dev/ip2stat3	Status device for board 3

 73 block	Compaq Intelligent Drive Array, second controller
		  0 = /dev/ida/c1d0	First logical drive whole disk
		 16 = /dev/ida/c1d1	Second logical drive whole disk
		    ...
		240 = /dev/ida/c1d15	16th logical drive whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

 74 char	SCI bridge
		  0 = /dev/SCI/0	SCI device 0
		  1 = /dev/SCI/1	SCI device 1
		    ...

		Currently for Dolphin Interconnect Solutions' PCI-SCI
		bridge.

 74 block	Compaq Intelligent Drive Array, third controller
		  0 = /dev/ida/c2d0	First logical drive whole disk
		 16 = /dev/ida/c2d1	Second logical drive whole disk
		    ...
		240 = /dev/ida/c2d15	16th logical drive whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

 75 char	Specialix IO8+ serial card
		  0 = /dev/ttyW0	First IO8+ port, first card
		  1 = /dev/ttyW1	Second IO8+ port, first card
		    ...
		  8 = /dev/ttyW8	First IO8+ port, second card
		    ...

 75 block	Compaq Intelligent Drive Array, fourth controller
		  0 = /dev/ida/c3d0	First logical drive whole disk
		 16 = /dev/ida/c3d1	Second logical drive whole disk
		    ...
		240 = /dev/ida/c3d15	16th logical drive whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

 76 char	Specialix IO8+ serial card - alternate devices
		  0 = /dev/cuw0		Callout device for ttyW0
		  1 = /dev/cuw1		Callout device for ttyW1
		    ...
		  8 = /dev/cuw8		Callout device for ttyW8
		    ...

 76 block	Compaq Intelligent Drive Array, fifth controller
		  0 = /dev/ida/c4d0	First logical drive whole disk
		 16 = /dev/ida/c4d1	Second logical drive whole disk
		    ...
		240 = /dev/ida/c4d15	16th logical drive whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.


 77 char	ComScire Quantum Noise Generator
		  0 = /dev/qng		ComScire Quantum Noise Generator

 77 block	Compaq Intelligent Drive Array, sixth controller
		  0 = /dev/ida/c5d0	First logical drive whole disk
		 16 = /dev/ida/c5d1	Second logical drive whole disk
		    ...
		240 = /dev/ida/c5d15	16th logical drive whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

 78 char	PAM Software's multimodem boards
		  0 = /dev/ttyM0	First PAM modem
		  1 = /dev/ttyM1	Second PAM modem
		    ...

 78 block	Compaq Intelligent Drive Array, seventh controller
		  0 = /dev/ida/c6d0	First logical drive whole disk
		 16 = /dev/ida/c6d1	Second logical drive whole disk
		    ...
		240 = /dev/ida/c6d15	16th logical drive whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

 79 char	PAM Software's multimodem boards - alternate devices
		  0 = /dev/cum0		Callout device for ttyM0
		  1 = /dev/cum1		Callout device for ttyM1
		    ...

 79 block	Compaq Intelligent Drive Array, eighth controller
		  0 = /dev/ida/c7d0	First logical drive whole disk
		 16 = /dev/ida/c7d1	Second logical drive whole disk
		    ...
		240 = /dev/ida/c715	16th logical drive whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

 80 char	Photometrics AT200 CCD camera
		  0 = /dev/at200	Photometrics AT200 CCD camera

 80 block	I2O hard disk
		  0 = /dev/i2o/hda	First I2O hard disk, whole disk
		 16 = /dev/i2o/hdb	Second I2O hard disk, whole disk
		    ...
		240 = /dev/i2o/hdp	16th I2O hard disk, whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 81 char	video4linux
		  0 = /dev/video0	Video capture/overlay device
		    ...
		 63 = /dev/video63	Video capture/overlay device
		 64 = /dev/radio0	Radio device
		    ...
		127 = /dev/radio63	Radio device
		224 = /dev/vbi0		Vertical blank interrupt
		    ...
		255 = /dev/vbi31	Vertical blank interrupt

 81 block	I2O hard disk
		  0 = /dev/i2o/hdq	17th I2O hard disk, whole disk
		 16 = /dev/i2o/hdr	18th I2O hard disk, whole disk
		    ...
		240 = /dev/i2o/hdaf	32nd I2O hard disk, whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 82 char	WiNRADiO communications receiver card
		  0 = /dev/winradio0	First WiNRADiO card
		  1 = /dev/winradio1	Second WiNRADiO card
		    ...

		The driver and documentation may be obtained from
		http://www.winradio.com/

 82 block	I2O hard disk
		  0 = /dev/i2o/hdag	33rd I2O hard disk, whole disk
		 16 = /dev/i2o/hdah	34th I2O hard disk, whole disk
		    ...
		240 = /dev/i2o/hdav	48th I2O hard disk, whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 83 char	Matrox mga_vid video driver
 		 0 = /dev/mga_vid0	1st video card
		 1 = /dev/mga_vid1	2nd video card
		 2 = /dev/mga_vid2	3rd video card
		  ...
	        15 = /dev/mga_vid15	16th video card

 83 block	I2O hard disk
		  0 = /dev/i2o/hdaw	49th I2O hard disk, whole disk
		 16 = /dev/i2o/hdax	50th I2O hard disk, whole disk
		    ...
		240 = /dev/i2o/hdbl	64th I2O hard disk, whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 84 char	Ikon 1011[57] Versatec Greensheet Interface
		  0 = /dev/ihcp0	First Greensheet port
		  1 = /dev/ihcp1	Second Greensheet port

 84 block	I2O hard disk
		  0 = /dev/i2o/hdbm	65th I2O hard disk, whole disk
		 16 = /dev/i2o/hdbn	66th I2O hard disk, whole disk
		    ...
		240 = /dev/i2o/hdcb	80th I2O hard disk, whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 85 char	Linux/SGI shared memory input queue
		  0 = /dev/shmiq	Master shared input queue
		  1 = /dev/qcntl0	First device pushed
		  2 = /dev/qcntl1	Second device pushed
		    ...

 85 block	I2O hard disk
		  0 = /dev/i2o/hdcc	81st I2O hard disk, whole disk
		 16 = /dev/i2o/hdcd	82nd I2O hard disk, whole disk
		    ...
		240 = /dev/i2o/hdcr	96th I2O hard disk, whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 86 char	SCSI media changer
		  0 = /dev/sch0		First SCSI media changer
		  1 = /dev/sch1		Second SCSI media changer
		    ...

 86 block	I2O hard disk
		  0 = /dev/i2o/hdcs	97th I2O hard disk, whole disk
		 16 = /dev/i2o/hdct	98th I2O hard disk, whole disk
		    ...
		240 = /dev/i2o/hddh	112th I2O hard disk, whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 87 char	Sony Control-A1 stereo control bus
		  0 = /dev/controla0	First device on chain
		  1 = /dev/controla1	Second device on chain
		    ...

 87 block	I2O hard disk
		  0 = /dev/i2o/hddi	113rd I2O hard disk, whole disk
		 16 = /dev/i2o/hddj	114th I2O hard disk, whole disk
		    ...
		240 = /dev/i2o/hddx	128th I2O hard disk, whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 88 char	COMX synchronous serial card
		  0 = /dev/comx0	COMX channel 0
		  1 = /dev/comx1	COMX channel 1
		    ...

 88 block	Seventh IDE hard disk/CD-ROM interface
		  0 = /dev/hdm		Master: whole disk (or CD-ROM)
		 64 = /dev/hdn		Slave: whole disk (or CD-ROM)

		Partitions are handled the same way as for the first
		interface (see major number 3).

 89 char	I2C bus interface
		  0 = /dev/i2c-0	First I2C adapter
		  1 = /dev/i2c-1	Second I2C adapter
		    ...

 89 block	Eighth IDE hard disk/CD-ROM interface
		  0 = /dev/hdo		Master: whole disk (or CD-ROM)
		 64 = /dev/hdp		Slave: whole disk (or CD-ROM)

		Partitions are handled the same way as for the first
		interface (see major number 3).

 90 char	Memory Technology Device (RAM, ROM, Flash)
		  0 = /dev/mtd0		First MTD (rw)
		  1 = /dev/mtdr0	First MTD (ro)
		    ...
		 30 = /dev/mtd15	16th MTD (rw)
		 31 = /dev/mtdr15	16th MTD (ro)

 90 block	Ninth IDE hard disk/CD-ROM interface
		  0 = /dev/hdq		Master: whole disk (or CD-ROM)
		 64 = /dev/hdr		Slave: whole disk (or CD-ROM)

		Partitions are handled the same way as for the first
		interface (see major number 3).

 91 char	CAN-Bus devices
		  0 = /dev/can0		First CAN-Bus controller
		  1 = /dev/can1		Second CAN-Bus controller
		    ...

 91 block	Tenth IDE hard disk/CD-ROM interface
		  0 = /dev/hds		Master: whole disk (or CD-ROM)
		 64 = /dev/hdt		Slave: whole disk (or CD-ROM)

		Partitions are handled the same way as for the first
		interface (see major number 3).

 92 char	Reserved for ith Kommunikationstechnik MIC ISDN card

 92 block	PPDD encrypted disk driver
		  0 = /dev/ppdd0	First encrypted disk
		  1 = /dev/ppdd1	Second encrypted disk
		    ...

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

 93 char

 93 block	NAND Flash Translation Layer filesystem
		  0 = /dev/nftla	First NFTL layer
		 16 = /dev/nftlb	Second NFTL layer
		    ...
		240 = /dev/nftlp	16th NTFL layer

 94 char

 94 block	IBM S/390 DASD block storage
    		  0 = /dev/dasda First DASD device, major
    		  1 = /dev/dasda1 First DASD device, block 1
	    	  2 = /dev/dasda2 First DASD device, block 2
    		  3 = /dev/dasda3 First DASD device, block 3
    		  4 = /dev/dasdb Second DASD device, major
    		  5 = /dev/dasdb1 Second DASD device, block 1
    		  6 = /dev/dasdb2 Second DASD device, block 2
    		  7 = /dev/dasdb3 Second DASD device, block 3
		    ...

 95 char	IP filter
		  0 = /dev/ipl		Filter control device/log file
		  1 = /dev/ipnat	NAT control device/log file
		  2 = /dev/ipstate	State information log file
		  3 = /dev/ipauth	Authentication control device/log file
		    ...

 96 char	Parallel port ATAPI tape devices
		  0 = /dev/pt0		First parallel port ATAPI tape
		  1 = /dev/pt1		Second parallel port ATAPI tape
		    ...
		128 = /dev/npt0		First p.p. ATAPI tape, no rewind
		129 = /dev/npt1		Second p.p. ATAPI tape, no rewind
		    ...

 96 block	Inverse NAND Flash Translation Layer
		  0 = /dev/inftla First INFTL layer
		 16 = /dev/inftlb Second INFTL layer
		    ...
		240 = /dev/inftlp	16th INTFL layer

 97 char	Parallel port generic ATAPI interface
		  0 = /dev/pg0		First parallel port ATAPI device
		  1 = /dev/pg1		Second parallel port ATAPI device
		  2 = /dev/pg2		Third parallel port ATAPI device
		  3 = /dev/pg3		Fourth parallel port ATAPI device

		These devices support the same API as the generic SCSI
		devices.

 98 char	Control and Measurement Device (comedi)
		  0 = /dev/comedi0	First comedi device
		  1 = /dev/comedi1	Second comedi device
		    ...

		See http://stm.lbl.gov/comedi.

 98 block	User-mode virtual block device
		  0 = /dev/ubda		First user-mode block device
		 16 = /dev/udbb		Second user-mode block device
		    ...

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

		This device is used by the user-mode virtual kernel port.

 99 char	Raw parallel ports
		  0 = /dev/parport0	First parallel port
		  1 = /dev/parport1	Second parallel port
		    ...

 99 block	JavaStation flash disk
		  0 = /dev/jsfd		JavaStation flash disk

100 char	Telephony for Linux
		  0 = /dev/phone0	First telephony device
		  1 = /dev/phone1	Second telephony device
		    ...

101 char	Motorola DSP 56xxx board
		  0 = /dev/mdspstat	Status information
		  1 = /dev/mdsp1	First DSP board I/O controls
		    ...
		 16 = /dev/mdsp16	16th DSP board I/O controls

101 block	AMI HyperDisk RAID controller
		  0 = /dev/amiraid/ar0	First array whole disk
		 16 = /dev/amiraid/ar1	Second array whole disk
		    ...
		240 = /dev/amiraid/ar15	16th array whole disk

		For each device, partitions are added as:
		  0 = /dev/amiraid/ar?	  Whole disk
		  1 = /dev/amiraid/ar?p1  First partition
		  2 = /dev/amiraid/ar?p2  Second partition
		    ...
		 15 = /dev/amiraid/ar?p15 15th partition

102 char

102 block	Compressed block device
		  0 = /dev/cbd/a	First compressed block device, whole device
		 16 = /dev/cbd/b	Second compressed block device, whole device
		    ...
		240 = /dev/cbd/p	16th compressed block device, whole device

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

103 char	Arla network file system
		  0 = /dev/nnpfs0	First NNPFS device
		  1 = /dev/nnpfs1	Second NNPFS device

		Arla is a free clone of the Andrew File System, AFS.
		The NNPFS device gives user mode filesystem
		implementations a kernel presence for caching and easy
		mounting.  For more information about the project,
		write to <arla-drinkers@stacken.kth.se> or see
		http://www.stacken.kth.se/project/arla/

103 block	Audit device
		  0 = /dev/audit	Audit device

104 char	Flash BIOS support

104 block	Compaq Next Generation Drive Array, first controller
		  0 = /dev/cciss/c0d0	First logical drive, whole disk
		 16 = /dev/cciss/c0d1	Second logical drive, whole disk
		    ...
		240 = /dev/cciss/c0d15	16th logical drive, whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

105 char	Comtrol VS-1000 serial controller
		  0 = /dev/ttyV0	First VS-1000 port
		  1 = /dev/ttyV1	Second VS-1000 port
		    ...

105 block	Compaq Next Generation Drive Array, second controller
		  0 = /dev/cciss/c1d0	First logical drive, whole disk
		 16 = /dev/cciss/c1d1	Second logical drive, whole disk
		    ...
		240 = /dev/cciss/c1d15	16th logical drive, whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

106 char	Comtrol VS-1000 serial controller - alternate devices
		  0 = /dev/cuv0		First VS-1000 port
		  1 = /dev/cuv1		Second VS-1000 port
		    ...

106 block	Compaq Next Generation Drive Array, third controller
		  0 = /dev/cciss/c2d0	First logical drive, whole disk
		 16 = /dev/cciss/c2d1	Second logical drive, whole disk
		    ...
		240 = /dev/cciss/c2d15	16th logical drive, whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

107 char	3Dfx Voodoo Graphics device
		  0 = /dev/3dfx		Primary 3Dfx graphics device

107 block	Compaq Next Generation Drive Array, fourth controller
		  0 = /dev/cciss/c3d0	First logical drive, whole disk
		 16 = /dev/cciss/c3d1	Second logical drive, whole disk
		    ...
		240 = /dev/cciss/c3d15	16th logical drive, whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

108 char	Device independent PPP interface
		  0 = /dev/ppp		Device independent PPP interface

108 block	Compaq Next Generation Drive Array, fifth controller
		  0 = /dev/cciss/c4d0	First logical drive, whole disk
		 16 = /dev/cciss/c4d1	Second logical drive, whole disk
		    ...
		240 = /dev/cciss/c4d15	16th logical drive, whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

109 char	Reserved for logical volume manager

109 block	Compaq Next Generation Drive Array, sixth controller
		  0 = /dev/cciss/c5d0	First logical drive, whole disk
		 16 = /dev/cciss/c5d1	Second logical drive, whole disk
		    ...
		240 = /dev/cciss/c5d15	16th logical drive, whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

110 char	miroMEDIA Surround board
		  0 = /dev/srnd0	First miroMEDIA Surround board
		  1 = /dev/srnd1	Second miroMEDIA Surround board
		    ...

110 block	Compaq Next Generation Drive Array, seventh controller
		  0 = /dev/cciss/c6d0	First logical drive, whole disk
		 16 = /dev/cciss/c6d1	Second logical drive, whole disk
		    ...
		240 = /dev/cciss/c6d15	16th logical drive, whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

111 char

111 block	Compaq Next Generation Drive Array, eighth controller
		  0 = /dev/cciss/c7d0	First logical drive, whole disk
		 16 = /dev/cciss/c7d1	Second logical drive, whole disk
		    ...
		240 = /dev/cciss/c7d15	16th logical drive, whole disk

		Partitions are handled the same way as for Mylex
		DAC960 (see major number 48) except that the limit on
		partitions is 15.

112 char	ISI serial card
		  0 = /dev/ttyM0	First ISI port
		  1 = /dev/ttyM1	Second ISI port
		    ...

		There is currently a device-naming conflict between
		these and PAM multimodems (major 78).

112 block	IBM iSeries virtual disk
		  0 = /dev/iseries/vda	First virtual disk, whole disk
		  8 = /dev/iseries/vdb	Second virtual disk, whole disk
		    ...
		200 = /dev/iseries/vdz	26th virtual disk, whole disk
		208 = /dev/iseries/vdaa	27th virtual disk, whole disk
		    ...
		248 = /dev/iseries/vdaf	32nd virtual disk, whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 7.

113 char	ISI serial card - alternate devices
		  0 = /dev/cum0		Callout device for ttyM0
		  1 = /dev/cum1		Callout device for ttyM1
		    ...

113 block	IBM iSeries virtual CD-ROM
		  0 = /dev/iseries/vcda	First virtual CD-ROM
		  1 = /dev/iseries/vcdb	Second virtual CD-ROM
		    ...

114 char	Picture Elements ISE board
		  0 = /dev/ise0		First ISE board
		  1 = /dev/ise1		Second ISE board
		    ...
		128 = /dev/isex0	Control node for first ISE board
		129 = /dev/isex1	Control node for second ISE board
		    ...

		The ISE board is an embedded computer, optimized for
		image processing. The /dev/iseN nodes are the general
		I/O access to the board, the /dev/isex0 nodes command
		nodes used to control the board.

114 block       IDE BIOS powered software RAID interfaces such as the
                Promise Fastrak

                  0 = /dev/ataraid/d0
                  1 = /dev/ataraid/d0p1
                  2 = /dev/ataraid/d0p2
                  ...
                 16 = /dev/ataraid/d1
                 17 = /dev/ataraid/d1p1
                 18 = /dev/ataraid/d1p2
                  ...
                255 = /dev/ataraid/d15p15

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

115 char	TI link cable devices (115 was formerly the console driver speaker)
		  0 = /dev/tipar0    Parallel cable on first parallel port
		  ...
		  7 = /dev/tipar7    Parallel cable on seventh parallel port

		  8 = /dev/tiser0    Serial cable on first serial port
		  ...
		 15 = /dev/tiser7    Serial cable on seventh serial port

		 16 = /dev/tiusb0    First USB cable
		  ...
		 47 = /dev/tiusb31   32nd USB cable

115 block       NetWare (NWFS) Devices (0-255)

                The NWFS (NetWare) devices are used to present a
                collection of NetWare Mirror Groups or NetWare
                Partitions as a logical storage segment for
                use in mounting NetWare volumes.  A maximum of
                256 NetWare volumes can be supported in a single
                machine.

                http://cgfa.telepac.pt/ftp2/kernel.org/linux/kernel/people/jmerkey/nwfs/

                0 = /dev/nwfs/v0    First NetWare (NWFS) Logical Volume
                1 = /dev/nwfs/v1    Second NetWare (NWFS) Logical Volume
                2 = /dev/nwfs/v2    Third NetWare (NWFS) Logical Volume
                      ...
                255 = /dev/nwfs/v255    Last NetWare (NWFS) Logical Volume

116 char	Advanced Linux Sound Driver (ALSA)

116 block       MicroMemory battery backed RAM adapter (NVRAM)
                Supports 16 boards, 15 partitions each.
                Requested by neilb at cse.unsw.edu.au.

		 0 = /dev/umem/d0      Whole of first board
		 1 = /dev/umem/d0p1    First partition of first board
		 2 = /dev/umem/d0p2    Second partition of first board
		15 = /dev/umem/d0p15   15th partition of first board

		16 = /dev/umem/d1      Whole of second board
		17 = /dev/umem/d1p1    First partition of second board
		    ...
		255= /dev/umem/d15p15  15th partition of 16th board.

117 char	COSA/SRP synchronous serial card
		  0 = /dev/cosa0c0	1st board, 1st channel
		  1 = /dev/cosa0c1	1st board, 2nd channel
		    ...
		 16 = /dev/cosa1c0	2nd board, 1st channel
		 17 = /dev/cosa1c1	2nd board, 2nd channel
		    ...

117 block       Enterprise Volume Management System (EVMS)

                The EVMS driver uses a layered, plug-in model to provide
                unparalleled flexibility and extensibility in managing
                storage.  This allows for easy expansion or customization
                of various levels of volume management.  Requested by
                Mark Peloquin (peloquin at us.ibm.com).

                Note: EVMS populates and manages all the devnodes in
                /dev/evms.

                http://sf.net/projects/evms

                  0 = /dev/evms/block_device   EVMS block device
                  1 = /dev/evms/legacyname1    First EVMS legacy device
                  2 = /dev/evms/legacyname2    Second EVMS legacy device
                    ...
                    Both ranges can grow (down or up) until they meet.
                    ...
                254 = /dev/evms/EVMSname2      Second EVMS native device
                255 = /dev/evms/EVMSname1      First EVMS native device

                Note: legacyname(s) are derived from the normal legacy
                device names.  For example, /dev/hda5 would become
                /dev/evms/hda5.

118 char	IBM Cryptographic Accelerator
		  0 = /dev/ica	Virtual interface to all IBM Crypto Accelerators
		  1 = /dev/ica0	IBMCA Device 0
		  2 = /dev/ica1	IBMCA Device 1
		    ...

119 char	VMware virtual network control
		  0 = /dev/vnet0	1st virtual network
		  1 = /dev/vnet1	2nd virtual network
		    ...

120-127 char	LOCAL/EXPERIMENTAL USE

120-127 block	LOCAL/EXPERIMENTAL USE
		Allocated for local/experimental use.  For devices not
		assigned official numbers, these ranges should be
		used in order to avoid conflicting with future assignments.

128-135 char	Unix98 PTY masters

		These devices should not have corresponding device
		nodes; instead they should be accessed through the
		/dev/ptmx cloning interface.

128 block       SCSI disk devices (128-143)
                  0 = /dev/sddy         129th SCSI disk whole disk
                 16 = /dev/sddz         130th SCSI disk whole disk
                 32 = /dev/sdea         131th SCSI disk whole disk
                    ...
                240 = /dev/sden         144th SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

129 block       SCSI disk devices (144-159)
                  0 = /dev/sdeo         145th SCSI disk whole disk
                 16 = /dev/sdep         146th SCSI disk whole disk
                 32 = /dev/sdeq         147th SCSI disk whole disk
                    ...
                240 = /dev/sdfd         160th SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

130 char 	(Misc devices)

130 block       SCSI disk devices (160-175)
                  0 = /dev/sdfe         161st SCSI disk whole disk
                 16 = /dev/sdff         162nd SCSI disk whole disk
                 32 = /dev/sdfg         163rd SCSI disk whole disk
                    ...
                240 = /dev/sdft         176th SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

131 block       SCSI disk devices (176-191)
                  0 = /dev/sdfu         177th SCSI disk whole disk
                 16 = /dev/sdfv         178th SCSI disk whole disk
                 32 = /dev/sdfw         179th SCSI disk whole disk
                    ...
                240 = /dev/sdgj         192nd SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

132 block       SCSI disk devices (192-207)
                  0 = /dev/sdgk         193rd SCSI disk whole disk
                 16 = /dev/sdgl         194th SCSI disk whole disk
                 32 = /dev/sdgm         195th SCSI disk whole disk
                    ...
                240 = /dev/sdgz         208th SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

133 block       SCSI disk devices (208-223)
                  0 = /dev/sdha         209th SCSI disk whole disk
                 16 = /dev/sdhb         210th SCSI disk whole disk
                 32 = /dev/sdhc         211th SCSI disk whole disk
                    ...
                240 = /dev/sdhp         224th SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

134 block       SCSI disk devices (224-239)
                  0 = /dev/sdhq         225th SCSI disk whole disk
                 16 = /dev/sdhr         226th SCSI disk whole disk
                 32 = /dev/sdhs         227th SCSI disk whole disk
                    ...
                240 = /dev/sdif         240th SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

135 block       SCSI disk devices (240-255)
                  0 = /dev/sdig         241st SCSI disk whole disk
                 16 = /dev/sdih         242nd SCSI disk whole disk
                 32 = /dev/sdih         243rd SCSI disk whole disk
                    ...
                240 = /dev/sdiv         256th SCSI disk whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

136-143 char	Unix98 PTY slaves
		  0 = /dev/pts/0	First Unix98 pseudo-TTY
		  1 = /dev/pts/1	Second Unix98 pseudo-TTY
		    ...

		These device nodes are automatically generated with
		the proper permissions and modes by mounting the
		devpts filesystem onto /dev/pts with the appropriate
		mount options (distribution dependent, however, on
		*most* distributions the appropriate options are
		"mode=0620,gid=<gid of the "tty" group>".)

136 block	Mylex DAC960 PCI RAID controller; ninth controller
		  0 = /dev/rd/c8d0	First disk, whole disk
		  8 = /dev/rd/c8d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c8d31	32nd disk, whole disk

		Partitions are handled as for major 48.

137 block	Mylex DAC960 PCI RAID controller; tenth controller
		  0 = /dev/rd/c9d0	First disk, whole disk
		  8 = /dev/rd/c9d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c9d31	32nd disk, whole disk

		Partitions are handled as for major 48.

138 block	Mylex DAC960 PCI RAID controller; eleventh controller
		  0 = /dev/rd/c10d0	First disk, whole disk
		  8 = /dev/rd/c10d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c10d31	32nd disk, whole disk

		Partitions are handled as for major 48.

139 block	Mylex DAC960 PCI RAID controller; twelfth controller
		  0 = /dev/rd/c11d0	First disk, whole disk
		  8 = /dev/rd/c11d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c11d31	32nd disk, whole disk

		Partitions are handled as for major 48.

140 block	Mylex DAC960 PCI RAID controller; thirteenth controller
		  0 = /dev/rd/c12d0	First disk, whole disk
		  8 = /dev/rd/c12d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c12d31	32nd disk, whole disk

		Partitions are handled as for major 48.

141 block	Mylex DAC960 PCI RAID controller; fourteenth controller
		  0 = /dev/rd/c13d0	First disk, whole disk
		  8 = /dev/rd/c13d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c13d31	32nd disk, whole disk

		Partitions are handled as for major 48.

142 block	Mylex DAC960 PCI RAID controller; fifteenth controller
		  0 = /dev/rd/c14d0	First disk, whole disk
		  8 = /dev/rd/c14d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c14d31	32nd disk, whole disk

		Partitions are handled as for major 48.

143 block	Mylex DAC960 PCI RAID controller; sixteenth controller
		  0 = /dev/rd/c15d0	First disk, whole disk
		  8 = /dev/rd/c15d1	Second disk, whole disk
		    ...
		248 = /dev/rd/c15d31	32nd disk, whole disk

		Partitions are handled as for major 48.

144 char	Encapsulated PPP
		  0 = /dev/pppox0	First PPP over Ethernet
		    ...
		 63 = /dev/pppox63	64th PPP over Ethernet

		This is primarily used for ADSL.

		The SST 5136-DN DeviceNet interface driver has been
		relocated to major 183 due to an unfortunate conflict.

144 block	Expansion Area #1 for more non-device (e.g. NFS) mounts
		  0 = mounted device 256
		255 = mounted device 511

145 char	SAM9407-based soundcard
		  0 = /dev/sam0_mixer
		  1 = /dev/sam0_sequencer
		  2 = /dev/sam0_midi00
		  3 = /dev/sam0_dsp
		  4 = /dev/sam0_audio
		  6 = /dev/sam0_sndstat
		 18 = /dev/sam0_midi01
		 34 = /dev/sam0_midi02
		 50 = /dev/sam0_midi03
		 64 = /dev/sam1_mixer
		    ...
		128 = /dev/sam2_mixer
		    ...
		192 = /dev/sam3_mixer
		    ...

		Device functions match OSS, but offer a number of
		addons, which are sam9407 specific.  OSS can be
		operated simultaneously, taking care of the codec.

145 block	Expansion Area #2 for more non-device (e.g. NFS) mounts
		  0 = mounted device 512
		255 = mounted device 767

146 char	SYSTRAM SCRAMNet mirrored-memory network
		  0 = /dev/scramnet0	First SCRAMNet device
		  1 = /dev/scramnet1	Second SCRAMNet device
		    ...

146 block	Expansion Area #3 for more non-device (e.g. NFS) mounts
		  0 = mounted device 768
		255 = mounted device 1023

147 char	Aureal Semiconductor Vortex Audio device
		  0 = /dev/aureal0	First Aureal Vortex
		  1 = /dev/aureal1	Second Aureal Vortex
		    ...

147 block	Distributed Replicated Block Device (DRBD)
		  0 = /dev/drbd0	First DRBD device
		  1 = /dev/drbd1	Second DRBD device
		    ...

148 char	Technology Concepts serial card
		  0 = /dev/ttyT0	First TCL port
		  1 = /dev/ttyT1	Second TCL port
		    ...

149 char	Technology Concepts serial card - alternate devices
		  0 = /dev/cut0		Callout device for ttyT0
		  1 = /dev/cut0		Callout device for ttyT1
		    ...

150 char	Real-Time Linux FIFOs
		  0 = /dev/rtf0		First RTLinux FIFO
		  1 = /dev/rtf1		Second RTLinux FIFO
		    ...

151 char	DPT I2O SmartRaid V controller
		  0 = /dev/dpti0	First DPT I2O adapter
		  1 = /dev/dpti1	Second DPT I2O adapter
		    ...

152 char	EtherDrive Control Device
		  0 = /dev/etherd/ctl	Connect/Disconnect an EtherDrive
		  1 = /dev/etherd/err	Monitor errors
		  2 = /dev/etherd/raw	Raw AoE packet monitor

152 block	EtherDrive Block Devices
		  0 = /dev/etherd/0	EtherDrive 0
		    ...
		255 = /dev/etherd/255	EtherDrive 255

153 char	SPI Bus Interface (sometimes referred to as MicroWire)
		  0 = /dev/spi0		First SPI device on the bus
		  1 = /dev/spi1		Second SPI device on the bus
		    ...
		 15 = /dev/spi15	Sixteenth SPI device on the bus

153 block	Enhanced Metadisk RAID (EMD) storage units
		  0 = /dev/emd/0	First unit
		  1 = /dev/emd/0p1	Partition 1 on First unit
		  2 = /dev/emd/0p2	Partition 2 on First unit
		    ...
		 15 = /dev/emd/0p15	Partition 15 on First unit

		 16 = /dev/emd/1	Second unit
		 32 = /dev/emd/2	Third unit
		    ...
		240 = /dev/emd/15	Sixteenth unit

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 15.

154 char	Specialix RIO serial card
		  0 = /dev/ttySR0	First RIO port
		    ...
		255 = /dev/ttySR255	256th RIO port

155 char	Specialix RIO serial card - alternate devices
		  0 = /dev/cusr0	Callout device for ttySR0
		    ...
		255 = /dev/cusr255	Callout device for ttySR255

156 char	Specialix RIO serial card
		  0 = /dev/ttySR256	257th RIO port
		    ...
		255 = /dev/ttySR511	512th RIO port

157 char	Specialix RIO serial card - alternate devices
		  0 = /dev/cusr256	Callout device for ttySR256
		    ...
		255 = /dev/cusr511	Callout device for ttySR511

158 char	Dialogic GammaLink fax driver
		  0 = /dev/gfax0	GammaLink channel 0
		  1 = /dev/gfax1	GammaLink channel 1
		    ...

159 char	RESERVED

159 block	RESERVED

160 char	General Purpose Instrument Bus (GPIB)
		  0 = /dev/gpib0	First GPIB bus
		  1 = /dev/gpib1	Second GPIB bus
		    ...

160 block       Carmel 8-port SATA Disks on First Controller
		  0 = /dev/carmel/0     SATA disk 0 whole disk
		  1 = /dev/carmel/0p1   SATA disk 0 partition 1
		    ...
		 31 = /dev/carmel/0p31  SATA disk 0 partition 31

		 32 = /dev/carmel/1     SATA disk 1 whole disk
		 64 = /dev/carmel/2     SATA disk 2 whole disk
		    ...
		224 = /dev/carmel/7     SATA disk 7 whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 31.

161 char	IrCOMM devices (IrDA serial/parallel emulation)
		  0 = /dev/ircomm0	First IrCOMM device
		  1 = /dev/ircomm1	Second IrCOMM device
		    ...
		 16 = /dev/irlpt0	First IrLPT device
		 17 = /dev/irlpt1	Second IrLPT device
		    ...

161 block       Carmel 8-port SATA Disks on Second Controller
		  0 = /dev/carmel/8     SATA disk 8 whole disk
		  1 = /dev/carmel/8p1   SATA disk 8 partition 1
		    ...
		 31 = /dev/carmel/8p31  SATA disk 8 partition 31

		 32 = /dev/carmel/9     SATA disk 9 whole disk
		 64 = /dev/carmel/10    SATA disk 10 whole disk
		    ...
		224 = /dev/carmel/15    SATA disk 15 whole disk

		Partitions are handled in the same way as for IDE
		disks (see major number 3) except that the limit on
		partitions is 31.

162 char	Raw block device interface
		  0 = /dev/rawctl	Raw I/O control device
		  1 = /dev/raw/raw1	First raw I/O device
		  2 = /dev/raw/raw2	Second raw I/O device
		    ...

163 char

164 char	Chase Research AT/PCI-Fast serial card
		  0 = /dev/ttyCH0	AT/PCI-Fast board 0, port 0
		    ...
		 15 = /dev/ttyCH15	AT/PCI-Fast board 0, port 15
		 16 = /dev/ttyCH16	AT/PCI-Fast board 1, port 0
		    ...
		 31 = /dev/ttyCH31	AT/PCI-Fast board 1, port 15
		 32 = /dev/ttyCH32	AT/PCI-Fast board 2, port 0
		    ...
		 47 = /dev/ttyCH47	AT/PCI-Fast board 2, port 15
		 48 = /dev/ttyCH48	AT/PCI-Fast board 3, port 0
		    ...
		 63 = /dev/ttyCH63	AT/PCI-Fast board 3, port 15

165 char	Chase Research AT/PCI-Fast serial card - alternate devices
		  0 = /dev/cuch0	Callout device for ttyCH0
		    ...
		 63 = /dev/cuch63	Callout device for ttyCH63

166 char	ACM USB modems
		  0 = /dev/ttyACM0	First ACM modem
		  1 = /dev/ttyACM1	Second ACM modem
		    ...

167 char	ACM USB modems - alternate devices
		  0 = /dev/cuacm0	Callout device for ttyACM0
		  1 = /dev/cuacm1	Callout device for ttyACM1
		    ...

168 char	Eracom CSA7000 PCI encryption adaptor
		  0 = /dev/ecsa0	First CSA7000
		  1 = /dev/ecsa1	Second CSA7000
		    ...

169 char	Eracom CSA8000 PCI encryption adaptor
		  0 = /dev/ecsa8-0	First CSA8000
		  1 = /dev/ecsa8-1	Second CSA8000
		    ...

170 char	AMI MegaRAC remote access controller
		  0 = /dev/megarac0	First MegaRAC card
		  1 = /dev/megarac1	Second MegaRAC card
		    ...

171 char	Reserved for IEEE 1394 (Firewire)

172 char	Moxa Intellio serial card
		  0 = /dev/ttyMX0	First Moxa port
		  1 = /dev/ttyMX1	Second Moxa port
		    ...
		127 = /dev/ttyMX127	128th Moxa port
		128 = /dev/moxactl	Moxa control port

173 char	Moxa Intellio serial card - alternate devices
		  0 = /dev/cumx0	Callout device for ttyMX0
		  1 = /dev/cumx1	Callout device for ttyMX1
		    ...
		127 = /dev/cumx127	Callout device for ttyMX127

174 char	SmartIO serial card
		  0 = /dev/ttySI0	First SmartIO port
		  1 = /dev/ttySI1	Second SmartIO port
		    ...

175 char	SmartIO serial card - alternate devices
		  0 = /dev/cusi0	Callout device for ttySI0
		  1 = /dev/cusi1	Callout device for ttySI1
		    ...

176 char	nCipher nFast PCI crypto accelerator
		  0 = /dev/nfastpci0	First nFast PCI device
		  1 = /dev/nfastpci1	First nFast PCI device
		    ...

177 char	TI PCILynx memory spaces
		  0 = /dev/pcilynx/aux0	 AUX space of first PCILynx card
		    ...
		 15 = /dev/pcilynx/aux15 AUX space of 16th PCILynx card
		 16 = /dev/pcilynx/rom0	 ROM space of first PCILynx card
		    ...
		 31 = /dev/pcilynx/rom15 ROM space of 16th PCILynx card
		 32 = /dev/pcilynx/ram0	 RAM space of first PCILynx card
		    ...
		 47 = /dev/pcilynx/ram15 RAM space of 16th PCILynx card

178 char	Giganet cLAN1xxx virtual interface adapter
		  0 = /dev/clanvi0	First cLAN adapter
		  1 = /dev/clanvi1	Second cLAN adapter
		    ...

179 block       MMC block devices
		  0 = /dev/mmcblk0      First SD/MMC card
		  1 = /dev/mmcblk0p1    First partition on first MMC card
		  8 = /dev/mmcblk1      Second SD/MMC card
		    ...

		The start of next SD/MMC card can be configured with
		CONFIG_MMC_BLOCK_MINORS, or overridden at boot/modprobe
		time using the mmcblk.perdev_minors option. That would
		bump the offset between each card to be the configured
		value instead of the default 8.

179 char	CCube DVXChip-based PCI products
		  0 = /dev/dvxirq0	First DVX device
		  1 = /dev/dvxirq1	Second DVX device
		    ...

180 char	USB devices
		  0 = /dev/usb/lp0	First USB printer
		    ...
		 15 = /dev/usb/lp15	16th USB printer
		 48 = /dev/usb/scanner0	First USB scanner
		    ...
		 63 = /dev/usb/scanner15 16th USB scanner
		 64 = /dev/usb/rio500	Diamond Rio 500
		 65 = /dev/usb/usblcd	USBLCD Interface (info@usblcd.de)
		 66 = /dev/usb/cpad0	Synaptics cPad (mouse/LCD)
		 96 = /dev/usb/hiddev0	1st USB HID device
		    ...
		111 = /dev/usb/hiddev15	16th USB HID device
		112 = /dev/usb/auer0	1st auerswald ISDN device
		    ...
		127 = /dev/usb/auer15	16th auerswald ISDN device
		128 = /dev/usb/brlvgr0	First Braille Voyager device
		    ...
		131 = /dev/usb/brlvgr3	Fourth Braille Voyager device
		132 = /dev/usb/idmouse	ID Mouse (fingerprint scanner) device
		133 = /dev/usb/sisusbvga1	First SiSUSB VGA device
		    ...
		140 = /dev/usb/sisusbvga8	Eighth SISUSB VGA device
		144 = /dev/usb/lcd	USB LCD device
		160 = /dev/usb/legousbtower0	1st USB Legotower device
		    ...
		175 = /dev/usb/legousbtower15	16th USB Legotower device
		176 = /dev/usb/usbtmc1	First USB TMC device
		   ...
		191 = /dev/usb/usbtmc16	16th USB TMC device
		192 = /dev/usb/yurex1	First USB Yurex device
		   ...
		209 = /dev/usb/yurex16	16th USB Yurex device
		240 = /dev/usb/dabusb0	First daubusb device
		    ...
		243 = /dev/usb/dabusb3	Fourth dabusb device

180 block	USB block devices
		  0 = /dev/uba		First USB block device
		  8 = /dev/ubb		Second USB block device
		 16 = /dev/ubc		Third USB block device
 		    ...

181 char	Conrad Electronic parallel port radio clocks
		  0 = /dev/pcfclock0	First Conrad radio clock
		  1 = /dev/pcfclock1	Second Conrad radio clock
		    ...

182 char	Picture Elements THR2 binarizer
		  0 = /dev/pethr0	First THR2 board
		  1 = /dev/pethr1	Second THR2 board
		    ...

183 char	SST 5136-DN DeviceNet interface
		  0 = /dev/ss5136dn0	First DeviceNet interface
		  1 = /dev/ss5136dn1	Second DeviceNet interface
		    ...

		This device used to be assigned to major number 144.
		It had to be moved due to an unfortunate conflict.

184 char	Picture Elements' video simulator/sender
		  0 = /dev/pevss0	First sender board
		  1 = /dev/pevss1	Second sender board
		    ...

185 char	InterMezzo high availability file system
		  0 = /dev/intermezzo0	First cache manager
		  1 = /dev/intermezzo1	Second cache manager
		    ...

		See http://web.archive.org/web/20080115195241/
		http://inter-mezzo.org/index.html

186 char	Object-based storage control device
		  0 = /dev/obd0		First obd control device
		  1 = /dev/obd1		Second obd control device
		    ...

		See ftp://ftp.lustre.org/pub/obd for code and information.

187 char	DESkey hardware encryption device
		  0 = /dev/deskey0	First DES key
		  1 = /dev/deskey1	Second DES key
		    ...

188 char	USB serial converters
		  0 = /dev/ttyUSB0	First USB serial converter
		  1 = /dev/ttyUSB1	Second USB serial converter
		    ...

189 char	USB serial converters - alternate devices
		  0 = /dev/cuusb0	Callout device for ttyUSB0
		  1 = /dev/cuusb1	Callout device for ttyUSB1
		    ...

190 char	Kansas City tracker/tuner card
		  0 = /dev/kctt0	First KCT/T card
		  1 = /dev/kctt1	Second KCT/T card
		    ...

191 char	Reserved for PCMCIA

192 char	Kernel profiling interface
		  0 = /dev/profile	Profiling control device
		  1 = /dev/profile0	Profiling device for CPU 0
		  2 = /dev/profile1	Profiling device for CPU 1
		    ...

193 char	Kernel event-tracing interface
		  0 = /dev/trace	Tracing control device
		  1 = /dev/trace0	Tracing device for CPU 0
		  2 = /dev/trace1	Tracing device for CPU 1
		    ...

194 char	linVideoStreams (LINVS)
		  0 = /dev/mvideo/status0	Video compression status
		  1 = /dev/mvideo/stream0	Video stream
		  2 = /dev/mvideo/frame0	Single compressed frame
		  3 = /dev/mvideo/rawframe0	Raw uncompressed frame
		  4 = /dev/mvideo/codec0	Direct codec access
		  5 = /dev/mvideo/video4linux0	Video4Linux compatibility

		 16 = /dev/mvideo/status1	Second device
		    ...
		 32 = /dev/mvideo/status2	Third device
		    ...
		    ...
		240 = /dev/mvideo/status15	16th device
		    ...

195 char	Nvidia graphics devices
		  0 = /dev/nvidia0		First Nvidia card
		  1 = /dev/nvidia1		Second Nvidia card
		    ...
		255 = /dev/nvidiactl		Nvidia card control device

196 char	Tormenta T1 card
		  0 = /dev/tor/0		Master control channel for all cards
		  1 = /dev/tor/1		First DS0
		  2 = /dev/tor/2		Second DS0
		    ...
		 48 = /dev/tor/48		48th DS0
		 49 = /dev/tor/49		First pseudo-channel
		 50 = /dev/tor/50		Second pseudo-channel
		    ...

197 char	OpenTNF tracing facility
		  0 = /dev/tnf/t0		Trace 0 data extraction
		  1 = /dev/tnf/t1		Trace 1 data extraction
		    ...
		128 = /dev/tnf/status		Tracing facility status
		130 = /dev/tnf/trace		Tracing device

198 char	Total Impact TPMP2 quad coprocessor PCI card
		  0 = /dev/tpmp2/0		First card
		  1 = /dev/tpmp2/1		Second card
		    ...

199 char	Veritas volume manager (VxVM) volumes
		  0 = /dev/vx/rdsk/*/*		First volume
		  1 = /dev/vx/rdsk/*/*		Second volume
		    ...

199 block	Veritas volume manager (VxVM) volumes
		  0 = /dev/vx/dsk/*/*		First volume
		  1 = /dev/vx/dsk/*/*		Second volume
		    ...

		The namespace in these directories is maintained by
		the user space VxVM software.

200 char	Veritas VxVM configuration interface
                  0 = /dev/vx/config		Configuration access node
                  1 = /dev/vx/trace		Volume i/o trace access node
                  2 = /dev/vx/iod		Volume i/o daemon access node
                  3 = /dev/vx/info		Volume information access node
                  4 = /dev/vx/task		Volume tasks access node
                  5 = /dev/vx/taskmon		Volume tasks monitor daemon

201 char	Veritas VxVM dynamic multipathing driver
		  0 = /dev/vx/rdmp/*		First multipath device
		  1 = /dev/vx/rdmp/*		Second multipath device
		    ...
201 block	Veritas VxVM dynamic multipathing driver
		  0 = /dev/vx/dmp/*		First multipath device
		  1 = /dev/vx/dmp/*		Second multipath device
		    ...

		The namespace in these directories is maintained by
		the user space VxVM software.

202 char	CPU model-specific registers
		  0 = /dev/cpu/0/msr		MSRs on CPU 0
		  1 = /dev/cpu/1/msr		MSRs on CPU 1
		    ...

202 block	Xen Virtual Block Device
		  0 = /dev/xvda       First Xen VBD whole disk
		  16 = /dev/xvdb      Second Xen VBD whole disk
		  32 = /dev/xvdc      Third Xen VBD whole disk
		    ...
		  240 = /dev/xvdp     Sixteenth Xen VBD whole disk

                Partitions are handled in the same way as for IDE
                disks (see major number 3) except that the limit on
                partitions is 15.

203 char	CPU CPUID information
		  0 = /dev/cpu/0/cpuid		CPUID on CPU 0
		  1 = /dev/cpu/1/cpuid		CPUID on CPU 1
		    ...

204 char	Low-density serial ports
		  0 = /dev/ttyLU0		LinkUp Systems L72xx UART - port 0
		  1 = /dev/ttyLU1		LinkUp Systems L72xx UART - port 1
		  2 = /dev/ttyLU2		LinkUp Systems L72xx UART - port 2
		  3 = /dev/ttyLU3		LinkUp Systems L72xx UART - port 3
		  4 = /dev/ttyFB0		Intel Footbridge (ARM)
		  5 = /dev/ttySA0		StrongARM builtin serial port 0
		  6 = /dev/ttySA1		StrongARM builtin serial port 1
		  7 = /dev/ttySA2		StrongARM builtin serial port 2
		  8 = /dev/ttySC0		SCI serial port (SuperH) - port 0
		  9 = /dev/ttySC1		SCI serial port (SuperH) - port 1
		 10 = /dev/ttySC2		SCI serial port (SuperH) - port 2
		 11 = /dev/ttySC3		SCI serial port (SuperH) - port 3
		 12 = /dev/ttyFW0		Firmware console - port 0
		 13 = /dev/ttyFW1		Firmware console - port 1
		 14 = /dev/ttyFW2		Firmware console - port 2
		 15 = /dev/ttyFW3		Firmware console - port 3
		 16 = /dev/ttyAM0		ARM "AMBA" serial port 0
		    ...
		 31 = /dev/ttyAM15		ARM "AMBA" serial port 15
		 32 = /dev/ttyDB0		DataBooster serial port 0
		    ...
		 39 = /dev/ttyDB7		DataBooster serial port 7
		 40 = /dev/ttySG0		SGI Altix console port
		 41 = /dev/ttySMX0		Motorola i.MX - port 0
		 42 = /dev/ttySMX1		Motorola i.MX - port 1
		 43 = /dev/ttySMX2		Motorola i.MX - port 2
		 44 = /dev/ttyMM0		Marvell MPSC - port 0
		 45 = /dev/ttyMM1		Marvell MPSC - port 1
		 46 = /dev/ttyCPM0		PPC CPM (SCC or SMC) - port 0
		    ...
		 47 = /dev/ttyCPM5		PPC CPM (SCC or SMC) - port 5
		 50 = /dev/ttyIOC0		Altix serial card
		    ...
		 81 = /dev/ttyIOC31		Altix serial card
		 82 = /dev/ttyVR0		NEC VR4100 series SIU
		 83 = /dev/ttyVR1		NEC VR4100 series DSIU
		 84 = /dev/ttyIOC84		Altix ioc4 serial card
		    ...
		 115 = /dev/ttyIOC115		Altix ioc4 serial card
		 116 = /dev/ttySIOC0		Altix ioc3 serial card
		    ...
		 147 = /dev/ttySIOC31		Altix ioc3 serial card
		 148 = /dev/ttyPSC0		PPC PSC - port 0
		    ...
		 153 = /dev/ttyPSC5		PPC PSC - port 5
		 154 = /dev/ttyAT0		ATMEL serial port 0
		    ...
		 169 = /dev/ttyAT15		ATMEL serial port 15
		 170 = /dev/ttyNX0		Hilscher netX serial port 0
		    ...
		 185 = /dev/ttyNX15		Hilscher netX serial port 15
		 186 = /dev/ttyJ0		JTAG1 DCC protocol based serial port emulation
		 187 = /dev/ttyUL0		Xilinx uartlite - port 0
		    ...
		 190 = /dev/ttyUL3		Xilinx uartlite - port 3
		 191 = /dev/xvc0		Xen virtual console - port 0
		 192 = /dev/ttyPZ0		pmac_zilog - port 0
		    ...
		 195 = /dev/ttyPZ3		pmac_zilog - port 3
		 196 = /dev/ttyTX0		TX39/49 serial port 0
		    ...
		 204 = /dev/ttyTX7		TX39/49 serial port 7
		 205 = /dev/ttySC0		SC26xx serial port 0
		 206 = /dev/ttySC1		SC26xx serial port 1
		 207 = /dev/ttySC2		SC26xx serial port 2
		 208 = /dev/ttySC3		SC26xx serial port 3
		 209 = /dev/ttyMAX0		MAX3100 serial port 0
		 210 = /dev/ttyMAX1		MAX3100 serial port 1
		 211 = /dev/ttyMAX2		MAX3100 serial port 2
		 212 = /dev/ttyMAX3		MAX3100 serial port 3

205 char	Low-density serial ports (alternate device)
		  0 = /dev/culu0		Callout device for ttyLU0
		  1 = /dev/culu1		Callout device for ttyLU1
		  2 = /dev/culu2		Callout device for ttyLU2
		  3 = /dev/culu3		Callout device for ttyLU3
		  4 = /dev/cufb0		Callout device for ttyFB0
		  5 = /dev/cusa0		Callout device for ttySA0
		  6 = /dev/cusa1		Callout device for ttySA1
		  7 = /dev/cusa2		Callout device for ttySA2
		  8 = /dev/cusc0		Callout device for ttySC0
		  9 = /dev/cusc1		Callout device for ttySC1
		 10 = /dev/cusc2		Callout device for ttySC2
		 11 = /dev/cusc3		Callout device for ttySC3
		 12 = /dev/cufw0		Callout device for ttyFW0
		 13 = /dev/cufw1		Callout device for ttyFW1
		 14 = /dev/cufw2		Callout device for ttyFW2
		 15 = /dev/cufw3		Callout device for ttyFW3
		 16 = /dev/cuam0		Callout device for ttyAM0
		    ...
		 31 = /dev/cuam15		Callout device for ttyAM15
		 32 = /dev/cudb0		Callout device for ttyDB0
		    ...
		 39 = /dev/cudb7		Callout device for ttyDB7
		 40 = /dev/cusg0		Callout device for ttySG0
		 41 = /dev/ttycusmx0		Callout device for ttySMX0
		 42 = /dev/ttycusmx1		Callout device for ttySMX1
		 43 = /dev/ttycusmx2		Callout device for ttySMX2
		 46 = /dev/cucpm0		Callout device for ttyCPM0
		    ...
		 49 = /dev/cucpm5		Callout device for ttyCPM5
		 50 = /dev/cuioc40		Callout device for ttyIOC40
		    ...
		 81 = /dev/cuioc431		Callout device for ttyIOC431
		 82 = /dev/cuvr0		Callout device for ttyVR0
		 83 = /dev/cuvr1		Callout device for ttyVR1

206 char	OnStream SC-x0 tape devices
		  0 = /dev/osst0		First OnStream SCSI tape, mode 0
		  1 = /dev/osst1		Second OnStream SCSI tape, mode 0
		    ...
		 32 = /dev/osst0l		First OnStream SCSI tape, mode 1
		 33 = /dev/osst1l		Second OnStream SCSI tape, mode 1
		    ...
		 64 = /dev/osst0m		First OnStream SCSI tape, mode 2
		 65 = /dev/osst1m		Second OnStream SCSI tape, mode 2
		    ...
		 96 = /dev/osst0a		First OnStream SCSI tape, mode 3
		 97 = /dev/osst1a		Second OnStream SCSI tape, mode 3
		    ...
		128 = /dev/nosst0		No rewind version of /dev/osst0
		129 = /dev/nosst1		No rewind version of /dev/osst1
		    ...
		160 = /dev/nosst0l		No rewind version of /dev/osst0l
		161 = /dev/nosst1l		No rewind version of /dev/osst1l
		    ...
		192 = /dev/nosst0m		No rewind version of /dev/osst0m
		193 = /dev/nosst1m		No rewind version of /dev/osst1m
		    ...
		224 = /dev/nosst0a		No rewind version of /dev/osst0a
		225 = /dev/nosst1a		No rewind version of /dev/osst1a
		    ...

		The OnStream SC-x0 SCSI tapes do not support the
		standard SCSI SASD command set and therefore need
		their own driver "osst". Note that the IDE, USB (and
		maybe ParPort) versions may be driven via ide-scsi or
		usb-storage SCSI emulation and this osst device and
		driver as well.  The ADR-x0 drives are QIC-157
		compliant and don't need osst.

207 char	Compaq ProLiant health feature indicate
		  0 = /dev/cpqhealth/cpqw	Redirector interface
		  1 = /dev/cpqhealth/crom	EISA CROM
		  2 = /dev/cpqhealth/cdt	Data Table
		  3 = /dev/cpqhealth/cevt	Event Log
		  4 = /dev/cpqhealth/casr	Automatic Server Recovery
		  5 = /dev/cpqhealth/cecc	ECC Memory
		  6 = /dev/cpqhealth/cmca	Machine Check Architecture
		  7 = /dev/cpqhealth/ccsm	Deprecated CDT
		  8 = /dev/cpqhealth/cnmi	NMI Handling
		  9 = /dev/cpqhealth/css	Sideshow Management
		 10 = /dev/cpqhealth/cram	CMOS interface
		 11 = /dev/cpqhealth/cpci	PCI IRQ interface

208 char	User space serial ports
		  0 = /dev/ttyU0		First user space serial port
		  1 = /dev/ttyU1		Second user space serial port
		    ...

209 char	User space serial ports (alternate devices)
		  0 = /dev/cuu0			Callout device for ttyU0
		  1 = /dev/cuu1			Callout device for ttyU1
		    ...

210 char	SBE, Inc. sync/async serial card
		  0 = /dev/sbei/wxcfg0		Configuration device for board 0
		  1 = /dev/sbei/dld0		Download device for board 0
		  2 = /dev/sbei/wan00		WAN device, port 0, board 0
		  3 = /dev/sbei/wan01		WAN device, port 1, board 0
		  4 = /dev/sbei/wan02		WAN device, port 2, board 0
		  5 = /dev/sbei/wan03		WAN device, port 3, board 0
		  6 = /dev/sbei/wanc00		WAN clone device, port 0, board 0
		  7 = /dev/sbei/wanc01		WAN clone device, port 1, board 0
		  8 = /dev/sbei/wanc02		WAN clone device, port 2, board 0
		  9 = /dev/sbei/wanc03		WAN clone device, port 3, board 0
		 10 = /dev/sbei/wxcfg1		Configuration device for board 1
		 11 = /dev/sbei/dld1		Download device for board 1
		 12 = /dev/sbei/wan10		WAN device, port 0, board 1
		 13 = /dev/sbei/wan11		WAN device, port 1, board 1
		 14 = /dev/sbei/wan12		WAN device, port 2, board 1
		 15 = /dev/sbei/wan13		WAN device, port 3, board 1
		 16 = /dev/sbei/wanc10		WAN clone device, port 0, board 1
		 17 = /dev/sbei/wanc11		WAN clone device, port 1, board 1
		 18 = /dev/sbei/wanc12		WAN clone device, port 2, board 1
		 19 = /dev/sbei/wanc13		WAN clone device, port 3, board 1
		    ...

		Yes, each board is really spaced 10 (decimal) apart.

211 char	Addinum CPCI1500 digital I/O card
		  0 = /dev/addinum/cpci1500/0	First CPCI1500 card
		  1 = /dev/addinum/cpci1500/1	Second CPCI1500 card
		    ...

212 char	LinuxTV.org DVB driver subsystem
		  0 = /dev/dvb/adapter0/video0    first video decoder of first card
		  1 = /dev/dvb/adapter0/audio0    first audio decoder of first card
		  2 = /dev/dvb/adapter0/sec0      (obsolete/unused)
		  3 = /dev/dvb/adapter0/frontend0 first frontend device of first card
		  4 = /dev/dvb/adapter0/demux0    first demux device of first card
		  5 = /dev/dvb/adapter0/dvr0      first digital video recoder device of first card
		  6 = /dev/dvb/adapter0/ca0       first common access port of first card
		  7 = /dev/dvb/adapter0/net0      first network device of first card
		  8 = /dev/dvb/adapter0/osd0      first on-screen-display device of first card
		  9 = /dev/dvb/adapter0/video1    second video decoder of first card
		    ...
		 64 = /dev/dvb/adapter1/video0    first video decoder of second card
		    ...
		128 = /dev/dvb/adapter2/video0    first video decoder of third card
		    ...
		196 = /dev/dvb/adapter3/video0    first video decoder of fourth card

216 char	Bluetooth RFCOMM TTY devices
		  0 = /dev/rfcomm0		First Bluetooth RFCOMM TTY device
		  1 = /dev/rfcomm1		Second Bluetooth RFCOMM TTY device
		    ...

217 char	Bluetooth RFCOMM TTY devices (alternate devices)
		  0 = /dev/curf0		Callout device for rfcomm0
		  1 = /dev/curf1		Callout device for rfcomm1
		    ...

218 char	The Logical Company bus Unibus/Qbus adapters
		  0 = /dev/logicalco/bci/0	First bus adapter
		  1 = /dev/logicalco/bci/1	First bus adapter
		    ...

219 char	The Logical Company DCI-1300 digital I/O card
		  0 = /dev/logicalco/dci1300/0	First DCI-1300 card
		  1 = /dev/logicalco/dci1300/1	Second DCI-1300 card
		    ...

220 char	Myricom Myrinet "GM" board
		  0 = /dev/myricom/gm0		First Myrinet GM board
		  1 = /dev/myricom/gmp0		First board "root access"
		  2 = /dev/myricom/gm1		Second Myrinet GM board
		  3 = /dev/myricom/gmp1		Second board "root access"
		    ...

221 char	VME bus
		  0 = /dev/bus/vme/m0		First master image
		  1 = /dev/bus/vme/m1		Second master image
		  2 = /dev/bus/vme/m2		Third master image
		  3 = /dev/bus/vme/m3		Fourth master image
		  4 = /dev/bus/vme/s0		First slave image
		  5 = /dev/bus/vme/s1		Second slave image
		  6 = /dev/bus/vme/s2		Third slave image
		  7 = /dev/bus/vme/s3		Fourth slave image
		  8 = /dev/bus/vme/ctl		Control

		It is expected that all VME bus drivers will use the
		same interface.  For interface documentation see
		http://www.vmelinux.org/.

224 char	A2232 serial card
		  0 = /dev/ttyY0		First A2232 port
		  1 = /dev/ttyY1		Second A2232 port
		    ...

225 char	A2232 serial card (alternate devices)
		  0 = /dev/cuy0			Callout device for ttyY0
		  1 = /dev/cuy1			Callout device for ttyY1
		    ...

226 char	Direct Rendering Infrastructure (DRI)
		  0 = /dev/dri/card0		First graphics card
		  1 = /dev/dri/card1		Second graphics card
		    ...

227 char	IBM 3270 terminal Unix tty access
		  1 = /dev/3270/tty1		First 3270 terminal
		  2 = /dev/3270/tty2		Seconds 3270 terminal
		    ...

228 char	IBM 3270 terminal block-mode access
		  0 = /dev/3270/tub		Controlling interface
		  1 = /dev/3270/tub1		First 3270 terminal
		  2 = /dev/3270/tub2		Second 3270 terminal
		    ...

229 char	IBM iSeries/pSeries virtual console
		  0 = /dev/hvc0			First console port
		  1 = /dev/hvc1			Second console port
		    ...

230 char	IBM iSeries virtual tape
		  0 = /dev/iseries/vt0		First virtual tape, mode 0
		  1 = /dev/iseries/vt1		Second virtual tape, mode 0
		    ...
		 32 = /dev/iseries/vt0l		First virtual tape, mode 1
		 33 = /dev/iseries/vt1l		Second virtual tape, mode 1
		    ...
		 64 = /dev/iseries/vt0m		First virtual tape, mode 2
		 65 = /dev/iseries/vt1m		Second virtual tape, mode 2
		    ...
		 96 = /dev/iseries/vt0a		First virtual tape, mode 3
		 97 = /dev/iseries/vt1a		Second virtual tape, mode 3
		      ...
		128 = /dev/iseries/nvt0		First virtual tape, mode 0, no rewind
		129 = /dev/iseries/nvt1		Second virtual tape, mode 0, no rewind
		    ...
		160 = /dev/iseries/nvt0l	First virtual tape, mode 1, no rewind
		161 = /dev/iseries/nvt1l	Second virtual tape, mode 1, no rewind
		    ...
		192 = /dev/iseries/nvt0m	First virtual tape, mode 2, no rewind
		193 = /dev/iseries/nvt1m	Second virtual tape, mode 2, no rewind
		    ...
		224 = /dev/iseries/nvt0a	First virtual tape, mode 3, no rewind
		225 = /dev/iseries/nvt1a	Second virtual tape, mode 3, no rewind
		    ...

		"No rewind" refers to the omission of the default
		automatic rewind on device close.  The MTREW or MTOFFL
		ioctl()'s can be used to rewind the tape regardless of
		the device used to access it.

231 char	InfiniBand
		0 = /dev/infiniband/umad0
		1 = /dev/infiniband/umad1
		  ...
		63 = /dev/infiniband/umad63    63rd InfiniBandMad device
		64 = /dev/infiniband/issm0     First InfiniBand IsSM device
		65 = /dev/infiniband/issm1     Second InfiniBand IsSM device
		  ...
		127 = /dev/infiniband/issm63    63rd InfiniBand IsSM device
		128 = /dev/infiniband/uverbs0   First InfiniBand verbs device
		129 = /dev/infiniband/uverbs1   Second InfiniBand verbs device
		  ...
		159 = /dev/infiniband/uverbs31  31st InfiniBand verbs device

232 char	Biometric Devices
		0 = /dev/biometric/sensor0/fingerprint	first fingerprint sensor on first device
		1 = /dev/biometric/sensor0/iris		first iris sensor on first device
		2 = /dev/biometric/sensor0/retina	first retina sensor on first device
		3 = /dev/biometric/sensor0/voiceprint	first voiceprint sensor on first device
		4 = /dev/biometric/sensor0/facial	first facial sensor on first device
		5 = /dev/biometric/sensor0/hand		first hand sensor on first device
		  ...
		10 = /dev/biometric/sensor1/fingerprint	first fingerprint sensor on second device
		  ...
		20 = /dev/biometric/sensor2/fingerprint	first fingerprint sensor on third device
		  ...

233 char	PathScale InfiniPath interconnect
		0 = /dev/ipath        Primary device for programs (any unit)
		1 = /dev/ipath0       Access specifically to unit 0
		2 = /dev/ipath1       Access specifically to unit 1
		  ...
		4 = /dev/ipath3       Access specifically to unit 3
		129 = /dev/ipath_sma    Device used by Subnet Management Agent
		130 = /dev/ipath_diag   Device used by diagnostics programs

234-239		UNASSIGNED

240-254 char	LOCAL/EXPERIMENTAL USE

240-254 block	LOCAL/EXPERIMENTAL USE
		Allocated for local/experimental use.  For devices not
		assigned official numbers, these ranges should be
		used in order to avoid conflicting with future assignments.

255 char	RESERVED

255 block	RESERVED

		This major is reserved to assist the expansion to a
		larger number space.  No device nodes with this major
		should ever be created on the filesystem.
		(This is probably not true anymore, but I'll leave it
		for now /Torben)

---LARGE MAJORS!!!!!---

256 char	Equinox SST multi-port serial boards
		   0 = /dev/ttyEQ0	First serial port on first Equinox SST board
		 127 = /dev/ttyEQ127	Last serial port on first Equinox SST board
		 128 = /dev/ttyEQ128	First serial port on second Equinox SST board
		  ...
		1027 = /dev/ttyEQ1027	Last serial port on eighth Equinox SST board

256 block	Resident Flash Disk Flash Translation Layer
		  0 = /dev/rfda		First RFD FTL layer
		 16 = /dev/rfdb		Second RFD FTL layer
		  ...
		240 = /dev/rfdp		16th RFD FTL layer

257 char	Phoenix Technologies Cryptographic Services Driver
		  0 = /dev/ptlsec	Crypto Services Driver

257 block	SSFDC Flash Translation Layer filesystem
		  0 = /dev/ssfdca	First SSFDC layer
		  8 = /dev/ssfdcb	Second SSFDC layer
		 16 = /dev/ssfdcc	Third SSFDC layer
		 24 = /dev/ssfdcd	4th SSFDC layer
		 32 = /dev/ssfdce	5th SSFDC layer
		 40 = /dev/ssfdcf	6th SSFDC layer
		 48 = /dev/ssfdcg	7th SSFDC layer
		 56 = /dev/ssfdch	8th SSFDC layer

258 block	ROM/Flash read-only translation layer
		  0 = /dev/blockrom0	First ROM card's translation layer interface
		  1 = /dev/blockrom1	Second ROM card's translation layer interface
		  ...

259 block	Block Extended Major
		  Used dynamically to hold additional partition minor
		  numbers and allow large numbers of partitions per device

259 char	FPGA configuration interfaces
		  0 = /dev/icap0	First Xilinx internal configuration
		  1 = /dev/icap1	Second Xilinx internal configuration

260 char	OSD (Object-based-device) SCSI Device
		  0 = /dev/osd0		First OSD Device
		  1 = /dev/osd1		Second OSD Device
		  ...
		  255 = /dev/osd255	256th OSD Device

 ****	ADDITIONAL /dev DIRECTORY ENTRIES

This section details additional entries that should or may exist in
the /dev directory.  It is preferred that symbolic links use the same
form (absolute or relative) as is indicated here.  Links are
classified as "hard" or "symbolic" depending on the preferred type of
link; if possible, the indicated type of link should be used.


	Compulsory links

These links should exist on all systems:

/dev/fd		/proc/self/fd	symbolic	File descriptors
/dev/stdin	fd/0		symbolic	stdin file descriptor
/dev/stdout	fd/1		symbolic	stdout file descriptor
/dev/stderr	fd/2		symbolic	stderr file descriptor
/dev/nfsd	socksys		symbolic	Required by iBCS-2
/dev/X0R	null		symbolic	Required by iBCS-2

Note: /dev/X0R is <letter X>-<digit 0>-<letter R>.

	Recommended links

It is recommended that these links exist on all systems:

/dev/core	/proc/kcore	symbolic	Backward compatibility
/dev/ramdisk	ram0		symbolic	Backward compatibility
/dev/ftape	qft0		symbolic	Backward compatibility
/dev/bttv0	video0		symbolic	Backward compatibility
/dev/radio	radio0		symbolic	Backward compatibility
/dev/i2o*	/dev/i2o/*	symbolic	Backward compatibility
/dev/scd?	sr?		hard		Alternate SCSI CD-ROM name

	Locally defined links

The following links may be established locally to conform to the
configuration of the system.  This is merely a tabulation of existing
practice, and does not constitute a recommendation.  However, if they
exist, they should have the following uses.

/dev/mouse	mouse port	symbolic	Current mouse device
/dev/tape	tape device	symbolic	Current tape device
/dev/cdrom	CD-ROM device	symbolic	Current CD-ROM device
/dev/cdwriter	CD-writer	symbolic	Current CD-writer device
/dev/scanner	scanner		symbolic	Current scanner device
/dev/modem	modem port	symbolic	Current dialout device
/dev/root	root device	symbolic	Current root filesystem
/dev/swap	swap device	symbolic	Current swap device

/dev/modem should not be used for a modem which supports dialin as
well as dialout, as it tends to cause lock file problems.  If it
exists, /dev/modem should point to the appropriate primary TTY device
(the use of the alternate callout devices is deprecated).

For SCSI devices, /dev/tape and /dev/cdrom should point to the
``cooked'' devices (/dev/st* and /dev/sr*, respectively), whereas
/dev/cdwriter and /dev/scanner should point to the appropriate generic
SCSI devices (/dev/sg*).

/dev/mouse may point to a primary serial TTY device, a hardware mouse
device, or a socket for a mouse driver program (e.g. /dev/gpmdata).

	Sockets and pipes

Non-transient sockets and named pipes may exist in /dev.  Common entries are:

/dev/printer	socket		lpd local socket
/dev/log	socket		syslog local socket
/dev/gpmdata	socket		gpm mouse multiplexer

	Mount points

The following names are reserved for mounting special filesystems
under /dev.  These special filesystems provide kernel interfaces that
cannot be provided with standard device nodes.

/dev/pts	devpts		PTY slave filesystem
/dev/shm	tmpfs		POSIX shared memory maintenance access

 ****	TERMINAL DEVICES

Terminal, or TTY devices are a special class of character devices.  A
terminal device is any device that could act as a controlling terminal
for a session; this includes virtual consoles, serial ports, and
pseudoterminals (PTYs).

All terminal devices share a common set of capabilities known as line
disciplines; these include the common terminal line discipline as well
as SLIP and PPP modes.

All terminal devices are named similarly; this section explains the
naming and use of the various types of TTYs.  Note that the naming
conventions include several historical warts; some of these are
Linux-specific, some were inherited from other systems, and some
reflect Linux outgrowing a borrowed convention.

A hash mark (#) in a device name is used here to indicate a decimal
number without leading zeroes.

	Virtual consoles and the console device

Virtual consoles are full-screen terminal displays on the system video
monitor.  Virtual consoles are named /dev/tty#, with numbering
starting at /dev/tty1; /dev/tty0 is the current virtual console.
/dev/tty0 is the device that should be used to access the system video
card on those architectures for which the frame buffer devices
(/dev/fb*) are not applicable.	Do not use /dev/console
for this purpose.

The console device, /dev/console, is the device to which system
messages should be sent, and on which logins should be permitted in
single-user mode.  Starting with Linux 2.1.71, /dev/console is managed
by the kernel; for previous versions it should be a symbolic link to
either /dev/tty0, a specific virtual console such as /dev/tty1, or to
a serial port primary (tty*, not cu*) device, depending on the
configuration of the system.

	Serial ports

Serial ports are RS-232 serial ports and any device which simulates
one, either in hardware (such as internal modems) or in software (such
as the ISDN driver.)  Under Linux, each serial ports has two device
names, the primary or callin device and the alternate or callout one.
Each kind of device is indicated by a different letter.	 For any
letter X, the names of the devices are /dev/ttyX# and /dev/cux#,
respectively; for historical reasons, /dev/ttyS# and /dev/ttyC#
correspond to /dev/cua# and /dev/cub#.	In the future, it should be
expected that multiple letters will be used; all letters will be upper
case for the "tty" device (e.g. /dev/ttyDP#) and lower case for the
"cu" device (e.g. /dev/cudp#).

The names /dev/ttyQ# and /dev/cuq# are reserved for local use.

The alternate devices provide for kernel-based exclusion and somewhat
different defaults than the primary devices.  Their main purpose is to
allow the use of serial ports with programs with no inherent or broken
support for serial ports.  Their use is deprecated, and they may be
removed from a future version of Linux.

Arbitration of serial ports is provided by the use of lock files with
the names /var/lock/LCK..ttyX#.	 The contents of the lock file should
be the PID of the locking process as an ASCII number.

It is common practice to install links such as /dev/modem
which point to serial ports.  In order to ensure proper locking in the
presence of these links, it is recommended that software chase
symlinks and lock all possible names; additionally, it is recommended
that a lock file be installed with the corresponding alternate
device.	 In order to avoid deadlocks, it is recommended that the locks
are acquired in the following order, and released in the reverse:

	1. The symbolic link name, if any (/var/lock/LCK..modem)
	2. The "tty" name (/var/lock/LCK..ttyS2)
	3. The alternate device name (/var/lock/LCK..cua2)

In the case of nested symbolic links, the lock files should be
installed in the order the symlinks are resolved.

Under no circumstances should an application hold a lock while waiting
for another to be released.  In addition, applications which attempt
to create lock files for the corresponding alternate device names
should take into account the possibility of being used on a non-serial
port TTY, for which no alternate device would exist.

	Pseudoterminals (PTYs)

Pseudoterminals, or PTYs, are used to create login sessions or provide
other capabilities requiring a TTY line discipline (including SLIP or
PPP capability) to arbitrary data-generation processes.	 Each PTY has
a master side, named /dev/pty[p-za-e][0-9a-f], and a slave side, named
/dev/tty[p-za-e][0-9a-f].  The kernel arbitrates the use of PTYs by
allowing each master side to be opened only once.

Once the master side has been opened, the corresponding slave device
can be used in the same manner as any TTY device.  The master and
slave devices are connected by the kernel, generating the equivalent
of a bidirectional pipe with TTY capabilities.

Recent versions of the Linux kernels and GNU libc contain support for
the System V/Unix98 naming scheme for PTYs, which assigns a common
device, /dev/ptmx, to all the masters (opening it will automatically
give you a previously unassigned PTY) and a subdirectory, /dev/pts,
for the slaves; the slaves are named with decimal integers (/dev/pts/#
in our notation).  This removes the problem of exhausting the
namespace and enables the kernel to automatically create the device
nodes for the slaves on demand using the "devpts" filesystem.

		     Dynamic DMA mapping Guide
		     =========================

		 David S. Miller <davem@redhat.com>
		 Richard Henderson <rth@cygnus.com>
		  Jakub Jelinek <jakub@redhat.com>

This is a guide to device driver writers on how to use the DMA API
with example pseudo-code.  For a concise description of the API, see
DMA-API.txt.

Most of the 64bit platforms have special hardware that translates bus
addresses (DMA addresses) into physical addresses.  This is similar to
how page tables and/or a TLB translates virtual addresses to physical
addresses on a CPU.  This is needed so that e.g. PCI devices can
access with a Single Address Cycle (32bit DMA address) any page in the
64bit physical address space.  Previously in Linux those 64bit
platforms had to set artificial limits on the maximum RAM size in the
system, so that the virt_to_bus() static scheme works (the DMA address
translation tables were simply filled on bootup to map each bus
address to the physical page __pa(bus_to_virt())).

So that Linux can use the dynamic DMA mapping, it needs some help from the
drivers, namely it has to take into account that DMA addresses should be
mapped only for the time they are actually used and unmapped after the DMA
transfer.

The following API will work of course even on platforms where no such
hardware exists.

Note that the DMA API works with any bus independent of the underlying
microprocessor architecture. You should use the DMA API rather than
the bus specific DMA API (e.g. pci_dma_*).

First of all, you should make sure

#include <linux/dma-mapping.h>

is in your driver. This file will obtain for you the definition of the
dma_addr_t (which can hold any valid DMA address for the platform)
type which should be used everywhere you hold a DMA (bus) address
returned from the DMA mapping functions.

			 What memory is DMA'able?

The first piece of information you must know is what kernel memory can
be used with the DMA mapping facilities.  There has been an unwritten
set of rules regarding this, and this text is an attempt to finally
write them down.

If you acquired your memory via the page allocator
(i.e. __get_free_page*()) or the generic memory allocators
(i.e. kmalloc() or kmem_cache_alloc()) then you may DMA to/from
that memory using the addresses returned from those routines.

This means specifically that you may _not_ use the memory/addresses
returned from vmalloc() for DMA.  It is possible to DMA to the
_underlying_ memory mapped into a vmalloc() area, but this requires
walking page tables to get the physical addresses, and then
translating each of those pages back to a kernel address using
something like __va().  [ EDIT: Update this when we integrate
Gerd Knorr's generic code which does this. ]

This rule also means that you may use neither kernel image addresses
(items in data/text/bss segments), nor module image addresses, nor
stack addresses for DMA.  These could all be mapped somewhere entirely
different than the rest of physical memory.  Even if those classes of
memory could physically work with DMA, you'd need to ensure the I/O
buffers were cacheline-aligned.  Without that, you'd see cacheline
sharing problems (data corruption) on CPUs with DMA-incoherent caches.
(The CPU could write to one word, DMA would write to a different one
in the same cache line, and one of them could be overwritten.)

Also, this means that you cannot take the return of a kmap()
call and DMA to/from that.  This is similar to vmalloc().

What about block I/O and networking buffers?  The block I/O and
networking subsystems make sure that the buffers they use are valid
for you to DMA from/to.

			DMA addressing limitations

Does your device have any DMA addressing limitations?  For example, is
your device only capable of driving the low order 24-bits of address?
If so, you need to inform the kernel of this fact.

By default, the kernel assumes that your device can address the full
32-bits.  For a 64-bit capable device, this needs to be increased.
And for a device with limitations, as discussed in the previous
paragraph, it needs to be decreased.

Special note about PCI: PCI-X specification requires PCI-X devices to
support 64-bit addressing (DAC) for all transactions.  And at least
one platform (SGI SN2) requires 64-bit consistent allocations to
operate correctly when the IO bus is in PCI-X mode.

For correct operation, you must interrogate the kernel in your device
probe routine to see if the DMA controller on the machine can properly
support the DMA addressing limitation your device has.  It is good
style to do this even if your device holds the default setting,
because this shows that you did think about these issues wrt. your
device.

The query is performed via a call to dma_set_mask():

	int dma_set_mask(struct device *dev, u64 mask);

The query for consistent allocations is performed via a call to
dma_set_coherent_mask():

	int dma_set_coherent_mask(struct device *dev, u64 mask);

Here, dev is a pointer to the device struct of your device, and mask
is a bit mask describing which bits of an address your device
supports.  It returns zero if your card can perform DMA properly on
the machine given the address mask you provided.  In general, the
device struct of your device is embedded in the bus specific device
struct of your device.  For example, a pointer to the device struct of
your PCI device is pdev->dev (pdev is a pointer to the PCI device
struct of your device).

If it returns non-zero, your device cannot perform DMA properly on
this platform, and attempting to do so will result in undefined
behavior.  You must either use a different mask, or not use DMA.

This means that in the failure case, you have three options:

1) Use another DMA mask, if possible (see below).
2) Use some non-DMA mode for data transfer, if possible.
3) Ignore this device and do not initialize it.

It is recommended that your driver print a kernel KERN_WARNING message
when you end up performing either #2 or #3.  In this manner, if a user
of your driver reports that performance is bad or that the device is not
even detected, you can ask them for the kernel messages to find out
exactly why.

The standard 32-bit addressing device would do something like this:

	if (dma_set_mask(dev, DMA_BIT_MASK(32))) {
		printk(KERN_WARNING
		       "mydev: No suitable DMA available.\n");
		goto ignore_this_device;
	}

Another common scenario is a 64-bit capable device.  The approach here
is to try for 64-bit addressing, but back down to a 32-bit mask that
should not fail.  The kernel may fail the 64-bit mask not because the
platform is not capable of 64-bit addressing.  Rather, it may fail in
this case simply because 32-bit addressing is done more efficiently
than 64-bit addressing.  For example, Sparc64 PCI SAC addressing is
more efficient than DAC addressing.

Here is how you would handle a 64-bit capable device which can drive
all 64-bits when accessing streaming DMA:

	int using_dac;

	if (!dma_set_mask(dev, DMA_BIT_MASK(64))) {
		using_dac = 1;
	} else if (!dma_set_mask(dev, DMA_BIT_MASK(32))) {
		using_dac = 0;
	} else {
		printk(KERN_WARNING
		       "mydev: No suitable DMA available.\n");
		goto ignore_this_device;
	}

If a card is capable of using 64-bit consistent allocations as well,
the case would look like this:

	int using_dac, consistent_using_dac;

	if (!dma_set_mask(dev, DMA_BIT_MASK(64))) {
		using_dac = 1;
	   	consistent_using_dac = 1;
		dma_set_coherent_mask(dev, DMA_BIT_MASK(64));
	} else if (!dma_set_mask(dev, DMA_BIT_MASK(32))) {
		using_dac = 0;
		consistent_using_dac = 0;
		dma_set_coherent_mask(dev, DMA_BIT_MASK(32));
	} else {
		printk(KERN_WARNING
		       "mydev: No suitable DMA available.\n");
		goto ignore_this_device;
	}

dma_set_coherent_mask() will always be able to set the same or a
smaller mask as dma_set_mask(). However for the rare case that a
device driver only uses consistent allocations, one would have to
check the return value from dma_set_coherent_mask().

Finally, if your device can only drive the low 24-bits of
address you might do something like:

	if (dma_set_mask(dev, DMA_BIT_MASK(24))) {
		printk(KERN_WARNING
		       "mydev: 24-bit DMA addressing not available.\n");
		goto ignore_this_device;
	}

When dma_set_mask() is successful, and returns zero, the kernel saves
away this mask you have provided.  The kernel will use this
information later when you make DMA mappings.

There is a case which we are aware of at this time, which is worth
mentioning in this documentation.  If your device supports multiple
functions (for example a sound card provides playback and record
functions) and the various different functions have _different_
DMA addressing limitations, you may wish to probe each mask and
only provide the functionality which the machine can handle.  It
is important that the last call to dma_set_mask() be for the
most specific mask.

Here is pseudo-code showing how this might be done:

	#define PLAYBACK_ADDRESS_BITS	DMA_BIT_MASK(32)
	#define RECORD_ADDRESS_BITS	DMA_BIT_MASK(24)

	struct my_sound_card *card;
	struct device *dev;

	...
	if (!dma_set_mask(dev, PLAYBACK_ADDRESS_BITS)) {
		card->playback_enabled = 1;
	} else {
		card->playback_enabled = 0;
		printk(KERN_WARNING "%s: Playback disabled due to DMA limitations.\n",
		       card->name);
	}
	if (!dma_set_mask(dev, RECORD_ADDRESS_BITS)) {
		card->record_enabled = 1;
	} else {
		card->record_enabled = 0;
		printk(KERN_WARNING "%s: Record disabled due to DMA limitations.\n",
		       card->name);
	}

A sound card was used as an example here because this genre of PCI
devices seems to be littered with ISA chips given a PCI front end,
and thus retaining the 16MB DMA addressing limitations of ISA.

			Types of DMA mappings

There are two types of DMA mappings:

- Consistent DMA mappings which are usually mapped at driver
  initialization, unmapped at the end and for which the hardware should
  guarantee that the device and the CPU can access the data
  in parallel and will see updates made by each other without any
  explicit software flushing.

  Think of "consistent" as "synchronous" or "coherent".

  The current default is to return consistent memory in the low 32
  bits of the bus space.  However, for future compatibility you should
  set the consistent mask even if this default is fine for your
  driver.

  Good examples of what to use consistent mappings for are:

	- Network card DMA ring descriptors.
	- SCSI adapter mailbox command data structures.
	- Device firmware microcode executed out of
	  main memory.

  The invariant these examples all require is that any CPU store
  to memory is immediately visible to the device, and vice
  versa.  Consistent mappings guarantee this.

  IMPORTANT: Consistent DMA memory does not preclude the usage of
             proper memory barriers.  The CPU may reorder stores to
	     consistent memory just as it may normal memory.  Example:
	     if it is important for the device to see the first word
	     of a descriptor updated before the second, you must do
	     something like:

		desc->word0 = address;
		wmb();
		desc->word1 = DESC_VALID;

             in order to get correct behavior on all platforms.

	     Also, on some platforms your driver may need to flush CPU write
	     buffers in much the same way as it needs to flush write buffers
	     found in PCI bridges (such as by reading a register's value
	     after writing it).

- Streaming DMA mappings which are usually mapped for one DMA
  transfer, unmapped right after it (unless you use dma_sync_* below)
  and for which hardware can optimize for sequential accesses.

  This of "streaming" as "asynchronous" or "outside the coherency
  domain".

  Good examples of what to use streaming mappings for are:

	- Networking buffers transmitted/received by a device.
	- Filesystem buffers written/read by a SCSI device.

  The interfaces for using this type of mapping were designed in
  such a way that an implementation can make whatever performance
  optimizations the hardware allows.  To this end, when using
  such mappings you must be explicit about what you want to happen.

Neither type of DMA mapping has alignment restrictions that come from
the underlying bus, although some devices may have such restrictions.
Also, systems with caches that aren't DMA-coherent will work better
when the underlying buffers don't share cache lines with other data.


		 Using Consistent DMA mappings.

To allocate and map large (PAGE_SIZE or so) consistent DMA regions,
you should do:

	dma_addr_t dma_handle;

	cpu_addr = dma_alloc_coherent(dev, size, &dma_handle, gfp);

where device is a struct device *. This may be called in interrupt
context with the GFP_ATOMIC flag.

Size is the length of the region you want to allocate, in bytes.

This routine will allocate RAM for that region, so it acts similarly to
__get_free_pages (but takes size instead of a page order).  If your
driver needs regions sized smaller than a page, you may prefer using
the dma_pool interface, described below.

The consistent DMA mapping interfaces, for non-NULL dev, will by
default return a DMA address which is 32-bit addressable.  Even if the
device indicates (via DMA mask) that it may address the upper 32-bits,
consistent allocation will only return > 32-bit addresses for DMA if
the consistent DMA mask has been explicitly changed via
dma_set_coherent_mask().  This is true of the dma_pool interface as
well.

dma_alloc_coherent returns two values: the virtual address which you
can use to access it from the CPU and dma_handle which you pass to the
card.

The cpu return address and the DMA bus master address are both
guaranteed to be aligned to the smallest PAGE_SIZE order which
is greater than or equal to the requested size.  This invariant
exists (for example) to guarantee that if you allocate a chunk
which is smaller than or equal to 64 kilobytes, the extent of the
buffer you receive will not cross a 64K boundary.

To unmap and free such a DMA region, you call:

	dma_free_coherent(dev, size, cpu_addr, dma_handle);

where dev, size are the same as in the above call and cpu_addr and
dma_handle are the values dma_alloc_coherent returned to you.
This function may not be called in interrupt context.

If your driver needs lots of smaller memory regions, you can write
custom code to subdivide pages returned by dma_alloc_coherent,
or you can use the dma_pool API to do that.  A dma_pool is like
a kmem_cache, but it uses dma_alloc_coherent not __get_free_pages.
Also, it understands common hardware constraints for alignment,
like queue heads needing to be aligned on N byte boundaries.

Create a dma_pool like this:

	struct dma_pool *pool;

	pool = dma_pool_create(name, dev, size, align, alloc);

The "name" is for diagnostics (like a kmem_cache name); dev and size
are as above.  The device's hardware alignment requirement for this
type of data is "align" (which is expressed in bytes, and must be a
power of two).  If your device has no boundary crossing restrictions,
pass 0 for alloc; passing 4096 says memory allocated from this pool
must not cross 4KByte boundaries (but at that time it may be better to
go for dma_alloc_coherent directly instead).

Allocate memory from a dma pool like this:

	cpu_addr = dma_pool_alloc(pool, flags, &dma_handle);

flags are SLAB_KERNEL if blocking is permitted (not in_interrupt nor
holding SMP locks), SLAB_ATOMIC otherwise.  Like dma_alloc_coherent,
this returns two values, cpu_addr and dma_handle.

Free memory that was allocated from a dma_pool like this:

	dma_pool_free(pool, cpu_addr, dma_handle);

where pool is what you passed to dma_pool_alloc, and cpu_addr and
dma_handle are the values dma_pool_alloc returned. This function
may be called in interrupt context.

Destroy a dma_pool by calling:

	dma_pool_destroy(pool);

Make sure you've called dma_pool_free for all memory allocated
from a pool before you destroy the pool. This function may not
be called in interrupt context.

			DMA Direction

The interfaces described in subsequent portions of this document
take a DMA direction argument, which is an integer and takes on
one of the following values:

 DMA_BIDIRECTIONAL
 DMA_TO_DEVICE
 DMA_FROM_DEVICE
 DMA_NONE

One should provide the exact DMA direction if you know it.

DMA_TO_DEVICE means "from main memory to the device"
DMA_FROM_DEVICE means "from the device to main memory"
It is the direction in which the data moves during the DMA
transfer.

You are _strongly_ encouraged to specify this as precisely
as you possibly can.

If you absolutely cannot know the direction of the DMA transfer,
specify DMA_BIDIRECTIONAL.  It means that the DMA can go in
either direction.  The platform guarantees that you may legally
specify this, and that it will work, but this may be at the
cost of performance for example.

The value DMA_NONE is to be used for debugging.  One can
hold this in a data structure before you come to know the
precise direction, and this will help catch cases where your
direction tracking logic has failed to set things up properly.

Another advantage of specifying this value precisely (outside of
potential platform-specific optimizations of such) is for debugging.
Some platforms actually have a write permission boolean which DMA
mappings can be marked with, much like page protections in the user
program address space.  Such platforms can and do report errors in the
kernel logs when the DMA controller hardware detects violation of the
permission setting.

Only streaming mappings specify a direction, consistent mappings
implicitly have a direction attribute setting of
DMA_BIDIRECTIONAL.

The SCSI subsystem tells you the direction to use in the
'sc_data_direction' member of the SCSI command your driver is
working on.

For Networking drivers, it's a rather simple affair.  For transmit
packets, map/unmap them with the DMA_TO_DEVICE direction
specifier.  For receive packets, just the opposite, map/unmap them
with the DMA_FROM_DEVICE direction specifier.

		  Using Streaming DMA mappings

The streaming DMA mapping routines can be called from interrupt
context.  There are two versions of each map/unmap, one which will
map/unmap a single memory region, and one which will map/unmap a
scatterlist.

To map a single region, you do:

	struct device *dev = &my_dev->dev;
	dma_addr_t dma_handle;
	void *addr = buffer->ptr;
	size_t size = buffer->len;

	dma_handle = dma_map_single(dev, addr, size, direction);

and to unmap it:

	dma_unmap_single(dev, dma_handle, size, direction);

You should call dma_unmap_single when the DMA activity is finished, e.g.
from the interrupt which told you that the DMA transfer is done.

Using cpu pointers like this for single mappings has a disadvantage,
you cannot reference HIGHMEM memory in this way.  Thus, there is a
map/unmap interface pair akin to dma_{map,unmap}_single.  These
interfaces deal with page/offset pairs instead of cpu pointers.
Specifically:

	struct device *dev = &my_dev->dev;
	dma_addr_t dma_handle;
	struct page *page = buffer->page;
	unsigned long offset = buffer->offset;
	size_t size = buffer->len;

	dma_handle = dma_map_page(dev, page, offset, size, direction);

	...

	dma_unmap_page(dev, dma_handle, size, direction);

Here, "offset" means byte offset within the given page.

With scatterlists, you map a region gathered from several regions by:

	int i, count = dma_map_sg(dev, sglist, nents, direction);
	struct scatterlist *sg;

	for_each_sg(sglist, sg, count, i) {
		hw_address[i] = sg_dma_address(sg);
		hw_len[i] = sg_dma_len(sg);
	}

where nents is the number of entries in the sglist.

The implementation is free to merge several consecutive sglist entries
into one (e.g. if DMA mapping is done with PAGE_SIZE granularity, any
consecutive sglist entries can be merged into one provided the first one
ends and the second one starts on a page boundary - in fact this is a huge
advantage for cards which either cannot do scatter-gather or have very
limited number of scatter-gather entries) and returns the actual number
of sg entries it mapped them to. On failure 0 is returned.

Then you should loop count times (note: this can be less than nents times)
and use sg_dma_address() and sg_dma_len() macros where you previously
accessed sg->address and sg->length as shown above.

To unmap a scatterlist, just call:

	dma_unmap_sg(dev, sglist, nents, direction);

Again, make sure DMA activity has already finished.

PLEASE NOTE:  The 'nents' argument to the dma_unmap_sg call must be
              the _same_ one you passed into the dma_map_sg call,
	      it should _NOT_ be the 'count' value _returned_ from the
              dma_map_sg call.

Every dma_map_{single,sg} call should have its dma_unmap_{single,sg}
counterpart, because the bus address space is a shared resource (although
in some ports the mapping is per each BUS so less devices contend for the
same bus address space) and you could render the machine unusable by eating
all bus addresses.

If you need to use the same streaming DMA region multiple times and touch
the data in between the DMA transfers, the buffer needs to be synced
properly in order for the cpu and device to see the most uptodate and
correct copy of the DMA buffer.

So, firstly, just map it with dma_map_{single,sg}, and after each DMA
transfer call either:

	dma_sync_single_for_cpu(dev, dma_handle, size, direction);

or:

	dma_sync_sg_for_cpu(dev, sglist, nents, direction);

as appropriate.

Then, if you wish to let the device get at the DMA area again,
finish accessing the data with the cpu, and then before actually
giving the buffer to the hardware call either:

	dma_sync_single_for_device(dev, dma_handle, size, direction);

or:

	dma_sync_sg_for_device(dev, sglist, nents, direction);

as appropriate.

After the last DMA transfer call one of the DMA unmap routines
dma_unmap_{single,sg}. If you don't touch the data from the first dma_map_*
call till dma_unmap_*, then you don't have to call the dma_sync_*
routines at all.

Here is pseudo code which shows a situation in which you would need
to use the dma_sync_*() interfaces.

	my_card_setup_receive_buffer(struct my_card *cp, char *buffer, int len)
	{
		dma_addr_t mapping;

		mapping = dma_map_single(cp->dev, buffer, len, DMA_FROM_DEVICE);

		cp->rx_buf = buffer;
		cp->rx_len = len;
		cp->rx_dma = mapping;

		give_rx_buf_to_card(cp);
	}

	...

	my_card_interrupt_handler(int irq, void *devid, struct pt_regs *regs)
	{
		struct my_card *cp = devid;

		...
		if (read_card_status(cp) == RX_BUF_TRANSFERRED) {
			struct my_card_header *hp;

			/* Examine the header to see if we wish
			 * to accept the data.  But synchronize
			 * the DMA transfer with the CPU first
			 * so that we see updated contents.
			 */
			dma_sync_single_for_cpu(&cp->dev, cp->rx_dma,
						cp->rx_len,
						DMA_FROM_DEVICE);

			/* Now it is safe to examine the buffer. */
			hp = (struct my_card_header *) cp->rx_buf;
			if (header_is_ok(hp)) {
				dma_unmap_single(&cp->dev, cp->rx_dma, cp->rx_len,
						 DMA_FROM_DEVICE);
				pass_to_upper_layers(cp->rx_buf);
				make_and_setup_new_rx_buf(cp);
			} else {
				/* Just sync the buffer and give it back
				 * to the card.
				 */
				dma_sync_single_for_device(&cp->dev,
							   cp->rx_dma,
							   cp->rx_len,
							   DMA_FROM_DEVICE);
				give_rx_buf_to_card(cp);
			}
		}
	}

Drivers converted fully to this interface should not use virt_to_bus any
longer, nor should they use bus_to_virt. Some drivers have to be changed a
little bit, because there is no longer an equivalent to bus_to_virt in the
dynamic DMA mapping scheme - you have to always store the DMA addresses
returned by the dma_alloc_coherent, dma_pool_alloc, and dma_map_single
calls (dma_map_sg stores them in the scatterlist itself if the platform
supports dynamic DMA mapping in hardware) in your driver structures and/or
in the card registers.

All drivers should be using these interfaces with no exceptions.  It
is planned to completely remove virt_to_bus() and bus_to_virt() as
they are entirely deprecated.  Some ports already do not provide these
as it is impossible to correctly support them.

			Handling Errors

DMA address space is limited on some architectures and an allocation
failure can be determined by:

- checking if dma_alloc_coherent returns NULL or dma_map_sg returns 0

- checking the returned dma_addr_t of dma_map_single and dma_map_page
  by using dma_mapping_error():

	dma_addr_t dma_handle;

	dma_handle = dma_map_single(dev, addr, size, direction);
	if (dma_mapping_error(dev, dma_handle)) {
		/*
		 * reduce current DMA mapping usage,
		 * delay and try again later or
		 * reset driver.
		 */
	}

Networking drivers must call dev_kfree_skb to free the socket buffer
and return NETDEV_TX_OK if the DMA mapping fails on the transmit hook
(ndo_start_xmit). This means that the socket buffer is just dropped in
the failure case.

SCSI drivers must return SCSI_MLQUEUE_HOST_BUSY if the DMA mapping
fails in the queuecommand hook. This means that the SCSI subsystem
passes the command to the driver again later.

		Optimizing Unmap State Space Consumption

On many platforms, dma_unmap_{single,page}() is simply a nop.
Therefore, keeping track of the mapping address and length is a waste
of space.  Instead of filling your drivers up with ifdefs and the like
to "work around" this (which would defeat the whole purpose of a
portable API) the following facilities are provided.

Actually, instead of describing the macros one by one, we'll
transform some example code.

1) Use DEFINE_DMA_UNMAP_{ADDR,LEN} in state saving structures.
   Example, before:

	struct ring_state {
		struct sk_buff *skb;
		dma_addr_t mapping;
		__u32 len;
	};

   after:

	struct ring_state {
		struct sk_buff *skb;
		DEFINE_DMA_UNMAP_ADDR(mapping);
		DEFINE_DMA_UNMAP_LEN(len);
	};

2) Use dma_unmap_{addr,len}_set to set these values.
   Example, before:

	ringp->mapping = FOO;
	ringp->len = BAR;

   after:

	dma_unmap_addr_set(ringp, mapping, FOO);
	dma_unmap_len_set(ringp, len, BAR);

3) Use dma_unmap_{addr,len} to access these values.
   Example, before:

	dma_unmap_single(dev, ringp->mapping, ringp->len,
			 DMA_FROM_DEVICE);

   after:

	dma_unmap_single(dev,
			 dma_unmap_addr(ringp, mapping),
			 dma_unmap_len(ringp, len),
			 DMA_FROM_DEVICE);

It really should be self-explanatory.  We treat the ADDR and LEN
separately, because it is possible for an implementation to only
need the address in order to perform the unmap operation.

			Platform Issues

If you are just writing drivers for Linux and do not maintain
an architecture port for the kernel, you can safely skip down
to "Closing".

1) Struct scatterlist requirements.

   Don't invent the architecture specific struct scatterlist; just use
   <asm-generic/scatterlist.h>. You need to enable
   CONFIG_NEED_SG_DMA_LENGTH if the architecture supports IOMMUs
   (including software IOMMU).

2) ARCH_DMA_MINALIGN

   Architectures must ensure that kmalloc'ed buffer is
   DMA-safe. Drivers and subsystems depend on it. If an architecture
   isn't fully DMA-coherent (i.e. hardware doesn't ensure that data in
   the CPU cache is identical to data in main memory),
   ARCH_DMA_MINALIGN must be set so that the memory allocator
   makes sure that kmalloc'ed buffer doesn't share a cache line with
   the others. See arch/arm/include/asm/cache.h as an example.

   Note that ARCH_DMA_MINALIGN is about DMA memory alignment
   constraints. You don't need to worry about the architecture data
   alignment constraints (e.g. the alignment constraints about 64-bit
   objects).

3) Supporting multiple types of IOMMUs

   If your architecture needs to support multiple types of IOMMUs, you
   can use include/linux/asm-generic/dma-mapping-common.h. It's a
   library to support the DMA API with multiple types of IOMMUs. Lots
   of architectures (x86, powerpc, sh, alpha, ia64, microblaze and
   sparc) use it. Choose one to see how it can be used. If you need to
   support multiple types of IOMMUs in a single system, the example of
   x86 or powerpc helps.

			   Closing

This document, and the API itself, would not be in its current
form without the feedback and suggestions from numerous individuals.
We would like to specifically mention, in no particular order, the
following people:

	Russell King <rmk@arm.linux.org.uk>
	Leo Dagum <dagum@barrel.engr.sgi.com>
	Ralf Baechle <ralf@oss.sgi.com>
	Grant Grundler <grundler@cup.hp.com>
	Jay Estabrook <Jay.Estabrook@compaq.com>
	Thomas Sailer <sailer@ife.ee.ethz.ch>
	Andrea Arcangeli <andrea@suse.de>
	Jens Axboe <jens.axboe@oracle.com>
	David Mosberger-Tang <davidm@hpl.hp.com>
               Dynamic DMA mapping using the generic device
               ============================================

        James E.J. Bottomley <James.Bottomley@HansenPartnership.com>

This document describes the DMA API.  For a more gentle introduction
of the API (and actual examples) see
Documentation/DMA-API-HOWTO.txt.

This API is split into two pieces.  Part I describes the API.  Part II
describes the extensions to the API for supporting non-consistent
memory machines.  Unless you know that your driver absolutely has to
support non-consistent platforms (this is usually only legacy
platforms) you should only use the API described in part I.

Part I - dma_ API
-------------------------------------

To get the dma_ API, you must #include <linux/dma-mapping.h>


Part Ia - Using large dma-coherent buffers
------------------------------------------

void *
dma_alloc_coherent(struct device *dev, size_t size,
			     dma_addr_t *dma_handle, gfp_t flag)

Consistent memory is memory for which a write by either the device or
the processor can immediately be read by the processor or device
without having to worry about caching effects.  (You may however need
to make sure to flush the processor's write buffers before telling
devices to read that memory.)

This routine allocates a region of <size> bytes of consistent memory.
It also returns a <dma_handle> which may be cast to an unsigned
integer the same width as the bus and used as the physical address
base of the region.

Returns: a pointer to the allocated region (in the processor's virtual
address space) or NULL if the allocation failed.

Note: consistent memory can be expensive on some platforms, and the
minimum allocation length may be as big as a page, so you should
consolidate your requests for consistent memory as much as possible.
The simplest way to do that is to use the dma_pool calls (see below).

The flag parameter (dma_alloc_coherent only) allows the caller to
specify the GFP_ flags (see kmalloc) for the allocation (the
implementation may choose to ignore flags that affect the location of
the returned memory, like GFP_DMA).

void
dma_free_coherent(struct device *dev, size_t size, void *cpu_addr,
			   dma_addr_t dma_handle)

Free the region of consistent memory you previously allocated.  dev,
size and dma_handle must all be the same as those passed into the
consistent allocate.  cpu_addr must be the virtual address returned by
the consistent allocate.

Note that unlike their sibling allocation calls, these routines
may only be called with IRQs enabled.


Part Ib - Using small dma-coherent buffers
------------------------------------------

To get this part of the dma_ API, you must #include <linux/dmapool.h>

Many drivers need lots of small dma-coherent memory regions for DMA
descriptors or I/O buffers.  Rather than allocating in units of a page
or more using dma_alloc_coherent(), you can use DMA pools.  These work
much like a struct kmem_cache, except that they use the dma-coherent allocator,
not __get_free_pages().  Also, they understand common hardware constraints
for alignment, like queue heads needing to be aligned on N-byte boundaries.


	struct dma_pool *
	dma_pool_create(const char *name, struct device *dev,
			size_t size, size_t align, size_t alloc);

The pool create() routines initialize a pool of dma-coherent buffers
for use with a given device.  It must be called in a context which
can sleep.

The "name" is for diagnostics (like a struct kmem_cache name); dev and size
are like what you'd pass to dma_alloc_coherent().  The device's hardware
alignment requirement for this type of data is "align" (which is expressed
in bytes, and must be a power of two).  If your device has no boundary
crossing restrictions, pass 0 for alloc; passing 4096 says memory allocated
from this pool must not cross 4KByte boundaries.


	void *dma_pool_alloc(struct dma_pool *pool, gfp_t gfp_flags,
			dma_addr_t *dma_handle);

This allocates memory from the pool; the returned memory will meet the size
and alignment requirements specified at creation time.  Pass GFP_ATOMIC to
prevent blocking, or if it's permitted (not in_interrupt, not holding SMP locks),
pass GFP_KERNEL to allow blocking.  Like dma_alloc_coherent(), this returns
two values:  an address usable by the cpu, and the dma address usable by the
pool's device.


	void dma_pool_free(struct dma_pool *pool, void *vaddr,
			dma_addr_t addr);

This puts memory back into the pool.  The pool is what was passed to
the pool allocation routine; the cpu (vaddr) and dma addresses are what
were returned when that routine allocated the memory being freed.


	void dma_pool_destroy(struct dma_pool *pool);

The pool destroy() routines free the resources of the pool.  They must be
called in a context which can sleep.  Make sure you've freed all allocated
memory back to the pool before you destroy it.


Part Ic - DMA addressing limitations
------------------------------------

int
dma_supported(struct device *dev, u64 mask)

Checks to see if the device can support DMA to the memory described by
mask.

Returns: 1 if it can and 0 if it can't.

Notes: This routine merely tests to see if the mask is possible.  It
won't change the current mask settings.  It is more intended as an
internal API for use by the platform than an external API for use by
driver writers.

int
dma_set_mask(struct device *dev, u64 mask)

Checks to see if the mask is possible and updates the device
parameters if it is.

Returns: 0 if successful and a negative error if not.

int
dma_set_coherent_mask(struct device *dev, u64 mask)

Checks to see if the mask is possible and updates the device
parameters if it is.

Returns: 0 if successful and a negative error if not.

u64
dma_get_required_mask(struct device *dev)

This API returns the mask that the platform requires to
operate efficiently.  Usually this means the returned mask
is the minimum required to cover all of memory.  Examining the
required mask gives drivers with variable descriptor sizes the
opportunity to use smaller descriptors as necessary.

Requesting the required mask does not alter the current mask.  If you
wish to take advantage of it, you should issue a dma_set_mask()
call to set the mask to the value returned.


Part Id - Streaming DMA mappings
--------------------------------

dma_addr_t
dma_map_single(struct device *dev, void *cpu_addr, size_t size,
		      enum dma_data_direction direction)

Maps a piece of processor virtual memory so it can be accessed by the
device and returns the physical handle of the memory.

The direction for both api's may be converted freely by casting.
However the dma_ API uses a strongly typed enumerator for its
direction:

DMA_NONE		no direction (used for debugging)
DMA_TO_DEVICE		data is going from the memory to the device
DMA_FROM_DEVICE		data is coming from the device to the memory
DMA_BIDIRECTIONAL	direction isn't known

Notes:  Not all memory regions in a machine can be mapped by this
API.  Further, regions that appear to be physically contiguous in
kernel virtual space may not be contiguous as physical memory.  Since
this API does not provide any scatter/gather capability, it will fail
if the user tries to map a non-physically contiguous piece of memory.
For this reason, it is recommended that memory mapped by this API be
obtained only from sources which guarantee it to be physically contiguous
(like kmalloc).

Further, the physical address of the memory must be within the
dma_mask of the device (the dma_mask represents a bit mask of the
addressable region for the device.  I.e., if the physical address of
the memory anded with the dma_mask is still equal to the physical
address, then the device can perform DMA to the memory).  In order to
ensure that the memory allocated by kmalloc is within the dma_mask,
the driver may specify various platform-dependent flags to restrict
the physical memory range of the allocation (e.g. on x86, GFP_DMA
guarantees to be within the first 16Mb of available physical memory,
as required by ISA devices).

Note also that the above constraints on physical contiguity and
dma_mask may not apply if the platform has an IOMMU (a device which
supplies a physical to virtual mapping between the I/O memory bus and
the device).  However, to be portable, device driver writers may *not*
assume that such an IOMMU exists.

Warnings:  Memory coherency operates at a granularity called the cache
line width.  In order for memory mapped by this API to operate
correctly, the mapped region must begin exactly on a cache line
boundary and end exactly on one (to prevent two separately mapped
regions from sharing a single cache line).  Since the cache line size
may not be known at compile time, the API will not enforce this
requirement.  Therefore, it is recommended that driver writers who
don't take special care to determine the cache line size at run time
only map virtual regions that begin and end on page boundaries (which
are guaranteed also to be cache line boundaries).

DMA_TO_DEVICE synchronisation must be done after the last modification
of the memory region by the software and before it is handed off to
the driver.  Once this primitive is used, memory covered by this
primitive should be treated as read-only by the device.  If the device
may write to it at any point, it should be DMA_BIDIRECTIONAL (see
below).

DMA_FROM_DEVICE synchronisation must be done before the driver
accesses data that may be changed by the device.  This memory should
be treated as read-only by the driver.  If the driver needs to write
to it at any point, it should be DMA_BIDIRECTIONAL (see below).

DMA_BIDIRECTIONAL requires special handling: it means that the driver
isn't sure if the memory was modified before being handed off to the
device and also isn't sure if the device will also modify it.  Thus,
you must always sync bidirectional memory twice: once before the
memory is handed off to the device (to make sure all memory changes
are flushed from the processor) and once before the data may be
accessed after being used by the device (to make sure any processor
cache lines are updated with data that the device may have changed).

void
dma_unmap_single(struct device *dev, dma_addr_t dma_addr, size_t size,
		 enum dma_data_direction direction)

Unmaps the region previously mapped.  All the parameters passed in
must be identical to those passed in (and returned) by the mapping
API.

dma_addr_t
dma_map_page(struct device *dev, struct page *page,
		    unsigned long offset, size_t size,
		    enum dma_data_direction direction)
void
dma_unmap_page(struct device *dev, dma_addr_t dma_address, size_t size,
	       enum dma_data_direction direction)

API for mapping and unmapping for pages.  All the notes and warnings
for the other mapping APIs apply here.  Also, although the <offset>
and <size> parameters are provided to do partial page mapping, it is
recommended that you never use these unless you really know what the
cache width is.

int
dma_mapping_error(struct device *dev, dma_addr_t dma_addr)

In some circumstances dma_map_single and dma_map_page will fail to create
a mapping. A driver can check for these errors by testing the returned
dma address with dma_mapping_error(). A non-zero return value means the mapping
could not be created and the driver should take appropriate action (e.g.
reduce current DMA mapping usage or delay and try again later).

	int
	dma_map_sg(struct device *dev, struct scatterlist *sg,
		int nents, enum dma_data_direction direction)

Returns: the number of physical segments mapped (this may be shorter
than <nents> passed in if some elements of the scatter/gather list are
physically or virtually adjacent and an IOMMU maps them with a single
entry).

Please note that the sg cannot be mapped again if it has been mapped once.
The mapping process is allowed to destroy information in the sg.

As with the other mapping interfaces, dma_map_sg can fail. When it
does, 0 is returned and a driver must take appropriate action. It is
critical that the driver do something, in the case of a block driver
aborting the request or even oopsing is better than doing nothing and
corrupting the filesystem.

With scatterlists, you use the resulting mapping like this:

	int i, count = dma_map_sg(dev, sglist, nents, direction);
	struct scatterlist *sg;

	for_each_sg(sglist, sg, count, i) {
		hw_address[i] = sg_dma_address(sg);
		hw_len[i] = sg_dma_len(sg);
	}

where nents is the number of entries in the sglist.

The implementation is free to merge several consecutive sglist entries
into one (e.g. with an IOMMU, or if several pages just happen to be
physically contiguous) and returns the actual number of sg entries it
mapped them to. On failure 0, is returned.

Then you should loop count times (note: this can be less than nents times)
and use sg_dma_address() and sg_dma_len() macros where you previously
accessed sg->address and sg->length as shown above.

	void
	dma_unmap_sg(struct device *dev, struct scatterlist *sg,
		int nhwentries, enum dma_data_direction direction)

Unmap the previously mapped scatter/gather list.  All the parameters
must be the same as those and passed in to the scatter/gather mapping
API.

Note: <nents> must be the number you passed in, *not* the number of
physical entries returned.

void
dma_sync_single_for_cpu(struct device *dev, dma_addr_t dma_handle, size_t size,
			enum dma_data_direction direction)
void
dma_sync_single_for_device(struct device *dev, dma_addr_t dma_handle, size_t size,
			   enum dma_data_direction direction)
void
dma_sync_sg_for_cpu(struct device *dev, struct scatterlist *sg, int nelems,
		    enum dma_data_direction direction)
void
dma_sync_sg_for_device(struct device *dev, struct scatterlist *sg, int nelems,
		       enum dma_data_direction direction)

Synchronise a single contiguous or scatter/gather mapping for the cpu
and device. With the sync_sg API, all the parameters must be the same
as those passed into the single mapping API. With the sync_single API,
you can use dma_handle and size parameters that aren't identical to
those passed into the single mapping API to do a partial sync.

Notes:  You must do this:

- Before reading values that have been written by DMA from the device
  (use the DMA_FROM_DEVICE direction)
- After writing values that will be written to the device using DMA
  (use the DMA_TO_DEVICE) direction
- before *and* after handing memory to the device if the memory is
  DMA_BIDIRECTIONAL

See also dma_map_single().

dma_addr_t
dma_map_single_attrs(struct device *dev, void *cpu_addr, size_t size,
		     enum dma_data_direction dir,
		     struct dma_attrs *attrs)

void
dma_unmap_single_attrs(struct device *dev, dma_addr_t dma_addr,
		       size_t size, enum dma_data_direction dir,
		       struct dma_attrs *attrs)

int
dma_map_sg_attrs(struct device *dev, struct scatterlist *sgl,
		 int nents, enum dma_data_direction dir,
		 struct dma_attrs *attrs)

void
dma_unmap_sg_attrs(struct device *dev, struct scatterlist *sgl,
		   int nents, enum dma_data_direction dir,
		   struct dma_attrs *attrs)

The four functions above are just like the counterpart functions
without the _attrs suffixes, except that they pass an optional
struct dma_attrs*.

struct dma_attrs encapsulates a set of "dma attributes". For the
definition of struct dma_attrs see linux/dma-attrs.h.

The interpretation of dma attributes is architecture-specific, and
each attribute should be documented in Documentation/DMA-attributes.txt.

If struct dma_attrs* is NULL, the semantics of each of these
functions is identical to those of the corresponding function
without the _attrs suffix. As a result dma_map_single_attrs()
can generally replace dma_map_single(), etc.

As an example of the use of the *_attrs functions, here's how
you could pass an attribute DMA_ATTR_FOO when mapping memory
for DMA:

#include <linux/dma-attrs.h>
/* DMA_ATTR_FOO should be defined in linux/dma-attrs.h and
 * documented in Documentation/DMA-attributes.txt */
...

	DEFINE_DMA_ATTRS(attrs);
	dma_set_attr(DMA_ATTR_FOO, &attrs);
	....
	n = dma_map_sg_attrs(dev, sg, nents, DMA_TO_DEVICE, &attr);
	....

Architectures that care about DMA_ATTR_FOO would check for its
presence in their implementations of the mapping and unmapping
routines, e.g.:

void whizco_dma_map_sg_attrs(struct device *dev, dma_addr_t dma_addr,
			     size_t size, enum dma_data_direction dir,
			     struct dma_attrs *attrs)
{
	....
	int foo =  dma_get_attr(DMA_ATTR_FOO, attrs);
	....
	if (foo)
		/* twizzle the frobnozzle */
	....


Part II - Advanced dma_ usage
-----------------------------

Warning: These pieces of the DMA API should not be used in the
majority of cases, since they cater for unlikely corner cases that
don't belong in usual drivers.

If you don't understand how cache line coherency works between a
processor and an I/O device, you should not be using this part of the
API at all.

void *
dma_alloc_noncoherent(struct device *dev, size_t size,
			       dma_addr_t *dma_handle, gfp_t flag)

Identical to dma_alloc_coherent() except that the platform will
choose to return either consistent or non-consistent memory as it sees
fit.  By using this API, you are guaranteeing to the platform that you
have all the correct and necessary sync points for this memory in the
driver should it choose to return non-consistent memory.

Note: where the platform can return consistent memory, it will
guarantee that the sync points become nops.

Warning:  Handling non-consistent memory is a real pain.  You should
only ever use this API if you positively know your driver will be
required to work on one of the rare (usually non-PCI) architectures
that simply cannot make consistent memory.

void
dma_free_noncoherent(struct device *dev, size_t size, void *cpu_addr,
			      dma_addr_t dma_handle)

Free memory allocated by the nonconsistent API.  All parameters must
be identical to those passed in (and returned by
dma_alloc_noncoherent()).

int
dma_get_cache_alignment(void)

Returns the processor cache alignment.  This is the absolute minimum
alignment *and* width that you must observe when either mapping
memory or doing partial flushes.

Notes: This API may return a number *larger* than the actual cache
line, but it will guarantee that one or more cache lines fit exactly
into the width returned by this call.  It will also always be a power
of two for easy alignment.

void
dma_cache_sync(struct device *dev, void *vaddr, size_t size,
	       enum dma_data_direction direction)

Do a partial sync of memory that was allocated by
dma_alloc_noncoherent(), starting at virtual address vaddr and
continuing on for size.  Again, you *must* observe the cache line
boundaries when doing this.

int
dma_declare_coherent_memory(struct device *dev, dma_addr_t bus_addr,
			    dma_addr_t device_addr, size_t size, int
			    flags)

Declare region of memory to be handed out by dma_alloc_coherent when
it's asked for coherent memory for this device.

bus_addr is the physical address to which the memory is currently
assigned in the bus responding region (this will be used by the
platform to perform the mapping).

device_addr is the physical address the device needs to be programmed
with actually to address this memory (this will be handed out as the
dma_addr_t in dma_alloc_coherent()).

size is the size of the area (must be multiples of PAGE_SIZE).

flags can be or'd together and are:

DMA_MEMORY_MAP - request that the memory returned from
dma_alloc_coherent() be directly writable.

DMA_MEMORY_IO - request that the memory returned from
dma_alloc_coherent() be addressable using read/write/memcpy_toio etc.

One or both of these flags must be present.

DMA_MEMORY_INCLUDES_CHILDREN - make the declared memory be allocated by
dma_alloc_coherent of any child devices of this one (for memory residing
on a bridge).

DMA_MEMORY_EXCLUSIVE - only allocate memory from the declared regions. 
Do not allow dma_alloc_coherent() to fall back to system memory when
it's out of memory in the declared region.

The return value will be either DMA_MEMORY_MAP or DMA_MEMORY_IO and
must correspond to a passed in flag (i.e. no returning DMA_MEMORY_IO
if only DMA_MEMORY_MAP were passed in) for success or zero for
failure.

Note, for DMA_MEMORY_IO returns, all subsequent memory returned by
dma_alloc_coherent() may no longer be accessed directly, but instead
must be accessed using the correct bus functions.  If your driver
isn't prepared to handle this contingency, it should not specify
DMA_MEMORY_IO in the input flags.

As a simplification for the platforms, only *one* such region of
memory may be declared per device.

For reasons of efficiency, most platforms choose to track the declared
region only at the granularity of a page.  For smaller allocations,
you should use the dma_pool() API.

void
dma_release_declared_memory(struct device *dev)

Remove the memory region previously declared from the system.  This
API performs *no* in-use checking for this region and will return
unconditionally having removed all the required structures.  It is the
driver's job to ensure that no parts of this memory region are
currently in use.

void *
dma_mark_declared_memory_occupied(struct device *dev,
				  dma_addr_t device_addr, size_t size)

This is used to occupy specific regions of the declared space
(dma_alloc_coherent() will hand out the first free region it finds).

device_addr is the *device* address of the region requested.

size is the size (and should be a page-sized multiple).

The return value will be either a pointer to the processor virtual
address of the memory, or an error (via PTR_ERR()) if any part of the
region is occupied.

Part III - Debug drivers use of the DMA-API
-------------------------------------------

The DMA-API as described above as some constraints. DMA addresses must be
released with the corresponding function with the same size for example. With
the advent of hardware IOMMUs it becomes more and more important that drivers
do not violate those constraints. In the worst case such a violation can
result in data corruption up to destroyed filesystems.

To debug drivers and find bugs in the usage of the DMA-API checking code can
be compiled into the kernel which will tell the developer about those
violations. If your architecture supports it you can select the "Enable
debugging of DMA-API usage" option in your kernel configuration. Enabling this
option has a performance impact. Do not enable it in production kernels.

If you boot the resulting kernel will contain code which does some bookkeeping
about what DMA memory was allocated for which device. If this code detects an
error it prints a warning message with some details into your kernel log. An
example warning message may look like this:

------------[ cut here ]------------
WARNING: at /data2/repos/linux-2.6-iommu/lib/dma-debug.c:448
	check_unmap+0x203/0x490()
Hardware name:
forcedeth 0000:00:08.0: DMA-API: device driver frees DMA memory with wrong
	function [device address=0x00000000640444be] [size=66 bytes] [mapped as
single] [unmapped as page]
Modules linked in: nfsd exportfs bridge stp llc r8169
Pid: 0, comm: swapper Tainted: G        W  2.6.28-dmatest-09289-g8bb99c0 #1
Call Trace:
 <IRQ>  [<ffffffff80240b22>] warn_slowpath+0xf2/0x130
 [<ffffffff80647b70>] _spin_unlock+0x10/0x30
 [<ffffffff80537e75>] usb_hcd_link_urb_to_ep+0x75/0xc0
 [<ffffffff80647c22>] _spin_unlock_irqrestore+0x12/0x40
 [<ffffffff8055347f>] ohci_urb_enqueue+0x19f/0x7c0
 [<ffffffff80252f96>] queue_work+0x56/0x60
 [<ffffffff80237e10>] enqueue_task_fair+0x20/0x50
 [<ffffffff80539279>] usb_hcd_submit_urb+0x379/0xbc0
 [<ffffffff803b78c3>] cpumask_next_and+0x23/0x40
 [<ffffffff80235177>] find_busiest_group+0x207/0x8a0
 [<ffffffff8064784f>] _spin_lock_irqsave+0x1f/0x50
 [<ffffffff803c7ea3>] check_unmap+0x203/0x490
 [<ffffffff803c8259>] debug_dma_unmap_page+0x49/0x50
 [<ffffffff80485f26>] nv_tx_done_optimized+0xc6/0x2c0
 [<ffffffff80486c13>] nv_nic_irq_optimized+0x73/0x2b0
 [<ffffffff8026df84>] handle_IRQ_event+0x34/0x70
 [<ffffffff8026ffe9>] handle_edge_irq+0xc9/0x150
 [<ffffffff8020e3ab>] do_IRQ+0xcb/0x1c0
 [<ffffffff8020c093>] ret_from_intr+0x0/0xa
 <EOI> <4>---[ end trace f6435a98e2a38c0e ]---

The driver developer can find the driver and the device including a stacktrace
of the DMA-API call which caused this warning.

Per default only the first error will result in a warning message. All other
errors will only silently counted. This limitation exist to prevent the code
from flooding your kernel log. To support debugging a device driver this can
be disabled via debugfs. See the debugfs interface documentation below for
details.

The debugfs directory for the DMA-API debugging code is called dma-api/. In
this directory the following files can currently be found:

	dma-api/all_errors	This file contains a numeric value. If this
				value is not equal to zero the debugging code
				will print a warning for every error it finds
				into the kernel log. Be careful with this
				option, as it can easily flood your logs.

	dma-api/disabled	This read-only file contains the character 'Y'
				if the debugging code is disabled. This can
				happen when it runs out of memory or if it was
				disabled at boot time

	dma-api/error_count	This file is read-only and shows the total
				numbers of errors found.

	dma-api/num_errors	The number in this file shows how many
				warnings will be printed to the kernel log
				before it stops. This number is initialized to
				one at system boot and be set by writing into
				this file

	dma-api/min_free_entries
				This read-only file can be read to get the
				minimum number of free dma_debug_entries the
				allocator has ever seen. If this value goes
				down to zero the code will disable itself
				because it is not longer reliable.

	dma-api/num_free_entries
				The current number of free dma_debug_entries
				in the allocator.

	dma-api/driver-filter
				You can write a name of a driver into this file
				to limit the debug output to requests from that
				particular driver. Write an empty string to
				that file to disable the filter and see
				all errors again.

If you have this code compiled into your kernel it will be enabled by default.
If you want to boot without the bookkeeping anyway you can provide
'dma_debug=off' as a boot parameter. This will disable DMA-API debugging.
Notice that you can not enable it again at runtime. You have to reboot to do
so.

If you want to see debug messages only for a special device driver you can
specify the dma_debug_driver=<drivername> parameter. This will enable the
driver filter at boot time. The debug code will only print errors for that
driver afterwards. This filter can be disabled or changed later using debugfs.

When the code disables itself at runtime this is most likely because it ran
out of dma_debug_entries. These entries are preallocated at boot. The number
of preallocated entries is defined per architecture. If it is too low for you
boot with 'dma_debug_entries=<your_desired_number>' to overwrite the
architectural default.
			DMA attributes
			==============

This document describes the semantics of the DMA attributes that are
defined in linux/dma-attrs.h.

DMA_ATTR_WRITE_BARRIER
----------------------

DMA_ATTR_WRITE_BARRIER is a (write) barrier attribute for DMA.  DMA
to a memory region with the DMA_ATTR_WRITE_BARRIER attribute forces
all pending DMA writes to complete, and thus provides a mechanism to
strictly order DMA from a device across all intervening busses and
bridges.  This barrier is not specific to a particular type of
interconnect, it applies to the system as a whole, and so its
implementation must account for the idiosyncracies of the system all
the way from the DMA device to memory.

As an example of a situation where DMA_ATTR_WRITE_BARRIER would be
useful, suppose that a device does a DMA write to indicate that data is
ready and available in memory.  The DMA of the "completion indication"
could race with data DMA.  Mapping the memory used for completion
indications with DMA_ATTR_WRITE_BARRIER would prevent the race.

DMA_ATTR_WEAK_ORDERING
----------------------

DMA_ATTR_WEAK_ORDERING specifies that reads and writes to the mapping
may be weakly ordered, that is that reads and writes may pass each other.

Since it is optional for platforms to implement DMA_ATTR_WEAK_ORDERING,
those that do not will simply ignore the attribute and exhibit default
behavior.
			DMA Engine API Guide
			====================

		 Vinod Koul <vinod dot koul at intel.com>

NOTE: For DMA Engine usage in async_tx please see:
	Documentation/crypto/async-tx-api.txt


Below is a guide to device driver writers on how to use the Slave-DMA API of the
DMA Engine. This is applicable only for slave DMA usage only.

The slave DMA usage consists of following steps
1. Allocate a DMA slave channel
2. Set slave and controller specific parameters
3. Get a descriptor for transaction
4. Submit the transaction and wait for callback notification

1. Allocate a DMA slave channel
Channel allocation is slightly different in the slave DMA context, client
drivers typically need a channel from a particular DMA controller only and even
in some cases a specific channel is desired. To request a channel
dma_request_channel() API is used.

Interface:
struct dma_chan *dma_request_channel(dma_cap_mask_t mask,
		dma_filter_fn filter_fn,
		void *filter_param);
where dma_filter_fn is defined as:
typedef bool (*dma_filter_fn)(struct dma_chan *chan, void *filter_param);

When the optional 'filter_fn' parameter is set to NULL dma_request_channel
simply returns the first channel that satisfies the capability mask.  Otherwise,
when the mask parameter is insufficient for specifying the necessary channel,
the filter_fn routine can be used to disposition the available channels in the
system. The filter_fn routine is called once for each free channel in the
system.  Upon seeing a suitable channel filter_fn returns DMA_ACK which flags
that channel to be the return value from dma_request_channel.  A channel
allocated via this interface is exclusive to the caller, until
dma_release_channel() is called.

2. Set slave and controller specific parameters
Next step is always to pass some specific information to the DMA driver. Most of
the generic information which a slave DMA can use is in struct dma_slave_config.
It allows the clients to specify DMA direction, DMA addresses, bus widths, DMA
burst lengths etc. If some DMA controllers have more parameters to be sent then
they should try to embed struct dma_slave_config in their controller specific
structure. That gives flexibility to client to pass more parameters, if
required.

Interface:
int dmaengine_slave_config(struct dma_chan *chan,
					  struct dma_slave_config *config)

3. Get a descriptor for transaction
For slave usage the various modes of slave transfers supported by the
DMA-engine are:
slave_sg	- DMA a list of scatter gather buffers from/to a peripheral
dma_cyclic	- Perform a cyclic DMA operation from/to a peripheral till the
		  operation is explicitly stopped.
The non NULL return of this transfer API represents a "descriptor" for the given
transaction.

Interface:
struct dma_async_tx_descriptor *(*chan->device->device_prep_dma_sg)(
		struct dma_chan *chan,
		struct scatterlist *dst_sg, unsigned int dst_nents,
		struct scatterlist *src_sg, unsigned int src_nents,
		unsigned long flags);
struct dma_async_tx_descriptor *(*chan->device->device_prep_dma_cyclic)(
		struct dma_chan *chan, dma_addr_t buf_addr, size_t buf_len,
		size_t period_len, enum dma_data_direction direction);

4. Submit the transaction and wait for callback notification
To schedule the transaction to be scheduled by dma device, the "descriptor"
returned in above (3) needs to be submitted.
To tell the dma driver that a transaction is ready to be serviced, the
descriptor->submit() callback needs to be invoked. This chains the descriptor to
the pending queue.
The transactions in the pending queue can be activated by calling the
issue_pending API. If channel is idle then the first transaction in queue is
started and subsequent ones queued up.
On completion of the DMA operation the next in queue is submitted and a tasklet
triggered. The tasklet would then call the client driver completion callback
routine for notification, if set.
Interface:
void dma_async_issue_pending(struct dma_chan *chan);

==============================================================================

Additional usage notes for dma driver writers
1/ Although DMA engine specifies that completion callback routines cannot submit
any new operations, but typically for slave DMA subsequent transaction may not
be available for submit prior to callback routine being called. This requirement
is not a requirement for DMA-slave devices. But they should take care to drop
the spin-lock they might be holding before calling the callback routine
                        DMA with ISA and LPC devices
                        ============================

                      Pierre Ossman <drzeus@drzeus.cx>

This document describes how to do DMA transfers using the old ISA DMA
controller. Even though ISA is more or less dead today the LPC bus
uses the same DMA system so it will be around for quite some time.

Part I - Headers and dependencies
---------------------------------

To do ISA style DMA you need to include two headers:

#include <linux/dma-mapping.h>
#include <asm/dma.h>

The first is the generic DMA API used to convert virtual addresses to
physical addresses (see Documentation/DMA-API.txt for details).

The second contains the routines specific to ISA DMA transfers. Since
this is not present on all platforms make sure you construct your
Kconfig to be dependent on ISA_DMA_API (not ISA) so that nobody tries
to build your driver on unsupported platforms.

Part II - Buffer allocation
---------------------------

The ISA DMA controller has some very strict requirements on which
memory it can access so extra care must be taken when allocating
buffers.

(You usually need a special buffer for DMA transfers instead of
transferring directly to and from your normal data structures.)

The DMA-able address space is the lowest 16 MB of _physical_ memory.
Also the transfer block may not cross page boundaries (which are 64
or 128 KiB depending on which channel you use).

In order to allocate a piece of memory that satisfies all these
requirements you pass the flag GFP_DMA to kmalloc.

Unfortunately the memory available for ISA DMA is scarce so unless you
allocate the memory during boot-up it's a good idea to also pass
__GFP_REPEAT and __GFP_NOWARN to make the allocater try a bit harder.

(This scarcity also means that you should allocate the buffer as
early as possible and not release it until the driver is unloaded.)

Part III - Address translation
------------------------------

To translate the virtual address to a physical use the normal DMA
API. Do _not_ use isa_virt_to_phys() even though it does the same
thing. The reason for this is that the function isa_virt_to_phys()
will require a Kconfig dependency to ISA, not just ISA_DMA_API which
is really all you need. Remember that even though the DMA controller
has its origins in ISA it is used elsewhere.

Note: x86_64 had a broken DMA API when it came to ISA but has since
been fixed. If your arch has problems then fix the DMA API instead of
reverting to the ISA functions.

Part IV - Channels
------------------

A normal ISA DMA controller has 8 channels. The lower four are for
8-bit transfers and the upper four are for 16-bit transfers.

(Actually the DMA controller is really two separate controllers where
channel 4 is used to give DMA access for the second controller (0-3).
This means that of the four 16-bits channels only three are usable.)

You allocate these in a similar fashion as all basic resources:

extern int request_dma(unsigned int dmanr, const char * device_id);
extern void free_dma(unsigned int dmanr);

The ability to use 16-bit or 8-bit transfers is _not_ up to you as a
driver author but depends on what the hardware supports. Check your
specs or test different channels.

Part V - Transfer data
----------------------

Now for the good stuff, the actual DMA transfer. :)

Before you use any ISA DMA routines you need to claim the DMA lock
using claim_dma_lock(). The reason is that some DMA operations are
not atomic so only one driver may fiddle with the registers at a
time.

The first time you use the DMA controller you should call
clear_dma_ff(). This clears an internal register in the DMA
controller that is used for the non-atomic operations. As long as you
(and everyone else) uses the locking functions then you only need to
reset this once.

Next, you tell the controller in which direction you intend to do the
transfer using set_dma_mode(). Currently you have the options
DMA_MODE_READ and DMA_MODE_WRITE.

Set the address from where the transfer should start (this needs to
be 16-bit aligned for 16-bit transfers) and how many bytes to
transfer. Note that it's _bytes_. The DMA routines will do all the
required translation to values that the DMA controller understands.

The final step is enabling the DMA channel and releasing the DMA
lock.

Once the DMA transfer is finished (or timed out) you should disable
the channel again. You should also check get_dma_residue() to make
sure that all data has been transferred.

Example:

int flags, residue;

flags = claim_dma_lock();

clear_dma_ff();

set_dma_mode(channel, DMA_MODE_WRITE);
set_dma_addr(channel, phys_addr);
set_dma_count(channel, num_bytes);

dma_enable(channel);

release_dma_lock(flags);

while (!device_done());

flags = claim_dma_lock();

dma_disable(channel);

residue = dma_get_residue(channel);
if (residue != 0)
	printk(KERN_ERR "driver: Incomplete DMA transfer!"
		" %d bytes left!\n", residue);

release_dma_lock(flags);

Part VI - Suspend/resume
------------------------

It is the driver's responsibility to make sure that the machine isn't
suspended while a DMA transfer is in progress. Also, all DMA settings
are lost when the system suspends so if your driver relies on the DMA
controller being in a certain state then you have to restore these
registers upon resume.

Introduction
============

This document describes how to use the dynamic debug (ddebug) feature.

Dynamic debug is designed to allow you to dynamically enable/disable kernel
code to obtain additional kernel information. Currently, if
CONFIG_DYNAMIC_DEBUG is set, then all pr_debug()/dev_dbg() calls can be
dynamically enabled per-callsite.

Dynamic debug has even more useful features:

 * Simple query language allows turning on and off debugging statements by
   matching any combination of:

   - source filename
   - function name
   - line number (including ranges of line numbers)
   - module name
   - format string

 * Provides a debugfs control file: <debugfs>/dynamic_debug/control which can be
   read to display the complete list of known debug statements, to help guide you

Controlling dynamic debug Behaviour
===================================

The behaviour of pr_debug()/dev_dbg()s are controlled via writing to a
control file in the 'debugfs' filesystem. Thus, you must first mount the debugfs
filesystem, in order to make use of this feature. Subsequently, we refer to the
control file as: <debugfs>/dynamic_debug/control. For example, if you want to
enable printing from source file 'svcsock.c', line 1603 you simply do:

nullarbor:~ # echo 'file svcsock.c line 1603 +p' >
				<debugfs>/dynamic_debug/control

If you make a mistake with the syntax, the write will fail thus:

nullarbor:~ # echo 'file svcsock.c wtf 1 +p' >
				<debugfs>/dynamic_debug/control
-bash: echo: write error: Invalid argument

Viewing Dynamic Debug Behaviour
===========================

You can view the currently configured behaviour of all the debug statements
via:

nullarbor:~ # cat <debugfs>/dynamic_debug/control
# filename:lineno [module]function flags format
/usr/src/packages/BUILD/sgi-enhancednfs-1.4/default/net/sunrpc/svc_rdma.c:323 [svcxprt_rdma]svc_rdma_cleanup - "SVCRDMA Module Removed, deregister RPC RDMA transport\012"
/usr/src/packages/BUILD/sgi-enhancednfs-1.4/default/net/sunrpc/svc_rdma.c:341 [svcxprt_rdma]svc_rdma_init - "\011max_inline       : %d\012"
/usr/src/packages/BUILD/sgi-enhancednfs-1.4/default/net/sunrpc/svc_rdma.c:340 [svcxprt_rdma]svc_rdma_init - "\011sq_depth         : %d\012"
/usr/src/packages/BUILD/sgi-enhancednfs-1.4/default/net/sunrpc/svc_rdma.c:338 [svcxprt_rdma]svc_rdma_init - "\011max_requests     : %d\012"
...


You can also apply standard Unix text manipulation filters to this
data, e.g.

nullarbor:~ # grep -i rdma <debugfs>/dynamic_debug/control  | wc -l
62

nullarbor:~ # grep -i tcp <debugfs>/dynamic_debug/control | wc -l
42

Note in particular that the third column shows the enabled behaviour
flags for each debug statement callsite (see below for definitions of the
flags).  The default value, no extra behaviour enabled, is "-".  So
you can view all the debug statement callsites with any non-default flags:

nullarbor:~ # awk '$3 != "-"' <debugfs>/dynamic_debug/control
# filename:lineno [module]function flags format
/usr/src/packages/BUILD/sgi-enhancednfs-1.4/default/net/sunrpc/svcsock.c:1603 [sunrpc]svc_send p "svc_process: st_sendto returned %d\012"


Command Language Reference
==========================

At the lexical level, a command comprises a sequence of words separated
by whitespace characters.  Note that newlines are treated as word
separators and do *not* end a command or allow multiple commands to
be done together.  So these are all equivalent:

nullarbor:~ # echo -c 'file svcsock.c line 1603 +p' >
				<debugfs>/dynamic_debug/control
nullarbor:~ # echo -c '  file   svcsock.c     line  1603 +p  ' >
				<debugfs>/dynamic_debug/control
nullarbor:~ # echo -c 'file svcsock.c\nline 1603 +p' >
				<debugfs>/dynamic_debug/control
nullarbor:~ # echo -n 'file svcsock.c line 1603 +p' >
				<debugfs>/dynamic_debug/control

Commands are bounded by a write() system call.  If you want to do
multiple commands you need to do a separate "echo" for each, like:

nullarbor:~ # echo 'file svcsock.c line 1603 +p' > /proc/dprintk ;\
> echo 'file svcsock.c line 1563 +p' > /proc/dprintk

or even like:

nullarbor:~ # (
> echo 'file svcsock.c line 1603 +p' ;\
> echo 'file svcsock.c line 1563 +p' ;\
> ) > /proc/dprintk

At the syntactical level, a command comprises a sequence of match
specifications, followed by a flags change specification.

command ::= match-spec* flags-spec

The match-spec's are used to choose a subset of the known dprintk()
callsites to which to apply the flags-spec.  Think of them as a query
with implicit ANDs between each pair.  Note that an empty list of
match-specs is possible, but is not very useful because it will not
match any debug statement callsites.

A match specification comprises a keyword, which controls the attribute
of the callsite to be compared, and a value to compare against.  Possible
keywords are:

match-spec ::= 'func' string |
	       'file' string |
	       'module' string |
	       'format' string |
	       'line' line-range

line-range ::= lineno |
	       '-'lineno |
	       lineno'-' |
	       lineno'-'lineno
// Note: line-range cannot contain space, e.g.
// "1-30" is valid range but "1 - 30" is not.

lineno ::= unsigned-int

The meanings of each keyword are:

func
    The given string is compared against the function name
    of each callsite.  Example:

    func svc_tcp_accept

file
    The given string is compared against either the full
    pathname or the basename of the source file of each
    callsite.  Examples:

    file svcsock.c
    file /usr/src/packages/BUILD/sgi-enhancednfs-1.4/default/net/sunrpc/svcsock.c

module
    The given string is compared against the module name
    of each callsite.  The module name is the string as
    seen in "lsmod", i.e. without the directory or the .ko
    suffix and with '-' changed to '_'.  Examples:

    module sunrpc
    module nfsd

format
    The given string is searched for in the dynamic debug format
    string.  Note that the string does not need to match the
    entire format, only some part.  Whitespace and other
    special characters can be escaped using C octal character
    escape \ooo notation, e.g. the space character is \040.
    Alternatively, the string can be enclosed in double quote
    characters (") or single quote characters (').
    Examples:

    format svcrdma:	    // many of the NFS/RDMA server dprintks
    format readahead	    // some dprintks in the readahead cache
    format nfsd:\040SETATTR // one way to match a format with whitespace
    format "nfsd: SETATTR"  // a neater way to match a format with whitespace
    format 'nfsd: SETATTR'  // yet another way to match a format with whitespace

line
    The given line number or range of line numbers is compared
    against the line number of each dprintk() callsite.  A single
    line number matches the callsite line number exactly.  A
    range of line numbers matches any callsite between the first
    and last line number inclusive.  An empty first number means
    the first line in the file, an empty line number means the
    last number in the file.  Examples:

    line 1603	    // exactly line 1603
    line 1600-1605  // the six lines from line 1600 to line 1605
    line -1605	    // the 1605 lines from line 1 to line 1605
    line 1600-	    // all lines from line 1600 to the end of the file

The flags specification comprises a change operation followed
by one or more flag characters.  The change operation is one
of the characters:

-
    remove the given flags

+
    add the given flags

=
    set the flags to the given flags

The flags are:

f
    Include the function name in the printed message
l
    Include line number in the printed message
m
    Include module name in the printed message
p
    Causes a printk() message to be emitted to dmesg
t
    Include thread ID in messages not generated from interrupt context

Note the regexp ^[-+=][flmpt]+$ matches a flags specification.
Note also that there is no convenient syntax to remove all
the flags at once, you need to use "-flmpt".


Debug messages during boot process
==================================

To be able to activate debug messages during the boot process,
even before userspace and debugfs exists, use the boot parameter:
ddebug_query="QUERY"

QUERY follows the syntax described above, but must not exceed 1023
characters. The enablement of debug messages is done as an arch_initcall.
Thus you can enable debug messages in all code processed after this
arch_initcall via this boot parameter.
On an x86 system for example ACPI enablement is a subsys_initcall and
ddebug_query="file ec.c +p"
will show early Embedded Controller transactions during ACPI setup if
your machine (typically a laptop) has an Embedded Controller.
PCI (or other devices) initialization also is a hot candidate for using
this boot parameter for debugging purposes.


Examples
========

// enable the message at line 1603 of file svcsock.c
nullarbor:~ # echo -n 'file svcsock.c line 1603 +p' >
				<debugfs>/dynamic_debug/control

// enable all the messages in file svcsock.c
nullarbor:~ # echo -n 'file svcsock.c +p' >
				<debugfs>/dynamic_debug/control

// enable all the messages in the NFS server module
nullarbor:~ # echo -n 'module nfsd +p' >
				<debugfs>/dynamic_debug/control

// enable all 12 messages in the function svc_process()
nullarbor:~ # echo -n 'func svc_process +p' >
				<debugfs>/dynamic_debug/control

// disable all 12 messages in the function svc_process()
nullarbor:~ # echo -n 'func svc_process -p' >
				<debugfs>/dynamic_debug/control

// enable messages for NFS calls READ, READLINK, READDIR and READDIR+.
nullarbor:~ # echo -n 'format "nfsd: READ" +p' >
				<debugfs>/dynamic_debug/control


EDAC - Error Detection And Correction

Written by Doug Thompson <dougthompson@xmission.com>
7 Dec 2005
17 Jul 2007	Updated

(c) Mauro Carvalho Chehab <mchehab@redhat.com>
05 Aug 2009	Nehalem interface

EDAC is maintained and written by:

	Doug Thompson, Dave Jiang, Dave Peterson et al,
	original author: Thayne Harbaugh,

Contact:
	website:	bluesmoke.sourceforge.net
	mailing list:	bluesmoke-devel@lists.sourceforge.net

"bluesmoke" was the name for this device driver when it was "out-of-tree"
and maintained at sourceforge.net.  When it was pushed into 2.6.16 for the
first time, it was renamed to 'EDAC'.

The bluesmoke project at sourceforge.net is now utilized as a 'staging area'
for EDAC development, before it is sent upstream to kernel.org

At the bluesmoke/EDAC project site is a series of quilt patches against
recent kernels, stored in a SVN repository. For easier downloading, there
is also a tarball snapshot available.

============================================================================
EDAC PURPOSE

The 'edac' kernel module goal is to detect and report errors that occur
within the computer system running under linux.

MEMORY

In the initial release, memory Correctable Errors (CE) and Uncorrectable
Errors (UE) are the primary errors being harvested. These types of errors
are harvested by the 'edac_mc' class of device.

Detecting CE events, then harvesting those events and reporting them,
CAN be a predictor of future UE events.  With CE events, the system can
continue to operate, but with less safety. Preventive maintenance and
proactive part replacement of memory DIMMs exhibiting CEs can reduce
the likelihood of the dreaded UE events and system 'panics'.

NON-MEMORY

A new feature for EDAC, the edac_device class of device, was added in
the 2.6.23 version of the kernel.

This new device type allows for non-memory type of ECC hardware detectors
to have their states harvested and presented to userspace via the sysfs
interface.

Some architectures have ECC detectors for L1, L2 and L3 caches, along with DMA
engines, fabric switches, main data path switches, interconnections,
and various other hardware data paths. If the hardware reports it, then
a edac_device device probably can be constructed to harvest and present
that to userspace.


PCI BUS SCANNING

In addition, PCI Bus Parity and SERR Errors are scanned for on PCI devices
in order to determine if errors are occurring on data transfers.

The presence of PCI Parity errors must be examined with a grain of salt.
There are several add-in adapters that do NOT follow the PCI specification
with regards to Parity generation and reporting. The specification says
the vendor should tie the parity status bits to 0 if they do not intend
to generate parity.  Some vendors do not do this, and thus the parity bit
can "float" giving false positives.

In the kernel there is a PCI device attribute located in sysfs that is
checked by the EDAC PCI scanning code. If that attribute is set,
PCI parity/error scanning is skipped for that device. The attribute
is:

	broken_parity_status

as is located in /sys/devices/pci<XXX>/0000:XX:YY.Z directories for
PCI devices.

FUTURE HARDWARE SCANNING

EDAC will have future error detectors that will be integrated with
EDAC or added to it, in the following list:

	MCE	Machine Check Exception
	MCA	Machine Check Architecture
	NMI	NMI notification of ECC errors
	MSRs 	Machine Specific Register error cases
	and other mechanisms.

These errors are usually bus errors, ECC errors, thermal throttling
and the like.


============================================================================
EDAC VERSIONING

EDAC is composed of a "core" module (edac_core.ko) and several Memory
Controller (MC) driver modules. On a given system, the CORE
is loaded and one MC driver will be loaded. Both the CORE and
the MC driver (or edac_device driver) have individual versions that reflect
current release level of their respective modules.

Thus, to "report" on what version a system is running, one must report both
the CORE's and the MC driver's versions.


LOADING

If 'edac' was statically linked with the kernel then no loading is
necessary.  If 'edac' was built as modules then simply modprobe the
'edac' pieces that you need.  You should be able to modprobe
hardware-specific modules and have the dependencies load the necessary core
modules.

Example:

$> modprobe amd76x_edac

loads both the amd76x_edac.ko memory controller module and the edac_mc.ko
core module.


============================================================================
EDAC sysfs INTERFACE

EDAC presents a 'sysfs' interface for control, reporting and attribute
reporting purposes.

EDAC lives in the /sys/devices/system/edac directory.

Within this directory there currently reside 2 'edac' components:

	mc	memory controller(s) system
	pci	PCI control and status system


============================================================================
Memory Controller (mc) Model

First a background on the memory controller's model abstracted in EDAC.
Each 'mc' device controls a set of DIMM memory modules. These modules are
laid out in a Chip-Select Row (csrowX) and Channel table (chX). There can
be multiple csrows and multiple channels.

Memory controllers allow for several csrows, with 8 csrows being a typical value.
Yet, the actual number of csrows depends on the electrical "loading"
of a given motherboard, memory controller and DIMM characteristics.

Dual channels allows for 128 bit data transfers to the CPU from memory.
Some newer chipsets allow for more than 2 channels, like Fully Buffered DIMMs
(FB-DIMMs). The following example will assume 2 channels:


		Channel 0	Channel 1
	===================================
	csrow0	| DIMM_A0	| DIMM_B0 |
	csrow1	| DIMM_A0	| DIMM_B0 |
	===================================

	===================================
	csrow2	| DIMM_A1	| DIMM_B1 |
	csrow3	| DIMM_A1	| DIMM_B1 |
	===================================

In the above example table there are 4 physical slots on the motherboard
for memory DIMMs:

	DIMM_A0
	DIMM_B0
	DIMM_A1
	DIMM_B1

Labels for these slots are usually silk screened on the motherboard. Slots
labeled 'A' are channel 0 in this example. Slots labeled 'B'
are channel 1. Notice that there are two csrows possible on a
physical DIMM. These csrows are allocated their csrow assignment
based on the slot into which the memory DIMM is placed. Thus, when 1 DIMM
is placed in each Channel, the csrows cross both DIMMs.

Memory DIMMs come single or dual "ranked". A rank is a populated csrow.
Thus, 2 single ranked DIMMs, placed in slots DIMM_A0 and DIMM_B0 above
will have 1 csrow, csrow0. csrow1 will be empty. On the other hand,
when 2 dual ranked DIMMs are similarly placed, then both csrow0 and
csrow1 will be populated. The pattern repeats itself for csrow2 and
csrow3.

The representation of the above is reflected in the directory tree
in EDAC's sysfs interface. Starting in directory
/sys/devices/system/edac/mc each memory controller will be represented
by its own 'mcX' directory, where 'X' is the index of the MC.


	..../edac/mc/
		   |
		   |->mc0
		   |->mc1
		   |->mc2
		   ....

Under each 'mcX' directory each 'csrowX' is again represented by a
'csrowX', where 'X' is the csrow index:


	.../mc/mc0/
		|
		|->csrow0
		|->csrow2
		|->csrow3
		....

Notice that there is no csrow1, which indicates that csrow0 is
composed of a single ranked DIMMs. This should also apply in both
Channels, in order to have dual-channel mode be operational. Since
both csrow2 and csrow3 are populated, this indicates a dual ranked
set of DIMMs for channels 0 and 1.


Within each of the 'mcX' and 'csrowX' directories are several
EDAC control and attribute files.

============================================================================
'mcX' DIRECTORIES


In 'mcX' directories are EDAC control and attribute files for
this 'X' instance of the memory controllers:


Counter reset control file:

	'reset_counters'

	This write-only control file will zero all the statistical counters
	for UE and CE errors.  Zeroing the counters will also reset the timer
	indicating how long since the last counter zero.  This is useful
	for computing errors/time.  Since the counters are always reset at
	driver initialization time, no module/kernel parameter is available.

	RUN TIME: echo "anything" >/sys/devices/system/edac/mc/mc0/counter_reset

		This resets the counters on memory controller 0


Seconds since last counter reset control file:

	'seconds_since_reset'

	This attribute file displays how many seconds have elapsed since the
	last counter reset. This can be used with the error counters to
	measure error rates.



Memory Controller name attribute file:

	'mc_name'

	This attribute file displays the type of memory controller
	that is being utilized.


Total memory managed by this memory controller attribute file:

	'size_mb'

	This attribute file displays, in count of megabytes, of memory
	that this instance of memory controller manages.


Total Uncorrectable Errors count attribute file:

	'ue_count'

	This attribute file displays the total count of uncorrectable
	errors that have occurred on this memory controller. If panic_on_ue
	is set this counter will not have a chance to increment,
	since EDAC will panic the system.


Total UE count that had no information attribute fileY:

	'ue_noinfo_count'

	This attribute file displays the number of UEs that have occurred
	with no information as to which DIMM slot is having errors.


Total Correctable Errors count attribute file:

	'ce_count'

	This attribute file displays the total count of correctable
	errors that have occurred on this memory controller. This
	count is very important to examine. CEs provide early
	indications that a DIMM is beginning to fail. This count
	field should be monitored for non-zero values and report
	such information to the system administrator.


Total Correctable Errors count attribute file:

	'ce_noinfo_count'

	This attribute file displays the number of CEs that
	have occurred wherewith no information as to which DIMM slot
	is having errors. Memory is handicapped, but operational,
	yet no information is available to indicate which slot
	the failing memory is in. This count field should be also
	be monitored for non-zero values.

Device Symlink:

	'device'

	Symlink to the memory controller device.

Sdram memory scrubbing rate:

	'sdram_scrub_rate'

	Read/Write attribute file that controls memory scrubbing. The scrubbing
	rate is set by writing a minimum bandwidth in bytes/sec to the attribute
	file. The rate will be translated to an internal value that gives at
	least the specified rate.

	Reading the file will return the actual scrubbing rate employed.

	If configuration fails or memory scrubbing is not implemented, the value
	of the attribute file will be -1.



============================================================================
'csrowX' DIRECTORIES

In the 'csrowX' directories are EDAC control and attribute files for
this 'X' instance of csrow:


Total Uncorrectable Errors count attribute file:

	'ue_count'

	This attribute file displays the total count of uncorrectable
	errors that have occurred on this csrow. If panic_on_ue is set
	this counter will not have a chance to increment, since EDAC
	will panic the system.


Total Correctable Errors count attribute file:

	'ce_count'

	This attribute file displays the total count of correctable
	errors that have occurred on this csrow. This
	count is very important to examine. CEs provide early
	indications that a DIMM is beginning to fail. This count
	field should be monitored for non-zero values and report
	such information to the system administrator.


Total memory managed by this csrow attribute file:

	'size_mb'

	This attribute file displays, in count of megabytes, of memory
	that this csrow contains.


Memory Type attribute file:

	'mem_type'

	This attribute file will display what type of memory is currently
	on this csrow. Normally, either buffered or unbuffered memory.
	Examples:
		Registered-DDR
		Unbuffered-DDR


EDAC Mode of operation attribute file:

	'edac_mode'

	This attribute file will display what type of Error detection
	and correction is being utilized.


Device type attribute file:

	'dev_type'

	This attribute file will display what type of DRAM device is
	being utilized on this DIMM.
	Examples:
		x1
		x2
		x4
		x8


Channel 0 CE Count attribute file:

	'ch0_ce_count'

	This attribute file will display the count of CEs on this
	DIMM located in channel 0.


Channel 0 UE Count attribute file:

	'ch0_ue_count'

	This attribute file will display the count of UEs on this
	DIMM located in channel 0.


Channel 0 DIMM Label control file:

	'ch0_dimm_label'

	This control file allows this DIMM to have a label assigned
	to it. With this label in the module, when errors occur
	the output can provide the DIMM label in the system log.
	This becomes vital for panic events to isolate the
	cause of the UE event.

	DIMM Labels must be assigned after booting, with information
	that correctly identifies the physical slot with its
	silk screen label. This information is currently very
	motherboard specific and determination of this information
	must occur in userland at this time.


Channel 1 CE Count attribute file:

	'ch1_ce_count'

	This attribute file will display the count of CEs on this
	DIMM located in channel 1.


Channel 1 UE Count attribute file:

	'ch1_ue_count'

	This attribute file will display the count of UEs on this
	DIMM located in channel 0.


Channel 1 DIMM Label control file:

	'ch1_dimm_label'

	This control file allows this DIMM to have a label assigned
	to it. With this label in the module, when errors occur
	the output can provide the DIMM label in the system log.
	This becomes vital for panic events to isolate the
	cause of the UE event.

	DIMM Labels must be assigned after booting, with information
	that correctly identifies the physical slot with its
	silk screen label. This information is currently very
	motherboard specific and determination of this information
	must occur in userland at this time.

============================================================================
SYSTEM LOGGING

If logging for UEs and CEs are enabled then system logs will have
error notices indicating errors that have been detected:

EDAC MC0: CE page 0x283, offset 0xce0, grain 8, syndrome 0x6ec3, row 0,
channel 1 "DIMM_B1": amd76x_edac

EDAC MC0: CE page 0x1e5, offset 0xfb0, grain 8, syndrome 0xb741, row 0,
channel 1 "DIMM_B1": amd76x_edac


The structure of the message is:
	the memory controller			(MC0)
	Error type				(CE)
	memory page				(0x283)
	offset in the page			(0xce0)
	the byte granularity 			(grain 8)
		or resolution of the error
	the error syndrome			(0xb741)
	memory row				(row 0)
	memory channel				(channel 1)
	DIMM label, if set prior		(DIMM B1
	and then an optional, driver-specific message that may
		have additional information.

Both UEs and CEs with no info will lack all but memory controller,
error type, a notice of "no info" and then an optional,
driver-specific error message.


============================================================================
PCI Bus Parity Detection


On Header Type 00 devices the primary status is looked at
for any parity error regardless of whether Parity is enabled on the
device.  (The spec indicates parity is generated in some cases).
On Header Type 01 bridges, the secondary status register is also
looked at to see if parity occurred on the bus on the other side of
the bridge.


SYSFS CONFIGURATION

Under /sys/devices/system/edac/pci are control and attribute files as follows:


Enable/Disable PCI Parity checking control file:

	'check_pci_parity'


	This control file enables or disables the PCI Bus Parity scanning
	operation. Writing a 1 to this file enables the scanning. Writing
	a 0 to this file disables the scanning.

	Enable:
	echo "1" >/sys/devices/system/edac/pci/check_pci_parity

	Disable:
	echo "0" >/sys/devices/system/edac/pci/check_pci_parity


Parity Count:

	'pci_parity_count'

	This attribute file will display the number of parity errors that
	have been detected.


============================================================================
MODULE PARAMETERS

Panic on UE control file:

	'edac_mc_panic_on_ue'

	An uncorrectable error will cause a machine panic.  This is usually
	desirable.  It is a bad idea to continue when an uncorrectable error
	occurs - it is indeterminate what was uncorrected and the operating
	system context might be so mangled that continuing will lead to further
	corruption. If the kernel has MCE configured, then EDAC will never
	notice the UE.

	LOAD TIME: module/kernel parameter: edac_mc_panic_on_ue=[0|1]

	RUN TIME:  echo "1" > /sys/module/edac_core/parameters/edac_mc_panic_on_ue


Log UE control file:

	'edac_mc_log_ue'

	Generate kernel messages describing uncorrectable errors.  These errors
	are reported through the system message log system.  UE statistics
	will be accumulated even when UE logging is disabled.

	LOAD TIME: module/kernel parameter: edac_mc_log_ue=[0|1]

	RUN TIME: echo "1" > /sys/module/edac_core/parameters/edac_mc_log_ue


Log CE control file:

	'edac_mc_log_ce'

	Generate kernel messages describing correctable errors.  These
	errors are reported through the system message log system.
	CE statistics will be accumulated even when CE logging is disabled.

	LOAD TIME: module/kernel parameter: edac_mc_log_ce=[0|1]

	RUN TIME: echo "1" > /sys/module/edac_core/parameters/edac_mc_log_ce


Polling period control file:

	'edac_mc_poll_msec'

	The time period, in milliseconds, for polling for error information.
	Too small a value wastes resources.  Too large a value might delay
	necessary handling of errors and might loose valuable information for
	locating the error.  1000 milliseconds (once each second) is the current
	default. Systems which require all the bandwidth they can get, may
	increase this.

	LOAD TIME: module/kernel parameter: edac_mc_poll_msec=[0|1]

	RUN TIME: echo "1000" > /sys/module/edac_core/parameters/edac_mc_poll_msec


Panic on PCI PARITY Error:

	'panic_on_pci_parity'


	This control files enables or disables panicking when a parity
	error has been detected.


	module/kernel parameter: edac_panic_on_pci_pe=[0|1]

	Enable:
	echo "1" > /sys/module/edac_core/parameters/edac_panic_on_pci_pe

	Disable:
	echo "0" > /sys/module/edac_core/parameters/edac_panic_on_pci_pe



=======================================================================


EDAC_DEVICE type of device

In the header file, edac_core.h, there is a series of edac_device structures
and APIs for the EDAC_DEVICE.

User space access to an edac_device is through the sysfs interface.

At the location /sys/devices/system/edac (sysfs) new edac_device devices will
appear.

There is a three level tree beneath the above 'edac' directory. For example,
the 'test_device_edac' device (found at the bluesmoke.sourceforget.net website)
installs itself as:

	/sys/devices/systm/edac/test-instance

in this directory are various controls, a symlink and one or more 'instance'
directorys.

The standard default controls are:

	log_ce		boolean to log CE events
	log_ue		boolean to log UE events
	panic_on_ue	boolean to 'panic' the system if an UE is encountered
			(default off, can be set true via startup script)
	poll_msec	time period between POLL cycles for events

The test_device_edac device adds at least one of its own custom control:

	test_bits	which in the current test driver does nothing but
			show how it is installed. A ported driver can
			add one or more such controls and/or attributes
			for specific uses.
			One out-of-tree driver uses controls here to allow
			for ERROR INJECTION operations to hardware
			injection registers

The symlink points to the 'struct dev' that is registered for this edac_device.

INSTANCES

One or more instance directories are present. For the 'test_device_edac' case:

	test-instance0


In this directory there are two default counter attributes, which are totals of
counter in deeper subdirectories.

	ce_count	total of CE events of subdirectories
	ue_count	total of UE events of subdirectories

BLOCKS

At the lowest directory level is the 'block' directory. There can be 0, 1
or more blocks specified in each instance.

	test-block0


In this directory the default attributes are:

	ce_count	which is counter of CE events for this 'block'
			of hardware being monitored
	ue_count	which is counter of UE events for this 'block'
			of hardware being monitored


The 'test_device_edac' device adds 4 attributes and 1 control:

	test-block-bits-0	for every POLL cycle this counter
				is incremented
	test-block-bits-1	every 10 cycles, this counter is bumped once,
				and test-block-bits-0 is set to 0
	test-block-bits-2	every 100 cycles, this counter is bumped once,
				and test-block-bits-1 is set to 0
	test-block-bits-3	every 1000 cycles, this counter is bumped once,
				and test-block-bits-2 is set to 0


	reset-counters		writing ANY thing to this control will
				reset all the above counters.


Use of the 'test_device_edac' driver should any others to create their own
unique drivers for their hardware systems.

The 'test_device_edac' sample driver is located at the
bluesmoke.sourceforge.net project site for EDAC.

=======================================================================
NEHALEM USAGE OF EDAC APIs

This chapter documents some EXPERIMENTAL mappings for EDAC API to handle
Nehalem EDAC driver. They will likely be changed on future versions
of the driver.

Due to the way Nehalem exports Memory Controller data, some adjustments
were done at i7core_edac driver. This chapter will cover those differences

1) On Nehalem, there are one Memory Controller per Quick Patch Interconnect
   (QPI). At the driver, the term "socket" means one QPI. This is
   associated with a physical CPU socket.

   Each MC have 3 physical read channels, 3 physical write channels and
   3 logic channels. The driver currenty sees it as just 3 channels.
   Each channel can have up to 3 DIMMs.

   The minimum known unity is DIMMs. There are no information about csrows.
   As EDAC API maps the minimum unity is csrows, the driver sequencially
   maps channel/dimm into different csrows.

   For example, supposing the following layout:
	Ch0 phy rd0, wr0 (0x063f4031): 2 ranks, UDIMMs
	  dimm 0 1024 Mb offset: 0, bank: 8, rank: 1, row: 0x4000, col: 0x400
	  dimm 1 1024 Mb offset: 4, bank: 8, rank: 1, row: 0x4000, col: 0x400
        Ch1 phy rd1, wr1 (0x063f4031): 2 ranks, UDIMMs
	  dimm 0 1024 Mb offset: 0, bank: 8, rank: 1, row: 0x4000, col: 0x400
	Ch2 phy rd3, wr3 (0x063f4031): 2 ranks, UDIMMs
	  dimm 0 1024 Mb offset: 0, bank: 8, rank: 1, row: 0x4000, col: 0x400
   The driver will map it as:
	csrow0: channel 0, dimm0
	csrow1: channel 0, dimm1
	csrow2: channel 1, dimm0
	csrow3: channel 2, dimm0

exports one
   DIMM per csrow.

   Each QPI is exported as a different memory controller.

2) Nehalem MC has the hability to generate errors. The driver implements this
   functionality via some error injection nodes:

   For injecting a memory error, there are some sysfs nodes, under
   /sys/devices/system/edac/mc/mc?/:

   inject_addrmatch/*:
      Controls the error injection mask register. It is possible to specify
      several characteristics of the address to match an error code:
         dimm = the affected dimm. Numbers are relative to a channel;
         rank = the memory rank;
         channel = the channel that will generate an error;
         bank = the affected bank;
         page = the page address;
         column (or col) = the address column.
      each of the above values can be set to "any" to match any valid value.

      At driver init, all values are set to any.

      For example, to generate an error at rank 1 of dimm 2, for any channel,
      any bank, any page, any column:
		echo 2 >/sys/devices/system/edac/mc/mc0/inject_addrmatch/dimm
		echo 1 >/sys/devices/system/edac/mc/mc0/inject_addrmatch/rank

	To return to the default behaviour of matching any, you can do:
		echo any >/sys/devices/system/edac/mc/mc0/inject_addrmatch/dimm
		echo any >/sys/devices/system/edac/mc/mc0/inject_addrmatch/rank

   inject_eccmask:
       specifies what bits will have troubles,

   inject_section:
       specifies what ECC cache section will get the error:
		3 for both
		2 for the highest
		1 for the lowest

   inject_type:
       specifies the type of error, being a combination of the following bits:
		bit 0 - repeat
		bit 1 - ecc
		bit 2 - parity

       inject_enable starts the error generation when something different
       than 0 is written.

   All inject vars can be read. root permission is needed for write.

   Datasheet states that the error will only be generated after a write on an
   address that matches inject_addrmatch. It seems, however, that reading will
   also produce an error.

   For example, the following code will generate an error for any write access
   at socket 0, on any DIMM/address on channel 2:

   echo 2 >/sys/devices/system/edac/mc/mc0/inject_addrmatch/channel
   echo 2 >/sys/devices/system/edac/mc/mc0/inject_type
   echo 64 >/sys/devices/system/edac/mc/mc0/inject_eccmask
   echo 3 >/sys/devices/system/edac/mc/mc0/inject_section
   echo 1 >/sys/devices/system/edac/mc/mc0/inject_enable
   dd if=/dev/mem of=/dev/null seek=16k bs=4k count=1 >& /dev/null

   For socket 1, it is needed to replace "mc0" by "mc1" at the above
   commands.

   The generated error message will look like:

   EDAC MC0: UE row 0, channel-a= 0 channel-b= 0 labels "-": NON_FATAL (addr = 0x0075b980, socket=0, Dimm=0, Channel=2, syndrome=0x00000040, count=1, Err=8c0000400001009f:4000080482 (read error: read ECC error))

3) Nehalem specific Corrected Error memory counters

   Nehalem have some registers to count memory errors. The driver uses those
   registers to report Corrected Errors on devices with Registered Dimms.

   However, those counters don't work with Unregistered Dimms. As the chipset
   offers some counters that also work with UDIMMS (but with a worse level of
   granularity than the default ones), the driver exposes those registers for
   UDIMM memories.

   They can be read by looking at the contents of all_channel_counts/

   $ for i in /sys/devices/system/edac/mc/mc0/all_channel_counts/*; do echo $i; cat $i; done
	/sys/devices/system/edac/mc/mc0/all_channel_counts/udimm0
	0
	/sys/devices/system/edac/mc/mc0/all_channel_counts/udimm1
	0
	/sys/devices/system/edac/mc/mc0/all_channel_counts/udimm2
	0

   What happens here is that errors on different csrows, but at the same
   dimm number will increment the same counter.
   So, in this memory mapping:
	csrow0: channel 0, dimm0
	csrow1: channel 0, dimm1
	csrow2: channel 1, dimm0
	csrow3: channel 2, dimm0
   The hardware will increment udimm0 for an error at the first dimm at either
	csrow0, csrow2  or csrow3;
   The hardware will increment udimm1 for an error at the second dimm at either
	csrow0, csrow2  or csrow3;
   The hardware will increment udimm2 for an error at the third dimm at either
	csrow0, csrow2  or csrow3;

4) Standard error counters

   The standard error counters are generated when an mcelog error is received
   by the driver. Since, with udimm, this is counted by software, it is
   possible that some errors could be lost. With rdimm's, they displays the
   contents of the registers
EISA bus support (Marc Zyngier <maz@wild-wind.fr.eu.org>)

This document groups random notes about porting EISA drivers to the
new EISA/sysfs API.

Starting from version 2.5.59, the EISA bus is almost given the same
status as other much more mainstream busses such as PCI or USB. This
has been possible through sysfs, which defines a nice enough set of
abstractions to manage busses, devices and drivers.

Although the new API is quite simple to use, converting existing
drivers to the new infrastructure is not an easy task (mostly because
detection code is generally also used to probe ISA cards). Moreover,
most EISA drivers are among the oldest Linux drivers so, as you can
imagine, some dust has settled here over the years.

The EISA infrastructure is made up of three parts :

    - The bus code implements most of the generic code. It is shared
    among all the architectures that the EISA code runs on. It
    implements bus probing (detecting EISA cards available on the bus),
    allocates I/O resources, allows fancy naming through sysfs, and
    offers interfaces for driver to register.

    - The bus root driver implements the glue between the bus hardware
    and the generic bus code. It is responsible for discovering the
    device implementing the bus, and setting it up to be latter probed
    by the bus code. This can go from something as simple as reserving
    an I/O region on x86, to the rather more complex, like the hppa
    EISA code. This is the part to implement in order to have EISA
    running on an "new" platform.

    - The driver offers the bus a list of devices that it manages, and
    implements the necessary callbacks to probe and release devices
    whenever told to.

Every function/structure below lives in <linux/eisa.h>, which depends
heavily on <linux/device.h>.

** Bus root driver :

int eisa_root_register (struct eisa_root_device *root);

The eisa_root_register function is used to declare a device as the
root of an EISA bus. The eisa_root_device structure holds a reference
to this device, as well as some parameters for probing purposes.

struct eisa_root_device {
	struct device   *dev;	 /* Pointer to bridge device */
	struct resource *res;
	unsigned long    bus_base_addr;
	int		 slots;  /* Max slot number */
	int		 force_probe; /* Probe even when no slot 0 */
	u64		 dma_mask; /* from bridge device */
	int              bus_nr; /* Set by eisa_root_register */
	struct resource  eisa_root_res;	/* ditto */
};

node          : used for eisa_root_register internal purpose
dev           : pointer to the root device
res           : root device I/O resource
bus_base_addr : slot 0 address on this bus
slots	      : max slot number to probe
force_probe   : Probe even when slot 0 is empty (no EISA mainboard)
dma_mask      : Default DMA mask. Usually the bridge device dma_mask.
bus_nr	      : unique bus id, set by eisa_root_register

** Driver :

int eisa_driver_register (struct eisa_driver *edrv);
void eisa_driver_unregister (struct eisa_driver *edrv);

Clear enough ?

struct eisa_device_id {
        char sig[EISA_SIG_LEN];
	unsigned long driver_data;
};

struct eisa_driver {
        const struct eisa_device_id *id_table;
        struct device_driver         driver;
};

id_table	: an array of NULL terminated EISA id strings,
		  followed by an empty string. Each string can
		  optionally be paired with a driver-dependent value
		  (driver_data).

driver		: a generic driver, such as described in
		  Documentation/driver-model/driver.txt. Only .name,
		  .probe and .remove members are mandatory.

An example is the 3c59x driver :

static struct eisa_device_id vortex_eisa_ids[] = {
	{ "TCM5920", EISA_3C592_OFFSET },
	{ "TCM5970", EISA_3C597_OFFSET },
	{ "" }
};

static struct eisa_driver vortex_eisa_driver = {
	.id_table = vortex_eisa_ids,
	.driver   = {
		.name    = "3c59x",
		.probe   = vortex_eisa_probe,
		.remove  = vortex_eisa_remove
	}
};

** Device :

The sysfs framework calls .probe and .remove functions upon device
discovery and removal (note that the .remove function is only called
when driver is built as a module).

Both functions are passed a pointer to a 'struct device', which is
encapsulated in a 'struct eisa_device' described as follows :

struct eisa_device {
        struct eisa_device_id id;
        int                   slot;
	int                   state;
	unsigned long         base_addr;
	struct resource       res[EISA_MAX_RESOURCES];
	u64                   dma_mask;
        struct device         dev; /* generic device */
};

id	: EISA id, as read from device. id.driver_data is set from the
	  matching driver EISA id.
slot	: slot number which the device was detected on
state   : set of flags indicating the state of the device. Current
	  flags are EISA_CONFIG_ENABLED and EISA_CONFIG_FORCED.
res	: set of four 256 bytes I/O regions allocated to this device
dma_mask: DMA mask set from the parent device.
dev	: generic device (see Documentation/driver-model/device.txt)

You can get the 'struct eisa_device' from 'struct device' using the
'to_eisa_device' macro.

** Misc stuff :

void eisa_set_drvdata (struct eisa_device *edev, void *data);

Stores data into the device's driver_data area.

void *eisa_get_drvdata (struct eisa_device *edev):

Gets the pointer previously stored into the device's driver_data area.

int eisa_get_region_index (void *addr);

Returns the region number (0 <= x < EISA_MAX_RESOURCES) of a given
address.

** Kernel parameters :

eisa_bus.enable_dev :

A comma-separated list of slots to be enabled, even if the firmware
set the card as disabled. The driver must be able to properly
initialize the device in such conditions.

eisa_bus.disable_dev :

A comma-separated list of slots to be enabled, even if the firmware
set the card as enabled. The driver won't be called to handle this
device.

virtual_root.force_probe :

Force the probing code to probe EISA slots even when it cannot find an
EISA compliant mainboard (nothing appears on slot 0). Defaults to 0
(don't force), and set to 1 (force probing) when either
CONFIG_ALPHA_JENSEN or CONFIG_EISA_VLB_PRIMING are set.

** Random notes :

Converting an EISA driver to the new API mostly involves *deleting*
code (since probing is now in the core EISA code). Unfortunately, most
drivers share their probing routine between ISA, MCA and EISA. Special
care must be taken when ripping out the EISA code, so other busses
won't suffer from these surgical strikes...

You *must not* expect any EISA device to be detected when returning
from eisa_driver_register, since the chances are that the bus has not
yet been probed. In fact, that's what happens most of the time (the
bus root driver usually kicks in rather late in the boot process).
Unfortunately, most drivers are doing the probing by themselves, and
expect to have explored the whole machine when they exit their probe
routine.

For example, switching your favorite EISA SCSI card to the "hotplug"
model is "the right thing"(tm).

** Thanks :

I'd like to thank the following people for their help :
- Xavier Benigni for lending me a wonderful Alpha Jensen,
- James Bottomley, Jeff Garzik for getting this stuff into the kernel,
- Andries Brouwer for contributing numerous EISA ids,
- Catrin Jones for coping with far too many machines at home.
Email clients info for Linux
======================================================================

General Preferences
----------------------------------------------------------------------
Patches for the Linux kernel are submitted via email, preferably as
inline text in the body of the email.  Some maintainers accept
attachments, but then the attachments should have content-type
"text/plain".  However, attachments are generally frowned upon because
it makes quoting portions of the patch more difficult in the patch
review process.

Email clients that are used for Linux kernel patches should send the
patch text untouched.  For example, they should not modify or delete tabs
or spaces, even at the beginning or end of lines.

Don't send patches with "format=flowed".  This can cause unexpected
and unwanted line breaks.

Don't let your email client do automatic word wrapping for you.
This can also corrupt your patch.

Email clients should not modify the character set encoding of the text.
Emailed patches should be in ASCII or UTF-8 encoding only.
If you configure your email client to send emails with UTF-8 encoding,
you avoid some possible charset problems.

Email clients should generate and maintain References: or In-Reply-To:
headers so that mail threading is not broken.

Copy-and-paste (or cut-and-paste) usually does not work for patches
because tabs are converted to spaces.  Using xclipboard, xclip, and/or
xcutsel may work, but it's best to test this for yourself or just avoid
copy-and-paste.

Don't use PGP/GPG signatures in mail that contains patches.
This breaks many scripts that read and apply the patches.
(This should be fixable.)

It's a good idea to send a patch to yourself, save the received message,
and successfully apply it with 'patch' before sending patches to Linux
mailing lists.


Some email client (MUA) hints
----------------------------------------------------------------------
Here are some specific MUA configuration hints for editing and sending
patches for the Linux kernel.  These are not meant to be complete
software package configuration summaries.

Legend:
TUI = text-based user interface
GUI = graphical user interface

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Alpine (TUI)

Config options:
In the "Sending Preferences" section:

- "Do Not Send Flowed Text" must be enabled
- "Strip Whitespace Before Sending" must be disabled

When composing the message, the cursor should be placed where the patch
should appear, and then pressing CTRL-R let you specify the patch file
to insert into the message.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Evolution (GUI)

Some people use this successfully for patches.

When composing mail select: Preformat
  from Format->Heading->Preformatted (Ctrl-7)
  or the toolbar

Then use:
  Insert->Text File... (Alt-n x)
to insert the patch.

You can also "diff -Nru old.c new.c | xclip", select Preformat, then
paste with the middle button.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Kmail (GUI)

Some people use Kmail successfully for patches.

The default setting of not composing in HTML is appropriate; do not
enable it.

When composing an email, under options, uncheck "word wrap". The only
disadvantage is any text you type in the email will not be word-wrapped
so you will have to manually word wrap text before the patch. The easiest
way around this is to compose your email with word wrap enabled, then save
it as a draft. Once you pull it up again from your drafts it is now hard
word-wrapped and you can uncheck "word wrap" without losing the existing
wrapping.

At the bottom of your email, put the commonly-used patch delimiter before
inserting your patch:  three hyphens (---).

Then from the "Message" menu item, select insert file and choose your patch.
As an added bonus you can customise the message creation toolbar menu
and put the "insert file" icon there.

Make the the composer window wide enough so that no lines wrap. As of
KMail 1.13.5 (KDE 4.5.4), KMail will apply word wrapping when sending
the email if the lines wrap in the composer window. Having word wrapping
disabled in the Options menu isn't enough. Thus, if your patch has very
long lines, you must make the composer window very wide before sending
the email. See: https://bugs.kde.org/show_bug.cgi?id=174034

You can safely GPG sign attachments, but inlined text is preferred for
patches so do not GPG sign them.  Signing patches that have been inserted
as inlined text will make them tricky to extract from their 7-bit encoding.

If you absolutely must send patches as attachments instead of inlining
them as text, right click on the attachment and select properties, and
highlight "Suggest automatic display" to make the attachment inlined to
make it more viewable.

When saving patches that are sent as inlined text, select the email that
contains the patch from the message list pane, right click and select
"save as".  You can use the whole email unmodified as a patch if it was
properly composed.  There is no option currently to save the email when you
are actually viewing it in its own window -- there has been a request filed
at kmail's bugzilla and hopefully this will be addressed.  Emails are saved
as read-write for user only so you will have to chmod them to make them
group and world readable if you copy them elsewhere.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Lotus Notes (GUI)

Run away from it.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Mutt (TUI)

Plenty of Linux developers use mutt, so it must work pretty well.

Mutt doesn't come with an editor, so whatever editor you use should be
used in a way that there are no automatic linebreaks.  Most editors have
an "insert file" option that inserts the contents of a file unaltered.

To use 'vim' with mutt:
  set editor="vi"

  If using xclip, type the command
  :set paste
  before middle button or shift-insert or use
  :r filename

if you want to include the patch inline.
(a)ttach works fine without "set paste".

Config options:
It should work with default settings.
However, it's a good idea to set the "send_charset" to:
  set send_charset="us-ascii:utf-8"

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Pine (TUI)

Pine has had some whitespace truncation issues in the past, but these
should all be fixed now.

Use alpine (pine's successor) if you can.

Config options:
- quell-flowed-text is needed for recent versions
- the "no-strip-whitespace-before-send" option is needed


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Sylpheed (GUI)

- Works well for inlining text (or using attachments).
- Allows use of an external editor.
- Is slow on large folders.
- Won't do TLS SMTP auth over a non-SSL connection.
- Has a helpful ruler bar in the compose window.
- Adding addresses to address book doesn't understand the display name
  properly.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Thunderbird (GUI)

Thunderbird is an Outlook clone that likes to mangle text, but there are ways
to coerce it into behaving.

- Allows use of an external editor:
  The easiest thing to do with Thunderbird and patches is to use an
  "external editor" extension and then just use your favorite $EDITOR
  for reading/merging patches into the body text.  To do this, download
  and install the extension, then add a button for it using
  View->Toolbars->Customize... and finally just click on it when in the
  Compose dialog.

To beat some sense out of the internal editor, do this:

- Under account settings, composition and addressing, uncheck "Compose
  messages in HTML format".

- Edit your Thunderbird config settings so that it won't use format=flowed.
  Go to "edit->preferences->advanced->config editor" to bring up the
  thunderbird's registry editor, and set "mailnews.send_plaintext_flowed" to
  "false".

- Enable "preformat" mode: Shft-click on the Write icon to bring up the HTML
  composer, select "Preformat" from the drop-down box just under the subject
  line, then close the message without saving.  (This setting also applies to
  the text composer, but the only control for it is in the HTML composer.)

- Install the "toggle wordwrap" extension.  Download the file from:
    https://addons.mozilla.org/thunderbird/addon/2351/
  Then go to "tools->add ons", select "install" at the bottom of the screen,
  and browse to where you saved the .xul file.  This adds an "Enable
  Wordwrap" entry under the Options menu of the message composer.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
TkRat (GUI)

Works.  Use "Insert file..." or external editor.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Gmail (Web GUI)

Does not work for sending patches.

Gmail web client converts tabs to spaces automatically.

At the same time it wraps lines every 78 chars with CRLF style line breaks
although tab2space problem can be solved with external editor.

Another problem is that Gmail will base64-encode any message that has a
non-ASCII character. That includes things like European names.

                                ###
The following is a list of files and features that are going to be
removed in the kernel source tree.  Every entry should contain what
exactly is going away, why it is happening, and who is going to be doing
the work.  When the feature is removed from the kernel, it should also
be removed from this file.

---------------------------

What:	x86 floppy disable_hlt
When:	2012
Why:	ancient workaround of dubious utility clutters the
	code used by everybody else.
Who:	Len Brown <len.brown@intel.com>

---------------------------

What:	CONFIG_APM_CPU_IDLE, and its ability to call APM BIOS in idle
When:	2012
Why:	This optional sub-feature of APM is of dubious reliability,
	and ancient APM laptops are likely better served by calling HLT.
	Deleting CONFIG_APM_CPU_IDLE allows x86 to stop exporting
	the pm_idle function pointer to modules.
Who:	Len Brown <len.brown@intel.com>

----------------------------

What:	x86_32 "no-hlt" cmdline param
When:	2012
Why:	remove a branch from idle path, simplify code used by everybody.
	This option disabled the use of HLT in idle and machine_halt()
	for hardware that was flakey 15-years ago.  Today we have
	"idle=poll" that removed HLT from idle, and so if such a machine
	is still running the upstream kernel, "idle=poll" is likely sufficient.
Who:	Len Brown <len.brown@intel.com>

----------------------------

What:	x86 "idle=mwait" cmdline param
When:	2012
Why:	simplify x86 idle code
Who:	Len Brown <len.brown@intel.com>

----------------------------

What:	PRISM54
When:	2.6.34

Why:	prism54 FullMAC PCI / Cardbus devices used to be supported only by the
	prism54 wireless driver. After Intersil stopped selling these
	devices in preference for the newer more flexible SoftMAC devices
	a SoftMAC device driver was required and prism54 did not support
	them. The p54pci driver now exists and has been present in the kernel for
	a while. This driver supports both SoftMAC devices and FullMAC devices.
	The main difference between these devices was the amount of memory which
	could be used for the firmware. The SoftMAC devices support a smaller
	amount of memory. Because of this the SoftMAC firmware fits into FullMAC
	devices's memory. p54pci supports not only PCI / Cardbus but also USB
	and SPI. Since p54pci supports all devices prism54 supports
	you will have a conflict. I'm not quite sure how distributions are
	handling this conflict right now. prism54 was kept around due to
	claims users may experience issues when using the SoftMAC driver.
	Time has passed users have not reported issues. If you use prism54
	and for whatever reason you cannot use p54pci please let us know!
	E-mail us at: linux-wireless@vger.kernel.org

	For more information see the p54 wiki page:

	http://wireless.kernel.org/en/users/Drivers/p54

Who:	Luis R. Rodriguez <lrodriguez@atheros.com>

---------------------------

What:	IRQF_SAMPLE_RANDOM
Check:	IRQF_SAMPLE_RANDOM
When:	July 2009

Why:	Many of IRQF_SAMPLE_RANDOM users are technically bogus as entropy
	sources in the kernel's current entropy model. To resolve this, every
	input point to the kernel's entropy pool needs to better document the
	type of entropy source it actually is. This will be replaced with
	additional add_*_randomness functions in drivers/char/random.c

Who:	Robin Getz <rgetz@blackfin.uclinux.org> & Matt Mackall <mpm@selenic.com>

---------------------------

What:	Deprecated snapshot ioctls
When:	2.6.36

Why:	The ioctls in kernel/power/user.c were marked as deprecated long time
	ago. Now they notify users about that so that they need to replace
	their userspace. After some more time, remove them completely.

Who:	Jiri Slaby <jirislaby@gmail.com>

---------------------------

What:	The ieee80211_regdom module parameter
When:	March 2010 / desktop catchup

Why:	This was inherited by the CONFIG_WIRELESS_OLD_REGULATORY code,
	and currently serves as an option for users to define an
	ISO / IEC 3166 alpha2 code for the country they are currently
	present in. Although there are userspace API replacements for this
	through nl80211 distributions haven't yet caught up with implementing
	decent alternatives through standard GUIs. Although available as an
	option through iw or wpa_supplicant its just a matter of time before
	distributions pick up good GUI options for this. The ideal solution
	would actually consist of intelligent designs which would do this for
	the user automatically even when travelling through different countries.
	Until then we leave this module parameter as a compromise.

	When userspace improves with reasonable widely-available alternatives for
	this we will no longer need this module parameter. This entry hopes that
	by the super-futuristically looking date of "March 2010" we will have
	such replacements widely available.

Who:	Luis R. Rodriguez <lrodriguez@atheros.com>

---------------------------

What:	dev->power.power_state
When:	July 2007
Why:	Broken design for runtime control over driver power states, confusing
	driver-internal runtime power management with:  mechanisms to support
	system-wide sleep state transitions; event codes that distinguish
	different phases of swsusp "sleep" transitions; and userspace policy
	inputs.  This framework was never widely used, and most attempts to
	use it were broken.  Drivers should instead be exposing domain-specific
	interfaces either to kernel or to userspace.
Who:	Pavel Machek <pavel@ucw.cz>

---------------------------

What:	sys_sysctl
When:	September 2010
Option: CONFIG_SYSCTL_SYSCALL
Why:	The same information is available in a more convenient from
	/proc/sys, and none of the sysctl variables appear to be
	important performance wise.

	Binary sysctls are a long standing source of subtle kernel
	bugs and security issues.

	When I looked several months ago all I could find after
	searching several distributions were 5 user space programs and
	glibc (which falls back to /proc/sys) using this syscall.

	The man page for sysctl(2) documents it as unusable for user
	space programs.

	sysctl(2) is not generally ABI compatible to a 32bit user
	space application on a 64bit and a 32bit kernel.

	For the last several months the policy has been no new binary
	sysctls and no one has put forward an argument to use them.

	Binary sysctls issues seem to keep happening appearing so
	properly deprecating them (with a warning to user space) and a
	2 year grace warning period will mean eventually we can kill
	them and end the pain.

	In the mean time individual binary sysctls can be dealt with
	in a piecewise fashion.

Who:	Eric Biederman <ebiederm@xmission.com>

---------------------------

What:	/proc/<pid>/oom_adj
When:	August 2012
Why:	/proc/<pid>/oom_adj allows userspace to influence the oom killer's
	badness heuristic used to determine which task to kill when the kernel
	is out of memory.

	The badness heuristic has since been rewritten since the introduction of
	this tunable such that its meaning is deprecated.  The value was
	implemented as a bitshift on a score generated by the badness()
	function that did not have any precise units of measure.  With the
	rewrite, the score is given as a proportion of available memory to the
	task allocating pages, so using a bitshift which grows the score
	exponentially is, thus, impossible to tune with fine granularity.

	A much more powerful interface, /proc/<pid>/oom_score_adj, was
	introduced with the oom killer rewrite that allows users to increase or
	decrease the badness() score linearly.  This interface will replace
	/proc/<pid>/oom_adj.

	A warning will be emitted to the kernel log if an application uses this
	deprecated interface.  After it is printed once, future warnings will be
	suppressed until the kernel is rebooted.

---------------------------

What:	CS5535/CS5536 obsolete GPIO driver
When:	June 2011
Files:	drivers/staging/cs5535_gpio/*
Check:	drivers/staging/cs5535_gpio/cs5535_gpio.c
Why:	A newer driver replaces this; it is drivers/gpio/cs5535-gpio.c, and
	integrates with the Linux GPIO subsystem.  The old driver has been
	moved to staging, and will be removed altogether around 2.6.40.
	Please test the new driver, and ensure that the functionality you
	need and any bugfixes from the old driver are available in the new
	one.
Who:	Andres Salomon <dilinger@queued.net>

--------------------------

What:	remove EXPORT_SYMBOL(kernel_thread)
When:	August 2006
Files:	arch/*/kernel/*_ksyms.c
Check:	kernel_thread
Why:	kernel_thread is a low-level implementation detail.  Drivers should
        use the <linux/kthread.h> API instead which shields them from
	implementation details and provides a higherlevel interface that
	prevents bugs and code duplication
Who:	Christoph Hellwig <hch@lst.de>

---------------------------

What:	Unused EXPORT_SYMBOL/EXPORT_SYMBOL_GPL exports
	(temporary transition config option provided until then)
	The transition config option will also be removed at the same time.
When:	before 2.6.19
Why:	Unused symbols are both increasing the size of the kernel binary
	and are often a sign of "wrong API"
Who:	Arjan van de Ven <arjan@linux.intel.com>

---------------------------

What:	PHYSDEVPATH, PHYSDEVBUS, PHYSDEVDRIVER in the uevent environment
When:	October 2008
Why:	The stacking of class devices makes these values misleading and
	inconsistent.
	Class devices should not carry any of these properties, and bus
	devices have SUBSYTEM and DRIVER as a replacement.
Who:	Kay Sievers <kay.sievers@suse.de>

---------------------------

What:	ACPI procfs interface
When:	July 2008
Why:	ACPI sysfs conversion should be finished by January 2008.
	ACPI procfs interface will be removed in July 2008 so that
	there is enough time for the user space to catch up.
Who:	Zhang Rui <rui.zhang@intel.com>

---------------------------

What:	CONFIG_ACPI_PROCFS_POWER
When:	2.6.39
Why:	sysfs I/F for ACPI power devices, including AC and Battery,
        has been working in upstream kernel since 2.6.24, Sep 2007.
	In 2.6.37, we make the sysfs I/F always built in and this option
	disabled by default.
	Remove this option and the ACPI power procfs interface in 2.6.39.
Who:	Zhang Rui <rui.zhang@intel.com>

---------------------------

What:	/proc/acpi/event
When:	February 2008
Why:	/proc/acpi/event has been replaced by events via the input layer
	and netlink since 2.6.23.
Who:	Len Brown <len.brown@intel.com>

---------------------------

What:	i386/x86_64 bzImage symlinks
When:	April 2010

Why:	The i386/x86_64 merge provides a symlink to the old bzImage
	location so not yet updated user space tools, e.g. package
	scripts, do not break.
Who:	Thomas Gleixner <tglx@linutronix.de>

---------------------------

What:	GPIO autorequest on gpio_direction_{input,output}() in gpiolib
When:	February 2010
Why:	All callers should use explicit gpio_request()/gpio_free().
	The autorequest mechanism in gpiolib was provided mostly as a
	migration aid for legacy GPIO interfaces (for SOC based GPIOs).
	Those users have now largely migrated.  Platforms implementing
	the GPIO interfaces without using gpiolib will see no changes.
Who:	David Brownell <dbrownell@users.sourceforge.net>
---------------------------

What:	b43 support for firmware revision < 410
When:	The schedule was July 2008, but it was decided that we are going to keep the
        code as long as there are no major maintanance headaches.
	So it _could_ be removed _any_ time now, if it conflicts with something new.
Why:	The support code for the old firmware hurts code readability/maintainability
	and slightly hurts runtime performance. Bugfixes for the old firmware
	are not provided by Broadcom anymore.
Who:	Michael Buesch <mb@bu3sch.de>

---------------------------

What:	Ability for non root users to shm_get hugetlb pages based on mlock
	resource limits
When:	2.6.31
Why:	Non root users need to be part of /proc/sys/vm/hugetlb_shm_group or
	have CAP_IPC_LOCK to be able to allocate shm segments backed by
	huge pages.  The mlock based rlimit check to allow shm hugetlb is
	inconsistent with mmap based allocations.  Hence it is being
	deprecated.
Who:	Ravikiran Thirumalai <kiran@scalex86.org>

---------------------------

What:	CONFIG_THERMAL_HWMON
When:	January 2009
Why:	This option was introduced just to allow older lm-sensors userspace
	to keep working over the upgrade to 2.6.26. At the scheduled time of
	removal fixed lm-sensors (2.x or 3.x) should be readily available.
Who:	Rene Herman <rene.herman@gmail.com>

---------------------------

What:	Code that is now under CONFIG_WIRELESS_EXT_SYSFS
	(in net/core/net-sysfs.c)
When:	After the only user (hal) has seen a release with the patches
	for enough time, probably some time in 2010.
Why:	Over 1K .text/.data size reduction, data is available in other
	ways (ioctls)
Who:	Johannes Berg <johannes@sipsolutions.net>

---------------------------

What:	sysfs ui for changing p4-clockmod parameters
When:	September 2009
Why:	See commits 129f8ae9b1b5be94517da76009ea956e89104ce8 and
	e088e4c9cdb618675874becb91b2fd581ee707e6.
	Removal is subject to fixing any remaining bugs in ACPI which may
	cause the thermal throttling not to happen at the right time.
Who:	Dave Jones <davej@redhat.com>, Matthew Garrett <mjg@redhat.com>

-----------------------------

What:	fakephp and associated sysfs files in /sys/bus/pci/slots/
When:	2011
Why:	In 2.6.27, the semantics of /sys/bus/pci/slots was redefined to
	represent a machine's physical PCI slots. The change in semantics
	had userspace implications, as the hotplug core no longer allowed
	drivers to create multiple sysfs files per physical slot (required
	for multi-function devices, e.g.). fakephp was seen as a developer's
	tool only, and its interface changed. Too late, we learned that
	there were some users of the fakephp interface.

	In 2.6.30, the original fakephp interface was restored. At the same
	time, the PCI core gained the ability that fakephp provided, namely
	function-level hot-remove and hot-add.

	Since the PCI core now provides the same functionality, exposed in:

		/sys/bus/pci/rescan
		/sys/bus/pci/devices/.../remove
		/sys/bus/pci/devices/.../rescan

	there is no functional reason to maintain fakephp as well.

	We will keep the existing module so that 'modprobe fakephp' will
	present the old /sys/bus/pci/slots/... interface for compatibility,
	but users are urged to migrate their applications to the API above.

	After a reasonable transition period, we will remove the legacy
	fakephp interface.
Who:	Alex Chiang <achiang@hp.com>

---------------------------

What:	CONFIG_RFKILL_INPUT
When:	2.6.33
Why:	Should be implemented in userspace, policy daemon.
Who:	Johannes Berg <johannes@sipsolutions.net>

----------------------------

What:	sound-slot/service-* module aliases and related clutters in
	sound/sound_core.c
When:	August 2010
Why:	OSS sound_core grabs all legacy minors (0-255) of SOUND_MAJOR
	(14) and requests modules using custom sound-slot/service-*
	module aliases.  The only benefit of doing this is allowing
	use of custom module aliases which might as well be considered
	a bug at this point.  This preemptive claiming prevents
	alternative OSS implementations.

	Till the feature is removed, the kernel will be requesting
	both sound-slot/service-* and the standard char-major-* module
	aliases and allow turning off the pre-claiming selectively via
	CONFIG_SOUND_OSS_CORE_PRECLAIM and soundcore.preclaim_oss
	kernel parameter.

	After the transition phase is complete, both the custom module
	aliases and switches to disable it will go away.  This removal
	will also allow making ALSA OSS emulation independent of
	sound_core.  The dependency will be broken then too.
Who:	Tejun Heo <tj@kernel.org>

----------------------------

What:	sysfs-class-rfkill state file
When:	Feb 2014
Files:	net/rfkill/core.c
Why: 	Documented as obsolete since Feb 2010. This file is limited to 3
	states while the rfkill drivers can have 4 states.
Who: 	anybody or Florian Mickler <florian@mickler.org>

----------------------------

What: 	sysfs-class-rfkill claim file
When:	Feb 2012
Files:	net/rfkill/core.c
Why:	It is not possible to claim an rfkill driver since 2007. This is
	Documented as obsolete since Feb 2010.
Who: 	anybody or Florian Mickler <florian@mickler.org>

----------------------------

What:	KVM paravirt mmu host support
When:	January 2011
Why:	The paravirt mmu host support is slower than non-paravirt mmu, both
	on newer and older hardware.  It is already not exposed to the guest,
	and kept only for live migration purposes.
Who:	Avi Kivity <avi@redhat.com>

----------------------------

What:	iwlwifi 50XX module parameters
When:	2.6.40
Why:	The "..50" modules parameters were used to configure 5000 series and
	up devices; different set of module parameters also available for 4965
	with same functionalities. Consolidate both set into single place
	in drivers/net/wireless/iwlwifi/iwl-agn.c

Who:	Wey-Yi Guy <wey-yi.w.guy@intel.com>

----------------------------

What:	iwl4965 alias support
When:	2.6.40
Why:	Internal alias support has been present in module-init-tools for some
	time, the MODULE_ALIAS("iwl4965") boilerplate aliases can be removed
	with no impact.

Who:	Wey-Yi Guy <wey-yi.w.guy@intel.com>

---------------------------

What:	xt_NOTRACK
Files:	net/netfilter/xt_NOTRACK.c
When:	April 2011
Why:	Superseded by xt_CT
Who:	Netfilter developer team <netfilter-devel@vger.kernel.org>

----------------------------

What:	IRQF_DISABLED
When:	2.6.36
Why:	The flag is a NOOP as we run interrupt handlers with interrupts disabled
Who:	Thomas Gleixner <tglx@linutronix.de>

----------------------------

What: 	PCI DMA unmap state API
When:	August 2012
Why:	PCI DMA unmap state API (include/linux/pci-dma.h) was replaced
	with DMA unmap state API (DMA unmap state API can be used for
	any bus).
Who:	FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>

----------------------------

What: 	DMA_xxBIT_MASK macros
When:	Jun 2011
Why:	DMA_xxBIT_MASK macros were replaced with DMA_BIT_MASK() macros.
Who:	FUJITA Tomonori <fujita.tomonori@lab.ntt.co.jp>

----------------------------

What:	iwlwifi disable_hw_scan module parameters
When:	2.6.40
Why:	Hareware scan is the prefer method for iwlwifi devices for
	scanning operation. Remove software scan support for all the
	iwlwifi devices.

Who:	Wey-Yi Guy <wey-yi.w.guy@intel.com>

----------------------------

What:   access to nfsd auth cache through sys_nfsservctl or '.' files
        in the 'nfsd' filesystem.
When:   2.6.40
Why:    This is a legacy interface which have been replaced by a more
        dynamic cache.  Continuing to maintain this interface is an
        unnecessary burden.
Who:    NeilBrown <neilb@suse.de>

----------------------------

What:	cancel_rearming_delayed_work[queue]()
When:	2.6.39

Why:	The functions have been superceded by cancel_delayed_work_sync()
	quite some time ago.  The conversion is trivial and there is no
	in-kernel user left.
Who:	Tejun Heo <tj@kernel.org>

----------------------------

What:	Legacy, non-standard chassis intrusion detection interface.
When:	June 2011
Why:	The adm9240, w83792d and w83793 hardware monitoring drivers have
	legacy interfaces for chassis intrusion detection. A standard
	interface has been added to each driver, so the legacy interface
	can be removed.
Who:	Jean Delvare <khali@linux-fr.org>

----------------------------

What:	xt_connlimit rev 0
When:	2012
Who:	Jan Engelhardt <jengelh@medozas.de>
Files:	net/netfilter/xt_connlimit.c

----------------------------

What:	noswapaccount kernel command line parameter
When:	2.6.40
Why:	The original implementation of memsw feature enabled by
	CONFIG_CGROUP_MEM_RES_CTLR_SWAP could be disabled by the noswapaccount
	kernel parameter (introduced in 2.6.29-rc1). Later on, this decision
	turned out to be not ideal because we cannot have the feature compiled
	in and disabled by default and let only interested to enable it
	(e.g. general distribution kernels might need it). Therefore we have
	added swapaccount[=0|1] parameter (introduced in 2.6.37) which provides
	the both possibilities. If we remove noswapaccount we will have
	less command line parameters with the same functionality and we
	can also cleanup the parameter handling a bit ().
Who:	Michal Hocko <mhocko@suse.cz>

----------------------------

What:	ipt_addrtype match include file
When:	2012
Why:	superseded by xt_addrtype
Who:	Florian Westphal <fw@strlen.de>
Files:	include/linux/netfilter_ipv4/ipt_addrtype.h

----------------------------

What:	i2c_driver.attach_adapter
	i2c_driver.detach_adapter
When:	September 2011
Why:	These legacy callbacks should no longer be used as i2c-core offers
	a variety of preferable alternative ways to instantiate I2C devices.
Who:	Jean Delvare <khali@linux-fr.org>

----------------------------

What:	Support for UVCIOC_CTRL_ADD in the uvcvideo driver
When:	2.6.42
Why:	The information passed to the driver by this ioctl is now queried
	dynamically from the device.
Who:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>

----------------------------

What:	Support for UVCIOC_CTRL_MAP_OLD in the uvcvideo driver
When:	2.6.42
Why:	Used only by applications compiled against older driver versions.
	Superseded by UVCIOC_CTRL_MAP which supports V4L2 menu controls.
Who:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>

----------------------------

What:	Support for UVCIOC_CTRL_GET and UVCIOC_CTRL_SET in the uvcvideo driver
When:	2.6.42
Why:	Superseded by the UVCIOC_CTRL_QUERY ioctl.
Who:	Laurent Pinchart <laurent.pinchart@ideasonboard.com>

----------------------------

What:	For VIDIOC_S_FREQUENCY the type field must match the device node's type.
	If not, return -EINVAL.
When:	3.2
Why:	It makes no sense to switch the tuner to radio mode by calling
	VIDIOC_S_FREQUENCY on a video node, or to switch the tuner to tv mode by
	calling VIDIOC_S_FREQUENCY on a radio node. This is the first step of a
	move to more consistent handling of tv and radio tuners.
Who:	Hans Verkuil <hans.verkuil@cisco.com>

----------------------------

What:	Opening a radio device node will no longer automatically switch the
	tuner mode from tv to radio.
When:	3.3
Why:	Just opening a V4L device should not change the state of the hardware
	like that. It's very unexpected and against the V4L spec. Instead, you
	switch to radio mode by calling VIDIOC_S_FREQUENCY. This is the second
	and last step of the move to consistent handling of tv and radio tuners.
Who:	Hans Verkuil <hans.verkuil@cisco.com>

----------------------------
Using flexible arrays in the kernel
Last updated for 2.6.32
Jonathan Corbet <corbet@lwn.net>

Large contiguous memory allocations can be unreliable in the Linux kernel.
Kernel programmers will sometimes respond to this problem by allocating
pages with vmalloc().  This solution not ideal, though.  On 32-bit systems,
memory from vmalloc() must be mapped into a relatively small address space;
it's easy to run out.  On SMP systems, the page table changes required by
vmalloc() allocations can require expensive cross-processor interrupts on
all CPUs.  And, on all systems, use of space in the vmalloc() range
increases pressure on the translation lookaside buffer (TLB), reducing the
performance of the system.

In many cases, the need for memory from vmalloc() can be eliminated by
piecing together an array from smaller parts; the flexible array library
exists to make this task easier.

A flexible array holds an arbitrary (within limits) number of fixed-sized
objects, accessed via an integer index.  Sparse arrays are handled
reasonably well.  Only single-page allocations are made, so memory
allocation failures should be relatively rare.  The down sides are that the
arrays cannot be indexed directly, individual object size cannot exceed the
system page size, and putting data into a flexible array requires a copy
operation.  It's also worth noting that flexible arrays do no internal
locking at all; if concurrent access to an array is possible, then the
caller must arrange for appropriate mutual exclusion.

The creation of a flexible array is done with:

    #include <linux/flex_array.h>

    struct flex_array *flex_array_alloc(int element_size,
					unsigned int total,
					gfp_t flags);

The individual object size is provided by element_size, while total is the
maximum number of objects which can be stored in the array.  The flags
argument is passed directly to the internal memory allocation calls.  With
the current code, using flags to ask for high memory is likely to lead to
notably unpleasant side effects.

It is also possible to define flexible arrays at compile time with:

    DEFINE_FLEX_ARRAY(name, element_size, total);

This macro will result in a definition of an array with the given name; the
element size and total will be checked for validity at compile time.

Storing data into a flexible array is accomplished with a call to:

    int flex_array_put(struct flex_array *array, unsigned int element_nr,
    		       void *src, gfp_t flags);

This call will copy the data from src into the array, in the position
indicated by element_nr (which must be less than the maximum specified when
the array was created).  If any memory allocations must be performed, flags
will be used.  The return value is zero on success, a negative error code
otherwise.

There might possibly be a need to store data into a flexible array while
running in some sort of atomic context; in this situation, sleeping in the
memory allocator would be a bad thing.  That can be avoided by using
GFP_ATOMIC for the flags value, but, often, there is a better way.  The
trick is to ensure that any needed memory allocations are done before
entering atomic context, using:

    int flex_array_prealloc(struct flex_array *array, unsigned int start,
			    unsigned int nr_elements, gfp_t flags);

This function will ensure that memory for the elements indexed in the range
defined by start and nr_elements has been allocated.  Thereafter, a
flex_array_put() call on an element in that range is guaranteed not to
block.

Getting data back out of the array is done with:

    void *flex_array_get(struct flex_array *fa, unsigned int element_nr);

The return value is a pointer to the data element, or NULL if that
particular element has never been allocated.

Note that it is possible to get back a valid pointer for an element which
has never been stored in the array.  Memory for array elements is allocated
one page at a time; a single allocation could provide memory for several
adjacent elements.  Flexible array elements are normally initialized to the
value FLEX_ARRAY_FREE (defined as 0x6c in <linux/poison.h>), so errors
involving that number probably result from use of unstored array entries.
Note that, if array elements are allocated with __GFP_ZERO, they will be
initialized to zero and this poisoning will not happen.

Individual elements in the array can be cleared with:

    int flex_array_clear(struct flex_array *array, unsigned int element_nr);

This function will set the given element to FLEX_ARRAY_FREE and return
zero.  If storage for the indicated element is not allocated for the array,
flex_array_clear() will return -EINVAL instead.  Note that clearing an
element does not release the storage associated with it; to reduce the
allocated size of an array, call:

    int flex_array_shrink(struct flex_array *array);

The return value will be the number of pages of memory actually freed.
This function works by scanning the array for pages containing nothing but
FLEX_ARRAY_FREE bytes, so (1) it can be expensive, and (2) it will not work
if the array's pages are allocated with __GFP_ZERO.

It is possible to remove all elements of an array with a call to:

    void flex_array_free_parts(struct flex_array *array);

This call frees all elements, but leaves the array itself in place.
Freeing the entire array is done with:

    void flex_array_free(struct flex_array *array);

As of this writing, there are no users of flexible arrays in the mainline
kernel.  The functions described here are also not exported to modules;
that will probably be fixed when somebody comes up with a need for it.
Futex Requeue PI
----------------

Requeueing of tasks from a non-PI futex to a PI futex requires
special handling in order to ensure the underlying rt_mutex is never
left without an owner if it has waiters; doing so would break the PI
boosting logic [see rt-mutex-desgin.txt] For the purposes of
brevity, this action will be referred to as "requeue_pi" throughout
this document.  Priority inheritance is abbreviated throughout as
"PI".

Motivation
----------

Without requeue_pi, the glibc implementation of
pthread_cond_broadcast() must resort to waking all the tasks waiting
on a pthread_condvar and letting them try to sort out which task
gets to run first in classic thundering-herd formation.  An ideal
implementation would wake the highest-priority waiter, and leave the
rest to the natural wakeup inherent in unlocking the mutex
associated with the condvar.

Consider the simplified glibc calls:

/* caller must lock mutex */
pthread_cond_wait(cond, mutex)
{
	lock(cond->__data.__lock);
	unlock(mutex);
	do {
	   unlock(cond->__data.__lock);
	   futex_wait(cond->__data.__futex);
	   lock(cond->__data.__lock);
	} while(...)
	unlock(cond->__data.__lock);
	lock(mutex);
}

pthread_cond_broadcast(cond)
{
	lock(cond->__data.__lock);
	unlock(cond->__data.__lock);
	futex_requeue(cond->data.__futex, cond->mutex);
}

Once pthread_cond_broadcast() requeues the tasks, the cond->mutex
has waiters. Note that pthread_cond_wait() attempts to lock the
mutex only after it has returned to user space.  This will leave the
underlying rt_mutex with waiters, and no owner, breaking the
previously mentioned PI-boosting algorithms.

In order to support PI-aware pthread_condvar's, the kernel needs to
be able to requeue tasks to PI futexes.  This support implies that
upon a successful futex_wait system call, the caller would return to
user space already holding the PI futex.  The glibc implementation
would be modified as follows:


/* caller must lock mutex */
pthread_cond_wait_pi(cond, mutex)
{
	lock(cond->__data.__lock);
	unlock(mutex);
	do {
	   unlock(cond->__data.__lock);
	   futex_wait_requeue_pi(cond->__data.__futex);
	   lock(cond->__data.__lock);
	} while(...)
	unlock(cond->__data.__lock);
        /* the kernel acquired the the mutex for us */
}

pthread_cond_broadcast_pi(cond)
{
	lock(cond->__data.__lock);
	unlock(cond->__data.__lock);
	futex_requeue_pi(cond->data.__futex, cond->mutex);
}

The actual glibc implementation will likely test for PI and make the
necessary changes inside the existing calls rather than creating new
calls for the PI cases.  Similar changes are needed for
pthread_cond_timedwait() and pthread_cond_signal().

Implementation
--------------

In order to ensure the rt_mutex has an owner if it has waiters, it
is necessary for both the requeue code, as well as the waiting code,
to be able to acquire the rt_mutex before returning to user space.
The requeue code cannot simply wake the waiter and leave it to
acquire the rt_mutex as it would open a race window between the
requeue call returning to user space and the waiter waking and
starting to run.  This is especially true in the uncontended case.

The solution involves two new rt_mutex helper routines,
rt_mutex_start_proxy_lock() and rt_mutex_finish_proxy_lock(), which
allow the requeue code to acquire an uncontended rt_mutex on behalf
of the waiter and to enqueue the waiter on a contended rt_mutex.
Two new system calls provide the kernel<->user interface to
requeue_pi: FUTEX_WAIT_REQUEUE_PI and FUTEX_REQUEUE_CMP_PI.

FUTEX_WAIT_REQUEUE_PI is called by the waiter (pthread_cond_wait()
and pthread_cond_timedwait()) to block on the initial futex and wait
to be requeued to a PI-aware futex.  The implementation is the
result of a high-speed collision between futex_wait() and
futex_lock_pi(), with some extra logic to check for the additional
wake-up scenarios.

FUTEX_REQUEUE_CMP_PI is called by the waker
(pthread_cond_broadcast() and pthread_cond_signal()) to requeue and
possibly wake the waiting tasks. Internally, this system call is
still handled by futex_requeue (by passing requeue_pi=1).  Before
requeueing, futex_requeue() attempts to acquire the requeue target
PI futex on behalf of the top waiter.  If it can, this waiter is
woken.  futex_requeue() then proceeds to requeue the remaining
nr_wake+nr_requeue tasks to the PI futex, calling
rt_mutex_start_proxy_lock() prior to each requeue to prepare the
task as a waiter on the underlying rt_mutex.  It is possible that
the lock can be acquired at this stage as well, if so, the next
waiter is woken to finish the acquisition of the lock.

FUTEX_REQUEUE_PI accepts nr_wake and nr_requeue as arguments, but
their sum is all that really matters.  futex_requeue() will wake or
requeue up to nr_wake + nr_requeue tasks.  It will wake only as many
tasks as it can acquire the lock for, which in the majority of cases
should be 0 as good programming practice dictates that the caller of
either pthread_cond_broadcast() or pthread_cond_signal() acquire the
mutex prior to making the call. FUTEX_REQUEUE_PI requires that
nr_wake=1.  nr_requeue should be INT_MAX for broadcast and 0 for
signal.
Using gcov with the Linux kernel
================================

1. Introduction
2. Preparation
3. Customization
4. Files
5. Modules
6. Separated build and test machines
7. Troubleshooting
Appendix A: sample script: gather_on_build.sh
Appendix B: sample script: gather_on_test.sh


1. Introduction
===============

gcov profiling kernel support enables the use of GCC's coverage testing
tool gcov [1] with the Linux kernel. Coverage data of a running kernel
is exported in gcov-compatible format via the "gcov" debugfs directory.
To get coverage data for a specific file, change to the kernel build
directory and use gcov with the -o option as follows (requires root):

# cd /tmp/linux-out
# gcov -o /sys/kernel/debug/gcov/tmp/linux-out/kernel spinlock.c

This will create source code files annotated with execution counts
in the current directory. In addition, graphical gcov front-ends such
as lcov [2] can be used to automate the process of collecting data
for the entire kernel and provide coverage overviews in HTML format.

Possible uses:

* debugging (has this line been reached at all?)
* test improvement (how do I change my test to cover these lines?)
* minimizing kernel configurations (do I need this option if the
  associated code is never run?)

--

[1] http://gcc.gnu.org/onlinedocs/gcc/Gcov.html
[2] http://ltp.sourceforge.net/coverage/lcov.php


2. Preparation
==============

Configure the kernel with:

        CONFIG_DEBUG_FS=y
        CONFIG_GCOV_KERNEL=y

and to get coverage data for the entire kernel:

        CONFIG_GCOV_PROFILE_ALL=y

Note that kernels compiled with profiling flags will be significantly
larger and run slower. Also CONFIG_GCOV_PROFILE_ALL may not be supported
on all architectures.

Profiling data will only become accessible once debugfs has been
mounted:

        mount -t debugfs none /sys/kernel/debug


3. Customization
================

To enable profiling for specific files or directories, add a line
similar to the following to the respective kernel Makefile:

        For a single file (e.g. main.o):
                GCOV_PROFILE_main.o := y

        For all files in one directory:
                GCOV_PROFILE := y

To exclude files from being profiled even when CONFIG_GCOV_PROFILE_ALL
is specified, use:

                GCOV_PROFILE_main.o := n
        and:
                GCOV_PROFILE := n

Only files which are linked to the main kernel image or are compiled as
kernel modules are supported by this mechanism.


4. Files
========

The gcov kernel support creates the following files in debugfs:

        /sys/kernel/debug/gcov
                Parent directory for all gcov-related files.

        /sys/kernel/debug/gcov/reset
                Global reset file: resets all coverage data to zero when
                written to.

        /sys/kernel/debug/gcov/path/to/compile/dir/file.gcda
                The actual gcov data file as understood by the gcov
                tool. Resets file coverage data to zero when written to.

        /sys/kernel/debug/gcov/path/to/compile/dir/file.gcno
                Symbolic link to a static data file required by the gcov
                tool. This file is generated by gcc when compiling with
                option -ftest-coverage.


5. Modules
==========

Kernel modules may contain cleanup code which is only run during
module unload time. The gcov mechanism provides a means to collect
coverage data for such code by keeping a copy of the data associated
with the unloaded module. This data remains available through debugfs.
Once the module is loaded again, the associated coverage counters are
initialized with the data from its previous instantiation.

This behavior can be deactivated by specifying the gcov_persist kernel
parameter:

        gcov_persist=0

At run-time, a user can also choose to discard data for an unloaded
module by writing to its data file or the global reset file.


6. Separated build and test machines
====================================

The gcov kernel profiling infrastructure is designed to work out-of-the
box for setups where kernels are built and run on the same machine. In
cases where the kernel runs on a separate machine, special preparations
must be made, depending on where the gcov tool is used:

a) gcov is run on the TEST machine

The gcov tool version on the test machine must be compatible with the
gcc version used for kernel build. Also the following files need to be
copied from build to test machine:

from the source tree:
  - all C source files + headers

from the build tree:
  - all C source files + headers
  - all .gcda and .gcno files
  - all links to directories

It is important to note that these files need to be placed into the
exact same file system location on the test machine as on the build
machine. If any of the path components is symbolic link, the actual
directory needs to be used instead (due to make's CURDIR handling).

b) gcov is run on the BUILD machine

The following files need to be copied after each test case from test
to build machine:

from the gcov directory in sysfs:
  - all .gcda files
  - all links to .gcno files

These files can be copied to any location on the build machine. gcov
must then be called with the -o option pointing to that directory.

Example directory setup on the build machine:

  /tmp/linux:    kernel source tree
  /tmp/out:      kernel build directory as specified by make O=
  /tmp/coverage: location of the files copied from the test machine

  [user@build] cd /tmp/out
  [user@build] gcov -o /tmp/coverage/tmp/out/init main.c


7. Troubleshooting
==================

Problem:  Compilation aborts during linker step.
Cause:    Profiling flags are specified for source files which are not
          linked to the main kernel or which are linked by a custom
          linker procedure.
Solution: Exclude affected source files from profiling by specifying
          GCOV_PROFILE := n or GCOV_PROFILE_basename.o := n in the
          corresponding Makefile.

Problem:  Files copied from sysfs appear empty or incomplete.
Cause:    Due to the way seq_file works, some tools such as cp or tar
          may not correctly copy files from sysfs.
Solution: Use 'cat' to read .gcda files and 'cp -d' to copy links.
          Alternatively use the mechanism shown in Appendix B.


Appendix A: gather_on_build.sh
==============================

Sample script to gather coverage meta files on the build machine
(see 6a):
#!/bin/bash

KSRC=$1
KOBJ=$2
DEST=$3

if [ -z "$KSRC" ] || [ -z "$KOBJ" ] || [ -z "$DEST" ]; then
  echo "Usage: $0 <ksrc directory> <kobj directory> <output.tar.gz>" >&2
  exit 1
fi

KSRC=$(cd $KSRC; printf "all:\n\t@echo \${CURDIR}\n" | make -f -)
KOBJ=$(cd $KOBJ; printf "all:\n\t@echo \${CURDIR}\n" | make -f -)

find $KSRC $KOBJ \( -name '*.gcno' -o -name '*.[ch]' -o -type l \) -a \
                 -perm /u+r,g+r | tar cfz $DEST -P -T -

if [ $? -eq 0 ] ; then
  echo "$DEST successfully created, copy to test system and unpack with:"
  echo "  tar xfz $DEST -P"
else
  echo "Could not create file $DEST"
fi


Appendix B: gather_on_test.sh
=============================

Sample script to gather coverage data files on the test machine
(see 6b):

#!/bin/bash -e

DEST=$1
GCDA=/sys/kernel/debug/gcov

if [ -z "$DEST" ] ; then
  echo "Usage: $0 <output.tar.gz>" >&2
  exit 1
fi

TEMPDIR=$(mktemp -d)
echo Collecting data..
find $GCDA -type d -exec mkdir -p $TEMPDIR/\{\} \;
find $GCDA -name '*.gcda' -exec sh -c 'cat < $0 > '$TEMPDIR'/$0' {} \;
find $GCDA -name '*.gcno' -exec sh -c 'cp -d $0 '$TEMPDIR'/$0' {} \;
tar czf $DEST -C $TEMPDIR sys
rm -rf $TEMPDIR

echo "$DEST successfully created, copy to build system and unpack with:"
echo "  tar xfz $DEST"
GPIO Interfaces

This provides an overview of GPIO access conventions on Linux.

These calls use the gpio_* naming prefix.  No other calls should use that
prefix, or the related __gpio_* prefix.


What is a GPIO?
===============
A "General Purpose Input/Output" (GPIO) is a flexible software-controlled
digital signal.  They are provided from many kinds of chip, and are familiar
to Linux developers working with embedded and custom hardware.  Each GPIO
represents a bit connected to a particular pin, or "ball" on Ball Grid Array
(BGA) packages.  Board schematics show which external hardware connects to
which GPIOs.  Drivers can be written generically, so that board setup code
passes such pin configuration data to drivers.

System-on-Chip (SOC) processors heavily rely on GPIOs.  In some cases, every
non-dedicated pin can be configured as a GPIO; and most chips have at least
several dozen of them.  Programmable logic devices (like FPGAs) can easily
provide GPIOs; multifunction chips like power managers, and audio codecs
often have a few such pins to help with pin scarcity on SOCs; and there are
also "GPIO Expander" chips that connect using the I2C or SPI serial busses.
Most PC southbridges have a few dozen GPIO-capable pins (with only the BIOS
firmware knowing how they're used).

The exact capabilities of GPIOs vary between systems.  Common options:

  - Output values are writable (high=1, low=0).  Some chips also have
    options about how that value is driven, so that for example only one
    value might be driven ... supporting "wire-OR" and similar schemes
    for the other value (notably, "open drain" signaling).

  - Input values are likewise readable (1, 0).  Some chips support readback
    of pins configured as "output", which is very useful in such "wire-OR"
    cases (to support bidirectional signaling).  GPIO controllers may have
    input de-glitch/debounce logic, sometimes with software controls.

  - Inputs can often be used as IRQ signals, often edge triggered but
    sometimes level triggered.  Such IRQs may be configurable as system
    wakeup events, to wake the system from a low power state.

  - Usually a GPIO will be configurable as either input or output, as needed
    by different product boards; single direction ones exist too.

  - Most GPIOs can be accessed while holding spinlocks, but those accessed
    through a serial bus normally can't.  Some systems support both types.

On a given board each GPIO is used for one specific purpose like monitoring
MMC/SD card insertion/removal, detecting card writeprotect status, driving
a LED, configuring a transceiver, bitbanging a serial bus, poking a hardware
watchdog, sensing a switch, and so on.


GPIO conventions
================
Note that this is called a "convention" because you don't need to do it this
way, and it's no crime if you don't.  There **are** cases where portability
is not the main issue; GPIOs are often used for the kind of board-specific
glue logic that may even change between board revisions, and can't ever be
used on a board that's wired differently.  Only least-common-denominator
functionality can be very portable.  Other features are platform-specific,
and that can be critical for glue logic.

Plus, this doesn't require any implementation framework, just an interface.
One platform might implement it as simple inline functions accessing chip
registers; another might implement it by delegating through abstractions
used for several very different kinds of GPIO controller.  (There is some
optional code supporting such an implementation strategy, described later
in this document, but drivers acting as clients to the GPIO interface must
not care how it's implemented.)

That said, if the convention is supported on their platform, drivers should
use it when possible.  Platforms must declare GENERIC_GPIO support in their
Kconfig (boolean true), and provide an <asm/gpio.h> file.  Drivers that can't
work without standard GPIO calls should have Kconfig entries which depend
on GENERIC_GPIO.  The GPIO calls are available, either as "real code" or as
optimized-away stubs, when drivers use the include file:

	#include <linux/gpio.h>

If you stick to this convention then it'll be easier for other developers to
see what your code is doing, and help maintain it.

Note that these operations include I/O barriers on platforms which need to
use them; drivers don't need to add them explicitly.


Identifying GPIOs
-----------------
GPIOs are identified by unsigned integers in the range 0..MAX_INT.  That
reserves "negative" numbers for other purposes like marking signals as
"not available on this board", or indicating faults.  Code that doesn't
touch the underlying hardware treats these integers as opaque cookies.

Platforms define how they use those integers, and usually #define symbols
for the GPIO lines so that board-specific setup code directly corresponds
to the relevant schematics.  In contrast, drivers should only use GPIO
numbers passed to them from that setup code, using platform_data to hold
board-specific pin configuration data (along with other board specific
data they need).  That avoids portability problems.

So for example one platform uses numbers 32-159 for GPIOs; while another
uses numbers 0..63 with one set of GPIO controllers, 64-79 with another
type of GPIO controller, and on one particular board 80-95 with an FPGA.
The numbers need not be contiguous; either of those platforms could also
use numbers 2000-2063 to identify GPIOs in a bank of I2C GPIO expanders.

If you want to initialize a structure with an invalid GPIO number, use
some negative number (perhaps "-EINVAL"); that will never be valid.  To
test if such number from such a structure could reference a GPIO, you
may use this predicate:

	int gpio_is_valid(int number);

A number that's not valid will be rejected by calls which may request
or free GPIOs (see below).  Other numbers may also be rejected; for
example, a number might be valid but temporarily unused on a given board.

Whether a platform supports multiple GPIO controllers is a platform-specific
implementation issue, as are whether that support can leave "holes" in the space
of GPIO numbers, and whether new controllers can be added at runtime.  Such issues
can affect things including whether adjacent GPIO numbers are both valid.

Using GPIOs
-----------
The first thing a system should do with a GPIO is allocate it, using
the gpio_request() call; see later.

One of the next things to do with a GPIO, often in board setup code when
setting up a platform_device using the GPIO, is mark its direction:

	/* set as input or output, returning 0 or negative errno */
	int gpio_direction_input(unsigned gpio);
	int gpio_direction_output(unsigned gpio, int value);

The return value is zero for success, else a negative errno.  It should
be checked, since the get/set calls don't have error returns and since
misconfiguration is possible.  You should normally issue these calls from
a task context.  However, for spinlock-safe GPIOs it's OK to use them
before tasking is enabled, as part of early board setup.

For output GPIOs, the value provided becomes the initial output value.
This helps avoid signal glitching during system startup.

For compatibility with legacy interfaces to GPIOs, setting the direction
of a GPIO implicitly requests that GPIO (see below) if it has not been
requested already.  That compatibility is being removed from the optional
gpiolib framework.

Setting the direction can fail if the GPIO number is invalid, or when
that particular GPIO can't be used in that mode.  It's generally a bad
idea to rely on boot firmware to have set the direction correctly, since
it probably wasn't validated to do more than boot Linux.  (Similarly,
that board setup code probably needs to multiplex that pin as a GPIO,
and configure pullups/pulldowns appropriately.)


Spinlock-Safe GPIO access
-------------------------
Most GPIO controllers can be accessed with memory read/write instructions.
Those don't need to sleep, and can safely be done from inside hard
(nonthreaded) IRQ handlers and similar contexts.

Use the following calls to access such GPIOs,
for which gpio_cansleep() will always return false (see below):

	/* GPIO INPUT:  return zero or nonzero */
	int gpio_get_value(unsigned gpio);

	/* GPIO OUTPUT */
	void gpio_set_value(unsigned gpio, int value);

The values are boolean, zero for low, nonzero for high.  When reading the
value of an output pin, the value returned should be what's seen on the
pin ... that won't always match the specified output value, because of
issues including open-drain signaling and output latencies.

The get/set calls have no error returns because "invalid GPIO" should have
been reported earlier from gpio_direction_*().  However, note that not all
platforms can read the value of output pins; those that can't should always
return zero.  Also, using these calls for GPIOs that can't safely be accessed
without sleeping (see below) is an error.

Platform-specific implementations are encouraged to optimize the two
calls to access the GPIO value in cases where the GPIO number (and for
output, value) are constant.  It's normal for them to need only a couple
of instructions in such cases (reading or writing a hardware register),
and not to need spinlocks.  Such optimized calls can make bitbanging
applications a lot more efficient (in both space and time) than spending
dozens of instructions on subroutine calls.


GPIO access that may sleep
--------------------------
Some GPIO controllers must be accessed using message based busses like I2C
or SPI.  Commands to read or write those GPIO values require waiting to
get to the head of a queue to transmit a command and get its response.
This requires sleeping, which can't be done from inside IRQ handlers.

Platforms that support this type of GPIO distinguish them from other GPIOs
by returning nonzero from this call (which requires a valid GPIO number,
which should have been previously allocated with gpio_request):

	int gpio_cansleep(unsigned gpio);

To access such GPIOs, a different set of accessors is defined:

	/* GPIO INPUT:  return zero or nonzero, might sleep */
	int gpio_get_value_cansleep(unsigned gpio);

	/* GPIO OUTPUT, might sleep */
	void gpio_set_value_cansleep(unsigned gpio, int value);


Accessing such GPIOs requires a context which may sleep,  for example
a threaded IRQ handler, and those accessors must be used instead of
spinlock-safe accessors without the cansleep() name suffix.

Other than the fact that these accessors might sleep, and will work
on GPIOs that can't be accessed from hardIRQ handlers, these calls act
the same as the spinlock-safe calls.

  ** IN ADDITION ** calls to setup and configure such GPIOs must be made
from contexts which may sleep, since they may need to access the GPIO
controller chip too:  (These setup calls are usually made from board
setup or driver probe/teardown code, so this is an easy constraint.)

	gpio_direction_input()
	gpio_direction_output()
	gpio_request()

## 	gpio_request_one()
##	gpio_request_array()
## 	gpio_free_array()

	gpio_free()
	gpio_set_debounce()



Claiming and Releasing GPIOs
----------------------------
To help catch system configuration errors, two calls are defined.

	/* request GPIO, returning 0 or negative errno.
	 * non-null labels may be useful for diagnostics.
	 */
	int gpio_request(unsigned gpio, const char *label);

	/* release previously-claimed GPIO */
	void gpio_free(unsigned gpio);

Passing invalid GPIO numbers to gpio_request() will fail, as will requesting
GPIOs that have already been claimed with that call.  The return value of
gpio_request() must be checked.  You should normally issue these calls from
a task context.  However, for spinlock-safe GPIOs it's OK to request GPIOs
before tasking is enabled, as part of early board setup.

These calls serve two basic purposes.  One is marking the signals which
are actually in use as GPIOs, for better diagnostics; systems may have
several hundred potential GPIOs, but often only a dozen are used on any
given board.  Another is to catch conflicts, identifying errors when
(a) two or more drivers wrongly think they have exclusive use of that
signal, or (b) something wrongly believes it's safe to remove drivers
needed to manage a signal that's in active use.  That is, requesting a
GPIO can serve as a kind of lock.

Some platforms may also use knowledge about what GPIOs are active for
power management, such as by powering down unused chip sectors and, more
easily, gating off unused clocks.

Note that requesting a GPIO does NOT cause it to be configured in any
way; it just marks that GPIO as in use.  Separate code must handle any
pin setup (e.g. controlling which pin the GPIO uses, pullup/pulldown).

Also note that it's your responsibility to have stopped using a GPIO
before you free it.

Considering in most cases GPIOs are actually configured right after they
are claimed, three additional calls are defined:

	/* request a single GPIO, with initial configuration specified by
	 * 'flags', identical to gpio_request() wrt other arguments and
	 * return value
	 */
	int gpio_request_one(unsigned gpio, unsigned long flags, const char *label);

	/* request multiple GPIOs in a single call
	 */
	int gpio_request_array(struct gpio *array, size_t num);

	/* release multiple GPIOs in a single call
	 */
	void gpio_free_array(struct gpio *array, size_t num);

where 'flags' is currently defined to specify the following properties:

	* GPIOF_DIR_IN		- to configure direction as input
	* GPIOF_DIR_OUT		- to configure direction as output

	* GPIOF_INIT_LOW	- as output, set initial level to LOW
	* GPIOF_INIT_HIGH	- as output, set initial level to HIGH

since GPIOF_INIT_* are only valid when configured as output, so group valid
combinations as:

	* GPIOF_IN		- configure as input
	* GPIOF_OUT_INIT_LOW	- configured as output, initial level LOW
	* GPIOF_OUT_INIT_HIGH	- configured as output, initial level HIGH

In the future, these flags can be extended to support more properties such
as open-drain status.

Further more, to ease the claim/release of multiple GPIOs, 'struct gpio' is
introduced to encapsulate all three fields as:

	struct gpio {
		unsigned	gpio;
		unsigned long	flags;
		const char	*label;
	};

A typical example of usage:

	static struct gpio leds_gpios[] = {
		{ 32, GPIOF_OUT_INIT_HIGH, "Power LED" }, /* default to ON */
		{ 33, GPIOF_OUT_INIT_LOW,  "Green LED" }, /* default to OFF */
		{ 34, GPIOF_OUT_INIT_LOW,  "Red LED"   }, /* default to OFF */
		{ 35, GPIOF_OUT_INIT_LOW,  "Blue LED"  }, /* default to OFF */
		{ ... },
	};

	err = gpio_request_one(31, GPIOF_IN, "Reset Button");
	if (err)
		...

	err = gpio_request_array(leds_gpios, ARRAY_SIZE(leds_gpios));
	if (err)
		...

	gpio_free_array(leds_gpios, ARRAY_SIZE(leds_gpios));


GPIOs mapped to IRQs
--------------------
GPIO numbers are unsigned integers; so are IRQ numbers.  These make up
two logically distinct namespaces (GPIO 0 need not use IRQ 0).  You can
map between them using calls like:

	/* map GPIO numbers to IRQ numbers */
	int gpio_to_irq(unsigned gpio);

	/* map IRQ numbers to GPIO numbers (avoid using this) */
	int irq_to_gpio(unsigned irq);

Those return either the corresponding number in the other namespace, or
else a negative errno code if the mapping can't be done.  (For example,
some GPIOs can't be used as IRQs.)  It is an unchecked error to use a GPIO
number that wasn't set up as an input using gpio_direction_input(), or
to use an IRQ number that didn't originally come from gpio_to_irq().

These two mapping calls are expected to cost on the order of a single
addition or subtraction.  They're not allowed to sleep.

Non-error values returned from gpio_to_irq() can be passed to request_irq()
or free_irq().  They will often be stored into IRQ resources for platform
devices, by the board-specific initialization code.  Note that IRQ trigger
options are part of the IRQ interface, e.g. IRQF_TRIGGER_FALLING, as are
system wakeup capabilities.

Non-error values returned from irq_to_gpio() would most commonly be used
with gpio_get_value(), for example to initialize or update driver state
when the IRQ is edge-triggered.  Note that some platforms don't support
this reverse mapping, so you should avoid using it.


Emulating Open Drain Signals
----------------------------
Sometimes shared signals need to use "open drain" signaling, where only the
low signal level is actually driven.  (That term applies to CMOS transistors;
"open collector" is used for TTL.)  A pullup resistor causes the high signal
level.  This is sometimes called a "wire-AND"; or more practically, from the
negative logic (low=true) perspective this is a "wire-OR".

One common example of an open drain signal is a shared active-low IRQ line.
Also, bidirectional data bus signals sometimes use open drain signals.

Some GPIO controllers directly support open drain outputs; many don't.  When
you need open drain signaling but your hardware doesn't directly support it,
there's a common idiom you can use to emulate it with any GPIO pin that can
be used as either an input or an output:

 LOW:	gpio_direction_output(gpio, 0) ... this drives the signal
	and overrides the pullup.

 HIGH:	gpio_direction_input(gpio) ... this turns off the output,
	so the pullup (or some other device) controls the signal.

If you are "driving" the signal high but gpio_get_value(gpio) reports a low
value (after the appropriate rise time passes), you know some other component
is driving the shared signal low.  That's not necessarily an error.  As one
common example, that's how I2C clocks are stretched:  a slave that needs a
slower clock delays the rising edge of SCK, and the I2C master adjusts its
signaling rate accordingly.


What do these conventions omit?
===============================
One of the biggest things these conventions omit is pin multiplexing, since
this is highly chip-specific and nonportable.  One platform might not need
explicit multiplexing; another might have just two options for use of any
given pin; another might have eight options per pin; another might be able
to route a given GPIO to any one of several pins.  (Yes, those examples all
come from systems that run Linux today.)

Related to multiplexing is configuration and enabling of the pullups or
pulldowns integrated on some platforms.  Not all platforms support them,
or support them in the same way; and any given board might use external
pullups (or pulldowns) so that the on-chip ones should not be used.
(When a circuit needs 5 kOhm, on-chip 100 kOhm resistors won't do.)
Likewise drive strength (2 mA vs 20 mA) and voltage (1.8V vs 3.3V) is a
platform-specific issue, as are models like (not) having a one-to-one
correspondence between configurable pins and GPIOs.

There are other system-specific mechanisms that are not specified here,
like the aforementioned options for input de-glitching and wire-OR output.
Hardware may support reading or writing GPIOs in gangs, but that's usually
configuration dependent:  for GPIOs sharing the same bank.  (GPIOs are
commonly grouped in banks of 16 or 32, with a given SOC having several such
banks.)  Some systems can trigger IRQs from output GPIOs, or read values
from pins not managed as GPIOs.  Code relying on such mechanisms will
necessarily be nonportable.

Dynamic definition of GPIOs is not currently standard; for example, as
a side effect of configuring an add-on board with some GPIO expanders.


GPIO implementor's framework (OPTIONAL)
=======================================
As noted earlier, there is an optional implementation framework making it
easier for platforms to support different kinds of GPIO controller using
the same programming interface.  This framework is called "gpiolib".

As a debugging aid, if debugfs is available a /sys/kernel/debug/gpio file
will be found there.  That will list all the controllers registered through
this framework, and the state of the GPIOs currently in use.


Controller Drivers: gpio_chip
-----------------------------
In this framework each GPIO controller is packaged as a "struct gpio_chip"
with information common to each controller of that type:

 - methods to establish GPIO direction
 - methods used to access GPIO values
 - flag saying whether calls to its methods may sleep
 - optional debugfs dump method (showing extra state like pullup config)
 - label for diagnostics

There is also per-instance data, which may come from device.platform_data:
the number of its first GPIO, and how many GPIOs it exposes.

The code implementing a gpio_chip should support multiple instances of the
controller, possibly using the driver model.  That code will configure each
gpio_chip and issue gpiochip_add().  Removing a GPIO controller should be
rare; use gpiochip_remove() when it is unavoidable.

Most often a gpio_chip is part of an instance-specific structure with state
not exposed by the GPIO interfaces, such as addressing, power management,
and more.  Chips such as codecs will have complex non-GPIO state.

Any debugfs dump method should normally ignore signals which haven't been
requested as GPIOs.  They can use gpiochip_is_requested(), which returns
either NULL or the label associated with that GPIO when it was requested.


Platform Support
----------------
To support this framework, a platform's Kconfig will "select" either
ARCH_REQUIRE_GPIOLIB or ARCH_WANT_OPTIONAL_GPIOLIB
and arrange that its <asm/gpio.h> includes <asm-generic/gpio.h> and defines
three functions: gpio_get_value(), gpio_set_value(), and gpio_cansleep().

It may also provide a custom value for ARCH_NR_GPIOS, so that it better
reflects the number of GPIOs in actual use on that platform, without
wasting static table space.  (It should count both built-in/SoC GPIOs and
also ones on GPIO expanders.

ARCH_REQUIRE_GPIOLIB means that the gpiolib code will always get compiled
into the kernel on that architecture.

ARCH_WANT_OPTIONAL_GPIOLIB means the gpiolib code defaults to off and the user
can enable it and build it into the kernel optionally.

If neither of these options are selected, the platform does not support
GPIOs through GPIO-lib and the code cannot be enabled by the user.

Trivial implementations of those functions can directly use framework
code, which always dispatches through the gpio_chip:

  #define gpio_get_value	__gpio_get_value
  #define gpio_set_value	__gpio_set_value
  #define gpio_cansleep		__gpio_cansleep

Fancier implementations could instead define those as inline functions with
logic optimizing access to specific SOC-based GPIOs.  For example, if the
referenced GPIO is the constant "12", getting or setting its value could
cost as little as two or three instructions, never sleeping.  When such an
optimization is not possible those calls must delegate to the framework
code, costing at least a few dozen instructions.  For bitbanged I/O, such
instruction savings can be significant.

For SOCs, platform-specific code defines and registers gpio_chip instances
for each bank of on-chip GPIOs.  Those GPIOs should be numbered/labeled to
match chip vendor documentation, and directly match board schematics.  They
may well start at zero and go up to a platform-specific limit.  Such GPIOs
are normally integrated into platform initialization to make them always be
available, from arch_initcall() or earlier; they can often serve as IRQs.


Board Support
-------------
For external GPIO controllers -- such as I2C or SPI expanders, ASICs, multi
function devices, FPGAs or CPLDs -- most often board-specific code handles
registering controller devices and ensures that their drivers know what GPIO
numbers to use with gpiochip_add().  Their numbers often start right after
platform-specific GPIOs.

For example, board setup code could create structures identifying the range
of GPIOs that chip will expose, and passes them to each GPIO expander chip
using platform_data.  Then the chip driver's probe() routine could pass that
data to gpiochip_add().

Initialization order can be important.  For example, when a device relies on
an I2C-based GPIO, its probe() routine should only be called after that GPIO
becomes available.  That may mean the device should not be registered until
calls for that GPIO can work.  One way to address such dependencies is for
such gpio_chip controllers to provide setup() and teardown() callbacks to
board specific code; those board specific callbacks would register devices
once all the necessary resources are available, and remove them later when
the GPIO controller device becomes unavailable.


Sysfs Interface for Userspace (OPTIONAL)
========================================
Platforms which use the "gpiolib" implementors framework may choose to
configure a sysfs user interface to GPIOs.  This is different from the
debugfs interface, since it provides control over GPIO direction and
value instead of just showing a gpio state summary.  Plus, it could be
present on production systems without debugging support.

Given appropriate hardware documentation for the system, userspace could
know for example that GPIO #23 controls the write protect line used to
protect boot loader segments in flash memory.  System upgrade procedures
may need to temporarily remove that protection, first importing a GPIO,
then changing its output state, then updating the code before re-enabling
the write protection.  In normal use, GPIO #23 would never be touched,
and the kernel would have no need to know about it.

Again depending on appropriate hardware documentation, on some systems
userspace GPIO can be used to determine system configuration data that
standard kernels won't know about.  And for some tasks, simple userspace
GPIO drivers could be all that the system really needs.

Note that standard kernel drivers exist for common "LEDs and Buttons"
GPIO tasks:  "leds-gpio" and "gpio_keys", respectively.  Use those
instead of talking directly to the GPIOs; they integrate with kernel
frameworks better than your userspace code could.


Paths in Sysfs
--------------
There are three kinds of entry in /sys/class/gpio:

   -	Control interfaces used to get userspace control over GPIOs;

   -	GPIOs themselves; and

   -	GPIO controllers ("gpio_chip" instances).

That's in addition to standard files including the "device" symlink.

The control interfaces are write-only:

    /sys/class/gpio/

    	"export" ... Userspace may ask the kernel to export control of
		a GPIO to userspace by writing its number to this file.

		Example:  "echo 19 > export" will create a "gpio19" node
		for GPIO #19, if that's not requested by kernel code.

    	"unexport" ... Reverses the effect of exporting to userspace.

		Example:  "echo 19 > unexport" will remove a "gpio19"
		node exported using the "export" file.

GPIO signals have paths like /sys/class/gpio/gpio42/ (for GPIO #42)
and have the following read/write attributes:

    /sys/class/gpio/gpioN/

	"direction" ... reads as either "in" or "out".  This value may
		normally be written.  Writing as "out" defaults to
		initializing the value as low.  To ensure glitch free
		operation, values "low" and "high" may be written to
		configure the GPIO as an output with that initial value.

		Note that this attribute *will not exist* if the kernel
		doesn't support changing the direction of a GPIO, or
		it was exported by kernel code that didn't explicitly
		allow userspace to reconfigure this GPIO's direction.

	"value" ... reads as either 0 (low) or 1 (high).  If the GPIO
		is configured as an output, this value may be written;
		any nonzero value is treated as high.

		If the pin can be configured as interrupt-generating interrupt
		and if it has been configured to generate interrupts (see the
		description of "edge"), you can poll(2) on that file and
		poll(2) will return whenever the interrupt was triggered. If
		you use poll(2), set the events POLLPRI and POLLERR. If you
		use select(2), set the file descriptor in exceptfds. After
		poll(2) returns, either lseek(2) to the beginning of the sysfs
		file and read the new value or close the file and re-open it
		to read the value.

	"edge" ... reads as either "none", "rising", "falling", or
		"both". Write these strings to select the signal edge(s)
		that will make poll(2) on the "value" file return.

		This file exists only if the pin can be configured as an
		interrupt generating input pin.

	"active_low" ... reads as either 0 (false) or 1 (true).  Write
		any nonzero value to invert the value attribute both
		for reading and writing.  Existing and subsequent
		poll(2) support configuration via the edge attribute
		for "rising" and "falling" edges will follow this
		setting.

GPIO controllers have paths like /sys/class/gpio/gpiochip42/ (for the
controller implementing GPIOs starting at #42) and have the following
read-only attributes:

    /sys/class/gpio/gpiochipN/

    	"base" ... same as N, the first GPIO managed by this chip

    	"label" ... provided for diagnostics (not always unique)

    	"ngpio" ... how many GPIOs this manges (N to N + ngpio - 1)

Board documentation should in most cases cover what GPIOs are used for
what purposes.  However, those numbers are not always stable; GPIOs on
a daughtercard might be different depending on the base board being used,
or other cards in the stack.  In such cases, you may need to use the
gpiochip nodes (possibly in conjunction with schematics) to determine
the correct GPIO number to use for a given signal.


Exporting from Kernel code
--------------------------
Kernel code can explicitly manage exports of GPIOs which have already been
requested using gpio_request():

	/* export the GPIO to userspace */
	int gpio_export(unsigned gpio, bool direction_may_change);

	/* reverse gpio_export() */
	void gpio_unexport();

	/* create a sysfs link to an exported GPIO node */
	int gpio_export_link(struct device *dev, const char *name,
		unsigned gpio)

	/* change the polarity of a GPIO node in sysfs */
	int gpio_sysfs_set_active_low(unsigned gpio, int value);

After a kernel driver requests a GPIO, it may only be made available in
the sysfs interface by gpio_export().  The driver can control whether the
signal direction may change.  This helps drivers prevent userspace code
from accidentally clobbering important system state.

This explicit exporting can help with debugging (by making some kinds
of experiments easier), or can provide an always-there interface that's
suitable for documenting as part of a board support package.

After the GPIO has been exported, gpio_export_link() allows creating
symlinks from elsewhere in sysfs to the GPIO sysfs node.  Drivers can
use this to provide the interface under their own device in sysfs with
a descriptive name.

Drivers can use gpio_sysfs_set_active_low() to hide GPIO line polarity
differences between boards from user space.  This only affects the
sysfs interface.  Polarity change can be done both before and after
gpio_export(), and previously enabled poll(2) support for either
rising or falling edge will be reconfigured to follow this setting.
Notes on the change from 16-bit UIDs to 32-bit UIDs:

- kernel code MUST take into account __kernel_uid_t and __kernel_uid32_t
  when communicating between user and kernel space in an ioctl or data
  structure.

- kernel code should use uid_t and gid_t in kernel-private structures and
  code.

What's left to be done for 32-bit UIDs on all Linux architectures:

- Disk quotas have an interesting limitation that is not related to the
  maximum UID/GID. They are limited by the maximum file size on the
  underlying filesystem, because quota records are written at offsets
  corresponding to the UID in question.
  Further investigation is needed to see if the quota system can cope
  properly with huge UIDs. If it can deal with 64-bit file offsets on all 
  architectures, this should not be a problem.

- Decide whether or not to keep backwards compatibility with the system
  accounting file, or if we should break it as the comments suggest
  (currently, the old 16-bit UID and GID are still written to disk, and
  part of the former pad space is used to store separate 32-bit UID and
  GID)

- Need to validate that OS emulation calls the 16-bit UID
  compatibility syscalls, if the OS being emulated used 16-bit UIDs, or
  uses the 32-bit UID system calls properly otherwise.

  This affects at least:
	iBCS on Intel

	sparc32 emulation on sparc64
	(need to support whatever new 32-bit UID system calls are added to
	sparc32)

- Validate that all filesystems behave properly.

  At present, 32-bit UIDs _should_ work for:
	ext2
	ufs
	isofs
	nfs
	coda
	udf

  Ioctl() fixups have been made for:
	ncpfs
	smbfs

  Filesystems with simple fixups to prevent 16-bit UID wraparound:
	minix
	sysv
	qnx4

  Other filesystems have not been checked yet.

- The ncpfs and smpfs filesystems cannot presently use 32-bit UIDs in
  all ioctl()s. Some new ioctl()s have been added with 32-bit UIDs, but
  more are needed. (as well as new user<->kernel data structures)

- The ELF core dump format only supports 16-bit UIDs on arm, i386, m68k,
  sh, and sparc32. Fixing this is probably not that important, but would
  require adding a new ELF section.

- The ioctl()s used to control the in-kernel NFS server only support
  16-bit UIDs on arm, i386, m68k, sh, and sparc32.

- make sure that the UID mapping feature of AX25 networking works properly
  (it should be safe because it's always used a 32-bit integer to
  communicate between user and kernel)


Chris Wing
wingc@umich.edu

last updated: January 11, 2000
HOWTO do Linux kernel development
---------------------------------

This is the be-all, end-all document on this topic.  It contains
instructions on how to become a Linux kernel developer and how to learn
to work with the Linux kernel development community.  It tries to not
contain anything related to the technical aspects of kernel programming,
but will help point you in the right direction for that.

If anything in this document becomes out of date, please send in patches
to the maintainer of this file, who is listed at the bottom of the
document.


Introduction
------------

So, you want to learn how to become a Linux kernel developer?  Or you
have been told by your manager, "Go write a Linux driver for this
device."  This document's goal is to teach you everything you need to
know to achieve this by describing the process you need to go through,
and hints on how to work with the community.  It will also try to
explain some of the reasons why the community works like it does.

The kernel is written mostly in C, with some architecture-dependent
parts written in assembly. A good understanding of C is required for
kernel development.  Assembly (any architecture) is not required unless
you plan to do low-level development for that architecture.  Though they
are not a good substitute for a solid C education and/or years of
experience, the following books are good for, if anything, reference:
 - "The C Programming Language" by Kernighan and Ritchie [Prentice Hall]
 - "Practical C Programming" by Steve Oualline [O'Reilly]
 - "C:  A Reference Manual" by Harbison and Steele [Prentice Hall]

The kernel is written using GNU C and the GNU toolchain.  While it
adheres to the ISO C89 standard, it uses a number of extensions that are
not featured in the standard.  The kernel is a freestanding C
environment, with no reliance on the standard C library, so some
portions of the C standard are not supported.  Arbitrary long long
divisions and floating point are not allowed.  It can sometimes be
difficult to understand the assumptions the kernel has on the toolchain
and the extensions that it uses, and unfortunately there is no
definitive reference for them.  Please check the gcc info pages (`info
gcc`) for some information on them.

Please remember that you are trying to learn how to work with the
existing development community.  It is a diverse group of people, with
high standards for coding, style and procedure.  These standards have
been created over time based on what they have found to work best for
such a large and geographically dispersed team.  Try to learn as much as
possible about these standards ahead of time, as they are well
documented; do not expect people to adapt to you or your company's way
of doing things.


Legal Issues
------------

The Linux kernel source code is released under the GPL.  Please see the
file, COPYING, in the main directory of the source tree, for details on
the license.  If you have further questions about the license, please
contact a lawyer, and do not ask on the Linux kernel mailing list.  The
people on the mailing lists are not lawyers, and you should not rely on
their statements on legal matters.

For common questions and answers about the GPL, please see:
	http://www.gnu.org/licenses/gpl-faq.html


Documentation
------------

The Linux kernel source tree has a large range of documents that are
invaluable for learning how to interact with the kernel community.  When
new features are added to the kernel, it is recommended that new
documentation files are also added which explain how to use the feature.
When a kernel change causes the interface that the kernel exposes to
userspace to change, it is recommended that you send the information or
a patch to the manual pages explaining the change to the manual pages
maintainer at mtk.manpages@gmail.com, and CC the list
linux-api@vger.kernel.org.

Here is a list of files that are in the kernel source tree that are
required reading:
  README
    This file gives a short background on the Linux kernel and describes
    what is necessary to do to configure and build the kernel.  People
    who are new to the kernel should start here.

  Documentation/Changes
    This file gives a list of the minimum levels of various software
    packages that are necessary to build and run the kernel
    successfully.

  Documentation/CodingStyle
    This describes the Linux kernel coding style, and some of the
    rationale behind it. All new code is expected to follow the
    guidelines in this document. Most maintainers will only accept
    patches if these rules are followed, and many people will only
    review code if it is in the proper style.

  Documentation/SubmittingPatches
  Documentation/SubmittingDrivers
    These files describe in explicit detail how to successfully create
    and send a patch, including (but not limited to):
       - Email contents
       - Email format
       - Who to send it to
    Following these rules will not guarantee success (as all patches are
    subject to scrutiny for content and style), but not following them
    will almost always prevent it.

    Other excellent descriptions of how to create patches properly are:
	"The Perfect Patch"
		http://userweb.kernel.org/~akpm/stuff/tpp.txt
	"Linux kernel patch submission format"
		http://linux.yyz.us/patch-format.html

  Documentation/stable_api_nonsense.txt
    This file describes the rationale behind the conscious decision to
    not have a stable API within the kernel, including things like:
      - Subsystem shim-layers (for compatibility?)
      - Driver portability between Operating Systems.
      - Mitigating rapid change within the kernel source tree (or
	preventing rapid change)
    This document is crucial for understanding the Linux development
    philosophy and is very important for people moving to Linux from
    development on other Operating Systems.

  Documentation/SecurityBugs
    If you feel you have found a security problem in the Linux kernel,
    please follow the steps in this document to help notify the kernel
    developers, and help solve the issue.

  Documentation/ManagementStyle
    This document describes how Linux kernel maintainers operate and the
    shared ethos behind their methodologies.  This is important reading
    for anyone new to kernel development (or anyone simply curious about
    it), as it resolves a lot of common misconceptions and confusion
    about the unique behavior of kernel maintainers.

  Documentation/stable_kernel_rules.txt
    This file describes the rules on how the stable kernel releases
    happen, and what to do if you want to get a change into one of these
    releases.

  Documentation/kernel-docs.txt
    A list of external documentation that pertains to kernel
    development.  Please consult this list if you do not find what you
    are looking for within the in-kernel documentation.

  Documentation/applying-patches.txt
    A good introduction describing exactly what a patch is and how to
    apply it to the different development branches of the kernel.

The kernel also has a large number of documents that can be
automatically generated from the source code itself.  This includes a
full description of the in-kernel API, and rules on how to handle
locking properly.  The documents will be created in the
Documentation/DocBook/ directory and can be generated as PDF,
Postscript, HTML, and man pages by running:
	make pdfdocs
	make psdocs
	make htmldocs
	make mandocs
respectively from the main kernel source directory.


Becoming A Kernel Developer
---------------------------

If you do not know anything about Linux kernel development, you should
look at the Linux KernelNewbies project:
	http://kernelnewbies.org
It consists of a helpful mailing list where you can ask almost any type
of basic kernel development question (make sure to search the archives
first, before asking something that has already been answered in the
past.)  It also has an IRC channel that you can use to ask questions in
real-time, and a lot of helpful documentation that is useful for
learning about Linux kernel development.

The website has basic information about code organization, subsystems,
and current projects (both in-tree and out-of-tree). It also describes
some basic logistical information, like how to compile a kernel and
apply a patch.

If you do not know where you want to start, but you want to look for
some task to start doing to join into the kernel development community,
go to the Linux Kernel Janitor's project:
	http://kernelnewbies.org/KernelJanitors	
It is a great place to start.  It describes a list of relatively simple
problems that need to be cleaned up and fixed within the Linux kernel
source tree.  Working with the developers in charge of this project, you
will learn the basics of getting your patch into the Linux kernel tree,
and possibly be pointed in the direction of what to go work on next, if
you do not already have an idea.

If you already have a chunk of code that you want to put into the kernel
tree, but need some help getting it in the proper form, the
kernel-mentors project was created to help you out with this.  It is a
mailing list, and can be found at:
	http://selenic.com/mailman/listinfo/kernel-mentors

Before making any actual modifications to the Linux kernel code, it is
imperative to understand how the code in question works.  For this
purpose, nothing is better than reading through it directly (most tricky
bits are commented well), perhaps even with the help of specialized
tools.  One such tool that is particularly recommended is the Linux
Cross-Reference project, which is able to present source code in a
self-referential, indexed webpage format. An excellent up-to-date
repository of the kernel code may be found at:
	http://lxr.linux.no/+trees


The development process
-----------------------

Linux kernel development process currently consists of a few different
main kernel "branches" and lots of different subsystem-specific kernel
branches.  These different branches are:
  - main 2.6.x kernel tree
  - 2.6.x.y -stable kernel tree
  - 2.6.x -git kernel patches
  - subsystem specific kernel trees and patches
  - the 2.6.x -next kernel tree for integration tests

2.6.x kernel tree
-----------------
2.6.x kernels are maintained by Linus Torvalds, and can be found on
kernel.org in the pub/linux/kernel/v2.6/ directory.  Its development
process is as follows:
  - As soon as a new kernel is released a two weeks window is open,
    during this period of time maintainers can submit big diffs to
    Linus, usually the patches that have already been included in the
    -next kernel for a few weeks.  The preferred way to submit big changes
    is using git (the kernel's source management tool, more information
    can be found at http://git-scm.com/) but plain patches are also just
    fine.
  - After two weeks a -rc1 kernel is released it is now possible to push
    only patches that do not include new features that could affect the
    stability of the whole kernel.  Please note that a whole new driver
    (or filesystem) might be accepted after -rc1 because there is no
    risk of causing regressions with such a change as long as the change
    is self-contained and does not affect areas outside of the code that
    is being added.  git can be used to send patches to Linus after -rc1
    is released, but the patches need to also be sent to a public
    mailing list for review.
  - A new -rc is released whenever Linus deems the current git tree to
    be in a reasonably sane state adequate for testing.  The goal is to
    release a new -rc kernel every week.
  - Process continues until the kernel is considered "ready", the
    process should last around 6 weeks.
  - Known regressions in each release are periodically posted to the 
    linux-kernel mailing list.  The goal is to reduce the length of 
    that list to zero before declaring the kernel to be "ready," but, in
    the real world, a small number of regressions often remain at 
    release time.

It is worth mentioning what Andrew Morton wrote on the linux-kernel
mailing list about kernel releases:
	"Nobody knows when a kernel will be released, because it's
	released according to perceived bug status, not according to a
	preconceived timeline."

2.6.x.y -stable kernel tree
---------------------------
Kernels with 4-part versions are -stable kernels. They contain
relatively small and critical fixes for security problems or significant
regressions discovered in a given 2.6.x kernel.

This is the recommended branch for users who want the most recent stable
kernel and are not interested in helping test development/experimental
versions.

If no 2.6.x.y kernel is available, then the highest numbered 2.6.x
kernel is the current stable kernel.

2.6.x.y are maintained by the "stable" team <stable@kernel.org>, and are
released as needs dictate.  The normal release period is approximately 
two weeks, but it can be longer if there are no pressing problems.  A
security-related problem, instead, can cause a release to happen almost
instantly.

The file Documentation/stable_kernel_rules.txt in the kernel tree
documents what kinds of changes are acceptable for the -stable tree, and
how the release process works.

2.6.x -git patches
------------------
These are daily snapshots of Linus' kernel tree which are managed in a
git repository (hence the name.) These patches are usually released
daily and represent the current state of Linus' tree.  They are more
experimental than -rc kernels since they are generated automatically
without even a cursory glance to see if they are sane.

Subsystem Specific kernel trees and patches
-------------------------------------------
The maintainers of the various kernel subsystems --- and also many
kernel subsystem developers --- expose their current state of
development in source repositories.  That way, others can see what is
happening in the different areas of the kernel.  In areas where
development is rapid, a developer may be asked to base his submissions
onto such a subsystem kernel tree so that conflicts between the
submission and other already ongoing work are avoided.

Most of these repositories are git trees, but there are also other SCMs
in use, or patch queues being published as quilt series.  Addresses of
these subsystem repositories are listed in the MAINTAINERS file.  Many
of them can be browsed at http://git.kernel.org/.

Before a proposed patch is committed to such a subsystem tree, it is
subject to review which primarily happens on mailing lists (see the
respective section below).  For several kernel subsystems, this review
process is tracked with the tool patchwork.  Patchwork offers a web
interface which shows patch postings, any comments on a patch or
revisions to it, and maintainers can mark patches as under review,
accepted, or rejected.  Most of these patchwork sites are listed at
http://patchwork.kernel.org/.

2.6.x -next kernel tree for integration tests
---------------------------------------------
Before updates from subsystem trees are merged into the mainline 2.6.x
tree, they need to be integration-tested.  For this purpose, a special
testing repository exists into which virtually all subsystem trees are
pulled on an almost daily basis:
	http://git.kernel.org/?p=linux/kernel/git/sfr/linux-next.git
	http://linux.f-seidel.de/linux-next/pmwiki/

This way, the -next kernel gives a summary outlook onto what will be
expected to go into the mainline kernel at the next merge period.
Adventurous testers are very welcome to runtime-test the -next kernel.


Bug Reporting
-------------

bugzilla.kernel.org is where the Linux kernel developers track kernel
bugs.  Users are encouraged to report all bugs that they find in this
tool.  For details on how to use the kernel bugzilla, please see:
	http://bugzilla.kernel.org/page.cgi?id=faq.html

The file REPORTING-BUGS in the main kernel source directory has a good
template for how to report a possible kernel bug, and details what kind
of information is needed by the kernel developers to help track down the
problem.


Managing bug reports
--------------------

One of the best ways to put into practice your hacking skills is by fixing
bugs reported by other people. Not only you will help to make the kernel
more stable, you'll learn to fix real world problems and you will improve
your skills, and other developers will be aware of your presence. Fixing
bugs is one of the best ways to get merits among other developers, because
not many people like wasting time fixing other people's bugs.

To work in the already reported bug reports, go to http://bugzilla.kernel.org.
If you want to be advised of the future bug reports, you can subscribe to the
bugme-new mailing list (only new bug reports are mailed here) or to the
bugme-janitor mailing list (every change in the bugzilla is mailed here)

	http://lists.linux-foundation.org/mailman/listinfo/bugme-new
	http://lists.linux-foundation.org/mailman/listinfo/bugme-janitors



Mailing lists
-------------

As some of the above documents describe, the majority of the core kernel
developers participate on the Linux Kernel Mailing list.  Details on how
to subscribe and unsubscribe from the list can be found at:
	http://vger.kernel.org/vger-lists.html#linux-kernel
There are archives of the mailing list on the web in many different
places.  Use a search engine to find these archives.  For example:
	http://dir.gmane.org/gmane.linux.kernel
It is highly recommended that you search the archives about the topic
you want to bring up, before you post it to the list. A lot of things
already discussed in detail are only recorded at the mailing list
archives.

Most of the individual kernel subsystems also have their own separate
mailing list where they do their development efforts.  See the
MAINTAINERS file for a list of what these lists are for the different
groups.

Many of the lists are hosted on kernel.org. Information on them can be
found at:
	http://vger.kernel.org/vger-lists.html

Please remember to follow good behavioral habits when using the lists.
Though a bit cheesy, the following URL has some simple guidelines for
interacting with the list (or any list):
	http://www.albion.com/netiquette/

If multiple people respond to your mail, the CC: list of recipients may
get pretty large. Don't remove anybody from the CC: list without a good
reason, or don't reply only to the list address. Get used to receiving the
mail twice, one from the sender and the one from the list, and don't try
to tune that by adding fancy mail-headers, people will not like it.

Remember to keep the context and the attribution of your replies intact,
keep the "John Kernelhacker wrote ...:" lines at the top of your reply, and
add your statements between the individual quoted sections instead of
writing at the top of the mail.

If you add patches to your mail, make sure they are plain readable text
as stated in Documentation/SubmittingPatches. Kernel developers don't
want to deal with attachments or compressed patches; they may want
to comment on individual lines of your patch, which works only that way.
Make sure you use a mail program that does not mangle spaces and tab
characters. A good first test is to send the mail to yourself and try
to apply your own patch by yourself. If that doesn't work, get your
mail program fixed or change it until it works.

Above all, please remember to show respect to other subscribers.


Working with the community
--------------------------

The goal of the kernel community is to provide the best possible kernel
there is.  When you submit a patch for acceptance, it will be reviewed
on its technical merits and those alone.  So, what should you be
expecting?
  - criticism
  - comments
  - requests for change
  - requests for justification
  - silence

Remember, this is part of getting your patch into the kernel.  You have
to be able to take criticism and comments about your patches, evaluate
them at a technical level and either rework your patches or provide
clear and concise reasoning as to why those changes should not be made.
If there are no responses to your posting, wait a few days and try
again, sometimes things get lost in the huge volume.

What should you not do?
  - expect your patch to be accepted without question
  - become defensive
  - ignore comments
  - resubmit the patch without making any of the requested changes

In a community that is looking for the best technical solution possible,
there will always be differing opinions on how beneficial a patch is.
You have to be cooperative, and willing to adapt your idea to fit within
the kernel.  Or at least be willing to prove your idea is worth it.
Remember, being wrong is acceptable as long as you are willing to work
toward a solution that is right.

It is normal that the answers to your first patch might simply be a list
of a dozen things you should correct.  This does _not_ imply that your
patch will not be accepted, and it is _not_ meant against you
personally.  Simply correct all issues raised against your patch and
resend it.


Differences between the kernel community and corporate structures
-----------------------------------------------------------------

The kernel community works differently than most traditional corporate
development environments.  Here are a list of things that you can try to
do to try to avoid problems:
  Good things to say regarding your proposed changes:
    - "This solves multiple problems."
    - "This deletes 2000 lines of code."
    - "Here is a patch that explains what I am trying to describe."
    - "I tested it on 5 different architectures..."
    - "Here is a series of small patches that..."
    - "This increases performance on typical machines..."

  Bad things you should avoid saying:
    - "We did it this way in AIX/ptx/Solaris, so therefore it must be
      good..."
    - "I've being doing this for 20 years, so..."
    - "This is required for my company to make money"
    - "This is for our Enterprise product line."
    - "Here is my 1000 page design document that describes my idea"
    - "I've been working on this for 6 months..."
    - "Here's a 5000 line patch that..."
    - "I rewrote all of the current mess, and here it is..."
    - "I have a deadline, and this patch needs to be applied now."

Another way the kernel community is different than most traditional
software engineering work environments is the faceless nature of
interaction.  One benefit of using email and irc as the primary forms of
communication is the lack of discrimination based on gender or race.
The Linux kernel work environment is accepting of women and minorities
because all you are is an email address.  The international aspect also
helps to level the playing field because you can't guess gender based on
a person's name. A man may be named Andrea and a woman may be named Pat.
Most women who have worked in the Linux kernel and have expressed an
opinion have had positive experiences.

The language barrier can cause problems for some people who are not
comfortable with English.  A good grasp of the language can be needed in
order to get ideas across properly on mailing lists, so it is
recommended that you check your emails to make sure they make sense in
English before sending them.


Break up your changes
---------------------

The Linux kernel community does not gladly accept large chunks of code
dropped on it all at once.  The changes need to be properly introduced,
discussed, and broken up into tiny, individual portions.  This is almost
the exact opposite of what companies are used to doing.  Your proposal
should also be introduced very early in the development process, so that
you can receive feedback on what you are doing.  It also lets the
community feel that you are working with them, and not simply using them
as a dumping ground for your feature.  However, don't send 50 emails at
one time to a mailing list, your patch series should be smaller than
that almost all of the time.

The reasons for breaking things up are the following:

1) Small patches increase the likelihood that your patches will be
   applied, since they don't take much time or effort to verify for
   correctness.  A 5 line patch can be applied by a maintainer with
   barely a second glance. However, a 500 line patch may take hours to
   review for correctness (the time it takes is exponentially
   proportional to the size of the patch, or something).

   Small patches also make it very easy to debug when something goes
   wrong.  It's much easier to back out patches one by one than it is
   to dissect a very large patch after it's been applied (and broken
   something).

2) It's important not only to send small patches, but also to rewrite
   and simplify (or simply re-order) patches before submitting them.

Here is an analogy from kernel developer Al Viro:
	"Think of a teacher grading homework from a math student.  The
	teacher does not want to see the student's trials and errors
	before they came up with the solution. They want to see the
	cleanest, most elegant answer.  A good student knows this, and
	would never submit her intermediate work before the final
	solution."

	The same is true of kernel development. The maintainers and
	reviewers do not want to see the thought process behind the
	solution to the problem one is solving. They want to see a
	simple and elegant solution."

It may be challenging to keep the balance between presenting an elegant
solution and working together with the community and discussing your
unfinished work. Therefore it is good to get early in the process to
get feedback to improve your work, but also keep your changes in small
chunks that they may get already accepted, even when your whole task is
not ready for inclusion now.

Also realize that it is not acceptable to send patches for inclusion
that are unfinished and will be "fixed up later."


Justify your change
-------------------

Along with breaking up your patches, it is very important for you to let
the Linux community know why they should add this change.  New features
must be justified as being needed and useful.


Document your change
--------------------

When sending in your patches, pay special attention to what you say in
the text in your email.  This information will become the ChangeLog
information for the patch, and will be preserved for everyone to see for
all time.  It should describe the patch completely, containing:
  - why the change is necessary
  - the overall design approach in the patch
  - implementation details
  - testing results

For more details on what this should all look like, please see the
ChangeLog section of the document:
  "The Perfect Patch"
      http://userweb.kernel.org/~akpm/stuff/tpp.txt




All of these things are sometimes very hard to do. It can take years to
perfect these practices (if at all). It's a continuous process of
improvement that requires a lot of patience and determination. But
don't give up, it's possible. Many have done it before, and each had to
start exactly where you are now.




----------
Thanks to Paolo Ciarrocchi who allowed the "Development Process"
(http://lwn.net/Articles/94386/) section
to be based on text he had written, and to Randy Dunlap and Gerrit
Huizenga for some of the list of things you should and should not say.
Also thanks to Pat Mochel, Hanna Linder, Randy Dunlap, Kay Sievers,
Vojtech Pavlik, Jan Kara, Josh Boyer, Kees Cook, Andrew Morton, Andi
Kleen, Vadim Lobanov, Jesper Juhl, Adrian Bunk, Keri Harris, Frans Pop,
David A. Wheeler, Junio Hamano, Michael Kerrisk, and Alex Shepard for
their review, comments, and contributions.  Without their help, this
document would not have been possible.



Maintainer: Greg Kroah-Hartman <greg@kroah.com>
Introduction:

	The hw_random framework is software that makes use of a
	special hardware feature on your CPU or motherboard,
	a Random Number Generator (RNG).  The software has two parts:
	a core providing the /dev/hw_random character device and its
	sysfs support, plus a hardware-specific driver that plugs
	into that core.

	To make the most effective use of these mechanisms, you
	should download the support software as well.  Download the
	latest version of the "rng-tools" package from the
	hw_random driver's official Web site:

		http://sourceforge.net/projects/gkernel/

	Those tools use /dev/hw_random to fill the kernel entropy pool,
	which is used internally and exported by the /dev/urandom and
	/dev/random special files.

Theory of operation:

	CHARACTER DEVICE.  Using the standard open()
	and read() system calls, you can read random data from
	the hardware RNG device.  This data is NOT CHECKED by any
	fitness tests, and could potentially be bogus (if the
	hardware is faulty or has been tampered with).  Data is only
	output if the hardware "has-data" flag is set, but nevertheless
	a security-conscious person would run fitness tests on the
	data before assuming it is truly random.

	The rng-tools package uses such tests in "rngd", and lets you
	run them by hand with a "rngtest" utility.

	/dev/hw_random is char device major 10, minor 183.

	CLASS DEVICE.  There is a /sys/class/misc/hw_random node with
	two unique attributes, "rng_available" and "rng_current".  The
	"rng_available" attribute lists the hardware-specific drivers
	available, while "rng_current" lists the one which is currently
	connected to /dev/hw_random.  If your system has more than one
	RNG available, you may change the one used by writing a name from
	the list in "rng_available" into "rng_current".

==========================================================================

	Hardware driver for Intel/AMD/VIA Random Number Generators (RNG)
	Copyright 2000,2001 Jeff Garzik <jgarzik@pobox.com>
	Copyright 2000,2001 Philipp Rumpf <prumpf@mandrakesoft.com>


About the Intel RNG hardware, from the firmware hub datasheet:

	The Firmware Hub integrates a Random Number Generator (RNG)
	using thermal noise generated from inherently random quantum
	mechanical properties of silicon. When not generating new random
	bits the RNG circuitry will enter a low power state. Intel will
	provide a binary software driver to give third party software
	access to our RNG for use as a security feature. At this time,
	the RNG is only to be used with a system in an OS-present state.

Intel RNG Driver notes:

	* FIXME: support poll(2)

	NOTE: request_mem_region was removed, for two reasons:
	1) Only one RNG is supported by this driver, 2) The location
	used by the RNG is a fixed location in MMIO-addressable memory,
	3) users with properly working BIOS e820 handling will always
	have the region in which the RNG is located reserved, so
	request_mem_region calls always fail for proper setups.
	However, for people who use mem=XX, BIOS e820 information is
	-not- in /proc/iomem, and request_mem_region(RNG_ADDR) can
	succeed.

Driver details:

	Based on:
	Intel 82802AB/82802AC Firmware Hub (FWH) Datasheet
		May 1999 Order Number: 290658-002 R

	Intel 82802 Firmware Hub: Random Number Generator
	Programmer's Reference Manual
		December 1999 Order Number: 298029-001 R

	Intel 82802 Firmware HUB Random Number Generator Driver
	Copyright (c) 2000 Matt Sottek <msottek@quiknet.com>

	Special thanks to Matt Sottek.  I did the "guts", he
	did the "brains" and all the testing.
Hardware Spinlock Framework

1. Introduction

Hardware spinlock modules provide hardware assistance for synchronization
and mutual exclusion between heterogeneous processors and those not operating
under a single, shared operating system.

For example, OMAP4 has dual Cortex-A9, dual Cortex-M3 and a C64x+ DSP,
each of which is running a different Operating System (the master, A9,
is usually running Linux and the slave processors, the M3 and the DSP,
are running some flavor of RTOS).

A generic hwspinlock framework allows platform-independent drivers to use
the hwspinlock device in order to access data structures that are shared
between remote processors, that otherwise have no alternative mechanism
to accomplish synchronization and mutual exclusion operations.

This is necessary, for example, for Inter-processor communications:
on OMAP4, cpu-intensive multimedia tasks are offloaded by the host to the
remote M3 and/or C64x+ slave processors (by an IPC subsystem called Syslink).

To achieve fast message-based communications, a minimal kernel support
is needed to deliver messages arriving from a remote processor to the
appropriate user process.

This communication is based on simple data structures that is shared between
the remote processors, and access to it is synchronized using the hwspinlock
module (remote processor directly places new messages in this shared data
structure).

A common hwspinlock interface makes it possible to have generic, platform-
independent, drivers.

2. User API

  struct hwspinlock *hwspin_lock_request(void);
   - dynamically assign an hwspinlock and return its address, or NULL
     in case an unused hwspinlock isn't available. Users of this
     API will usually want to communicate the lock's id to the remote core
     before it can be used to achieve synchronization.
     Can be called from an atomic context (this function will not sleep) but
     not from within interrupt context.

  struct hwspinlock *hwspin_lock_request_specific(unsigned int id);
   - assign a specific hwspinlock id and return its address, or NULL
     if that hwspinlock is already in use. Usually board code will
     be calling this function in order to reserve specific hwspinlock
     ids for predefined purposes.
     Can be called from an atomic context (this function will not sleep) but
     not from within interrupt context.

  int hwspin_lock_free(struct hwspinlock *hwlock);
   - free a previously-assigned hwspinlock; returns 0 on success, or an
     appropriate error code on failure (e.g. -EINVAL if the hwspinlock
     is already free).
     Can be called from an atomic context (this function will not sleep) but
     not from within interrupt context.

  int hwspin_lock_timeout(struct hwspinlock *hwlock, unsigned int timeout);
   - lock a previously-assigned hwspinlock with a timeout limit (specified in
     msecs). If the hwspinlock is already taken, the function will busy loop
     waiting for it to be released, but give up when the timeout elapses.
     Upon a successful return from this function, preemption is disabled so
     the caller must not sleep, and is advised to release the hwspinlock as
     soon as possible, in order to minimize remote cores polling on the
     hardware interconnect.
     Returns 0 when successful and an appropriate error code otherwise (most
     notably -ETIMEDOUT if the hwspinlock is still busy after timeout msecs).
     The function will never sleep.

  int hwspin_lock_timeout_irq(struct hwspinlock *hwlock, unsigned int timeout);
   - lock a previously-assigned hwspinlock with a timeout limit (specified in
     msecs). If the hwspinlock is already taken, the function will busy loop
     waiting for it to be released, but give up when the timeout elapses.
     Upon a successful return from this function, preemption and the local
     interrupts are disabled, so the caller must not sleep, and is advised to
     release the hwspinlock as soon as possible.
     Returns 0 when successful and an appropriate error code otherwise (most
     notably -ETIMEDOUT if the hwspinlock is still busy after timeout msecs).
     The function will never sleep.

  int hwspin_lock_timeout_irqsave(struct hwspinlock *hwlock, unsigned int to,
							unsigned long *flags);
   - lock a previously-assigned hwspinlock with a timeout limit (specified in
     msecs). If the hwspinlock is already taken, the function will busy loop
     waiting for it to be released, but give up when the timeout elapses.
     Upon a successful return from this function, preemption is disabled,
     local interrupts are disabled and their previous state is saved at the
     given flags placeholder. The caller must not sleep, and is advised to
     release the hwspinlock as soon as possible.
     Returns 0 when successful and an appropriate error code otherwise (most
     notably -ETIMEDOUT if the hwspinlock is still busy after timeout msecs).
     The function will never sleep.

  int hwspin_trylock(struct hwspinlock *hwlock);
   - attempt to lock a previously-assigned hwspinlock, but immediately fail if
     it is already taken.
     Upon a successful return from this function, preemption is disabled so
     caller must not sleep, and is advised to release the hwspinlock as soon as
     possible, in order to minimize remote cores polling on the hardware
     interconnect.
     Returns 0 on success and an appropriate error code otherwise (most
     notably -EBUSY if the hwspinlock was already taken).
     The function will never sleep.

  int hwspin_trylock_irq(struct hwspinlock *hwlock);
   - attempt to lock a previously-assigned hwspinlock, but immediately fail if
     it is already taken.
     Upon a successful return from this function, preemption and the local
     interrupts are disabled so caller must not sleep, and is advised to
     release the hwspinlock as soon as possible.
     Returns 0 on success and an appropriate error code otherwise (most
     notably -EBUSY if the hwspinlock was already taken).
     The function will never sleep.

  int hwspin_trylock_irqsave(struct hwspinlock *hwlock, unsigned long *flags);
   - attempt to lock a previously-assigned hwspinlock, but immediately fail if
     it is already taken.
     Upon a successful return from this function, preemption is disabled,
     the local interrupts are disabled and their previous state is saved
     at the given flags placeholder. The caller must not sleep, and is advised
     to release the hwspinlock as soon as possible.
     Returns 0 on success and an appropriate error code otherwise (most
     notably -EBUSY if the hwspinlock was already taken).
     The function will never sleep.

  void hwspin_unlock(struct hwspinlock *hwlock);
   - unlock a previously-locked hwspinlock. Always succeed, and can be called
     from any context (the function never sleeps). Note: code should _never_
     unlock an hwspinlock which is already unlocked (there is no protection
     against this).

  void hwspin_unlock_irq(struct hwspinlock *hwlock);
   - unlock a previously-locked hwspinlock and enable local interrupts.
     The caller should _never_ unlock an hwspinlock which is already unlocked.
     Doing so is considered a bug (there is no protection against this).
     Upon a successful return from this function, preemption and local
     interrupts are enabled. This function will never sleep.

  void
  hwspin_unlock_irqrestore(struct hwspinlock *hwlock, unsigned long *flags);
   - unlock a previously-locked hwspinlock.
     The caller should _never_ unlock an hwspinlock which is already unlocked.
     Doing so is considered a bug (there is no protection against this).
     Upon a successful return from this function, preemption is reenabled,
     and the state of the local interrupts is restored to the state saved at
     the given flags. This function will never sleep.

  int hwspin_lock_get_id(struct hwspinlock *hwlock);
   - retrieve id number of a given hwspinlock. This is needed when an
     hwspinlock is dynamically assigned: before it can be used to achieve
     mutual exclusion with a remote cpu, the id number should be communicated
     to the remote task with which we want to synchronize.
     Returns the hwspinlock id number, or -EINVAL if hwlock is null.

3. Typical usage

#include <linux/hwspinlock.h>
#include <linux/err.h>

int hwspinlock_example1(void)
{
	struct hwspinlock *hwlock;
	int ret;

	/* dynamically assign a hwspinlock */
	hwlock = hwspin_lock_request();
	if (!hwlock)
		...

	id = hwspin_lock_get_id(hwlock);
	/* probably need to communicate id to a remote processor now */

	/* take the lock, spin for 1 sec if it's already taken */
	ret = hwspin_lock_timeout(hwlock, 1000);
	if (ret)
		...

	/*
	 * we took the lock, do our thing now, but do NOT sleep
	 */

	/* release the lock */
	hwspin_unlock(hwlock);

	/* free the lock */
	ret = hwspin_lock_free(hwlock);
	if (ret)
		...

	return ret;
}

int hwspinlock_example2(void)
{
	struct hwspinlock *hwlock;
	int ret;

	/*
	 * assign a specific hwspinlock id - this should be called early
	 * by board init code.
	 */
	hwlock = hwspin_lock_request_specific(PREDEFINED_LOCK_ID);
	if (!hwlock)
		...

	/* try to take it, but don't spin on it */
	ret = hwspin_trylock(hwlock);
	if (!ret) {
		pr_info("lock is already taken\n");
		return -EBUSY;
	}

	/*
	 * we took the lock, do our thing now, but do NOT sleep
	 */

	/* release the lock */
	hwspin_unlock(hwlock);

	/* free the lock */
	ret = hwspin_lock_free(hwlock);
	if (ret)
		...

	return ret;
}


4. API for implementors

  int hwspin_lock_register(struct hwspinlock *hwlock);
   - to be called from the underlying platform-specific implementation, in
     order to register a new hwspinlock instance. Can be called from an atomic
     context (this function will not sleep) but not from within interrupt
     context. Returns 0 on success, or appropriate error code on failure.

  struct hwspinlock *hwspin_lock_unregister(unsigned int id);
   - to be called from the underlying vendor-specific implementation, in order
     to unregister an existing (and unused) hwspinlock instance.
     Can be called from an atomic context (will not sleep) but not from
     within interrupt context.
     Returns the address of hwspinlock on success, or NULL on error (e.g.
     if the hwspinlock is sill in use).

5. struct hwspinlock

This struct represents an hwspinlock instance. It is registered by the
underlying hwspinlock implementation using the hwspin_lock_register() API.

/**
 * struct hwspinlock - vendor-specific hwspinlock implementation
 *
 * @dev: underlying device, will be used with runtime PM api
 * @ops: vendor-specific hwspinlock handlers
 * @id: a global, unique, system-wide, index of the lock.
 * @lock: initialized and used by hwspinlock core
 * @owner: underlying implementation module, used to maintain module ref count
 */
struct hwspinlock {
	struct device *dev;
	const struct hwspinlock_ops *ops;
	int id;
	spinlock_t lock;
	struct module *owner;
};

The underlying implementation is responsible to assign the dev, ops, id and
owner members. The lock member, OTOH, is initialized and used by the hwspinlock
core.

6. Implementation callbacks

There are three possible callbacks defined in 'struct hwspinlock_ops':

struct hwspinlock_ops {
	int (*trylock)(struct hwspinlock *lock);
	void (*unlock)(struct hwspinlock *lock);
	void (*relax)(struct hwspinlock *lock);
};

The first two callbacks are mandatory:

The ->trylock() callback should make a single attempt to take the lock, and
return 0 on failure and 1 on success. This callback may _not_ sleep.

The ->unlock() callback releases the lock. It always succeed, and it, too,
may _not_ sleep.

The ->relax() callback is optional. It is called by hwspinlock core while
spinning on a lock, and can be used by the underlying implementation to force
a delay between two successive invocations of ->trylock(). It may _not_ sleep.
Using the initial RAM disk (initrd)
===================================

Written 1996,2000 by Werner Almesberger <werner.almesberger@epfl.ch> and
                     Hans Lermen <lermen@fgan.de>


initrd provides the capability to load a RAM disk by the boot loader.
This RAM disk can then be mounted as the root file system and programs
can be run from it. Afterwards, a new root file system can be mounted
from a different device. The previous root (from initrd) is then moved
to a directory and can be subsequently unmounted.

initrd is mainly designed to allow system startup to occur in two phases,
where the kernel comes up with a minimum set of compiled-in drivers, and
where additional modules are loaded from initrd.

This document gives a brief overview of the use of initrd. A more detailed
discussion of the boot process can be found in [1].


Operation
---------

When using initrd, the system typically boots as follows:

  1) the boot loader loads the kernel and the initial RAM disk
  2) the kernel converts initrd into a "normal" RAM disk and
     frees the memory used by initrd
  3) if the root device is not /dev/ram0, the old (deprecated)
     change_root procedure is followed. see the "Obsolete root change
     mechanism" section below.
  4) root device is mounted. if it is /dev/ram0, the initrd image is
     then mounted as root
  5) /sbin/init is executed (this can be any valid executable, including
     shell scripts; it is run with uid 0 and can do basically everything
     init can do).
  6) init mounts the "real" root file system
  7) init places the root file system at the root directory using the
     pivot_root system call
  8) init execs the /sbin/init on the new root filesystem, performing
     the usual boot sequence
  9) the initrd file system is removed

Note that changing the root directory does not involve unmounting it.
It is therefore possible to leave processes running on initrd during that
procedure. Also note that file systems mounted under initrd continue to
be accessible.


Boot command-line options
-------------------------

initrd adds the following new options:

  initrd=<path>    (e.g. LOADLIN)

    Loads the specified file as the initial RAM disk. When using LILO, you
    have to specify the RAM disk image file in /etc/lilo.conf, using the
    INITRD configuration variable.

  noinitrd

    initrd data is preserved but it is not converted to a RAM disk and
    the "normal" root file system is mounted. initrd data can be read
    from /dev/initrd. Note that the data in initrd can have any structure
    in this case and doesn't necessarily have to be a file system image.
    This option is used mainly for debugging.

    Note: /dev/initrd is read-only and it can only be used once. As soon
    as the last process has closed it, all data is freed and /dev/initrd
    can't be opened anymore.

  root=/dev/ram0

    initrd is mounted as root, and the normal boot procedure is followed,
    with the RAM disk mounted as root.

Compressed cpio images
----------------------

Recent kernels have support for populating a ramdisk from a compressed cpio
archive. On such systems, the creation of a ramdisk image doesn't need to
involve special block devices or loopbacks; you merely create a directory on
disk with the desired initrd content, cd to that directory, and run (as an
example):

find . | cpio --quiet -H newc -o | gzip -9 -n > /boot/imagefile.img

Examining the contents of an existing image file is just as simple:

mkdir /tmp/imagefile
cd /tmp/imagefile
gzip -cd /boot/imagefile.img | cpio -imd --quiet

Installation
------------

First, a directory for the initrd file system has to be created on the
"normal" root file system, e.g.

# mkdir /initrd

The name is not relevant. More details can be found on the pivot_root(2)
man page.

If the root file system is created during the boot procedure (i.e. if
you're building an install floppy), the root file system creation
procedure should create the /initrd directory.

If initrd will not be mounted in some cases, its content is still
accessible if the following device has been created:

# mknod /dev/initrd b 1 250 
# chmod 400 /dev/initrd

Second, the kernel has to be compiled with RAM disk support and with
support for the initial RAM disk enabled. Also, at least all components
needed to execute programs from initrd (e.g. executable format and file
system) must be compiled into the kernel.

Third, you have to create the RAM disk image. This is done by creating a
file system on a block device, copying files to it as needed, and then
copying the content of the block device to the initrd file. With recent
kernels, at least three types of devices are suitable for that:

 - a floppy disk (works everywhere but it's painfully slow)
 - a RAM disk (fast, but allocates physical memory)
 - a loopback device (the most elegant solution)

We'll describe the loopback device method:

 1) make sure loopback block devices are configured into the kernel
 2) create an empty file system of the appropriate size, e.g.
    # dd if=/dev/zero of=initrd bs=300k count=1
    # mke2fs -F -m0 initrd
    (if space is critical, you may want to use the Minix FS instead of Ext2)
 3) mount the file system, e.g.
    # mount -t ext2 -o loop initrd /mnt
 4) create the console device:
    # mkdir /mnt/dev
    # mknod /mnt/dev/console c 5 1
 5) copy all the files that are needed to properly use the initrd
    environment. Don't forget the most important file, /sbin/init
    Note that /sbin/init's permissions must include "x" (execute).
 6) correct operation the initrd environment can frequently be tested
    even without rebooting with the command
    # chroot /mnt /sbin/init
    This is of course limited to initrds that do not interfere with the
    general system state (e.g. by reconfiguring network interfaces,
    overwriting mounted devices, trying to start already running demons,
    etc. Note however that it is usually possible to use pivot_root in
    such a chroot'ed initrd environment.)
 7) unmount the file system
    # umount /mnt
 8) the initrd is now in the file "initrd". Optionally, it can now be
    compressed
    # gzip -9 initrd

For experimenting with initrd, you may want to take a rescue floppy and
only add a symbolic link from /sbin/init to /bin/sh. Alternatively, you
can try the experimental newlib environment [2] to create a small
initrd.

Finally, you have to boot the kernel and load initrd. Almost all Linux
boot loaders support initrd. Since the boot process is still compatible
with an older mechanism, the following boot command line parameters
have to be given:

  root=/dev/ram0 rw

(rw is only necessary if writing to the initrd file system.)

With LOADLIN, you simply execute

     LOADLIN <kernel> initrd=<disk_image>
e.g. LOADLIN C:\LINUX\BZIMAGE initrd=C:\LINUX\INITRD.GZ root=/dev/ram0 rw

With LILO, you add the option INITRD=<path> to either the global section
or to the section of the respective kernel in /etc/lilo.conf, and pass
the options using APPEND, e.g.

  image = /bzImage
    initrd = /boot/initrd.gz
    append = "root=/dev/ram0 rw"

and run /sbin/lilo

For other boot loaders, please refer to the respective documentation.

Now you can boot and enjoy using initrd.


Changing the root device
------------------------

When finished with its duties, init typically changes the root device
and proceeds with starting the Linux system on the "real" root device.

The procedure involves the following steps:
 - mounting the new root file system
 - turning it into the root file system
 - removing all accesses to the old (initrd) root file system
 - unmounting the initrd file system and de-allocating the RAM disk

Mounting the new root file system is easy: it just needs to be mounted on
a directory under the current root. Example:

# mkdir /new-root
# mount -o ro /dev/hda1 /new-root

The root change is accomplished with the pivot_root system call, which
is also available via the pivot_root utility (see pivot_root(8) man
page; pivot_root is distributed with util-linux version 2.10h or higher
[3]). pivot_root moves the current root to a directory under the new
root, and puts the new root at its place. The directory for the old root
must exist before calling pivot_root. Example:

# cd /new-root
# mkdir initrd
# pivot_root . initrd

Now, the init process may still access the old root via its
executable, shared libraries, standard input/output/error, and its
current root directory. All these references are dropped by the
following command:

# exec chroot . what-follows <dev/console >dev/console 2>&1

Where what-follows is a program under the new root, e.g. /sbin/init
If the new root file system will be used with udev and has no valid
/dev directory, udev must be initialized before invoking chroot in order
to provide /dev/console.

Note: implementation details of pivot_root may change with time. In order
to ensure compatibility, the following points should be observed:

 - before calling pivot_root, the current directory of the invoking
   process should point to the new root directory
 - use . as the first argument, and the _relative_ path of the directory
   for the old root as the second argument
 - a chroot program must be available under the old and the new root
 - chroot to the new root afterwards
 - use relative paths for dev/console in the exec command

Now, the initrd can be unmounted and the memory allocated by the RAM
disk can be freed:

# umount /initrd
# blockdev --flushbufs /dev/ram0

It is also possible to use initrd with an NFS-mounted root, see the
pivot_root(8) man page for details.


Usage scenarios
---------------

The main motivation for implementing initrd was to allow for modular
kernel configuration at system installation. The procedure would work
as follows:

  1) system boots from floppy or other media with a minimal kernel
     (e.g. support for RAM disks, initrd, a.out, and the Ext2 FS) and
     loads initrd
  2) /sbin/init determines what is needed to (1) mount the "real" root FS
     (i.e. device type, device drivers, file system) and (2) the
     distribution media (e.g. CD-ROM, network, tape, ...). This can be
     done by asking the user, by auto-probing, or by using a hybrid
     approach.
  3) /sbin/init loads the necessary kernel modules
  4) /sbin/init creates and populates the root file system (this doesn't
     have to be a very usable system yet)
  5) /sbin/init invokes pivot_root to change the root file system and
     execs - via chroot - a program that continues the installation
  6) the boot loader is installed
  7) the boot loader is configured to load an initrd with the set of
     modules that was used to bring up the system (e.g. /initrd can be
     modified, then unmounted, and finally, the image is written from
     /dev/ram0 or /dev/rd/0 to a file)
  8) now the system is bootable and additional installation tasks can be
     performed

The key role of initrd here is to re-use the configuration data during
normal system operation without requiring the use of a bloated "generic"
kernel or re-compiling or re-linking the kernel.

A second scenario is for installations where Linux runs on systems with
different hardware configurations in a single administrative domain. In
such cases, it is desirable to generate only a small set of kernels
(ideally only one) and to keep the system-specific part of configuration
information as small as possible. In this case, a common initrd could be
generated with all the necessary modules. Then, only /sbin/init or a file
read by it would have to be different.

A third scenario is more convenient recovery disks, because information
like the location of the root FS partition doesn't have to be provided at
boot time, but the system loaded from initrd can invoke a user-friendly
dialog and it can also perform some sanity checks (or even some form of
auto-detection).

Last not least, CD-ROM distributors may use it for better installation
from CD, e.g. by using a boot floppy and bootstrapping a bigger RAM disk
via initrd from CD; or by booting via a loader like LOADLIN or directly
from the CD-ROM, and loading the RAM disk from CD without need of
floppies. 


Obsolete root change mechanism
------------------------------

The following mechanism was used before the introduction of pivot_root.
Current kernels still support it, but you should _not_ rely on its
continued availability.

It works by mounting the "real" root device (i.e. the one set with rdev
in the kernel image or with root=... at the boot command line) as the
root file system when linuxrc exits. The initrd file system is then
unmounted, or, if it is still busy, moved to a directory /initrd, if
such a directory exists on the new root file system.

In order to use this mechanism, you do not have to specify the boot
command options root, init, or rw. (If specified, they will affect
the real root file system, not the initrd environment.)
  
If /proc is mounted, the "real" root device can be changed from within
linuxrc by writing the number of the new root FS device to the special
file /proc/sys/kernel/real-root-dev, e.g.

  # echo 0x301 >/proc/sys/kernel/real-root-dev

Note that the mechanism is incompatible with NFS and similar file
systems.

This old, deprecated mechanism is commonly called "change_root", while
the new, supported mechanism is called "pivot_root".


Mixed change_root and pivot_root mechanism
------------------------------------------

In case you did not want to use root=/dev/ram0 to trigger the pivot_root
mechanism, you may create both /linuxrc and /sbin/init in your initrd image.

/linuxrc would contain only the following:

#! /bin/sh
mount -n -t proc proc /proc
echo 0x0100 >/proc/sys/kernel/real-root-dev
umount -n /proc

Once linuxrc exited, the kernel would mount again your initrd as root,
this time executing /sbin/init. Again, it would be the duty of this init
to build the right environment (maybe using the root= device passed on
the cmdline) before the final execution of the real /sbin/init.


Resources
---------

[1] Almesberger, Werner; "Booting Linux: The History and the Future"
    http://www.almesberger.net/cv/papers/ols2k-9.ps.gz
[2] newlib package (experimental), with initrd example
    http://sources.redhat.com/newlib/
[3] Brouwer, Andries; "util-linux: Miscellaneous utilities for Linux"
    ftp://ftp.win.tue.nl/pub/linux-local/utils/util-linux/
Explaining the dreaded "No init found." boot hang message
=========================================================

OK, so you've got this pretty unintuitive message (currently located
in init/main.c) and are wondering what the H*** went wrong.
Some high-level reasons for failure (listed roughly in order of execution)
to load the init binary are:
A) Unable to mount root FS
B) init binary doesn't exist on rootfs
C) broken console device
D) binary exists but dependencies not available
E) binary cannot be loaded

Detailed explanations:
0) Set "debug" kernel parameter (in bootloader config file or CONFIG_CMDLINE)
   to get more detailed kernel messages.
A) make sure you have the correct root FS type
   (and root= kernel parameter points to the correct partition),
   required drivers such as storage hardware (such as SCSI or USB!)
   and filesystem (ext3, jffs2 etc.) are builtin (alternatively as modules,
   to be pre-loaded by an initrd)
C) Possibly a conflict in console= setup --> initial console unavailable.
   E.g. some serial consoles are unreliable due to serial IRQ issues (e.g.
   missing interrupt-based configuration).
   Try using a different console= device or e.g. netconsole= .
D) e.g. required library dependencies of the init binary such as
   /lib/ld-linux.so.2 missing or broken. Use readelf -d <INIT>|grep NEEDED
   to find out which libraries are required.
E) make sure the binary's architecture matches your hardware.
   E.g. i386 vs. x86_64 mismatch, or trying to load x86 on ARM hardware.
   In case you tried loading a non-binary file here (shell script?),
   you should make sure that the script specifies an interpreter in its shebang
   header line (#!/...) that is fully working (including its library
   dependencies). And before tackling scripts, better first test a simple
   non-script binary such as /bin/sh and confirm its successful execution.
   To find out more, add code to init/main.c to display kernel_execve()s
   return values.

Please extend this explanation whenever you find new failure causes
(after all loading the init binary is a CRITICAL and hard transition step
which needs to be made as painless as possible), then submit patch to LKML.
Further TODOs:
- Implement the various run_init_process() invocations via a struct array
  which can then store the kernel_execve() result value and on failure
  log it all by iterating over _all_ results (very important usability fix).
- try to make the implementation itself more helpful in general,
  e.g. by providing additional error messages at affected places.

Andreas Mohr <andi at lisas period de>
Linux IOMMU Support
===================

The architecture spec can be obtained from the below location.

http://www.intel.com/technology/virtualization/

This guide gives a quick cheat sheet for some basic understanding.

Some Keywords

DMAR - DMA remapping
DRHD - DMA Engine Reporting Structure
RMRR - Reserved memory Region Reporting Structure
ZLR  - Zero length reads from PCI devices
IOVA - IO Virtual address.

Basic stuff
-----------

ACPI enumerates and lists the different DMA engines in the platform, and
device scope relationships between PCI devices and which DMA engine  controls
them.

What is RMRR?
-------------

There are some devices the BIOS controls, for e.g USB devices to perform
PS2 emulation. The regions of memory used for these devices are marked
reserved in the e820 map. When we turn on DMA translation, DMA to those
regions will fail. Hence BIOS uses RMRR to specify these regions along with
devices that need to access these regions. OS is expected to setup
unity mappings for these regions for these devices to access these regions.

How is IOVA generated?
---------------------

Well behaved drivers call pci_map_*() calls before sending command to device
that needs to perform DMA. Once DMA is completed and mapping is no longer
required, device performs a pci_unmap_*() calls to unmap the region.

The Intel IOMMU driver allocates a virtual address per domain. Each PCIE
device has its own domain (hence protection). Devices under p2p bridges
share the virtual address with all devices under the p2p bridge due to
transaction id aliasing for p2p bridges.

IOVA generation is pretty generic. We used the same technique as vmalloc()
but these are not global address spaces, but separate for each domain.
Different DMA engines may support different number of domains.

We also allocate guard pages with each mapping, so we can attempt to catch
any overflow that might happen.


Graphics Problems?
------------------
If you encounter issues with graphics devices, you can try adding
option intel_iommu=igfx_off to turn off the integrated graphics engine.
If this fixes anything, please ensure you file a bug reporting the problem.

Some exceptions to IOVA
-----------------------
Interrupt ranges are not address translated, (0xfee00000 - 0xfeefffff).
The same is true for peer to peer transactions. Hence we reserve the
address from PCI MMIO ranges so they are not allocated for IOVA addresses.


Fault reporting
---------------
When errors are reported, the DMA engine signals via an interrupt. The fault
reason and device that caused it with fault reason is printed on console.

See below for sample.


Boot Message Sample
-------------------

Something like this gets printed indicating presence of DMAR tables
in ACPI.

ACPI: DMAR (v001 A M I  OEMDMAR  0x00000001 MSFT 0x00000097) @ 0x000000007f5b5ef0

When DMAR is being processed and initialized by ACPI, prints DMAR locations
and any RMRR's processed.

ACPI DMAR:Host address width 36
ACPI DMAR:DRHD (flags: 0x00000000)base: 0x00000000fed90000
ACPI DMAR:DRHD (flags: 0x00000000)base: 0x00000000fed91000
ACPI DMAR:DRHD (flags: 0x00000001)base: 0x00000000fed93000
ACPI DMAR:RMRR base: 0x00000000000ed000 end: 0x00000000000effff
ACPI DMAR:RMRR base: 0x000000007f600000 end: 0x000000007fffffff

When DMAR is enabled for use, you will notice..

PCI-DMA: Using DMAR IOMMU

Fault reporting
---------------

DMAR:[DMA Write] Request device [00:02.0] fault addr 6df084000
DMAR:[fault reason 05] PTE Write access is not set
DMAR:[DMA Write] Request device [00:02.0] fault addr 6df084000
DMAR:[fault reason 05] PTE Write access is not set

TBD
----

- For compatibility testing, could use unity map domain for all devices, just
  provide a 1-1 for all useful memory under a single domain for all devices.
- API for paravirt ops for abstracting functionality for VMM folks.
Intel(R) TXT Overview:
=====================

Intel's technology for safer computing, Intel(R) Trusted Execution
Technology (Intel(R) TXT), defines platform-level enhancements that
provide the building blocks for creating trusted platforms.

Intel TXT was formerly known by the code name LaGrande Technology (LT).

Intel TXT in Brief:
o  Provides dynamic root of trust for measurement (DRTM)
o  Data protection in case of improper shutdown
o  Measurement and verification of launched environment

Intel TXT is part of the vPro(TM) brand and is also available some
non-vPro systems.  It is currently available on desktop systems
based on the Q35, X38, Q45, and Q43 Express chipsets (e.g. Dell
Optiplex 755, HP dc7800, etc.) and mobile systems based on the GM45,
PM45, and GS45 Express chipsets.

For more information, see http://www.intel.com/technology/security/.
This site also has a link to the Intel TXT MLE Developers Manual,
which has been updated for the new released platforms.

Intel TXT has been presented at various events over the past few
years, some of which are:
      LinuxTAG 2008:
          http://www.linuxtag.org/2008/en/conf/events/vp-donnerstag.html
      TRUST2008:
          http://www.trust-conference.eu/downloads/Keynote-Speakers/
          3_David-Grawrock_The-Front-Door-of-Trusted-Computing.pdf
      IDF, Shanghai:
          http://www.prcidf.com.cn/index_en.html
      IDFs 2006, 2007 (I'm not sure if/where they are online)

Trusted Boot Project Overview:
=============================

Trusted Boot (tboot) is an open source, pre-kernel/VMM module that
uses Intel TXT to perform a measured and verified launch of an OS
kernel/VMM.

It is hosted on SourceForge at http://sourceforge.net/projects/tboot.
The mercurial source repo is available at http://www.bughost.org/
repos.hg/tboot.hg.

Tboot currently supports launching Xen (open source VMM/hypervisor
w/ TXT support since v3.2), and now Linux kernels.


Value Proposition for Linux or "Why should you care?"
=====================================================

While there are many products and technologies that attempt to
measure or protect the integrity of a running kernel, they all
assume the kernel is "good" to begin with.  The Integrity
Measurement Architecture (IMA) and Linux Integrity Module interface
are examples of such solutions.

To get trust in the initial kernel without using Intel TXT, a
static root of trust must be used.  This bases trust in BIOS
starting at system reset and requires measurement of all code
executed between system reset through the completion of the kernel
boot as well as data objects used by that code.  In the case of a
Linux kernel, this means all of BIOS, any option ROMs, the
bootloader and the boot config.  In practice, this is a lot of
code/data, much of which is subject to change from boot to boot
(e.g. changing NICs may change option ROMs).  Without reference
hashes, these measurement changes are difficult to assess or
confirm as benign.  This process also does not provide DMA
protection, memory configuration/alias checks and locks, crash
protection, or policy support.

By using the hardware-based root of trust that Intel TXT provides,
many of these issues can be mitigated.  Specifically: many
pre-launch components can be removed from the trust chain, DMA
protection is provided to all launched components, a large number
of platform configuration checks are performed and values locked,
protection is provided for any data in the event of an improper
shutdown, and there is support for policy-based execution/verification.
This provides a more stable measurement and a higher assurance of
system configuration and initial state than would be otherwise
possible.  Since the tboot project is open source, source code for
almost all parts of the trust chain is available (excepting SMM and
Intel-provided firmware).

How Does it Work?
=================

o  Tboot is an executable that is launched by the bootloader as
   the "kernel" (the binary the bootloader executes).
o  It performs all of the work necessary to determine if the
   platform supports Intel TXT and, if so, executes the GETSEC[SENTER]
   processor instruction that initiates the dynamic root of trust.
   -  If tboot determines that the system does not support Intel TXT
      or is not configured correctly (e.g. the SINIT AC Module was
      incorrect), it will directly launch the kernel with no changes
      to any state.
   -  Tboot will output various information about its progress to the
      terminal, serial port, and/or an in-memory log; the output
      locations can be configured with a command line switch.
o  The GETSEC[SENTER] instruction will return control to tboot and
   tboot then verifies certain aspects of the environment (e.g. TPM NV
   lock, e820 table does not have invalid entries, etc.).
o  It will wake the APs from the special sleep state the GETSEC[SENTER]
   instruction had put them in and place them into a wait-for-SIPI
   state.
   -  Because the processors will not respond to an INIT or SIPI when
      in the TXT environment, it is necessary to create a small VT-x
      guest for the APs.  When they run in this guest, they will
      simply wait for the INIT-SIPI-SIPI sequence, which will cause
      VMEXITs, and then disable VT and jump to the SIPI vector.  This
      approach seemed like a better choice than having to insert
      special code into the kernel's MP wakeup sequence.
o  Tboot then applies an (optional) user-defined launch policy to
   verify the kernel and initrd.
   -  This policy is rooted in TPM NV and is described in the tboot
      project.  The tboot project also contains code for tools to
      create and provision the policy.
   -  Policies are completely under user control and if not present
      then any kernel will be launched.
   -  Policy action is flexible and can include halting on failures
      or simply logging them and continuing.
o  Tboot adjusts the e820 table provided by the bootloader to reserve
   its own location in memory as well as to reserve certain other
   TXT-related regions.
o  As part of its launch, tboot DMA protects all of RAM (using the
   VT-d PMRs).  Thus, the kernel must be booted with 'intel_iommu=on'
   in order to remove this blanket protection and use VT-d's
   page-level protection.
o  Tboot will populate a shared page with some data about itself and
   pass this to the Linux kernel as it transfers control.
   -  The location of the shared page is passed via the boot_params
      struct as a physical address.
o  The kernel will look for the tboot shared page address and, if it
   exists, map it.
o  As one of the checks/protections provided by TXT, it makes a copy
   of the VT-d DMARs in a DMA-protected region of memory and verifies
   them for correctness.  The VT-d code will detect if the kernel was
   launched with tboot and use this copy instead of the one in the
   ACPI table.
o  At this point, tboot and TXT are out of the picture until a
   shutdown (S<n>)
o  In order to put a system into any of the sleep states after a TXT
   launch, TXT must first be exited.  This is to prevent attacks that
   attempt to crash the system to gain control on reboot and steal
   data left in memory.
   -  The kernel will perform all of its sleep preparation and
      populate the shared page with the ACPI data needed to put the
      platform in the desired sleep state.
   -  Then the kernel jumps into tboot via the vector specified in the
      shared page.
   -  Tboot will clean up the environment and disable TXT, then use the
      kernel-provided ACPI information to actually place the platform
      into the desired sleep state.
   -  In the case of S3, tboot will also register itself as the resume
      vector.  This is necessary because it must re-establish the
      measured environment upon resume.  Once the TXT environment
      has been restored, it will restore the TPM PCRs and then
      transfer control back to the kernel's S3 resume vector.
      In order to preserve system integrity across S3, the kernel
      provides tboot with a set of memory ranges (RAM and RESERVED_KERN
      in the e820 table, but not any memory that BIOS might alter over
      the S3 transition) that tboot will calculate a MAC (message
      authentication code) over and then seal with the TPM. On resume
      and once the measured environment has been re-established, tboot
      will re-calculate the MAC and verify it against the sealed value.
      Tboot's policy determines what happens if the verification fails.
      Note that the c/s 194 of tboot which has the new MAC code supports
      this.

That's pretty much it for TXT support.


Configuring the System:
======================

This code works with 32bit, 32bit PAE, and 64bit (x86_64) kernels.

In BIOS, the user must enable:  TPM, TXT, VT-x, VT-d.  Not all BIOSes
allow these to be individually enabled/disabled and the screens in
which to find them are BIOS-specific.

grub.conf needs to be modified as follows:
        title Linux 2.6.29-tip w/ tboot
          root (hd0,0)
                kernel /tboot.gz logging=serial,vga,memory
                module /vmlinuz-2.6.29-tip intel_iommu=on ro
                       root=LABEL=/ rhgb console=ttyS0,115200 3
                module /initrd-2.6.29-tip.img
                module /Q35_SINIT_17.BIN

The kernel option for enabling Intel TXT support is found under the
Security top-level menu and is called "Enable Intel(R) Trusted
Execution Technology (TXT)".  It is marked as EXPERIMENTAL and
depends on the generic x86 support (to allow maximum flexibility in
kernel build options), since the tboot code will detect whether the
platform actually supports Intel TXT and thus whether any of the
kernel code is executed.

The Q35_SINIT_17.BIN file is what Intel TXT refers to as an
Authenticated Code Module.  It is specific to the chipset in the
system and can also be found on the Trusted Boot site.  It is an
(unencrypted) module signed by Intel that is used as part of the
DRTM process to verify and configure the system.  It is signed
because it operates at a higher privilege level in the system than
any other macrocode and its correct operation is critical to the
establishment of the DRTM.  The process for determining the correct
SINIT ACM for a system is documented in the SINIT-guide.txt file
that is on the tboot SourceForge site under the SINIT ACM downloads.
The io_mapping functions in linux/io-mapping.h provide an abstraction for
efficiently mapping small regions of an I/O device to the CPU. The initial
usage is to support the large graphics aperture on 32-bit processors where
ioremap_wc cannot be used to statically map the entire aperture to the CPU
as it would consume too much of the kernel address space.

A mapping object is created during driver initialization using

	struct io_mapping *io_mapping_create_wc(unsigned long base,
						unsigned long size)

		'base' is the bus address of the region to be made
		mappable, while 'size' indicates how large a mapping region to
		enable. Both are in bytes.

		This _wc variant provides a mapping which may only be used
		with the io_mapping_map_atomic_wc or io_mapping_map_wc.

With this mapping object, individual pages can be mapped either atomically
or not, depending on the necessary scheduling environment. Of course, atomic
maps are more efficient:

	void *io_mapping_map_atomic_wc(struct io_mapping *mapping,
				       unsigned long offset)

		'offset' is the offset within the defined mapping region.
		Accessing addresses beyond the region specified in the
		creation function yields undefined results. Using an offset
		which is not page aligned yields an undefined result. The
		return value points to a single page in CPU address space.

		This _wc variant returns a write-combining map to the
		page and may only be used with mappings created by
		io_mapping_create_wc

		Note that the task may not sleep while holding this page
		mapped.

	void io_mapping_unmap_atomic(void *vaddr)

		'vaddr' must be the the value returned by the last
		io_mapping_map_atomic_wc call. This unmaps the specified
		page and allows the task to sleep once again.

If you need to sleep while holding the lock, you can use the non-atomic
variant, although they may be significantly slower.

	void *io_mapping_map_wc(struct io_mapping *mapping,
				unsigned long offset)

		This works like io_mapping_map_atomic_wc except it allows
		the task to sleep while holding the page mapped.

	void io_mapping_unmap(void *vaddr)

		This works like io_mapping_unmap_atomic, except it is used
		for pages mapped with io_mapping_map_wc.

At driver close time, the io_mapping object must be freed:

	void io_mapping_free(struct io_mapping *mapping)

Current Implementation:

The initial implementation of these functions uses existing mapping
mechanisms and so provides only an abstraction layer and no new
functionality.

On 64-bit processors, io_mapping_create_wc calls ioremap_wc for the whole
range, creating a permanent kernel-visible mapping to the resource. The
map_atomic and map functions add the requested offset to the base of the
virtual address returned by ioremap_wc.

On 32-bit processors with HIGHMEM defined, io_mapping_map_atomic_wc uses
kmap_atomic_pfn to map the specified page in an atomic fashion;
kmap_atomic_pfn isn't really supposed to be used with device pages, but it
provides an efficient mapping for this usage.

On 32-bit processors without HIGHMEM defined, io_mapping_map_atomic_wc and
io_mapping_map_wc both use ioremap_wc, a terribly inefficient function which
performs an IPI to inform all processors about the new mapping. This results
in a significant performance penalty.
On some platforms, so-called memory-mapped I/O is weakly ordered.  On such
platforms, driver writers are responsible for ensuring that I/O writes to
memory-mapped addresses on their device arrive in the order intended.  This is
typically done by reading a 'safe' device or bridge register, causing the I/O
chipset to flush pending writes to the device before any reads are posted.  A
driver would usually use this technique immediately prior to the exit of a
critical section of code protected by spinlocks.  This would ensure that
subsequent writes to I/O space arrived only after all prior writes (much like a
memory barrier op, mb(), only with respect to I/O).

A more concrete example from a hypothetical device driver:

        ...
CPU A:  spin_lock_irqsave(&dev_lock, flags)
CPU A:  val = readl(my_status);
CPU A:  ...
CPU A:  writel(newval, ring_ptr);
CPU A:  spin_unlock_irqrestore(&dev_lock, flags)
        ...
CPU B:  spin_lock_irqsave(&dev_lock, flags)
CPU B:  val = readl(my_status);
CPU B:  ...
CPU B:  writel(newval2, ring_ptr);
CPU B:  spin_unlock_irqrestore(&dev_lock, flags)
        ...

In the case above, the device may receive newval2 before it receives newval,
which could cause problems.  Fixing it is easy enough though:

        ...
CPU A:  spin_lock_irqsave(&dev_lock, flags)
CPU A:  val = readl(my_status);
CPU A:  ...
CPU A:  writel(newval, ring_ptr);
CPU A:  (void)readl(safe_register); /* maybe a config register? */
CPU A:  spin_unlock_irqrestore(&dev_lock, flags)
        ...
CPU B:  spin_lock_irqsave(&dev_lock, flags)
CPU B:  val = readl(my_status);
CPU B:  ...
CPU B:  writel(newval2, ring_ptr);
CPU B:  (void)readl(safe_register); /* maybe a config register? */
CPU B:  spin_unlock_irqrestore(&dev_lock, flags)

Here, the reads from safe_register will cause the I/O chipset to flush any
pending writes before actually posting the read to the chipset, preventing
possible data corruption.
I/O statistics fields
---------------

Since 2.4.20 (and some versions before, with patches), and 2.5.45,
more extensive disk statistics have been introduced to help measure disk
activity. Tools such as sar and iostat typically interpret these and do
the work for you, but in case you are interested in creating your own
tools, the fields are explained here.

In 2.4 now, the information is found as additional fields in
/proc/partitions.  In 2.6, the same information is found in two
places: one is in the file /proc/diskstats, and the other is within
the sysfs file system, which must be mounted in order to obtain
the information. Throughout this document we'll assume that sysfs
is mounted on /sys, although of course it may be mounted anywhere.
Both /proc/diskstats and sysfs use the same source for the information
and so should not differ.

Here are examples of these different formats:

2.4:
   3     0   39082680 hda 446216 784926 9550688 4382310 424847 312726 5922052 19310380 0 3376340 23705160
   3     1    9221278 hda1 35486 0 35496 38030 0 0 0 0 0 38030 38030


2.6 sysfs:
   446216 784926 9550688 4382310 424847 312726 5922052 19310380 0 3376340 23705160
   35486    38030    38030    38030

2.6 diskstats:
   3    0   hda 446216 784926 9550688 4382310 424847 312726 5922052 19310380 0 3376340 23705160
   3    1   hda1 35486 38030 38030 38030

On 2.4 you might execute "grep 'hda ' /proc/partitions". On 2.6, you have
a choice of "cat /sys/block/hda/stat" or "grep 'hda ' /proc/diskstats".
The advantage of one over the other is that the sysfs choice works well
if you are watching a known, small set of disks.  /proc/diskstats may
be a better choice if you are watching a large number of disks because
you'll avoid the overhead of 50, 100, or 500 or more opens/closes with
each snapshot of your disk statistics.

In 2.4, the statistics fields are those after the device name. In
the above example, the first field of statistics would be 446216.
By contrast, in 2.6 if you look at /sys/block/hda/stat, you'll
find just the eleven fields, beginning with 446216.  If you look at
/proc/diskstats, the eleven fields will be preceded by the major and
minor device numbers, and device name.  Each of these formats provides
eleven fields of statistics, each meaning exactly the same things.
All fields except field 9 are cumulative since boot.  Field 9 should
go to zero as I/Os complete; all others only increase (unless they
overflow and wrap).  Yes, these are (32-bit or 64-bit) unsigned long
(native word size) numbers, and on a very busy or long-lived system they
may wrap. Applications should be prepared to deal with that; unless
your observations are measured in large numbers of minutes or hours,
they should not wrap twice before you notice them.

Each set of stats only applies to the indicated device; if you want
system-wide stats you'll have to find all the devices and sum them all up.

Field  1 -- # of reads completed
    This is the total number of reads completed successfully.
Field  2 -- # of reads merged, field 6 -- # of writes merged
    Reads and writes which are adjacent to each other may be merged for
    efficiency.  Thus two 4K reads may become one 8K read before it is
    ultimately handed to the disk, and so it will be counted (and queued)
    as only one I/O.  This field lets you know how often this was done.
Field  3 -- # of sectors read
    This is the total number of sectors read successfully.
Field  4 -- # of milliseconds spent reading
    This is the total number of milliseconds spent by all reads (as
    measured from __make_request() to end_that_request_last()).
Field  5 -- # of writes completed
    This is the total number of writes completed successfully.
Field  7 -- # of sectors written
    This is the total number of sectors written successfully.
Field  8 -- # of milliseconds spent writing
    This is the total number of milliseconds spent by all writes (as
    measured from __make_request() to end_that_request_last()).
Field  9 -- # of I/Os currently in progress
    The only field that should go to zero. Incremented as requests are
    given to appropriate struct request_queue and decremented as they finish.
Field 10 -- # of milliseconds spent doing I/Os
    This field increases so long as field 9 is nonzero.
Field 11 -- weighted # of milliseconds spent doing I/Os
    This field is incremented at each I/O start, I/O completion, I/O
    merge, or read of these stats by the number of I/Os in progress
    (field 9) times the number of milliseconds spent doing I/O since the
    last update of this field.  This can provide an easy measure of both
    I/O completion time and the backlog that may be accumulating.


To avoid introducing performance bottlenecks, no locks are held while
modifying these counters.  This implies that minor inaccuracies may be
introduced when changes collide, so (for instance) adding up all the
read I/Os issued per partition should equal those made to the disks ...
but due to the lack of locking it may only be very close.

In 2.6, there are counters for each CPU, which make the lack of locking
almost a non-issue.  When the statistics are read, the per-CPU counters
are summed (possibly overflowing the unsigned long variable they are
summed to) and the result given to the user.  There is no convenient
user interface for accessing the per-CPU counters themselves.

Disks vs Partitions
-------------------

There were significant changes between 2.4 and 2.6 in the I/O subsystem.
As a result, some statistic information disappeared. The translation from
a disk address relative to a partition to the disk address relative to
the host disk happens much earlier.  All merges and timings now happen
at the disk level rather than at both the disk and partition level as
in 2.4.  Consequently, you'll see a different statistics output on 2.6 for
partitions from that for disks.  There are only *four* fields available
for partitions on 2.6 machines.  This is reflected in the examples above.

Field  1 -- # of reads issued
    This is the total number of reads issued to this partition.
Field  2 -- # of sectors read
    This is the total number of sectors requested to be read from this
    partition.
Field  3 -- # of writes issued
    This is the total number of writes issued to this partition.
Field  4 -- # of sectors written
    This is the total number of sectors requested to be written to
    this partition.

Note that since the address is translated to a disk-relative one, and no
record of the partition-relative address is kept, the subsequent success
or failure of the read cannot be attributed to the partition.  In other
words, the number of reads for partitions is counted slightly before time
of queuing for partitions, and at completion for whole disks.  This is
a subtle distinction that is probably uninteresting for most cases.

More significant is the error induced by counting the numbers of
reads/writes before merges for partitions and after for disks. Since a
typical workload usually contains a lot of successive and adjacent requests,
the number of reads/writes issued can be several times higher than the
number of reads/writes completed.

In 2.6.25, the full statistic set is again available for partitions and
disk and partition statistics are consistent again. Since we still don't
keep record of the partition-relative address, an operation is attributed to
the partition which contains the first sector of the request after the
eventual merges. As requests can be merged across partition, this could lead
to some (probably insignificant) inaccuracy.

Additional notes
----------------

In 2.6, sysfs is not mounted by default.  If your distribution of
Linux hasn't added it already, here's the line you'll want to add to
your /etc/fstab:

none /sys sysfs defaults 0 0


In 2.6, all disk statistics were removed from /proc/stat.  In 2.4, they
appear in both /proc/partitions and /proc/stat, although the ones in
/proc/stat take a very different format from those in /proc/partitions
(see proc(5), if your system has it.)

-- ricklind@us.ibm.com

                          The Linux IPMI Driver
			  ---------------------
			      Corey Minyard
			  <minyard@mvista.com>
			    <minyard@acm.org>

The Intelligent Platform Management Interface, or IPMI, is a
standard for controlling intelligent devices that monitor a system.
It provides for dynamic discovery of sensors in the system and the
ability to monitor the sensors and be informed when the sensor's
values change or go outside certain boundaries.  It also has a
standardized database for field-replaceable units (FRUs) and a watchdog
timer.

To use this, you need an interface to an IPMI controller in your
system (called a Baseboard Management Controller, or BMC) and
management software that can use the IPMI system.

This document describes how to use the IPMI driver for Linux.  If you
are not familiar with IPMI itself, see the web site at
http://www.intel.com/design/servers/ipmi/index.htm.  IPMI is a big
subject and I can't cover it all here!

Configuration
-------------

The Linux IPMI driver is modular, which means you have to pick several
things to have it work right depending on your hardware.  Most of
these are available in the 'Character Devices' menu then the IPMI
menu.

No matter what, you must pick 'IPMI top-level message handler' to use
IPMI.  What you do beyond that depends on your needs and hardware.

The message handler does not provide any user-level interfaces.
Kernel code (like the watchdog) can still use it.  If you need access
from userland, you need to select 'Device interface for IPMI' if you
want access through a device driver.

The driver interface depends on your hardware.  If your system
properly provides the SMBIOS info for IPMI, the driver will detect it
and just work.  If you have a board with a standard interface (These
will generally be either "KCS", "SMIC", or "BT", consult your hardware
manual), choose the 'IPMI SI handler' option.  A driver also exists
for direct I2C access to the IPMI management controller.  Some boards
support this, but it is unknown if it will work on every board.  For
this, choose 'IPMI SMBus handler', but be ready to try to do some
figuring to see if it will work on your system if the SMBIOS/APCI
information is wrong or not present.  It is fairly safe to have both
these enabled and let the drivers auto-detect what is present.

You should generally enable ACPI on your system, as systems with IPMI
can have ACPI tables describing them.

If you have a standard interface and the board manufacturer has done
their job correctly, the IPMI controller should be automatically
detected (via ACPI or SMBIOS tables) and should just work.  Sadly,
many boards do not have this information.  The driver attempts
standard defaults, but they may not work.  If you fall into this
situation, you need to read the section below named 'The SI Driver' or
"The SMBus Driver" on how to hand-configure your system.

IPMI defines a standard watchdog timer.  You can enable this with the
'IPMI Watchdog Timer' config option.  If you compile the driver into
the kernel, then via a kernel command-line option you can have the
watchdog timer start as soon as it initializes.  It also have a lot
of other options, see the 'Watchdog' section below for more details.
Note that you can also have the watchdog continue to run if it is
closed (by default it is disabled on close).  Go into the 'Watchdog
Cards' menu, enable 'Watchdog Timer Support', and enable the option
'Disable watchdog shutdown on close'.

IPMI systems can often be powered off using IPMI commands.  Select
'IPMI Poweroff' to do this.  The driver will auto-detect if the system
can be powered off by IPMI.  It is safe to enable this even if your
system doesn't support this option.  This works on ATCA systems, the
Radisys CPI1 card, and any IPMI system that supports standard chassis
management commands.

If you want the driver to put an event into the event log on a panic,
enable the 'Generate a panic event to all BMCs on a panic' option.  If
you want the whole panic string put into the event log using OEM
events, enable the 'Generate OEM events containing the panic string'
option.

Basic Design
------------

The Linux IPMI driver is designed to be very modular and flexible, you
only need to take the pieces you need and you can use it in many
different ways.  Because of that, it's broken into many chunks of
code.  These chunks (by module name) are:

ipmi_msghandler - This is the central piece of software for the IPMI
system.  It handles all messages, message timing, and responses.  The
IPMI users tie into this, and the IPMI physical interfaces (called
System Management Interfaces, or SMIs) also tie in here.  This
provides the kernelland interface for IPMI, but does not provide an
interface for use by application processes.

ipmi_devintf - This provides a userland IOCTL interface for the IPMI
driver, each open file for this device ties in to the message handler
as an IPMI user.

ipmi_si - A driver for various system interfaces.  This supports KCS,
SMIC, and BT interfaces.  Unless you have an SMBus interface or your
own custom interface, you probably need to use this.

ipmi_smb - A driver for accessing BMCs on the SMBus. It uses the
I2C kernel driver's SMBus interfaces to send and receive IPMI messages
over the SMBus.

ipmi_watchdog - IPMI requires systems to have a very capable watchdog
timer.  This driver implements the standard Linux watchdog timer
interface on top of the IPMI message handler.

ipmi_poweroff - Some systems support the ability to be turned off via
IPMI commands.

These are all individually selectable via configuration options.

Note that the KCS-only interface has been removed.  The af_ipmi driver
is no longer supported and has been removed because it was impossible
to do 32 bit emulation on 64-bit kernels with it.

Much documentation for the interface is in the include files.  The
IPMI include files are:

net/af_ipmi.h - Contains the socket interface.

linux/ipmi.h - Contains the user interface and IOCTL interface for IPMI.

linux/ipmi_smi.h - Contains the interface for system management interfaces
(things that interface to IPMI controllers) to use.

linux/ipmi_msgdefs.h - General definitions for base IPMI messaging.


Addressing
----------

The IPMI addressing works much like IP addresses, you have an overlay
to handle the different address types.  The overlay is:

  struct ipmi_addr
  {
	int   addr_type;
	short channel;
	char  data[IPMI_MAX_ADDR_SIZE];
  };

The addr_type determines what the address really is.  The driver
currently understands two different types of addresses.

"System Interface" addresses are defined as:

  struct ipmi_system_interface_addr
  {
	int   addr_type;
	short channel;
  };

and the type is IPMI_SYSTEM_INTERFACE_ADDR_TYPE.  This is used for talking
straight to the BMC on the current card.  The channel must be
IPMI_BMC_CHANNEL.

Messages that are destined to go out on the IPMB bus use the
IPMI_IPMB_ADDR_TYPE address type.  The format is

  struct ipmi_ipmb_addr
  {
	int           addr_type;
	short         channel;
	unsigned char slave_addr;
	unsigned char lun;
  };

The "channel" here is generally zero, but some devices support more
than one channel, it corresponds to the channel as defined in the IPMI
spec.


Messages
--------

Messages are defined as:

struct ipmi_msg
{
	unsigned char netfn;
	unsigned char lun;
	unsigned char cmd;
	unsigned char *data;
	int           data_len;
};

The driver takes care of adding/stripping the header information.  The
data portion is just the data to be send (do NOT put addressing info
here) or the response.  Note that the completion code of a response is
the first item in "data", it is not stripped out because that is how
all the messages are defined in the spec (and thus makes counting the
offsets a little easier :-).

When using the IOCTL interface from userland, you must provide a block
of data for "data", fill it, and set data_len to the length of the
block of data, even when receiving messages.  Otherwise the driver
will have no place to put the message.

Messages coming up from the message handler in kernelland will come in
as:

  struct ipmi_recv_msg
  {
	struct list_head link;

	/* The type of message as defined in the "Receive Types"
           defines above. */
	int         recv_type;

	ipmi_user_t      *user;
	struct ipmi_addr addr;
	long             msgid;
	struct ipmi_msg  msg;

	/* Call this when done with the message.  It will presumably free
	   the message and do any other necessary cleanup. */
	void (*done)(struct ipmi_recv_msg *msg);

	/* Place-holder for the data, don't make any assumptions about
	   the size or existence of this, since it may change. */
	unsigned char   msg_data[IPMI_MAX_MSG_LENGTH];
  };

You should look at the receive type and handle the message
appropriately.


The Upper Layer Interface (Message Handler)
-------------------------------------------

The upper layer of the interface provides the users with a consistent
view of the IPMI interfaces.  It allows multiple SMI interfaces to be
addressed (because some boards actually have multiple BMCs on them)
and the user should not have to care what type of SMI is below them.


Creating the User

To user the message handler, you must first create a user using
ipmi_create_user.  The interface number specifies which SMI you want
to connect to, and you must supply callback functions to be called
when data comes in.  The callback function can run at interrupt level,
so be careful using the callbacks.  This also allows to you pass in a
piece of data, the handler_data, that will be passed back to you on
all calls.

Once you are done, call ipmi_destroy_user() to get rid of the user.

From userland, opening the device automatically creates a user, and
closing the device automatically destroys the user.


Messaging

To send a message from kernel-land, the ipmi_request() call does
pretty much all message handling.  Most of the parameter are
self-explanatory.  However, it takes a "msgid" parameter.  This is NOT
the sequence number of messages.  It is simply a long value that is
passed back when the response for the message is returned.  You may
use it for anything you like.

Responses come back in the function pointed to by the ipmi_recv_hndl
field of the "handler" that you passed in to ipmi_create_user().
Remember again, these may be running at interrupt level.  Remember to
look at the receive type, too.

From userland, you fill out an ipmi_req_t structure and use the
IPMICTL_SEND_COMMAND ioctl.  For incoming stuff, you can use select()
or poll() to wait for messages to come in.  However, you cannot use
read() to get them, you must call the IPMICTL_RECEIVE_MSG with the
ipmi_recv_t structure to actually get the message.  Remember that you
must supply a pointer to a block of data in the msg.data field, and
you must fill in the msg.data_len field with the size of the data.
This gives the receiver a place to actually put the message.

If the message cannot fit into the data you provide, you will get an
EMSGSIZE error and the driver will leave the data in the receive
queue.  If you want to get it and have it truncate the message, us
the IPMICTL_RECEIVE_MSG_TRUNC ioctl.

When you send a command (which is defined by the lowest-order bit of
the netfn per the IPMI spec) on the IPMB bus, the driver will
automatically assign the sequence number to the command and save the
command.  If the response is not receive in the IPMI-specified 5
seconds, it will generate a response automatically saying the command
timed out.  If an unsolicited response comes in (if it was after 5
seconds, for instance), that response will be ignored.

In kernelland, after you receive a message and are done with it, you
MUST call ipmi_free_recv_msg() on it, or you will leak messages.  Note
that you should NEVER mess with the "done" field of a message, that is
required to properly clean up the message.

Note that when sending, there is an ipmi_request_supply_msgs() call
that lets you supply the smi and receive message.  This is useful for
pieces of code that need to work even if the system is out of buffers
(the watchdog timer uses this, for instance).  You supply your own
buffer and own free routines.  This is not recommended for normal use,
though, since it is tricky to manage your own buffers.


Events and Incoming Commands

The driver takes care of polling for IPMI events and receiving
commands (commands are messages that are not responses, they are
commands that other things on the IPMB bus have sent you).  To receive
these, you must register for them, they will not automatically be sent
to you.

To receive events, you must call ipmi_set_gets_events() and set the
"val" to non-zero.  Any events that have been received by the driver
since startup will immediately be delivered to the first user that
registers for events.  After that, if multiple users are registered
for events, they will all receive all events that come in.

For receiving commands, you have to individually register commands you
want to receive.  Call ipmi_register_for_cmd() and supply the netfn
and command name for each command you want to receive.  You also
specify a bitmask of the channels you want to receive the command from
(or use IPMI_CHAN_ALL for all channels if you don't care).  Only one
user may be registered for each netfn/cmd/channel, but different users
may register for different commands, or the same command if the
channel bitmasks do not overlap.

From userland, equivalent IOCTLs are provided to do these functions.


The Lower Layer (SMI) Interface
-------------------------------

As mentioned before, multiple SMI interfaces may be registered to the
message handler, each of these is assigned an interface number when
they register with the message handler.  They are generally assigned
in the order they register, although if an SMI unregisters and then
another one registers, all bets are off.

The ipmi_smi.h defines the interface for management interfaces, see
that for more details.


The SI Driver
-------------

The SI driver allows up to 4 KCS or SMIC interfaces to be configured
in the system.  By default, scan the ACPI tables for interfaces, and
if it doesn't find any the driver will attempt to register one KCS
interface at the spec-specified I/O port 0xca2 without interrupts.
You can change this at module load time (for a module) with:

  modprobe ipmi_si.o type=<type1>,<type2>....
       ports=<port1>,<port2>... addrs=<addr1>,<addr2>...
       irqs=<irq1>,<irq2>... trydefaults=[0|1]
       regspacings=<sp1>,<sp2>,... regsizes=<size1>,<size2>,...
       regshifts=<shift1>,<shift2>,...
       slave_addrs=<addr1>,<addr2>,...
       force_kipmid=<enable1>,<enable2>,...
       kipmid_max_busy_us=<ustime1>,<ustime2>,...
       unload_when_empty=[0|1]

Each of these except si_trydefaults is a list, the first item for the
first interface, second item for the second interface, etc.

The si_type may be either "kcs", "smic", or "bt".  If you leave it blank, it
defaults to "kcs".

If you specify si_addrs as non-zero for an interface, the driver will
use the memory address given as the address of the device.  This
overrides si_ports.

If you specify si_ports as non-zero for an interface, the driver will
use the I/O port given as the device address.

If you specify si_irqs as non-zero for an interface, the driver will
attempt to use the given interrupt for the device.

si_trydefaults sets whether the standard IPMI interface at 0xca2 and
any interfaces specified by ACPE are tried.  By default, the driver
tries it, set this value to zero to turn this off.

The next three parameters have to do with register layout.  The
registers used by the interfaces may not appear at successive
locations and they may not be in 8-bit registers.  These parameters
allow the layout of the data in the registers to be more precisely
specified.

The regspacings parameter give the number of bytes between successive
register start addresses.  For instance, if the regspacing is set to 4
and the start address is 0xca2, then the address for the second
register would be 0xca6.  This defaults to 1.

The regsizes parameter gives the size of a register, in bytes.  The
data used by IPMI is 8-bits wide, but it may be inside a larger
register.  This parameter allows the read and write type to specified.
It may be 1, 2, 4, or 8.  The default is 1.

Since the register size may be larger than 32 bits, the IPMI data may not
be in the lower 8 bits.  The regshifts parameter give the amount to shift
the data to get to the actual IPMI data.

The slave_addrs specifies the IPMI address of the local BMC.  This is
usually 0x20 and the driver defaults to that, but in case it's not, it
can be specified when the driver starts up.

The force_ipmid parameter forcefully enables (if set to 1) or disables
(if set to 0) the kernel IPMI daemon.  Normally this is auto-detected
by the driver, but systems with broken interrupts might need an enable,
or users that don't want the daemon (don't need the performance, don't
want the CPU hit) can disable it.

If unload_when_empty is set to 1, the driver will be unloaded if it
doesn't find any interfaces or all the interfaces fail to work.  The
default is one.  Setting to 0 is useful with the hotmod, but is
obviously only useful for modules.

When compiled into the kernel, the parameters can be specified on the
kernel command line as:

  ipmi_si.type=<type1>,<type2>...
       ipmi_si.ports=<port1>,<port2>... ipmi_si.addrs=<addr1>,<addr2>...
       ipmi_si.irqs=<irq1>,<irq2>... ipmi_si.trydefaults=[0|1]
       ipmi_si.regspacings=<sp1>,<sp2>,...
       ipmi_si.regsizes=<size1>,<size2>,...
       ipmi_si.regshifts=<shift1>,<shift2>,...
       ipmi_si.slave_addrs=<addr1>,<addr2>,...
       ipmi_si.force_kipmid=<enable1>,<enable2>,...
       ipmi_si.kipmid_max_busy_us=<ustime1>,<ustime2>,...

It works the same as the module parameters of the same names.

By default, the driver will attempt to detect any device specified by
ACPI, and if none of those then a KCS device at the spec-specified
0xca2.  If you want to turn this off, set the "trydefaults" option to
false.

If your IPMI interface does not support interrupts and is a KCS or
SMIC interface, the IPMI driver will start a kernel thread for the
interface to help speed things up.  This is a low-priority kernel
thread that constantly polls the IPMI driver while an IPMI operation
is in progress.  The force_kipmid module parameter will all the user to
force this thread on or off.  If you force it off and don't have
interrupts, the driver will run VERY slowly.  Don't blame me,
these interfaces suck.

Unfortunately, this thread can use a lot of CPU depending on the
interface's performance.  This can waste a lot of CPU and cause
various issues with detecting idle CPU and using extra power.  To
avoid this, the kipmid_max_busy_us sets the maximum amount of time, in
microseconds, that kipmid will spin before sleeping for a tick.  This
value sets a balance between performance and CPU waste and needs to be
tuned to your needs.  Maybe, someday, auto-tuning will be added, but
that's not a simple thing and even the auto-tuning would need to be
tuned to the user's desired performance.

The driver supports a hot add and remove of interfaces.  This way,
interfaces can be added or removed after the kernel is up and running.
This is done using /sys/modules/ipmi_si/parameters/hotmod, which is a
write-only parameter.  You write a string to this interface.  The string
has the format:
   <op1>[:op2[:op3...]]
The "op"s are:
   add|remove,kcs|bt|smic,mem|i/o,<address>[,<opt1>[,<opt2>[,...]]]
You can specify more than one interface on the line.  The "opt"s are:
   rsp=<regspacing>
   rsi=<regsize>
   rsh=<regshift>
   irq=<irq>
   ipmb=<ipmb slave addr>
and these have the same meanings as discussed above.  Note that you
can also use this on the kernel command line for a more compact format
for specifying an interface.  Note that when removing an interface,
only the first three parameters (si type, address type, and address)
are used for the comparison.  Any options are ignored for removing.

The SMBus Driver
----------------

The SMBus driver allows up to 4 SMBus devices to be configured in the
system.  By default, the driver will register any SMBus interfaces it finds
in the I2C address range of 0x20 to 0x4f on any adapter.  You can change this
at module load time (for a module) with:

  modprobe ipmi_smb.o
	addr=<adapter1>,<i2caddr1>[,<adapter2>,<i2caddr2>[,...]]
	dbg=<flags1>,<flags2>...
	[defaultprobe=1] [dbg_probe=1]

The addresses are specified in pairs, the first is the adapter ID and the
second is the I2C address on that adapter.

The debug flags are bit flags for each BMC found, they are:
IPMI messages: 1, driver state: 2, timing: 4, I2C probe: 8

Setting smb_defaultprobe to zero disabled the default probing of SMBus
interfaces at address range 0x20 to 0x4f.  This means that only the
BMCs specified on the smb_addr line will be detected.

Setting smb_dbg_probe to 1 will enable debugging of the probing and
detection process for BMCs on the SMBusses.

Discovering the IPMI compliant BMC on the SMBus can cause devices
on the I2C bus to fail. The SMBus driver writes a "Get Device ID" IPMI
message as a block write to the I2C bus and waits for a response.
This action can be detrimental to some I2C devices. It is highly recommended
that the known I2c address be given to the SMBus driver in the smb_addr
parameter. The default address range will not be used when a smb_addr
parameter is provided.

When compiled into the kernel, the addresses can be specified on the
kernel command line as:

  ipmb_smb.addr=<adapter1>,<i2caddr1>[,<adapter2>,<i2caddr2>[,...]]
	ipmi_smb.dbg=<flags1>,<flags2>...
	ipmi_smb.defaultprobe=0 ipmi_smb.dbg_probe=1

These are the same options as on the module command line.

Note that you might need some I2C changes if CONFIG_IPMI_PANIC_EVENT
is enabled along with this, so the I2C driver knows to run to
completion during sending a panic event.


Other Pieces
------------

Get the detailed info related with the IPMI device
--------------------------------------------------

Some users need more detailed information about a device, like where
the address came from or the raw base device for the IPMI interface.
You can use the IPMI smi_watcher to catch the IPMI interfaces as they
come or go, and to grab the information, you can use the function
ipmi_get_smi_info(), which returns the following structure:

struct ipmi_smi_info {
	enum ipmi_addr_src addr_src;
	struct device *dev;
	union {
		struct {
			void *acpi_handle;
		} acpi_info;
	} addr_info;
};

Currently special info for only for SI_ACPI address sources is
returned.  Others may be added as necessary.

Note that the dev pointer is included in the above structure, and
assuming ipmi_smi_get_info returns success, you must call put_device
on the dev pointer.


Watchdog
--------

A watchdog timer is provided that implements the Linux-standard
watchdog timer interface.  It has three module parameters that can be
used to control it:

  modprobe ipmi_watchdog timeout=<t> pretimeout=<t> action=<action type>
      preaction=<preaction type> preop=<preop type> start_now=x
      nowayout=x ifnum_to_use=n

ifnum_to_use specifies which interface the watchdog timer should use.
The default is -1, which means to pick the first one registered.

The timeout is the number of seconds to the action, and the pretimeout
is the amount of seconds before the reset that the pre-timeout panic will
occur (if pretimeout is zero, then pretimeout will not be enabled).  Note
that the pretimeout is the time before the final timeout.  So if the
timeout is 50 seconds and the pretimeout is 10 seconds, then the pretimeout
will occur in 40 second (10 seconds before the timeout).

The action may be "reset", "power_cycle", or "power_off", and
specifies what to do when the timer times out, and defaults to
"reset".

The preaction may be "pre_smi" for an indication through the SMI
interface, "pre_int" for an indication through the SMI with an
interrupts, and "pre_nmi" for a NMI on a preaction.  This is how
the driver is informed of the pretimeout.

The preop may be set to "preop_none" for no operation on a pretimeout,
"preop_panic" to set the preoperation to panic, or "preop_give_data"
to provide data to read from the watchdog device when the pretimeout
occurs.  A "pre_nmi" setting CANNOT be used with "preop_give_data"
because you can't do data operations from an NMI.

When preop is set to "preop_give_data", one byte comes ready to read
on the device when the pretimeout occurs.  Select and fasync work on
the device, as well.

If start_now is set to 1, the watchdog timer will start running as
soon as the driver is loaded.

If nowayout is set to 1, the watchdog timer will not stop when the
watchdog device is closed.  The default value of nowayout is true
if the CONFIG_WATCHDOG_NOWAYOUT option is enabled, or false if not.

When compiled into the kernel, the kernel command line is available
for configuring the watchdog:

  ipmi_watchdog.timeout=<t> ipmi_watchdog.pretimeout=<t>
	ipmi_watchdog.action=<action type>
	ipmi_watchdog.preaction=<preaction type>
	ipmi_watchdog.preop=<preop type>
	ipmi_watchdog.start_now=x
	ipmi_watchdog.nowayout=x

The options are the same as the module parameter options.

The watchdog will panic and start a 120 second reset timeout if it
gets a pre-action.  During a panic or a reboot, the watchdog will
start a 120 timer if it is running to make sure the reboot occurs.

Note that if you use the NMI preaction for the watchdog, you MUST NOT
use the nmi watchdog.  There is no reasonable way to tell if an NMI
comes from the IPMI controller, so it must assume that if it gets an
otherwise unhandled NMI, it must be from IPMI and it will panic
immediately.

Once you open the watchdog timer, you must write a 'V' character to the
device to close it, or the timer will not stop.  This is a new semantic
for the driver, but makes it consistent with the rest of the watchdog
drivers in Linux.


Panic Timeouts
--------------

The OpenIPMI driver supports the ability to put semi-custom and custom
events in the system event log if a panic occurs.  if you enable the
'Generate a panic event to all BMCs on a panic' option, you will get
one event on a panic in a standard IPMI event format.  If you enable
the 'Generate OEM events containing the panic string' option, you will
also get a bunch of OEM events holding the panic string.


The field settings of the events are:
* Generator ID: 0x21 (kernel)
* EvM Rev: 0x03 (this event is formatting in IPMI 1.0 format)
* Sensor Type: 0x20 (OS critical stop sensor)
* Sensor #: The first byte of the panic string (0 if no panic string)
* Event Dir | Event Type: 0x6f (Assertion, sensor-specific event info)
* Event Data 1: 0xa1 (Runtime stop in OEM bytes 2 and 3)
* Event data 2: second byte of panic string
* Event data 3: third byte of panic string
See the IPMI spec for the details of the event layout.  This event is
always sent to the local management controller.  It will handle routing
the message to the right place

Other OEM events have the following format:
Record ID (bytes 0-1): Set by the SEL.
Record type (byte 2): 0xf0 (OEM non-timestamped)
byte 3: The slave address of the card saving the panic
byte 4: A sequence number (starting at zero)
The rest of the bytes (11 bytes) are the panic string.  If the panic string
is longer than 11 bytes, multiple messages will be sent with increasing
sequence numbers.

Because you cannot send OEM events using the standard interface, this
function will attempt to find an SEL and add the events there.  It
will first query the capabilities of the local management controller.
If it has an SEL, then they will be stored in the SEL of the local
management controller.  If not, and the local management controller is
an event generator, the event receiver from the local management
controller will be queried and the events sent to the SEL on that
device.  Otherwise, the events go nowhere since there is nowhere to
send them.


Poweroff
--------

If the poweroff capability is selected, the IPMI driver will install
a shutdown function into the standard poweroff function pointer.  This
is in the ipmi_poweroff module.  When the system requests a powerdown,
it will send the proper IPMI commands to do this.  This is supported on
several platforms.

There is a module parameter named "poweroff_powercycle" that may
either be zero (do a power down) or non-zero (do a power cycle, power
the system off, then power it on in a few seconds).  Setting
ipmi_poweroff.poweroff_control=x will do the same thing on the kernel
command line.  The parameter is also available via the proc filesystem
in /proc/sys/dev/ipmi/poweroff_powercycle.  Note that if the system
does not support power cycling, it will always do the power off.

The "ifnum_to_use" parameter specifies which interface the poweroff
code should use.  The default is -1, which means to pick the first one
registered.

Note that if you have ACPI enabled, the system will prefer using ACPI to
power off.
ChangeLog:
	Started by Ingo Molnar <mingo@redhat.com>
	Update by Max Krasnyansky <maxk@qualcomm.com>

SMP IRQ affinity

/proc/irq/IRQ#/smp_affinity and /proc/irq/IRQ#/smp_affinity_list specify
which target CPUs are permitted for a given IRQ source.  It's a bitmask
(smp_affinity) or cpu list (smp_affinity_list) of allowed CPUs.  It's not
allowed to turn off all CPUs, and if an IRQ controller does not support
IRQ affinity then the value will not change from the default of all cpus.

/proc/irq/default_smp_affinity specifies default affinity mask that applies
to all non-active IRQs. Once IRQ is allocated/activated its affinity bitmask
will be set to the default mask. It can then be changed as described above.
Default mask is 0xffffffff.

Here is an example of restricting IRQ44 (eth1) to CPU0-3 then restricting
it to CPU4-7 (this is an 8-CPU SMP box):

[root@moon 44]# cd /proc/irq/44
[root@moon 44]# cat smp_affinity
ffffffff

[root@moon 44]# echo 0f > smp_affinity
[root@moon 44]# cat smp_affinity
0000000f
[root@moon 44]# ping -f h
PING hell (195.4.7.3): 56 data bytes
...
--- hell ping statistics ---
6029 packets transmitted, 6027 packets received, 0% packet loss
round-trip min/avg/max = 0.1/0.1/0.4 ms
[root@moon 44]# cat /proc/interrupts | grep 'CPU\|44:'
           CPU0       CPU1       CPU2       CPU3      CPU4       CPU5        CPU6       CPU7
 44:       1068       1785       1785       1783         0          0           0         0    IO-APIC-level  eth1

As can be seen from the line above IRQ44 was delivered only to the first four
processors (0-3).
Now lets restrict that IRQ to CPU(4-7).

[root@moon 44]# echo f0 > smp_affinity
[root@moon 44]# cat smp_affinity
000000f0
[root@moon 44]# ping -f h
PING hell (195.4.7.3): 56 data bytes
..
--- hell ping statistics ---
2779 packets transmitted, 2777 packets received, 0% packet loss
round-trip min/avg/max = 0.1/0.5/585.4 ms
[root@moon 44]# cat /proc/interrupts |  'CPU\|44:'
           CPU0       CPU1       CPU2       CPU3      CPU4       CPU5        CPU6       CPU7
 44:       1068       1785       1785       1783      1784       1069        1070       1069   IO-APIC-level  eth1

This time around IRQ44 was delivered only to the last four processors.
i.e counters for the CPU0-3 did not change.

Here is an example of limiting that same irq (44) to cpus 1024 to 1031:

[root@moon 44]# echo 1024-1031 > smp_affinity
[root@moon 44]# cat smp_affinity
1024-1031

Note that to do this with a bitmask would require 32 bitmasks of zero
to follow the pertinent one.
IRQ-flags state tracing

started by Ingo Molnar <mingo@redhat.com>

the "irq-flags tracing" feature "traces" hardirq and softirq state, in
that it gives interested subsystems an opportunity to be notified of
every hardirqs-off/hardirqs-on, softirqs-off/softirqs-on event that
happens in the kernel.

CONFIG_TRACE_IRQFLAGS_SUPPORT is needed for CONFIG_PROVE_SPIN_LOCKING
and CONFIG_PROVE_RW_LOCKING to be offered by the generic lock debugging
code. Otherwise only CONFIG_PROVE_MUTEX_LOCKING and
CONFIG_PROVE_RWSEM_LOCKING will be offered on an architecture - these
are locking APIs that are not used in IRQ context. (the one exception
for rwsems is worked around)

architecture support for this is certainly not in the "trivial"
category, because lots of lowlevel assembly code deal with irq-flags
state changes. But an architecture can be irq-flags-tracing enabled in a
rather straightforward and risk-free manner.

Architectures that want to support this need to do a couple of
code-organizational changes first:

- move their irq-flags manipulation code from their asm/system.h header
  to asm/irqflags.h

- rename local_irq_disable()/etc to raw_local_irq_disable()/etc. so that
  the linux/irqflags.h code can inject callbacks and can construct the
  real local_irq_disable()/etc APIs.

- add and enable TRACE_IRQFLAGS_SUPPORT in their arch level Kconfig file

and then a couple of functional changes are needed as well to implement
irq-flags-tracing support:

- in lowlevel entry code add (build-conditional) calls to the
  trace_hardirqs_off()/trace_hardirqs_on() functions. The lock validator
  closely guards whether the 'real' irq-flags matches the 'virtual'
  irq-flags state, and complains loudly (and turns itself off) if the
  two do not match. Usually most of the time for arch support for
  irq-flags-tracing is spent in this state: look at the lockdep
  complaint, try to figure out the assembly code we did not cover yet,
  fix and repeat. Once the system has booted up and works without a
  lockdep complaint in the irq-flags-tracing functions arch support is
  complete.
- if the architecture has non-maskable interrupts then those need to be
  excluded from the irq-tracing [and lock validation] mechanism via
  lockdep_off()/lockdep_on().

in general there is no risk from having an incomplete irq-flags-tracing
implementation in an architecture: lockdep will detect that and will
turn itself off. I.e. the lock validator will still be reliable. There
should be no crashes due to irq-tracing bugs. (except if the assembly
changes break other code by modifying conditions or registers that
shouldn't be)

What is an IRQ?

An IRQ is an interrupt request from a device.
Currently they can come in over a pin, or over a packet.
Several devices may be connected to the same pin thus
sharing an IRQ.

An IRQ number is a kernel identifier used to talk about a hardware
interrupt source.  Typically this is an index into the global irq_desc
array, but except for what linux/interrupt.h implements the details
are architecture specific.

An IRQ number is an enumeration of the possible interrupt sources on a
machine.  Typically what is enumerated is the number of input pins on
all of the interrupt controller in the system.  In the case of ISA
what is enumerated are the 16 input pins on the two i8259 interrupt
controllers.

Architectures can assign additional meaning to the IRQ numbers, and
are encouraged to in the case  where there is any manual configuration
of the hardware involved.  The ISA IRQs are a classic example of
assigning this kind of additional meaning.
ISA Plug & Play support by Jaroslav Kysela <perex@suse.cz>
==========================================================

Interface /proc/isapnp
======================

The interface has been removed. See pnp.txt for more details.

Interface /proc/bus/isapnp
==========================

This directory allows access to ISA PnP cards and logical devices.
The regular files contain the contents of ISA PnP registers for
a logical device.
kernel-doc nano-HOWTO
=====================

How to format kernel-doc comments
---------------------------------

In order to provide embedded, 'C' friendly, easy to maintain,
but consistent and extractable documentation of the functions and
data structures in the Linux kernel, the Linux kernel has adopted
a consistent style for documenting functions and their parameters,
and structures and their members.

The format for this documentation is called the kernel-doc format.
It is documented in this Documentation/kernel-doc-nano-HOWTO.txt file.

This style embeds the documentation within the source files, using
a few simple conventions.  The scripts/kernel-doc perl script, some
SGML templates in Documentation/DocBook, and other tools understand
these conventions, and are used to extract this embedded documentation
into various documents.

In order to provide good documentation of kernel functions and data
structures, please use the following conventions to format your
kernel-doc comments in Linux kernel source.

We definitely need kernel-doc formatted documentation for functions
that are exported to loadable modules using EXPORT_SYMBOL.

We also look to provide kernel-doc formatted documentation for
functions externally visible to other kernel files (not marked
"static").

We also recommend providing kernel-doc formatted documentation
for private (file "static") routines, for consistency of kernel
source code layout.  But this is lower priority and at the
discretion of the MAINTAINER of that kernel source file.

Data structures visible in kernel include files should also be
documented using kernel-doc formatted comments.

The opening comment mark "/**" is reserved for kernel-doc comments.
Only comments so marked will be considered by the kernel-doc scripts,
and any comment so marked must be in kernel-doc format.  Do not use
"/**" to be begin a comment block unless the comment block contains
kernel-doc formatted comments.  The closing comment marker for
kernel-doc comments can be either "*/" or "**/", but "*/" is
preferred in the Linux kernel tree.

Kernel-doc comments should be placed just before the function
or data structure being described.

Example kernel-doc function comment:

/**
 * foobar() - short function description of foobar
 * @arg1:	Describe the first argument to foobar.
 * @arg2:	Describe the second argument to foobar.
 *		One can provide multiple line descriptions
 *		for arguments.
 *
 * A longer description, with more discussion of the function foobar()
 * that might be useful to those using or modifying it.  Begins with
 * empty comment line, and may include additional embedded empty
 * comment lines.
 *
 * The longer description can have multiple paragraphs.
 */

The short description following the subject can span multiple lines
and ends with an @argument description, an empty line or the end of
the comment block.

The @argument descriptions must begin on the very next line following
this opening short function description line, with no intervening
empty comment lines.

If a function parameter is "..." (varargs), it should be listed in
kernel-doc notation as:
 * @...: description


Example kernel-doc data structure comment.

/**
 * struct blah - the basic blah structure
 * @mem1:	describe the first member of struct blah
 * @mem2:	describe the second member of struct blah,
 *		perhaps with more lines and words.
 *
 * Longer description of this structure.
 */

The kernel-doc function comments describe each parameter to the
function, in order, with the @name lines.

The kernel-doc data structure comments describe each structure member
in the data structure, with the @name lines.

The longer description formatting is "reflowed", losing your line
breaks.  So presenting carefully formatted lists within these
descriptions won't work so well; derived documentation will lose
the formatting.

See the section below "How to add extractable documentation to your
source files" for more details and notes on how to format kernel-doc
comments.

Components of the kernel-doc system
-----------------------------------

Many places in the source tree have extractable documentation in the
form of block comments above functions.  The components of this system
are:

- scripts/kernel-doc

  This is a perl script that hunts for the block comments and can mark
  them up directly into DocBook, man, text, and HTML. (No, not
  texinfo.)

- Documentation/DocBook/*.tmpl

  These are SGML template files, which are normal SGML files with
  special place-holders for where the extracted documentation should
  go.

- scripts/basic/docproc.c

  This is a program for converting SGML template files into SGML
  files. When a file is referenced it is searched for symbols
  exported (EXPORT_SYMBOL), to be able to distinguish between internal
  and external functions.
  It invokes kernel-doc, giving it the list of functions that
  are to be documented.
  Additionally it is used to scan the SGML template files to locate
  all the files referenced herein. This is used to generate dependency
  information as used by make.

- Makefile

  The targets 'sgmldocs', 'psdocs', 'pdfdocs', and 'htmldocs' are used
  to build DocBook files, PostScript files, PDF files, and html files
  in Documentation/DocBook.

- Documentation/DocBook/Makefile

  This is where C files are associated with SGML templates.


How to extract the documentation
--------------------------------

If you just want to read the ready-made books on the various
subsystems (see Documentation/DocBook/*.tmpl), just type 'make
psdocs', or 'make pdfdocs', or 'make htmldocs', depending on your
preference.  If you would rather read a different format, you can type
'make sgmldocs' and then use DocBook tools to convert
Documentation/DocBook/*.sgml to a format of your choice (for example,
'db2html ...' if 'make htmldocs' was not defined).

If you want to see man pages instead, you can do this:

$ cd linux
$ scripts/kernel-doc -man $(find -name '*.c') | split-man.pl /tmp/man
$ scripts/kernel-doc -man $(find -name '*.h') | split-man.pl /tmp/man

Here is split-man.pl:

-->
#!/usr/bin/perl

if ($#ARGV < 0) {
   die "where do I put the results?\n";
}

mkdir $ARGV[0],0777;
$state = 0;
while (<STDIN>) {
    if (/^\.TH \"[^\"]*\" 9 \"([^\"]*)\"/) {
	if ($state == 1) { close OUT }
	$state = 1;
	$fn = "$ARGV[0]/$1.9";
	print STDERR "Creating $fn\n";
	open OUT, ">$fn" or die "can't open $fn: $!\n";
	print OUT $_;
    } elsif ($state != 0) {
	print OUT $_;
    }
}

close OUT;
<--

If you just want to view the documentation for one function in one
file, you can do this:

$ scripts/kernel-doc -man -function fn file | nroff -man | less

or this:

$ scripts/kernel-doc -text -function fn file


How to add extractable documentation to your source files
---------------------------------------------------------

The format of the block comment is like this:

/**
 * function_name(:)? (- short description)?
(* @parameterx(space)*: (description of parameter x)?)*
(* a blank line)?
 * (Description:)? (Description of function)?
 * (section header: (section description)? )*
(*)?*/

All "description" text can span multiple lines, although the
function_name & its short description are traditionally on a single line.
Description text may also contain blank lines (i.e., lines that contain
only a "*").

"section header:" names must be unique per function (or struct,
union, typedef, enum).

Avoid putting a spurious blank line after the function name, or else the
description will be repeated!

All descriptive text is further processed, scanning for the following special
patterns, which are highlighted appropriately.

'funcname()' - function
'$ENVVAR' - environment variable
'&struct_name' - name of a structure (up to two words including 'struct')
'@parameter' - name of a parameter
'%CONST' - name of a constant.

NOTE 1:  The multi-line descriptive text you provide does *not* recognize
line breaks, so if you try to format some text nicely, as in:

  Return codes
    0 - cool
    1 - invalid arg
    2 - out of memory

this will all run together and produce:

  Return codes 0 - cool 1 - invalid arg 2 - out of memory

NOTE 2:  If the descriptive text you provide has lines that begin with
some phrase followed by a colon, each of those phrases will be taken as
a new section heading, which means you should similarly try to avoid text
like:

  Return codes:
    0: cool
    1: invalid arg
    2: out of memory

every line of which would start a new section.  Again, probably not
what you were after.

Take a look around the source tree for examples.


kernel-doc for structs, unions, enums, and typedefs
---------------------------------------------------

Beside functions you can also write documentation for structs, unions,
enums and typedefs. Instead of the function name you must write the name
of the declaration;  the struct/union/enum/typedef must always precede
the name. Nesting of declarations is not supported.
Use the argument mechanism to document members or constants.

Inside a struct description, you can use the "private:" and "public:"
comment tags.  Structure fields that are inside a "private:" area
are not listed in the generated output documentation.  The "private:"
and "public:" tags must begin immediately following a "/*" comment
marker.  They may optionally include comments between the ":" and the
ending "*/" marker.

Example:

/**
 * struct my_struct - short description
 * @a: first member
 * @b: second member
 *
 * Longer description
 */
struct my_struct {
    int a;
    int b;
/* private: internal use only */
    int c;
};


Including documentation blocks in source files
----------------------------------------------

To facilitate having source code and comments close together, you can
include kernel-doc documentation blocks that are free-form comments
instead of being kernel-doc for functions, structures, unions,
enums, or typedefs.  This could be used for something like a
theory of operation for a driver or library code, for example.

This is done by using a DOC: section keyword with a section title.  E.g.:

/**
 * DOC: Theory of Operation
 *
 * The whizbang foobar is a dilly of a gizmo.  It can do whatever you
 * want it to do, at any time.  It reads your mind.  Here's how it works.
 *
 * foo bar splat
 *
 * The only drawback to this gizmo is that is can sometimes damage
 * hardware, software, or its subject(s).
 */

DOC: sections are used in SGML templates files as indicated below.


How to make new SGML template files
-----------------------------------

SGML template files (*.tmpl) are like normal SGML files, except that
they can contain escape sequences where extracted documentation should
be inserted.

!E<filename> is replaced by the documentation, in <filename>, for
functions that are exported using EXPORT_SYMBOL: the function list is
collected from files listed in Documentation/DocBook/Makefile.

!I<filename> is replaced by the documentation for functions that are
_not_ exported using EXPORT_SYMBOL.

!D<filename> is used to name additional files to search for functions
exported using EXPORT_SYMBOL.

!F<filename> <function [functions...]> is replaced by the
documentation, in <filename>, for the functions listed.

!P<filename> <section title> is replaced by the contents of the DOC:
section titled <section title> from <filename>.
Spaces are allowed in <section title>; do not quote the <section title>.

!C<filename> is replaced by nothing, but makes the tools check that
all DOC: sections and documented functions, symbols, etc. are used.
This makes sense to use when you use !F/!P only and want to verify
that all documentation is included.

Tim.
*/ <twaugh@redhat.com>
                          Kernel Parameters
                          ~~~~~~~~~~~~~~~~~

The following is a consolidated list of the kernel parameters as implemented
(mostly) by the __setup() macro and sorted into English Dictionary order
(defined as ignoring all punctuation and sorting digits before letters in a
case insensitive manner), and with descriptions where known.

Module parameters for loadable modules are specified only as the
parameter name with optional '=' and value as appropriate, such as:

	modprobe usbcore blinkenlights=1

Module parameters for modules that are built into the kernel image
are specified on the kernel command line with the module name plus
'.' plus parameter name, with '=' and value if appropriate, such as:

	usbcore.blinkenlights=1

Hyphens (dashes) and underscores are equivalent in parameter names, so
	log_buf_len=1M print-fatal-signals=1
can also be entered as
	log-buf-len=1M print_fatal_signals=1


This document may not be entirely up to date and comprehensive. The command
"modinfo -p ${modulename}" shows a current list of all parameters of a loadable
module. Loadable modules, after being loaded into the running kernel, also
reveal their parameters in /sys/module/${modulename}/parameters/. Some of these
parameters may be changed at runtime by the command
"echo -n ${value} > /sys/module/${modulename}/parameters/${parm}".

The parameters listed below are only valid if certain kernel build options were
enabled and if respective hardware is present. The text in square brackets at
the beginning of each description states the restrictions within which a
parameter is applicable:

	ACPI	ACPI support is enabled.
	AGP	AGP (Accelerated Graphics Port) is enabled.
	ALSA	ALSA sound support is enabled.
	APIC	APIC support is enabled.
	APM	Advanced Power Management support is enabled.
	AVR32	AVR32 architecture is enabled.
	AX25	Appropriate AX.25 support is enabled.
	BLACKFIN Blackfin architecture is enabled.
	DRM	Direct Rendering Management support is enabled.
	DYNAMIC_DEBUG Build in debug messages and enable them at runtime
	EDD	BIOS Enhanced Disk Drive Services (EDD) is enabled
	EFI	EFI Partitioning (GPT) is enabled
	EIDE	EIDE/ATAPI support is enabled.
	FB	The frame buffer device is enabled.
	GCOV	GCOV profiling is enabled.
	HW	Appropriate hardware is enabled.
	IA-64	IA-64 architecture is enabled.
	IMA     Integrity measurement architecture is enabled.
	IOSCHED	More than one I/O scheduler is enabled.
	IP_PNP	IP DHCP, BOOTP, or RARP is enabled.
	IPV6	IPv6 support is enabled.
	ISAPNP	ISA PnP code is enabled.
	ISDN	Appropriate ISDN support is enabled.
	JOY	Appropriate joystick support is enabled.
	KGDB	Kernel debugger support is enabled.
	KVM	Kernel Virtual Machine support is enabled.
	LIBATA  Libata driver is enabled
	LP	Printer support is enabled.
	LOOP	Loopback device support is enabled.
	M68k	M68k architecture is enabled.
			These options have more detailed description inside of
			Documentation/m68k/kernel-options.txt.
	MCA	MCA bus support is enabled.
	MDA	MDA console support is enabled.
	MOUSE	Appropriate mouse support is enabled.
	MSI	Message Signaled Interrupts (PCI).
	MTD	MTD (Memory Technology Device) support is enabled.
	NET	Appropriate network support is enabled.
	NUMA	NUMA support is enabled.
	NFS	Appropriate NFS support is enabled.
	OSS	OSS sound support is enabled.
	PV_OPS	A paravirtualized kernel is enabled.
	PARIDE	The ParIDE (parallel port IDE) subsystem is enabled.
	PARISC	The PA-RISC architecture is enabled.
	PCI	PCI bus support is enabled.
	PCIE	PCI Express support is enabled.
	PCMCIA	The PCMCIA subsystem is enabled.
	PNP	Plug & Play support is enabled.
	PPC	PowerPC architecture is enabled.
	PPT	Parallel port support is enabled.
	PS2	Appropriate PS/2 support is enabled.
	RAM	RAM disk support is enabled.
	S390	S390 architecture is enabled.
	SCSI	Appropriate SCSI support is enabled.
			A lot of drivers have their options described inside
			the Documentation/scsi/ sub-directory.
	SECURITY Different security models are enabled.
	SELINUX SELinux support is enabled.
	APPARMOR AppArmor support is enabled.
	SERIAL	Serial support is enabled.
	SH	SuperH architecture is enabled.
	SMP	The kernel is an SMP kernel.
	SPARC	Sparc architecture is enabled.
	SWSUSP	Software suspend (hibernation) is enabled.
	SUSPEND	System suspend states are enabled.
	FTRACE	Function tracing enabled.
	TPM	TPM drivers are enabled.
	TS	Appropriate touchscreen support is enabled.
	UMS	USB Mass Storage support is enabled.
	USB	USB support is enabled.
	USBHID	USB Human Interface Device support is enabled.
	V4L	Video For Linux support is enabled.
	VGA	The VGA console has been enabled.
	VT	Virtual terminal support is enabled.
	WDT	Watchdog support is enabled.
	XT	IBM PC/XT MFM hard disk support is enabled.
	X86-32	X86-32, aka i386 architecture is enabled.
	X86-64	X86-64 architecture is enabled.
			More X86-64 boot options can be found in
			Documentation/x86/x86_64/boot-options.txt .
	X86	Either 32bit or 64bit x86 (same as X86-32+X86-64)
	XEN	Xen support is enabled

In addition, the following text indicates that the option:

	BUGS=	Relates to possible processor bugs on the said processor.
	KNL	Is a kernel start-up parameter.
	BOOT	Is a boot loader parameter.

Parameters denoted with BOOT are actually interpreted by the boot
loader, and have no meaning to the kernel directly.
Do not modify the syntax of boot loader parameters without extreme
need or coordination with <Documentation/x86/boot.txt>.

There are also arch-specific kernel-parameters not documented here.
See for example <Documentation/x86/x86_64/boot-options.txt>.

Note that ALL kernel parameters listed below are CASE SENSITIVE, and that
a trailing = on the name of any parameter states that that parameter will
be entered as an environment variable, whereas its absence indicates that
it will appear as a kernel argument readable via /proc/cmdline by programs
running once the system is up.

The number of kernel parameters is not limited, but the length of the
complete command line (parameters including spaces etc.) is limited to
a fixed number of characters. This limit depends on the architecture
and is between 256 and 4096 characters. It is defined in the file
./include/asm/setup.h as COMMAND_LINE_SIZE.

Finally, the [KMG] suffix is commonly described after a number of kernel
parameter values. These 'K', 'M', and 'G' letters represent the _binary_
multipliers 'Kilo', 'Mega', and 'Giga', equalling 2^10, 2^20, and 2^30
bytes respectively. Such letter suffixes can also be entirely omitted.


	acpi=		[HW,ACPI,X86]
			Advanced Configuration and Power Interface
			Format: { force | off | strict | noirq | rsdt }
			force -- enable ACPI if default was off
			off -- disable ACPI if default was on
			noirq -- do not use ACPI for IRQ routing
			strict -- Be less tolerant of platforms that are not
				strictly ACPI specification compliant.
			rsdt -- prefer RSDT over (default) XSDT
			copy_dsdt -- copy DSDT to memory

			See also Documentation/power/pm.txt, pci=noacpi

	acpi_apic_instance=	[ACPI, IOAPIC]
			Format: <int>
			2: use 2nd APIC table, if available
			1,0: use 1st APIC table
			default: 0

	acpi_backlight=	[HW,ACPI]
			acpi_backlight=vendor
			acpi_backlight=video
			If set to vendor, prefer vendor specific driver
			(e.g. thinkpad_acpi, sony_acpi, etc.) instead
			of the ACPI video.ko driver.

	acpi.debug_layer=	[HW,ACPI,ACPI_DEBUG]
	acpi.debug_level=	[HW,ACPI,ACPI_DEBUG]
			Format: <int>
			CONFIG_ACPI_DEBUG must be enabled to produce any ACPI
			debug output.  Bits in debug_layer correspond to a
			_COMPONENT in an ACPI source file, e.g.,
			    #define _COMPONENT ACPI_PCI_COMPONENT
			Bits in debug_level correspond to a level in
			ACPI_DEBUG_PRINT statements, e.g.,
			    ACPI_DEBUG_PRINT((ACPI_DB_INFO, ...
			The debug_level mask defaults to "info".  See
			Documentation/acpi/debug.txt for more information about
			debug layers and levels.

			Enable processor driver info messages:
			    acpi.debug_layer=0x20000000
			Enable PCI/PCI interrupt routing info messages:
			    acpi.debug_layer=0x400000
			Enable AML "Debug" output, i.e., stores to the Debug
			object while interpreting AML:
			    acpi.debug_layer=0xffffffff acpi.debug_level=0x2
			Enable all messages related to ACPI hardware:
			    acpi.debug_layer=0x2 acpi.debug_level=0xffffffff

			Some values produce so much output that the system is
			unusable.  The "log_buf_len" parameter may be useful
			if you need to capture more output.

	acpi_irq_balance [HW,ACPI]
			ACPI will balance active IRQs
			default in APIC mode

	acpi_irq_nobalance [HW,ACPI]
			ACPI will not move active IRQs (default)
			default in PIC mode

	acpi_irq_isa=	[HW,ACPI] If irq_balance, mark listed IRQs used by ISA
			Format: <irq>,<irq>...

	acpi_irq_pci=	[HW,ACPI] If irq_balance, clear listed IRQs for
			use by PCI
			Format: <irq>,<irq>...

	acpi_no_auto_ssdt	[HW,ACPI] Disable automatic loading of SSDT

	acpi_os_name=	[HW,ACPI] Tell ACPI BIOS the name of the OS
			Format: To spoof as Windows 98: ="Microsoft Windows"

	acpi_osi=	[HW,ACPI] Modify list of supported OS interface strings
			acpi_osi="string1"	# add string1 -- only one string
			acpi_osi="!string2"	# remove built-in string2
			acpi_osi=		# disable all strings

	acpi_pm_good	[X86]
			Override the pmtimer bug detection: force the kernel
			to assume that this machine's pmtimer latches its value
			and always returns good values.

	acpi_sci=	[HW,ACPI] ACPI System Control Interrupt trigger mode
			Format: { level | edge | high | low }

	acpi_serialize	[HW,ACPI] force serialization of AML methods

	acpi_skip_timer_override [HW,ACPI]
			Recognize and ignore IRQ0/pin2 Interrupt Override.
			For broken nForce2 BIOS resulting in XT-PIC timer.

	acpi_sleep=	[HW,ACPI] Sleep options
			Format: { s3_bios, s3_mode, s3_beep, s4_nohwsig,
				  old_ordering, nonvs, sci_force_enable }
			See Documentation/power/video.txt for information on
			s3_bios and s3_mode.
			s3_beep is for debugging; it makes the PC's speaker beep
			as soon as the kernel's real-mode entry point is called.
			s4_nohwsig prevents ACPI hardware signature from being
			used during resume from hibernation.
			old_ordering causes the ACPI 1.0 ordering of the _PTS
			control method, with respect to putting devices into
			low power states, to be enforced (the ACPI 2.0 ordering
			of _PTS is used by default).
			nonvs prevents the kernel from saving/restoring the
			ACPI NVS memory during suspend/hibernation and resume.
			sci_force_enable causes the kernel to set SCI_EN directly
			on resume from S1/S3 (which is against the ACPI spec,
			but some broken systems don't work without it).

	acpi_use_timer_override [HW,ACPI]
			Use timer override. For some broken Nvidia NF5 boards
			that require a timer override, but don't have HPET

	acpi_enforce_resources=	[ACPI]
			{ strict | lax | no }
			Check for resource conflicts between native drivers
			and ACPI OperationRegions (SystemIO and SystemMemory
			only). IO ports and memory declared in ACPI might be
			used by the ACPI subsystem in arbitrary AML code and
			can interfere with legacy drivers.
			strict (default): access to resources claimed by ACPI
			is denied; legacy drivers trying to access reserved
			resources will fail to bind to device using them.
			lax: access to resources claimed by ACPI is allowed;
			legacy drivers trying to access reserved resources
			will bind successfully but a warning message is logged.
			no: ACPI OperationRegions are not marked as reserved,
			no further checks are performed.

	add_efi_memmap	[EFI; X86] Include EFI memory map in
			kernel's map of available physical RAM.

	agp=		[AGP]
			{ off | try_unsupported }
			off: disable AGP support
			try_unsupported: try to drive unsupported chipsets
				(may crash computer or cause data corruption)

	ALSA		[HW,ALSA]
			See Documentation/sound/alsa/alsa-parameters.txt

	alignment=	[KNL,ARM]
			Allow the default userspace alignment fault handler
			behaviour to be specified.  Bit 0 enables warnings,
			bit 1 enables fixups, and bit 2 sends a segfault.

	amd_iommu=	[HW,X86-84]
			Pass parameters to the AMD IOMMU driver in the system.
			Possible values are:
			fullflush - enable flushing of IO/TLB entries when
				    they are unmapped. Otherwise they are
				    flushed before they will be reused, which
				    is a lot of faster
			off	  - do not initialize any AMD IOMMU found in
				    the system

	amijoy.map=	[HW,JOY] Amiga joystick support
			Map of devices attached to JOY0DAT and JOY1DAT
			Format: <a>,<b>
			See also Documentation/kernel/input/joystick.txt

	analog.map=	[HW,JOY] Analog joystick and gamepad support
			Specifies type or capabilities of an analog joystick
			connected to one of 16 gameports
			Format: <type1>,<type2>,..<type16>

	apc=		[HW,SPARC]
			Power management functions (SPARCstation-4/5 + deriv.)
			Format: noidle
			Disable APC CPU standby support. SPARCstation-Fox does
			not play well with APC CPU idle - disable it if you have
			APC and your system crashes randomly.

	apic=		[APIC,X86-32] Advanced Programmable Interrupt Controller
			Change the output verbosity whilst booting
			Format: { quiet (default) | verbose | debug }
			Change the amount of debugging information output
			when initialising the APIC and IO-APIC components.

	autoconf=	[IPV6]
			See Documentation/networking/ipv6.txt.

	show_lapic=	[APIC,X86] Advanced Programmable Interrupt Controller
			Limit apic dumping. The parameter defines the maximal
			number of local apics being dumped. Also it is possible
			to set it to "all" by meaning -- no limit here.
			Format: { 1 (default) | 2 | ... | all }.
			The parameter valid if only apic=debug or
			apic=verbose is specified.
			Example: apic=debug show_lapic=all

	apm=		[APM] Advanced Power Management
			See header of arch/x86/kernel/apm_32.c.

	arcrimi=	[HW,NET] ARCnet - "RIM I" (entirely mem-mapped) cards
			Format: <io>,<irq>,<nodeID>

	ataflop=	[HW,M68k]

	atarimouse=	[HW,MOUSE] Atari Mouse

	atkbd.extra=	[HW] Enable extra LEDs and keys on IBM RapidAccess,
			EzKey and similar keyboards

	atkbd.reset=	[HW] Reset keyboard during initialization

	atkbd.set=	[HW] Select keyboard code set
			Format: <int> (2 = AT (default), 3 = PS/2)

	atkbd.scroll=	[HW] Enable scroll wheel on MS Office and similar
			keyboards

	atkbd.softraw=	[HW] Choose between synthetic and real raw mode
			Format: <bool> (0 = real, 1 = synthetic (default))

	atkbd.softrepeat= [HW]
			Use software keyboard repeat

	autotest	[IA64]

	baycom_epp=	[HW,AX25]
			Format: <io>,<mode>

	baycom_par=	[HW,AX25] BayCom Parallel Port AX.25 Modem
			Format: <io>,<mode>
			See header of drivers/net/hamradio/baycom_par.c.

	baycom_ser_fdx=	[HW,AX25]
			BayCom Serial Port AX.25 Modem (Full Duplex Mode)
			Format: <io>,<irq>,<mode>[,<baud>]
			See header of drivers/net/hamradio/baycom_ser_fdx.c.

	baycom_ser_hdx=	[HW,AX25]
			BayCom Serial Port AX.25 Modem (Half Duplex Mode)
			Format: <io>,<irq>,<mode>
			See header of drivers/net/hamradio/baycom_ser_hdx.c.

	boot_delay=	Milliseconds to delay each printk during boot.
			Values larger than 10 seconds (10000) are changed to
			no delay (0).
			Format: integer

	bootmem_debug	[KNL] Enable bootmem allocator debug messages.

	bttv.card=	[HW,V4L] bttv (bt848 + bt878 based grabber cards)
	bttv.radio=	Most important insmod options are available as
			kernel args too.
	bttv.pll=	See Documentation/video4linux/bttv/Insmod-options
	bttv.tuner=	and Documentation/video4linux/bttv/CARDLIST

	bulk_remove=off	[PPC]  This parameter disables the use of the pSeries
			firmware feature for flushing multiple hpte entries
			at a time.

	c101=		[NET] Moxa C101 synchronous serial card

	cachesize=	[BUGS=X86-32] Override level 2 CPU cache size detection.
			Sometimes CPU hardware bugs make them report the cache
			size incorrectly. The kernel will attempt work arounds
			to fix known problems, but for some CPUs it is not
			possible to determine what the correct size should be.
			This option provides an override for these situations.

	capability.disable=
			[SECURITY] Disable capabilities.  This would normally
			be used only if an alternative security model is to be
			configured.  Potentially dangerous and should only be
			used if you are entirely sure of the consequences.

	ccw_timeout_log [S390]
			See Documentation/s390/CommonIO for details.

	cgroup_disable= [KNL] Disable a particular controller
			Format: {name of the controller(s) to disable}
				{Currently supported controllers - "memory"}

	checkreqprot	[SELINUX] Set initial checkreqprot flag value.
			Format: { "0" | "1" }
			See security/selinux/Kconfig help text.
			0 -- check protection applied by kernel (includes
				any implied execute protection).
			1 -- check protection requested by application.
			Default value is set via a kernel config option.
			Value can be changed at runtime via
				/selinux/checkreqprot.

	cio_ignore=	[S390]
			See Documentation/s390/CommonIO for details.

	clock=		[BUGS=X86-32, HW] gettimeofday clocksource override.
			[Deprecated]
			Forces specified clocksource (if available) to be used
			when calculating gettimeofday(). If specified
			clocksource is not available, it defaults to PIT.
			Format: { pit | tsc | cyclone | pmtmr }

	clocksource=	Override the default clocksource
			Format: <string>
			Override the default clocksource and use the clocksource
			with the name specified.
			Some clocksource names to choose from, depending on
			the platform:
			[all] jiffies (this is the base, fallback clocksource)
			[ACPI] acpi_pm
			[ARM] imx_timer1,OSTS,netx_timer,mpu_timer2,
				pxa_timer,timer3,32k_counter,timer0_1
			[AVR32] avr32
			[X86-32] pit,hpet,tsc;
				scx200_hrt on Geode; cyclone on IBM x440
			[MIPS] MIPS
			[PARISC] cr16
			[S390] tod
			[SH] SuperH
			[SPARC64] tick
			[X86-64] hpet,tsc

	clearcpuid=BITNUM [X86]
			Disable CPUID feature X for the kernel. See
			arch/x86/include/asm/cpufeature.h for the valid bit
			numbers. Note the Linux specific bits are not necessarily
			stable over kernel options, but the vendor specific
			ones should be.
			Also note that user programs calling CPUID directly
			or using the feature without checking anything
			will still see it. This just prevents it from
			being used by the kernel or shown in /proc/cpuinfo.
			Also note the kernel might malfunction if you disable
			some critical bits.

	cmo_free_hint=	[PPC] Format: { yes | no }
			Specify whether pages are marked as being inactive
			when they are freed.  This is used in CMO environments
			to determine OS memory pressure for page stealing by
			a hypervisor.
			Default: yes

	code_bytes	[X86] How many bytes of object code to print
			in an oops report.
			Range: 0 - 8192
			Default: 64

	com20020=	[HW,NET] ARCnet - COM20020 chipset
			Format:
			<io>[,<irq>[,<nodeID>[,<backplane>[,<ckp>[,<timeout>]]]]]

	com90io=	[HW,NET] ARCnet - COM90xx chipset (IO-mapped buffers)
			Format: <io>[,<irq>]

	com90xx=	[HW,NET]
			ARCnet - COM90xx chipset (memory-mapped buffers)
			Format: <io>[,<irq>[,<memstart>]]

	condev=		[HW,S390] console device
	conmode=

	console=	[KNL] Output console device and options.

		tty<n>	Use the virtual console device <n>.

		ttyS<n>[,options]
		ttyUSB0[,options]
			Use the specified serial port.  The options are of
			the form "bbbbpnf", where "bbbb" is the baud rate,
			"p" is parity ("n", "o", or "e"), "n" is number of
			bits, and "f" is flow control ("r" for RTS or
			omit it).  Default is "9600n8".

			See Documentation/serial-console.txt for more
			information.  See
			Documentation/networking/netconsole.txt for an
			alternative.

		uart[8250],io,<addr>[,options]
		uart[8250],mmio,<addr>[,options]
			Start an early, polled-mode console on the 8250/16550
			UART at the specified I/O port or MMIO address,
			switching to the matching ttyS device later.  The
			options are the same as for ttyS, above.

                If the device connected to the port is not a TTY but a braille
                device, prepend "brl," before the device type, for instance
			console=brl,ttyS0
		For now, only VisioBraille is supported.

	consoleblank=	[KNL] The console blank (screen saver) timeout in
			seconds. Defaults to 10*60 = 10mins. A value of 0
			disables the blank timer.

	coredump_filter=
			[KNL] Change the default value for
			/proc/<pid>/coredump_filter.
			See also Documentation/filesystems/proc.txt.

	cpcihp_generic=	[HW,PCI] Generic port I/O CompactPCI driver
			Format:
			<first_slot>,<last_slot>,<port>,<enum_bit>[,<debug>]

	crashkernel=size[KMG][@offset[KMG]]
			[KNL] Using kexec, Linux can switch to a 'crash kernel'
			upon panic. This parameter reserves the physical
			memory region [offset, offset + size] for that kernel
			image. If '@offset' is omitted, then a suitable offset
			is selected automatically. Check
			Documentation/kdump/kdump.txt for further details.

	crashkernel=range1:size1[,range2:size2,...][@offset]
			[KNL] Same as above, but depends on the memory
			in the running system. The syntax of range is
			start-[end] where start and end are both
			a memory unit (amount[KMG]). See also
			Documentation/kdump/kdump.txt for an example.

	cs89x0_dma=	[HW,NET]
			Format: <dma>

	cs89x0_media=	[HW,NET]
			Format: { rj45 | aui | bnc }

	dasd=		[HW,NET]
			See header of drivers/s390/block/dasd_devmap.c.

	db9.dev[2|3]=	[HW,JOY] Multisystem joystick support via parallel port
			(one device per port)
			Format: <port#>,<type>
			See also Documentation/input/joystick-parport.txt

	ddebug_query=   [KNL,DYNAMIC_DEBUG] Enable debug messages at early boot
			time. See Documentation/dynamic-debug-howto.txt for
			details.

	debug		[KNL] Enable kernel debugging (events log level).

	debug_locks_verbose=
			[KNL] verbose self-tests
			Format=<0|1>
			Print debugging info while doing the locking API
			self-tests.
			We default to 0 (no extra messages), setting it to
			1 will print _a lot_ more information - normally
			only useful to kernel developers.

	debug_objects	[KNL] Enable object debugging

	no_debug_objects
			[KNL] Disable object debugging

	debugpat	[X86] Enable PAT debugging

	decnet.addr=	[HW,NET]
			Format: <area>[,<node>]
			See also Documentation/networking/decnet.txt.

	default_hugepagesz=
			[same as hugepagesz=] The size of the default
			HugeTLB page size. This is the size represented by
			the legacy /proc/ hugepages APIs, used for SHM, and
			default size when mounting hugetlbfs filesystems.
			Defaults to the default architecture's huge page size
			if not specified.

	dhash_entries=	[KNL]
			Set number of hash buckets for dentry cache.

	digi=		[HW,SERIAL]
			IO parameters + enable/disable command.

	digiepca=	[HW,SERIAL]
			See drivers/char/README.epca and
			Documentation/serial/digiepca.txt.

	disable=	[IPV6]
			See Documentation/networking/ipv6.txt.

	disable_ddw     [PPC/PSERIES]
			Disable Dynamic DMA Window support. Use this if
			to workaround buggy firmware.

	disable_ipv6=	[IPV6]
			See Documentation/networking/ipv6.txt.

	disable_mtrr_cleanup [X86]
			The kernel tries to adjust MTRR layout from continuous
			to discrete, to make X server driver able to add WB
			entry later. This parameter disables that.

	disable_mtrr_trim [X86, Intel and AMD only]
			By default the kernel will trim any uncacheable
			memory out of your available memory pool based on
			MTRR settings.  This parameter disables that behavior,
			possibly causing your machine to run very slowly.

	disable_timer_pin_1 [X86]
			Disable PIN 1 of APIC timer
			Can be useful to work around chipset bugs.

	dma_debug=off	If the kernel is compiled with DMA_API_DEBUG support,
			this option disables the debugging code at boot.

	dma_debug_entries=<number>
			This option allows to tune the number of preallocated
			entries for DMA-API debugging code. One entry is
			required per DMA-API allocation. Use this if the
			DMA-API debugging code disables itself because the
			architectural default is too low.

	dma_debug_driver=<driver_name>
			With this option the DMA-API debugging driver
			filter feature can be enabled at boot time. Just
			pass the driver to filter for as the parameter.
			The filter can be disabled or changed to another
			driver later using sysfs.

	dscc4.setup=	[NET]

	earlycon=	[KNL] Output early console device and options.
		uart[8250],io,<addr>[,options]
		uart[8250],mmio,<addr>[,options]
		uart[8250],mmio32,<addr>[,options]
			Start an early, polled-mode console on the 8250/16550
			UART at the specified I/O port or MMIO address.
			MMIO inter-register address stride is either 8bit (mmio)
                        or 32bit (mmio32).
			The options are the same as for ttyS, above.

	earlyprintk=	[X86,SH,BLACKFIN]
			earlyprintk=vga
			earlyprintk=serial[,ttySn[,baudrate]]
			earlyprintk=ttySn[,baudrate]
			earlyprintk=dbgp[debugController#]

			Append ",keep" to not disable it when the real console
			takes over.

			Only vga or serial or usb debug port at a time.

			Currently only ttyS0 and ttyS1 are supported.

			Interaction with the standard serial driver is not
			very good.

			The VGA output is eventually overwritten by the real
			console.

	ekgdboc=	[X86,KGDB] Allow early kernel console debugging
			ekgdboc=kbd

			This is designed to be used in conjunction with
			the boot argument: earlyprintk=vga

	edd=		[EDD]
			Format: {"off" | "on" | "skip[mbr]"}

	eisa_irq_edge=	[PARISC,HW]
			See header of drivers/parisc/eisa.c.

	elanfreq=	[X86-32]
			See comment before function elanfreq_setup() in
			arch/x86/kernel/cpu/cpufreq/elanfreq.c.

	elevator=	[IOSCHED]
			Format: {"cfq" | "deadline" | "noop"}
			See Documentation/block/as-iosched.txt and
			Documentation/block/deadline-iosched.txt for details.

	elfcorehdr=	[IA64,PPC,SH,X86]
			Specifies physical address of start of kernel core
			image elf header. Generally kexec loader will
			pass this option to capture kernel.
			See Documentation/kdump/kdump.txt for details.

	enable_mtrr_cleanup [X86]
			The kernel tries to adjust MTRR layout from continuous
			to discrete, to make X server driver able to add WB
			entry later. This parameter enables that.

	enable_timer_pin_1 [X86]
			Enable PIN 1 of APIC timer
			Can be useful to work around chipset bugs
			(in particular on some ATI chipsets).
			The kernel tries to set a reasonable default.

	enforcing	[SELINUX] Set initial enforcing status.
			Format: {"0" | "1"}
			See security/selinux/Kconfig help text.
			0 -- permissive (log only, no denials).
			1 -- enforcing (deny and log).
			Default value is 0.
			Value can be changed at runtime via /selinux/enforce.

	erst_disable	[ACPI]
			Disable Error Record Serialization Table (ERST)
			support.

	ether=		[HW,NET] Ethernet cards parameters
			This option is obsoleted by the "netdev=" option, which
			has equivalent usage. See its documentation for details.

	failslab=
	fail_page_alloc=
	fail_make_request=[KNL]
			General fault injection mechanism.
			Format: <interval>,<probability>,<space>,<times>
			See also /Documentation/fault-injection/.

	floppy=		[HW]
			See Documentation/blockdev/floppy.txt.

	force_pal_cache_flush
			[IA-64] Avoid check_sal_cache_flush which may hang on
			buggy SAL_CACHE_FLUSH implementations. Using this
			parameter will force ia64_sal_cache_flush to call
			ia64_pal_cache_flush instead of SAL_CACHE_FLUSH.

	ftrace=[tracer]
			[FTRACE] will set and start the specified tracer
			as early as possible in order to facilitate early
			boot debugging.

	ftrace_dump_on_oops[=orig_cpu]
			[FTRACE] will dump the trace buffers on oops.
			If no parameter is passed, ftrace will dump
			buffers of all CPUs, but if you pass orig_cpu, it will
			dump only the buffer of the CPU that triggered the
			oops.

	ftrace_filter=[function-list]
			[FTRACE] Limit the functions traced by the function
			tracer at boot up. function-list is a comma separated
			list of functions. This list can be changed at run
			time by the set_ftrace_filter file in the debugfs
			tracing directory. 

	ftrace_notrace=[function-list]
			[FTRACE] Do not trace the functions specified in
			function-list. This list can be changed at run time
			by the set_ftrace_notrace file in the debugfs
			tracing directory.

	ftrace_graph_filter=[function-list]
			[FTRACE] Limit the top level callers functions traced
			by the function graph tracer at boot up.
			function-list is a comma separated list of functions
			that can be changed at run time by the
			set_graph_function file in the debugfs tracing directory.

	gamecon.map[2|3]=
			[HW,JOY] Multisystem joystick and NES/SNES/PSX pad
			support via parallel port (up to 5 devices per port)
			Format: <port#>,<pad1>,<pad2>,<pad3>,<pad4>,<pad5>
			See also Documentation/input/joystick-parport.txt

	gamma=		[HW,DRM]

	gart_fix_e820=  [X86_64] disable the fix e820 for K8 GART
			Format: off | on
			default: on

	gcov_persist=	[GCOV] When non-zero (default), profiling data for
			kernel modules is saved and remains accessible via
			debugfs, even when the module is unloaded/reloaded.
			When zero, profiling data is discarded and associated
			debugfs files are removed at module unload time.

	gpt		[EFI] Forces disk with valid GPT signature but
			invalid Protective MBR to be treated as GPT.

	hashdist=	[KNL,NUMA] Large hashes allocated during boot
			are distributed across NUMA nodes.  Defaults on
			for 64bit NUMA, off otherwise.
			Format: 0 | 1 (for off | on)

	hcl=		[IA-64] SGI's Hardware Graph compatibility layer

	hd=		[EIDE] (E)IDE hard drive subsystem geometry
			Format: <cyl>,<head>,<sect>

	hest_disable	[ACPI]
			Disable Hardware Error Source Table (HEST) support;
			corresponding firmware-first mode error processing
			logic will be disabled.

	highmem=nn[KMG]	[KNL,BOOT] forces the highmem zone to have an exact
			size of <nn>. This works even on boxes that have no
			highmem otherwise. This also works to reduce highmem
			size on bigger boxes.

	highres=	[KNL] Enable/disable high resolution timer mode.
			Valid parameters: "on", "off"
			Default: "on"

	hisax=		[HW,ISDN]
			See Documentation/isdn/README.HiSax.

	hlt		[BUGS=ARM,SH]

	hpet=		[X86-32,HPET] option to control HPET usage
			Format: { enable (default) | disable | force |
				verbose }
			disable: disable HPET and use PIT instead
			force: allow force enabled of undocumented chips (ICH4,
				VIA, nVidia)
			verbose: show contents of HPET registers during setup

	hugepages=	[HW,X86-32,IA-64] HugeTLB pages to allocate at boot.
	hugepagesz=	[HW,IA-64,PPC,X86-64] The size of the HugeTLB pages.
			On x86-64 and powerpc, this option can be specified
			multiple times interleaved with hugepages= to reserve
			huge pages of different sizes. Valid pages sizes on
			x86-64 are 2M (when the CPU supports "pse") and 1G
			(when the CPU supports the "pdpe1gb" cpuinfo flag)
			Note that 1GB pages can only be allocated at boot time
			using hugepages= and not freed afterwards.

	hvc_iucv=	[S390] Number of z/VM IUCV hypervisor console (HVC)
			       terminal devices. Valid values: 0..8
	hvc_iucv_allow=	[S390] Comma-separated list of z/VM user IDs.
			       If specified, z/VM IUCV HVC accepts connections
			       from listed z/VM user IDs only.

	keep_bootcon	[KNL]
			Do not unregister boot console at start. This is only
			useful for debugging when something happens in the window
			between unregistering the boot console and initializing
			the real console.

	i2c_bus=	[HW] Override the default board specific I2C bus speed
			     or register an additional I2C bus that is not
			     registered from board initialization code.
			     Format:
			     <bus_id>,<clkrate>

	i8042.debug	[HW] Toggle i8042 debug mode
	i8042.direct	[HW] Put keyboard port into non-translated mode
	i8042.dumbkbd	[HW] Pretend that controller can only read data from
			     keyboard and cannot control its state
			     (Don't attempt to blink the leds)
	i8042.noaux	[HW] Don't check for auxiliary (== mouse) port
	i8042.nokbd	[HW] Don't check/create keyboard port
	i8042.noloop	[HW] Disable the AUX Loopback command while probing
			     for the AUX port
	i8042.nomux	[HW] Don't check presence of an active multiplexing
			     controller
	i8042.nopnp	[HW] Don't use ACPIPnP / PnPBIOS to discover KBD/AUX
			     controllers
	i8042.notimeout	[HW] Ignore timeout condition signalled by conroller
	i8042.reset	[HW] Reset the controller during init and cleanup
	i8042.unlock	[HW] Unlock (ignore) the keylock

	i810=		[HW,DRM]

	i8k.ignore_dmi	[HW] Continue probing hardware even if DMI data
			indicates that the driver is running on unsupported
			hardware.
	i8k.force	[HW] Activate i8k driver even if SMM BIOS signature
			does not match list of supported models.
	i8k.power_status
			[HW] Report power status in /proc/i8k
			(disabled by default)
	i8k.restricted	[HW] Allow controlling fans only if SYS_ADMIN
			capability is set.

	icn=		[HW,ISDN]
			Format: <io>[,<membase>[,<icn_id>[,<icn_id2>]]]

	ide-core.nodma=	[HW] (E)IDE subsystem
			Format: =0.0 to prevent dma on hda, =0.1 hdb =1.0 hdc
			.vlb_clock .pci_clock .noflush .nohpa .noprobe .nowerr
			.cdrom .chs .ignore_cable are additional options
			See Documentation/ide/ide.txt.

	ide-pci-generic.all-generic-ide [HW] (E)IDE subsystem
			Claim all unknown PCI IDE storage controllers.

	idle=		[X86]
			Format: idle=poll, idle=mwait, idle=halt, idle=nomwait
			Poll forces a polling idle loop that can slightly
			improve the performance of waking up a idle CPU, but
			will use a lot of power and make the system run hot.
			Not recommended.
			idle=mwait: On systems which support MONITOR/MWAIT but
			the kernel chose to not use it because it doesn't save
			as much power as a normal idle loop, use the
			MONITOR/MWAIT idle loop anyways. Performance should be
			the same as idle=poll.
			idle=halt: Halt is forced to be used for CPU idle.
			In such case C2/C3 won't be used again.
			idle=nomwait: Disable mwait for CPU C-states

	ignore_loglevel	[KNL]
			Ignore loglevel setting - this will print /all/
			kernel messages to the console. Useful for debugging.

	ihash_entries=	[KNL]
			Set number of hash buckets for inode cache.

	ima_audit=	[IMA]
			Format: { "0" | "1" }
			0 -- integrity auditing messages. (Default)
			1 -- enable informational integrity auditing messages.

	ima_hash=	[IMA]
			Format: { "sha1" | "md5" }
			default: "sha1"

	ima_tcb		[IMA]
			Load a policy which meets the needs of the Trusted
			Computing Base.  This means IMA will measure all
			programs exec'd, files mmap'd for exec, and all files
			opened for read by uid=0.

	init=		[KNL]
			Format: <full_path>
			Run specified binary instead of /sbin/init as init
			process.

	initcall_debug	[KNL] Trace initcalls as they are executed.  Useful
			for working out where the kernel is dying during
			startup.

	initrd=		[BOOT] Specify the location of the initial ramdisk

	inport.irq=	[HW] Inport (ATI XL and Microsoft) busmouse driver
			Format: <irq>

	intel_iommu=	[DMAR] Intel IOMMU driver (DMAR) option
		on
			Enable intel iommu driver.
		off
			Disable intel iommu driver.
		igfx_off [Default Off]
			By default, gfx is mapped as normal device. If a gfx
			device has a dedicated DMAR unit, the DMAR unit is
			bypassed by not enabling DMAR with this option. In
			this case, gfx device will use physical address for
			DMA.
		forcedac [x86_64]
			With this option iommu will not optimize to look
			for io virtual address below 32 bit forcing dual
			address cycle on pci bus for cards supporting greater
			than 32 bit addressing. The default is to look
			for translation below 32 bit and if not available
			then look in the higher range.
		strict [Default Off]
			With this option on every unmap_single operation will
			result in a hardware IOTLB flush operation as opposed
			to batching them for performance.
		sp_off [Default Off]
			By default, super page will be supported if Intel IOMMU
			has the capability. With this option, super page will
			not be supported.
	intremap=	[X86-64, Intel-IOMMU]
			Format: { on (default) | off | nosid }
			on	enable Interrupt Remapping (default)
			off	disable Interrupt Remapping
			nosid	disable Source ID checking

	inttest=	[IA64]

	iomem=		Disable strict checking of access to MMIO memory
		strict	regions from userspace.
		relaxed

	iommu=		[x86]
		off
		force
		noforce
		biomerge
		panic
		nopanic
		merge
		nomerge
		forcesac
		soft
		pt	[x86, IA64]

	io7=		[HW] IO7 for Marvel based alpha systems
			See comment before marvel_specify_io7 in
			arch/alpha/kernel/core_marvel.c.

	io_delay=	[X86] I/O delay method
		0x80
			Standard port 0x80 based delay
		0xed
			Alternate port 0xed based delay (needed on some systems)
		udelay
			Simple two microseconds delay
		none
			No delay

	ip=		[IP_PNP]
			See Documentation/filesystems/nfs/nfsroot.txt.

	ip2=		[HW] Set IO/IRQ pairs for up to 4 IntelliPort boards
			See comment before ip2_setup() in
			drivers/char/ip2/ip2base.c.

	irqfixup	[HW]
			When an interrupt is not handled search all handlers
			for it. Intended to get systems with badly broken
			firmware running.

	irqpoll		[HW]
			When an interrupt is not handled search all handlers
			for it. Also check all handlers each timer
			interrupt. Intended to get systems with badly broken
			firmware running.

	isapnp=		[ISAPNP]
			Format: <RDP>,<reset>,<pci_scan>,<verbosity>

	isolcpus=	[KNL,SMP] Isolate CPUs from the general scheduler.
			Format:
			<cpu number>,...,<cpu number>
			or
			<cpu number>-<cpu number>
			(must be a positive range in ascending order)
			or a mixture
			<cpu number>,...,<cpu number>-<cpu number>

			This option can be used to specify one or more CPUs
			to isolate from the general SMP balancing and scheduling
			algorithms. You can move a process onto or off an
			"isolated" CPU via the CPU affinity syscalls or cpuset.
			<cpu number> begins at 0 and the maximum value is
			"number of CPUs in system - 1".

			This option is the preferred way to isolate CPUs. The
			alternative -- manually setting the CPU mask of all
			tasks in the system -- can cause problems and
			suboptimal load balancer performance.

	iucv=		[HW,NET]

	js=		[HW,JOY] Analog joystick
			See Documentation/input/joystick.txt.

	keepinitrd	[HW,ARM]

	kernelcore=nn[KMG]	[KNL,X86,IA-64,PPC] This parameter
			specifies the amount of memory usable by the kernel
			for non-movable allocations.  The requested amount is
			spread evenly throughout all nodes in the system. The
			remaining memory in each node is used for Movable
			pages. In the event, a node is too small to have both
			kernelcore and Movable pages, kernelcore pages will
			take priority and other nodes will have a larger number
			of kernelcore pages.  The Movable zone is used for the
			allocation of pages that may be reclaimed or moved
			by the page migration subsystem.  This means that
			HugeTLB pages may not be allocated from this zone.
			Note that allocations like PTEs-from-HighMem still
			use the HighMem zone if it exists, and the Normal
			zone if it does not.

	kgdbdbgp=	[KGDB,HW] kgdb over EHCI usb debug port.
			Format: <Controller#>[,poll interval]
			The controller # is the number of the ehci usb debug
			port as it is probed via PCI.  The poll interval is
			optional and is the number seconds in between
			each poll cycle to the debug port in case you need
			the functionality for interrupting the kernel with
			gdb or control-c on the dbgp connection.  When
			not using this parameter you use sysrq-g to break into
			the kernel debugger.

	kgdboc=		[KGDB,HW] kgdb over consoles.
			Requires a tty driver that supports console polling,
			or a supported polling keyboard driver (non-usb).
			 Serial only format: <serial_device>[,baud]
			 keyboard only format: kbd
			 keyboard and serial format: kbd,<serial_device>[,baud]
			Optional Kernel mode setting:
			 kms, kbd format: kms,kbd
			 kms, kbd and serial format: kms,kbd,<ser_dev>[,baud]

	kgdbwait	[KGDB] Stop kernel execution and enter the
			kernel debugger at the earliest opportunity.

	kmac=		[MIPS] korina ethernet MAC address.
			Configure the RouterBoard 532 series on-chip
			Ethernet adapter MAC address.

	kmemleak=	[KNL] Boot-time kmemleak enable/disable
			Valid arguments: on, off
			Default: on

	kstack=N	[X86] Print N words from the kernel stack
			in oops dumps.

	kvm.ignore_msrs=[KVM] Ignore guest accesses to unhandled MSRs.
			Default is 0 (don't ignore, but inject #GP)

	kvm.oos_shadow=	[KVM] Disable out-of-sync shadow paging.
			Default is 1 (enabled)

	kvm.mmu_audit=	[KVM] This is a R/W parameter which allows audit
			KVM MMU at runtime.
			Default is 0 (off)

	kvm-amd.nested=	[KVM,AMD] Allow nested virtualization in KVM/SVM.
			Default is 1 (enabled)

	kvm-amd.npt=	[KVM,AMD] Disable nested paging (virtualized MMU)
			for all guests.
			Default is 1 (enabled) if in 64bit or 32bit-PAE mode

	kvm-intel.bypass_guest_pf=
			[KVM,Intel] Disables bypassing of guest page faults
			on Intel chips. Default is 1 (enabled)

	kvm-intel.ept=	[KVM,Intel] Disable extended page tables
			(virtualized MMU) support on capable Intel chips.
			Default is 1 (enabled)

	kvm-intel.emulate_invalid_guest_state=
			[KVM,Intel] Enable emulation of invalid guest states
			Default is 0 (disabled)

	kvm-intel.flexpriority=
			[KVM,Intel] Disable FlexPriority feature (TPR shadow).
			Default is 1 (enabled)

	kvm-intel.unrestricted_guest=
			[KVM,Intel] Disable unrestricted guest feature
			(virtualized real and unpaged mode) on capable
			Intel chips. Default is 1 (enabled)

	kvm-intel.vpid=	[KVM,Intel] Disable Virtual Processor Identification
			feature (tagged TLBs) on capable Intel chips.
			Default is 1 (enabled)

	l2cr=		[PPC]

	l3cr=		[PPC]

	lapic		[X86-32,APIC] Enable the local APIC even if BIOS
			disabled it.

	lapic_timer_c2_ok	[X86,APIC] trust the local apic timer
			in C2 power state.

	libata.dma=	[LIBATA] DMA control
			libata.dma=0	  Disable all PATA and SATA DMA
			libata.dma=1	  PATA and SATA Disk DMA only
			libata.dma=2	  ATAPI (CDROM) DMA only
			libata.dma=4	  Compact Flash DMA only 
			Combinations also work, so libata.dma=3 enables DMA
			for disks and CDROMs, but not CFs.
	
	libata.ignore_hpa=	[LIBATA] Ignore HPA limit
			libata.ignore_hpa=0	  keep BIOS limits (default)
			libata.ignore_hpa=1	  ignore limits, using full disk

	libata.noacpi	[LIBATA] Disables use of ACPI in libata suspend/resume
			when set.
			Format: <int>

	libata.force=	[LIBATA] Force configurations.  The format is comma
			separated list of "[ID:]VAL" where ID is
			PORT[.DEVICE].  PORT and DEVICE are decimal numbers
			matching port, link or device.  Basically, it matches
			the ATA ID string printed on console by libata.  If
			the whole ID part is omitted, the last PORT and DEVICE
			values are used.  If ID hasn't been specified yet, the
			configuration applies to all ports, links and devices.

			If only DEVICE is omitted, the parameter applies to
			the port and all links and devices behind it.  DEVICE
			number of 0 either selects the first device or the
			first fan-out link behind PMP device.  It does not
			select the host link.  DEVICE number of 15 selects the
			host link and device attached to it.

			The VAL specifies the configuration to force.  As long
			as there's no ambiguity shortcut notation is allowed.
			For example, both 1.5 and 1.5G would work for 1.5Gbps.
			The following configurations can be forced.

			* Cable type: 40c, 80c, short40c, unk, ign or sata.
			  Any ID with matching PORT is used.

			* SATA link speed limit: 1.5Gbps or 3.0Gbps.

			* Transfer mode: pio[0-7], mwdma[0-4] and udma[0-7].
			  udma[/][16,25,33,44,66,100,133] notation is also
			  allowed.

			* [no]ncq: Turn on or off NCQ.

			* nohrst, nosrst, norst: suppress hard, soft
                          and both resets.

			* dump_id: dump IDENTIFY data.

			If there are multiple matching configurations changing
			the same attribute, the last one is used.

	memblock=debug	[KNL] Enable memblock debug messages.

	load_ramdisk=	[RAM] List of ramdisks to load from floppy
			See Documentation/blockdev/ramdisk.txt.

	lockd.nlm_grace_period=P  [NFS] Assign grace period.
			Format: <integer>

	lockd.nlm_tcpport=N	[NFS] Assign TCP port.
			Format: <integer>

	lockd.nlm_timeout=T	[NFS] Assign timeout value.
			Format: <integer>

	lockd.nlm_udpport=M	[NFS] Assign UDP port.
			Format: <integer>

	logibm.irq=	[HW,MOUSE] Logitech Bus Mouse Driver
			Format: <irq>

	loglevel=	All Kernel Messages with a loglevel smaller than the
			console loglevel will be printed to the console. It can
			also be changed with klogd or other programs. The
			loglevels are defined as follows:

			0 (KERN_EMERG)		system is unusable
			1 (KERN_ALERT)		action must be taken immediately
			2 (KERN_CRIT)		critical conditions
			3 (KERN_ERR)		error conditions
			4 (KERN_WARNING)	warning conditions
			5 (KERN_NOTICE)		normal but significant condition
			6 (KERN_INFO)		informational
			7 (KERN_DEBUG)		debug-level messages

	log_buf_len=n[KMG]	Sets the size of the printk ring buffer,
			in bytes.  n must be a power of two.  The default
			size is set in the kernel config file.

	logo.nologo	[FB] Disables display of the built-in Linux logo.
			This may be used to provide more screen space for
			kernel log messages and is useful when debugging
			kernel boot problems.

	lp=0		[LP]	Specify parallel ports to use, e.g,
	lp=port[,port...]	lp=none,parport0 (lp0 not configured, lp1 uses
	lp=reset		first parallel port). 'lp=0' disables the
	lp=auto			printer driver. 'lp=reset' (which can be
				specified in addition to the ports) causes
				attached printers to be reset. Using
				lp=port1,port2,... specifies the parallel ports
				to associate lp devices with, starting with
				lp0. A port specification may be 'none' to skip
				that lp device, or a parport name such as
				'parport0'. Specifying 'lp=auto' instead of a
				port specification list means that device IDs
				from each port should be examined, to see if
				an IEEE 1284-compliant printer is attached; if
				so, the driver will manage that printer.
				See also header of drivers/char/lp.c.

	lpj=n		[KNL]
			Sets loops_per_jiffy to given constant, thus avoiding
			time-consuming boot-time autodetection (up to 250 ms per
			CPU). 0 enables autodetection (default). To determine
			the correct value for your kernel, boot with normal
			autodetection and see what value is printed. Note that
			on SMP systems the preset will be applied to all CPUs,
			which is likely to cause problems if your CPUs need
			significantly divergent settings. An incorrect value
			will cause delays in the kernel to be wrong, leading to
			unpredictable I/O errors and other breakage. Although
			unlikely, in the extreme case this might damage your
			hardware.

	ltpc=		[NET]
			Format: <io>,<irq>,<dma>

	machvec=	[IA64] Force the use of a particular machine-vector
			(machvec) in a generic kernel.
			Example: machvec=hpzx1_swiotlb

	machtype=	[Loongson] Share the same kernel image file between different
			 yeeloong laptop.
			Example: machtype=lemote-yeeloong-2f-7inch

	max_addr=nn[KMG]	[KNL,BOOT,ia64] All physical memory greater
			than or equal to this physical address is ignored.

	maxcpus=	[SMP] Maximum number of processors that	an SMP kernel
			should make use of.  maxcpus=n : n >= 0 limits the
			kernel to using 'n' processors.  n=0 is a special case,
			it is equivalent to "nosmp", which also disables
			the IO APIC.

	max_loop=	[LOOP] Maximum number of loopback devices that can
			be mounted
			Format: <1-256>

	mcatest=	[IA-64]

	mce		[X86-32] Machine Check Exception

	mce=option	[X86-64] See Documentation/x86/x86_64/boot-options.txt

	md=		[HW] RAID subsystems devices and level
			See Documentation/md.txt.

	mdacon=		[MDA]
			Format: <first>,<last>
			Specifies range of consoles to be captured by the MDA.

	mem=nn[KMG]	[KNL,BOOT] Force usage of a specific amount of memory
			Amount of memory to be used when the kernel is not able
			to see the whole system memory or for test.
			[X86-32] Use together with memmap= to avoid physical
			address space collisions. Without memmap= PCI devices
			could be placed at addresses belonging to unused RAM.

	mem=nopentium	[BUGS=X86-32] Disable usage of 4MB pages for kernel
			memory.

	memchunk=nn[KMG]
			[KNL,SH] Allow user to override the default size for
			per-device physically contiguous DMA buffers.

	memmap=exactmap	[KNL,X86] Enable setting of an exact
			E820 memory map, as specified by the user.
			Such memmap=exactmap lines can be constructed based on
			BIOS output or other requirements. See the memmap=nn@ss
			option description.

	memmap=nn[KMG]@ss[KMG]
			[KNL] Force usage of a specific region of memory
			Region of memory to be used, from ss to ss+nn.

	memmap=nn[KMG]#ss[KMG]
			[KNL,ACPI] Mark specific memory as ACPI data.
			Region of memory to be used, from ss to ss+nn.

	memmap=nn[KMG]$ss[KMG]
			[KNL,ACPI] Mark specific memory as reserved.
			Region of memory to be used, from ss to ss+nn.
			Example: Exclude memory from 0x18690000-0x1869ffff
			         memmap=64K$0x18690000
			         or
			         memmap=0x10000$0x18690000

	memory_corruption_check=0/1 [X86]
			Some BIOSes seem to corrupt the first 64k of
			memory when doing things like suspend/resume.
			Setting this option will scan the memory
			looking for corruption.  Enabling this will
			both detect corruption and prevent the kernel
			from using the memory being corrupted.
			However, its intended as a diagnostic tool; if
			repeatable BIOS-originated corruption always
			affects the same memory, you can use memmap=
			to prevent the kernel from using that memory.

	memory_corruption_check_size=size [X86]
			By default it checks for corruption in the low
			64k, making this memory unavailable for normal
			use.  Use this parameter to scan for
			corruption in more or less memory.

	memory_corruption_check_period=seconds [X86]
			By default it checks for corruption every 60
			seconds.  Use this parameter to check at some
			other rate.  0 disables periodic checking.

	memtest=	[KNL,X86] Enable memtest
			Format: <integer>
			default : 0 <disable>
			Specifies the number of memtest passes to be
			performed. Each pass selects another test
			pattern from a given set of patterns. Memtest
			fills the memory with this pattern, validates
			memory contents and reserves bad memory
			regions that are detected.

	meye.*=		[HW] Set MotionEye Camera parameters
			See Documentation/video4linux/meye.txt.

	mfgpt_irq=	[IA-32] Specify the IRQ to use for the
			Multi-Function General Purpose Timers on AMD Geode
			platforms.

	mfgptfix	[X86-32] Fix MFGPT timers on AMD Geode platforms when
			the BIOS has incorrectly applied a workaround. TinyBIOS
			version 0.98 is known to be affected, 0.99 fixes the
			problem by letting the user disable the workaround.

	mga=		[HW,DRM]

	min_addr=nn[KMG]	[KNL,BOOT,ia64] All physical memory below this
			physical address is ignored.

	mini2440=	[ARM,HW,KNL]
			Format:[0..2][b][c][t]
			Default: "0tb"
			MINI2440 configuration specification:
			0 - The attached screen is the 3.5" TFT
			1 - The attached screen is the 7" TFT
			2 - The VGA Shield is attached (1024x768)
			Leaving out the screen size parameter will not load
			the TFT driver, and the framebuffer will be left
			unconfigured.
			b - Enable backlight. The TFT backlight pin will be
			linked to the kernel VESA blanking code and a GPIO
			LED. This parameter is not necessary when using the
			VGA shield.
			c - Enable the s3c camera interface.
			t - Reserved for enabling touchscreen support. The
			touchscreen support is not enabled in the mainstream
			kernel as of 2.6.30, a preliminary port can be found
			in the "bleeding edge" mini2440 support kernel at
			http://repo.or.cz/w/linux-2.6/mini2440.git

	mminit_loglevel=
			[KNL] When CONFIG_DEBUG_MEMORY_INIT is set, this
			parameter allows control of the logging verbosity for
			the additional memory initialisation checks. A value
			of 0 disables mminit logging and a level of 4 will
			log everything. Information is printed at KERN_DEBUG
			so loglevel=8 may also need to be specified.

	mousedev.tap_time=
			[MOUSE] Maximum time between finger touching and
			leaving touchpad surface for touch to be considered
			a tap and be reported as a left button click (for
			touchpads working in absolute mode only).
			Format: <msecs>
	mousedev.xres=	[MOUSE] Horizontal screen resolution, used for devices
			reporting absolute coordinates, such as tablets
	mousedev.yres=	[MOUSE] Vertical screen resolution, used for devices
			reporting absolute coordinates, such as tablets

	movablecore=nn[KMG]	[KNL,X86,IA-64,PPC] This parameter
			is similar to kernelcore except it specifies the
			amount of memory used for migratable allocations.
			If both kernelcore and movablecore is specified,
			then kernelcore will be at *least* the specified
			value but may be more. If movablecore on its own
			is specified, the administrator must be careful
			that the amount of memory usable for all allocations
			is not too small.

	MTD_Partition=	[MTD]
			Format: <name>,<region-number>,<size>,<offset>

	MTD_Region=	[MTD] Format:
			<name>,<region-number>[,<base>,<size>,<buswidth>,<altbuswidth>]

	mtdparts=	[MTD]
			See drivers/mtd/cmdlinepart.c.

	multitce=off	[PPC]  This parameter disables the use of the pSeries
			firmware feature for updating multiple TCE entries
			at a time.

	onenand.bdry=	[HW,MTD] Flex-OneNAND Boundary Configuration

			Format: [die0_boundary][,die0_lock][,die1_boundary][,die1_lock]

			boundary - index of last SLC block on Flex-OneNAND.
				   The remaining blocks are configured as MLC blocks.
			lock	 - Configure if Flex-OneNAND boundary should be locked.
				   Once locked, the boundary cannot be changed.
				   1 indicates lock status, 0 indicates unlock status.

	mtdset=		[ARM]
			ARM/S3C2412 JIVE boot control

			See arch/arm/mach-s3c2412/mach-jive.c

	mtouchusb.raw_coordinates=
			[HW] Make the MicroTouch USB driver use raw coordinates
			('y', default) or cooked coordinates ('n')

	mtrr_chunk_size=nn[KMG] [X86]
			used for mtrr cleanup. It is largest continuous chunk
			that could hold holes aka. UC entries.

	mtrr_gran_size=nn[KMG] [X86]
			Used for mtrr cleanup. It is granularity of mtrr block.
			Default is 1.
			Large value could prevent small alignment from
			using up MTRRs.

	mtrr_spare_reg_nr=n [X86]
			Format: <integer>
			Range: 0,7 : spare reg number
			Default : 1
			Used for mtrr cleanup. It is spare mtrr entries number.
			Set to 2 or more if your graphical card needs more.

	n2=		[NET] SDL Inc. RISCom/N2 synchronous serial card

	netdev=		[NET] Network devices parameters
			Format: <irq>,<io>,<mem_start>,<mem_end>,<name>
			Note that mem_start is often overloaded to mean
			something different and driver-specific.
			This usage is only documented in each driver source
			file if at all.

	nf_conntrack.acct=
			[NETFILTER] Enable connection tracking flow accounting
			0 to disable accounting
			1 to enable accounting
			Default value is 0.

	nfsaddrs=	[NFS] Deprecated.  Use ip= instead.
			See Documentation/filesystems/nfs/nfsroot.txt.

	nfsroot=	[NFS] nfs root filesystem for disk-less boxes.
			See Documentation/filesystems/nfs/nfsroot.txt.

	nfsrootdebug	[NFS] enable nfsroot debugging messages.
			See Documentation/filesystems/nfs/nfsroot.txt.

	nfs.callback_tcpport=
			[NFS] set the TCP port on which the NFSv4 callback
			channel should listen.

	nfs.cache_getent=
			[NFS] sets the pathname to the program which is used
			to update the NFS client cache entries.

	nfs.cache_getent_timeout=
			[NFS] sets the timeout after which an attempt to
			update a cache entry is deemed to have failed.

	nfs.idmap_cache_timeout=
			[NFS] set the maximum lifetime for idmapper cache
			entries.

	nfs.enable_ino64=
			[NFS] enable 64-bit inode numbers.
			If zero, the NFS client will fake up a 32-bit inode
			number for the readdir() and stat() syscalls instead
			of returning the full 64-bit number.
			The default is to return 64-bit inode numbers.

	nfs.nfs4_disable_idmapping=
			[NFSv4] When set, this option disables the NFSv4
			idmapper on the client, but only if the mount
			is using the 'sec=sys' security flavour. This may
			make migration from legacy NFSv2/v3 systems easier
			provided that the server has the appropriate support.
			The default is to always enable NFSv4 idmapping.

	nmi_debug=	[KNL,AVR32,SH] Specify one or more actions to take
			when a NMI is triggered.
			Format: [state][,regs][,debounce][,die]

	nmi_watchdog=	[KNL,BUGS=X86] Debugging features for SMP kernels
			Format: [panic,][nopanic,][num]
			Valid num: 0
			0 - turn nmi_watchdog off
			When panic is specified, panic when an NMI watchdog
			timeout occurs (or 'nopanic' to override the opposite
			default).
			This is useful when you use a panic=... timeout and
			need the box quickly up again.

	netpoll.carrier_timeout=
			[NET] Specifies amount of time (in seconds) that
			netpoll should wait for a carrier. By default netpoll
			waits 4 seconds.

	no387		[BUGS=X86-32] Tells the kernel to use the 387 maths
			emulation library even if a 387 maths coprocessor
			is present.

	no_console_suspend
			[HW] Never suspend the console
			Disable suspending of consoles during suspend and
			hibernate operations.  Once disabled, debugging
			messages can reach various consoles while the rest
			of the system is being put to sleep (ie, while
			debugging driver suspend/resume hooks).  This may
			not work reliably with all consoles, but is known
			to work with serial and VGA consoles.

	noaliencache	[MM, NUMA, SLAB] Disables the allocation of alien
			caches in the slab allocator.  Saves per-node memory,
			but will impact performance.

	noalign		[KNL,ARM]

	noapic		[SMP,APIC] Tells the kernel to not make use of any
			IOAPICs that may be present in the system.

	noautogroup	Disable scheduler automatic task group creation.

	nobats		[PPC] Do not use BATs for mapping kernel lowmem
			on "Classic" PPC cores.

	nocache		[ARM]

	noclflush	[BUGS=X86] Don't use the CLFLUSH instruction

	nodelayacct	[KNL] Disable per-task delay accounting

	nodisconnect	[HW,SCSI,M68K] Disables SCSI disconnects.

	nodsp		[SH] Disable hardware DSP at boot time.

	noefi		[X86] Disable EFI runtime services support.

	noexec		[IA-64]

	noexec		[X86]
			On X86-32 available only on PAE configured kernels.
			noexec=on: enable non-executable mappings (default)
			noexec=off: disable non-executable mappings

	nosmep		[X86]
			Disable SMEP (Supervisor Mode Execution Protection)
			even if it is supported by processor.

	noexec32	[X86-64]
			This affects only 32-bit executables.
			noexec32=on: enable non-executable mappings (default)
				read doesn't imply executable mappings
			noexec32=off: disable non-executable mappings
				read implies executable mappings

	nofpu		[SH] Disable hardware FPU at boot time.

	nofxsr		[BUGS=X86-32] Disables x86 floating point extended
			register save and restore. The kernel will only save
			legacy floating-point registers on task switch.

	noxsave		[BUGS=X86] Disables x86 extended register state save
			and restore using xsave. The kernel will fallback to
			enabling legacy floating-point and sse state.

	nohlt		[BUGS=ARM,SH] Tells the kernel that the sleep(SH) or
			wfi(ARM) instruction doesn't work correctly and not to
			use it. This is also useful when using JTAG debugger.

	no-hlt		[BUGS=X86-32] Tells the kernel that the hlt
			instruction doesn't work correctly and not to
			use it.

	no_file_caps	Tells the kernel not to honor file capabilities.  The
			only way then for a file to be executed with privilege
			is to be setuid root or executed by root.

	nohalt		[IA-64] Tells the kernel not to use the power saving
			function PAL_HALT_LIGHT when idle. This increases
			power-consumption. On the positive side, it reduces
			interrupt wake-up latency, which may improve performance
			in certain environments such as networked servers or
			real-time systems.

	nohz=		[KNL] Boottime enable/disable dynamic ticks
			Valid arguments: on, off
			Default: on

	noiotrap	[SH] Disables trapped I/O port accesses.

	noirqdebug	[X86-32] Disables the code which attempts to detect and
			disable unhandled interrupt sources.

	no_timer_check	[X86,APIC] Disables the code which tests for
			broken timer IRQ sources.

	noisapnp	[ISAPNP] Disables ISA PnP code.

	noinitrd	[RAM] Tells the kernel not to load any configured
			initial RAM disk.

	nointremap	[X86-64, Intel-IOMMU] Do not enable interrupt
			remapping.
			[Deprecated - use intremap=off]

	nointroute	[IA-64]

	nojitter	[IA64] Disables jitter checking for ITC timers.

	no-kvmclock	[X86,KVM] Disable paravirtualized KVM clock driver

	no-kvmapf	[X86,KVM] Disable paravirtualized asynchronous page
			fault handling.

	nolapic		[X86-32,APIC] Do not enable or use the local APIC.

	nolapic_timer	[X86-32,APIC] Do not use the local APIC timer.

	noltlbs		[PPC] Do not use large page/tlb entries for kernel
			lowmem mapping on PPC40x.

	nomca		[IA-64] Disable machine check abort handling

	nomce		[X86-32] Machine Check Exception

	nomfgpt		[X86-32] Disable Multi-Function General Purpose
			Timer usage (for AMD Geode machines).

	nopat		[X86] Disable PAT (page attribute table extension of
			pagetables) support.

	norandmaps	Don't use address space randomization.  Equivalent to
			echo 0 > /proc/sys/kernel/randomize_va_space

	noreplace-paravirt	[X86,IA-64,PV_OPS] Don't patch paravirt_ops

	noreplace-smp	[X86-32,SMP] Don't replace SMP instructions
			with UP alternatives

	noresidual	[PPC] Don't use residual data on PReP machines.

	noresume	[SWSUSP] Disables resume and restores original swap
			space.

	no-scroll	[VGA] Disables scrollback.
			This is required for the Braillex ib80-piezo Braille
			reader made by F.H. Papenmeier (Germany).

	nosbagart	[IA-64]

	nosep		[BUGS=X86-32] Disables x86 SYSENTER/SYSEXIT support.

	nosmp		[SMP] Tells an SMP kernel to act as a UP kernel,
			and disable the IO APIC.  legacy for "maxcpus=0".

	nosoftlockup	[KNL] Disable the soft-lockup detector.

	nosync		[HW,M68K] Disables sync negotiation for all devices.

	notsc		[BUGS=X86-32] Disable Time Stamp Counter

	nousb		[USB] Disable the USB subsystem

	nowatchdog	[KNL] Disable the lockup detector (NMI watchdog).

	nowb		[ARM]

	nox2apic	[X86-64,APIC] Do not enable x2APIC mode.

	nptcg=		[IA64] Override max number of concurrent global TLB
			purges which is reported from either PAL_VM_SUMMARY or
			SAL PALO.

	nr_cpus=	[SMP] Maximum number of processors that	an SMP kernel
			could support.  nr_cpus=n : n >= 1 limits the kernel to
			supporting 'n' processors. Later in runtime you can not
			use hotplug cpu feature to put more cpu back to online.
			just like you compile the kernel NR_CPUS=n

	nr_uarts=	[SERIAL] maximum number of UARTs to be registered.

	numa_zonelist_order= [KNL, BOOT] Select zonelist order for NUMA.
			one of ['zone', 'node', 'default'] can be specified
			This can be set from sysctl after boot.
			See Documentation/sysctl/vm.txt for details.

	ohci1394_dma=early	[HW] enable debugging via the ohci1394 driver.
			See Documentation/debugging-via-ohci1394.txt for more
			info.

	olpc_ec_timeout= [OLPC] ms delay when issuing EC commands
			Rather than timing out after 20 ms if an EC
			command is not properly ACKed, override the length
			of the timeout.  We have interrupts disabled while
			waiting for the ACK, so if this is set too high
			interrupts *may* be lost!

	omap_mux=	[OMAP] Override bootloader pin multiplexing.
			Format: <mux_mode0.mode_name=value>...
			For example, to override I2C bus2:
			omap_mux=i2c2_scl.i2c2_scl=0x100,i2c2_sda.i2c2_sda=0x100

	oprofile.timer=	[HW]
			Use timer interrupt instead of performance counters

	oprofile.cpu_type=	Force an oprofile cpu type
			This might be useful if you have an older oprofile
			userland or if you want common events.
			Format: { arch_perfmon }
			arch_perfmon: [X86] Force use of architectural
				perfmon on Intel CPUs instead of the
				CPU specific event set.

	oops=panic	Always panic on oopses. Default is to just kill the
			process, but there is a small probability of
			deadlocking the machine.
			This will also cause panics on machine check exceptions.
			Useful together with panic=30 to trigger a reboot.

	OSS		[HW,OSS]
			See Documentation/sound/oss/oss-parameters.txt

	panic=		[KNL] Kernel behaviour on panic: delay <timeout>
			seconds before rebooting
			Format: <timeout>

	parkbd.port=	[HW] Parallel port number the keyboard adapter is
			connected to, default is 0.
			Format: <parport#>
	parkbd.mode=	[HW] Parallel port keyboard adapter mode of operation,
			0 for XT, 1 for AT (default is AT).
			Format: <mode>

	parport=	[HW,PPT] Specify parallel ports. 0 disables.
			Format: { 0 | auto | 0xBBB[,IRQ[,DMA]] }
			Use 'auto' to force the driver to use any
			IRQ/DMA settings detected (the default is to
			ignore detected IRQ/DMA settings because of
			possible conflicts). You can specify the base
			address, IRQ, and DMA settings; IRQ and DMA
			should be numbers, or 'auto' (for using detected
			settings on that particular port), or 'nofifo'
			(to avoid using a FIFO even if it is detected).
			Parallel ports are assigned in the order they
			are specified on the command line, starting
			with parport0.

	parport_init_mode=	[HW,PPT]
			Configure VIA parallel port to operate in
			a specific mode. This is necessary on Pegasos
			computer where firmware has no options for setting
			up parallel port mode and sets it to spp.
			Currently this function knows 686a and 8231 chips.
			Format: [spp|ps2|epp|ecp|ecpepp]

	pause_on_oops=
			Halt all CPUs after the first oops has been printed for
			the specified number of seconds.  This is to be used if
			your oopses keep scrolling off the screen.

	pcbit=		[HW,ISDN]

	pcd.		[PARIDE]
			See header of drivers/block/paride/pcd.c.
			See also Documentation/blockdev/paride.txt.

	pci=option[,option...]	[PCI] various PCI subsystem options:
		earlydump	[X86] dump PCI config space before the kernel
			        changes anything
		off		[X86] don't probe for the PCI bus
		bios		[X86-32] force use of PCI BIOS, don't access
				the hardware directly. Use this if your machine
				has a non-standard PCI host bridge.
		nobios		[X86-32] disallow use of PCI BIOS, only direct
				hardware access methods are allowed. Use this
				if you experience crashes upon bootup and you
				suspect they are caused by the BIOS.
		conf1		[X86] Force use of PCI Configuration
				Mechanism 1.
		conf2		[X86] Force use of PCI Configuration
				Mechanism 2.
		noaer		[PCIE] If the PCIEAER kernel config parameter is
				enabled, this kernel boot option can be used to
				disable the use of PCIE advanced error reporting.
		nodomains	[PCI] Disable support for multiple PCI
				root domains (aka PCI segments, in ACPI-speak).
		nommconf	[X86] Disable use of MMCONFIG for PCI
				Configuration
		check_enable_amd_mmconf [X86] check for and enable
				properly configured MMIO access to PCI
				config space on AMD family 10h CPU
		nomsi		[MSI] If the PCI_MSI kernel config parameter is
				enabled, this kernel boot option can be used to
				disable the use of MSI interrupts system-wide.
		noioapicquirk	[APIC] Disable all boot interrupt quirks.
				Safety option to keep boot IRQs enabled. This
				should never be necessary.
		ioapicreroute	[APIC] Enable rerouting of boot IRQs to the
				primary IO-APIC for bridges that cannot disable
				boot IRQs. This fixes a source of spurious IRQs
				when the system masks IRQs.
		noioapicreroute	[APIC] Disable workaround that uses the
				boot IRQ equivalent of an IRQ that connects to
				a chipset where boot IRQs cannot be disabled.
				The opposite of ioapicreroute.
		biosirq		[X86-32] Use PCI BIOS calls to get the interrupt
				routing table. These calls are known to be buggy
				on several machines and they hang the machine
				when used, but on other computers it's the only
				way to get the interrupt routing table. Try
				this option if the kernel is unable to allocate
				IRQs or discover secondary PCI buses on your
				motherboard.
		rom		[X86] Assign address space to expansion ROMs.
				Use with caution as certain devices share
				address decoders between ROMs and other
				resources.
		norom		[X86] Do not assign address space to
				expansion ROMs that do not already have
				BIOS assigned address ranges.
		nobar		[X86] Do not assign address space to the
				BARs that weren't assigned by the BIOS.
		irqmask=0xMMMM	[X86] Set a bit mask of IRQs allowed to be
				assigned automatically to PCI devices. You can
				make the kernel exclude IRQs of your ISA cards
				this way.
		pirqaddr=0xAAAAA	[X86] Specify the physical address
				of the PIRQ table (normally generated
				by the BIOS) if it is outside the
				F0000h-100000h range.
		lastbus=N	[X86] Scan all buses thru bus #N. Can be
				useful if the kernel is unable to find your
				secondary buses and you want to tell it
				explicitly which ones they are.
		assign-busses	[X86] Always assign all PCI bus
				numbers ourselves, overriding
				whatever the firmware may have done.
		usepirqmask	[X86] Honor the possible IRQ mask stored
				in the BIOS $PIR table. This is needed on
				some systems with broken BIOSes, notably
				some HP Pavilion N5400 and Omnibook XE3
				notebooks. This will have no effect if ACPI
				IRQ routing is enabled.
		noacpi		[X86] Do not use ACPI for IRQ routing
				or for PCI scanning.
		use_crs		[X86] Use PCI host bridge window information
				from ACPI.  On BIOSes from 2008 or later, this
				is enabled by default.  If you need to use this,
				please report a bug.
		nocrs		[X86] Ignore PCI host bridge windows from ACPI.
			        If you need to use this, please report a bug.
		routeirq	Do IRQ routing for all PCI devices.
				This is normally done in pci_enable_device(),
				so this option is a temporary workaround
				for broken drivers that don't call it.
		skip_isa_align	[X86] do not align io start addr, so can
				handle more pci cards
		firmware	[ARM] Do not re-enumerate the bus but instead
				just use the configuration from the
				bootloader. This is currently used on
				IXP2000 systems where the bus has to be
				configured a certain way for adjunct CPUs.
		noearly		[X86] Don't do any early type 1 scanning.
				This might help on some broken boards which
				machine check when some devices' config space
				is read. But various workarounds are disabled
				and some IOMMU drivers will not work.
		bfsort		Sort PCI devices into breadth-first order.
				This sorting is done to get a device
				order compatible with older (<= 2.4) kernels.
		nobfsort	Don't sort PCI devices into breadth-first order.
		cbiosize=nn[KMG]	The fixed amount of bus space which is
				reserved for the CardBus bridge's IO window.
				The default value is 256 bytes.
		cbmemsize=nn[KMG]	The fixed amount of bus space which is
				reserved for the CardBus bridge's memory
				window. The default value is 64 megabytes.
		resource_alignment=
				Format:
				[<order of align>@][<domain>:]<bus>:<slot>.<func>[; ...]
				Specifies alignment and device to reassign
				aligned memory resources.
				If <order of align> is not specified,
				PAGE_SIZE is used as alignment.
				PCI-PCI bridge can be specified, if resource
				windows need to be expanded.
		ecrc=		Enable/disable PCIe ECRC (transaction layer
				end-to-end CRC checking).
				bios: Use BIOS/firmware settings. This is the
				the default.
				off: Turn ECRC off
				on: Turn ECRC on.
		realloc		reallocate PCI resources if allocations done by BIOS
				are erroneous.

	pcie_aspm=	[PCIE] Forcibly enable or disable PCIe Active State Power
			Management.
		off	Disable ASPM.
		force	Enable ASPM even on devices that claim not to support it.
			WARNING: Forcing ASPM on may cause system lockups.

	pcie_ports=	[PCIE] PCIe ports handling:
		auto	Ask the BIOS whether or not to use native PCIe services
			associated with PCIe ports (PME, hot-plug, AER).  Use
			them only if that is allowed by the BIOS.
		native	Use native PCIe services associated with PCIe ports
			unconditionally.
		compat	Treat PCIe ports as PCI-to-PCI bridges, disable the PCIe
			ports driver.

	pcie_pme=	[PCIE,PM] Native PCIe PME signaling options:
		nomsi	Do not use MSI for native PCIe PME signaling (this makes
			all PCIe root ports use INTx for all services).

	pcmv=		[HW,PCMCIA] BadgePAD 4

	pd.		[PARIDE]
			See Documentation/blockdev/paride.txt.

	pdcchassis=	[PARISC,HW] Disable/Enable PDC Chassis Status codes at
			boot time.
			Format: { 0 | 1 }
			See arch/parisc/kernel/pdc_chassis.c

	percpu_alloc=	Select which percpu first chunk allocator to use.
			Currently supported values are "embed" and "page".
			Archs may support subset or none of the	selections.
			See comments in mm/percpu.c for details on each
			allocator.  This parameter is primarily	for debugging
			and performance comparison.

	pf.		[PARIDE]
			See Documentation/blockdev/paride.txt.

	pg.		[PARIDE]
			See Documentation/blockdev/paride.txt.

	pirq=		[SMP,APIC] Manual mp-table setup
			See Documentation/x86/i386/IO-APIC.txt.

	plip=		[PPT,NET] Parallel port network link
			Format: { parport<nr> | timid | 0 }
			See also Documentation/parport.txt.

	pmtmr=		[X86] Manual setup of pmtmr I/O Port. 
			Override pmtimer IOPort with a hex value.
			e.g. pmtmr=0x508

	pnp.debug	[PNP]
			Enable PNP debug messages.  This depends on the
			CONFIG_PNP_DEBUG_MESSAGES option.

	pnpacpi=	[ACPI]
			{ off }

	pnpbios=	[ISAPNP]
			{ on | off | curr | res | no-curr | no-res }

	pnp_reserve_irq=
			[ISAPNP] Exclude IRQs for the autoconfiguration

	pnp_reserve_dma=
			[ISAPNP] Exclude DMAs for the autoconfiguration

	pnp_reserve_io=	[ISAPNP] Exclude I/O ports for the autoconfiguration
			Ranges are in pairs (I/O port base and size).

	pnp_reserve_mem=
			[ISAPNP] Exclude memory regions for the
			autoconfiguration.
			Ranges are in pairs (memory base and size).

	ports=		[IP_VS_FTP] IPVS ftp helper module
			Default is 21.
			Up to 8 (IP_VS_APP_MAX_PORTS) ports
			may be specified.
			Format: <port>,<port>....

	print-fatal-signals=
			[KNL] debug: print fatal signals

			If enabled, warn about various signal handling
			related application anomalies: too many signals,
			too many POSIX.1 timers, fatal signals causing a
			coredump - etc.

			If you hit the warning due to signal overflow,
			you might want to try "ulimit -i unlimited".

			default: off.

	printk.time=	Show timing data prefixed to each printk message line
			Format: <bool>  (1/Y/y=enable, 0/N/n=disable)

	processor.max_cstate=	[HW,ACPI]
			Limit processor to maximum C-state
			max_cstate=9 overrides any DMI blacklist limit.

	processor.nocst	[HW,ACPI]
			Ignore the _CST method to determine C-states,
			instead using the legacy FADT method

	profile=	[KNL] Enable kernel profiling via /proc/profile
			Format: [schedule,]<number>
			Param: "schedule" - profile schedule points.
			Param: <number> - step/bucket size as a power of 2 for
				statistical time based profiling.
			Param: "sleep" - profile D-state sleeping (millisecs).
				Requires CONFIG_SCHEDSTATS
			Param: "kvm" - profile VM exits.

	prompt_ramdisk=	[RAM] List of RAM disks to prompt for floppy disk
			before loading.
			See Documentation/blockdev/ramdisk.txt.

	psmouse.proto=	[HW,MOUSE] Highest PS2 mouse protocol extension to
			probe for; one of (bare|imps|exps|lifebook|any).
	psmouse.rate=	[HW,MOUSE] Set desired mouse report rate, in reports
			per second.
	psmouse.resetafter=	[HW,MOUSE]
			Try to reset the device after so many bad packets
			(0 = never).
	psmouse.resolution=
			[HW,MOUSE] Set desired mouse resolution, in dpi.
	psmouse.smartscroll=
			[HW,MOUSE] Controls Logitech smartscroll autorepeat.
			0 = disabled, 1 = enabled (default).

	pt.		[PARIDE]
			See Documentation/blockdev/paride.txt.

	pty.legacy_count=
			[KNL] Number of legacy pty's. Overwrites compiled-in
			default number.

	quiet		[KNL] Disable most log messages

	r128=		[HW,DRM]

	raid=		[HW,RAID]
			See Documentation/md.txt.

	ramdisk_blocksize=	[RAM]
			See Documentation/blockdev/ramdisk.txt.

	ramdisk_size=	[RAM] Sizes of RAM disks in kilobytes
			See Documentation/blockdev/ramdisk.txt.

	rcupdate.blimit=	[KNL,BOOT]
			Set maximum number of finished RCU callbacks to process
			in one batch.

	rcupdate.qhimark=	[KNL,BOOT]
			Set threshold of queued
			RCU callbacks over which batch limiting is disabled.

	rcupdate.qlowmark=	[KNL,BOOT]
			Set threshold of queued RCU callbacks below which
			batch limiting is re-enabled.

	rdinit=		[KNL]
			Format: <full_path>
			Run specified binary instead of /init from the ramdisk,
			used for early userspace startup. See initrd.

	reboot=		[BUGS=X86-32,BUGS=ARM,BUGS=IA-64] Rebooting mode
			Format: <reboot_mode>[,<reboot_mode2>[,...]]
			See arch/*/kernel/reboot.c or arch/*/kernel/process.c

	relax_domain_level=
			[KNL, SMP] Set scheduler's default relax_domain_level.
			See Documentation/cgroups/cpusets.txt.

	reserve=	[KNL,BUGS] Force the kernel to ignore some iomem area

	reservetop=	[X86-32]
			Format: nn[KMG]
			Reserves a hole at the top of the kernel virtual
			address space.

	reservelow=	[X86]
			Format: nn[K]
			Set the amount of memory to reserve for BIOS at
			the bottom of the address space.

	reset_devices	[KNL] Force drivers to reset the underlying device
			during initialization.

	resume=		[SWSUSP]
			Specify the partition device for software suspend

	resume_offset=	[SWSUSP]
			Specify the offset from the beginning of the partition
			given by "resume=" at which the swap header is located,
			in <PAGE_SIZE> units (needed only for swap files).
			See  Documentation/power/swsusp-and-swap-files.txt

	hibernate=	[HIBERNATION]
		noresume	Don't check if there's a hibernation image
				present during boot.
		nocompress	Don't compress/decompress hibernation images.

	retain_initrd	[RAM] Keep initrd memory after extraction

	rhash_entries=	[KNL,NET]
			Set number of hash buckets for route cache

	riscom8=	[HW,SERIAL]
			Format: <io_board1>[,<io_board2>[,...<io_boardN>]]

	ro		[KNL] Mount root device read-only on boot

	root=		[KNL] Root filesystem

	rootdelay=	[KNL] Delay (in seconds) to pause before attempting to
			mount the root filesystem

	rootflags=	[KNL] Set root filesystem mount option string

	rootfstype=	[KNL] Set root filesystem type

	rootwait	[KNL] Wait (indefinitely) for root device to show up.
			Useful for devices that are detected asynchronously
			(e.g. USB and MMC devices).

	rw		[KNL] Mount root device read-write on boot

	S		[KNL] Run init in single mode

	sa1100ir	[NET]
			See drivers/net/irda/sa1100_ir.c.

	sbni=		[NET] Granch SBNI12 leased line adapter

	sched_debug	[KNL] Enables verbose scheduler debug messages.

	security=	[SECURITY] Choose a security module to enable at boot.
			If this boot parameter is not specified, only the first
			security module asking for security registration will be
			loaded. An invalid security module name will be treated
			as if no module has been chosen.

	selinux=	[SELINUX] Disable or enable SELinux at boot time.
			Format: { "0" | "1" }
			See security/selinux/Kconfig help text.
			0 -- disable.
			1 -- enable.
			Default value is set via kernel config option.
			If enabled at boot time, /selinux/disable can be used
			later to disable prior to initial policy load.

	apparmor=	[APPARMOR] Disable or enable AppArmor at boot time
			Format: { "0" | "1" }
			See security/apparmor/Kconfig help text
			0 -- disable.
			1 -- enable.
			Default value is set via kernel config option.

	serialnumber	[BUGS=X86-32]

	shapers=	[NET]
			Maximal number of shapers.

	show_msr=	[x86] show boot-time MSR settings
			Format: { <integer> }
			Show boot-time (BIOS-initialized) MSR settings.
			The parameter means the number of CPUs to show,
			for example 1 means boot CPU only.

	simeth=		[IA-64]
	simscsi=

	slram=		[HW,MTD]

	slub_debug[=options[,slabs]]	[MM, SLUB]
			Enabling slub_debug allows one to determine the
			culprit if slab objects become corrupted. Enabling
			slub_debug can create guard zones around objects and
			may poison objects when not in use. Also tracks the
			last alloc / free. For more information see
			Documentation/vm/slub.txt.

	slub_max_order= [MM, SLUB]
			Determines the maximum allowed order for slabs.
			A high setting may cause OOMs due to memory
			fragmentation. For more information see
			Documentation/vm/slub.txt.

	slub_min_objects=	[MM, SLUB]
			The minimum number of objects per slab. SLUB will
			increase the slab order up to slub_max_order to
			generate a sufficiently large slab able to contain
			the number of objects indicated. The higher the number
			of objects the smaller the overhead of tracking slabs
			and the less frequently locks need to be acquired.
			For more information see Documentation/vm/slub.txt.

	slub_min_order=	[MM, SLUB]
			Determines the mininum page order for slabs. Must be
			lower than slub_max_order.
			For more information see Documentation/vm/slub.txt.

	slub_nomerge	[MM, SLUB]
			Disable merging of slabs with similar size. May be
			necessary if there is some reason to distinguish
			allocs to different slabs. Debug options disable
			merging on their own.
			For more information see Documentation/vm/slub.txt.

	smart2=		[HW]
			Format: <io1>[,<io2>[,...,<io8>]]

	smp-alt-once	[X86-32,SMP] On a hotplug CPU system, only
			attempt to substitute SMP alternatives once at boot.

	smsc-ircc2.nopnp	[HW] Don't use PNP to discover SMC devices
	smsc-ircc2.ircc_cfg=	[HW] Device configuration I/O port
	smsc-ircc2.ircc_sir=	[HW] SIR base I/O port
	smsc-ircc2.ircc_fir=	[HW] FIR base I/O port
	smsc-ircc2.ircc_irq=	[HW] IRQ line
	smsc-ircc2.ircc_dma=	[HW] DMA channel
	smsc-ircc2.ircc_transceiver= [HW] Transceiver type:
				0: Toshiba Satellite 1800 (GP data pin select)
				1: Fast pin select (default)
				2: ATC IRMode

	softlockup_panic=
			[KNL] Should the soft-lockup detector generate panics.
			Format: <integer>

	sonypi.*=	[HW] Sony Programmable I/O Control Device driver
			See Documentation/sonypi.txt

	specialix=	[HW,SERIAL] Specialix multi-serial port adapter
			See Documentation/serial/specialix.txt.

	spia_io_base=	[HW,MTD]
	spia_fio_base=
	spia_pedr=
	spia_peddr=

	stacktrace	[FTRACE]
			Enabled the stack tracer on boot up.

	sti=		[PARISC,HW]
			Format: <num>
			Set the STI (builtin display/keyboard on the HP-PARISC
			machines) console (graphic card) which should be used
			as the initial boot-console.
			See also comment in drivers/video/console/sticore.c.

	sti_font=	[HW]
			See comment in drivers/video/console/sticore.c.

	stifb=		[HW]
			Format: bpp:<bpp1>[:<bpp2>[:<bpp3>...]]

	sunrpc.min_resvport=
	sunrpc.max_resvport=
			[NFS,SUNRPC]
			SunRPC servers often require that client requests
			originate from a privileged port (i.e. a port in the
			range 0 < portnr < 1024).
			An administrator who wishes to reserve some of these
			ports for other uses may adjust the range that the
			kernel's sunrpc client considers to be privileged
			using these two parameters to set the minimum and
			maximum port values.

	sunrpc.pool_mode=
			[NFS]
			Control how the NFS server code allocates CPUs to
			service thread pools.  Depending on how many NICs
			you have and where their interrupts are bound, this
			option will affect which CPUs will do NFS serving.
			Note: this parameter cannot be changed while the
			NFS server is running.

			auto	    the server chooses an appropriate mode
				    automatically using heuristics
			global	    a single global pool contains all CPUs
			percpu	    one pool for each CPU
			pernode	    one pool for each NUMA node (equivalent
				    to global on non-NUMA machines)

	sunrpc.tcp_slot_table_entries=
	sunrpc.udp_slot_table_entries=
			[NFS,SUNRPC]
			Sets the upper limit on the number of simultaneous
			RPC calls that can be sent from the client to a
			server. Increasing these values may allow you to
			improve throughput, but will also increase the
			amount of memory reserved for use by the client.

	swapaccount[=0|1]
			[KNL] Enable accounting of swap in memory resource
			controller if no parameter or 1 is given or disable
			it if 0 is given (See Documentation/cgroups/memory.txt)

	swiotlb=	[IA-64] Number of I/O TLB slabs

	switches=	[HW,M68k]

	sysfs.deprecated=0|1 [KNL]
			Enable/disable old style sysfs layout for old udev
			on older distributions. When this option is enabled
			very new udev will not work anymore. When this option
			is disabled (or CONFIG_SYSFS_DEPRECATED not compiled)
			in older udev will not work anymore.
			Default depends on CONFIG_SYSFS_DEPRECATED_V2 set in
			the kernel configuration.

	sysrq_always_enabled
			[KNL]
			Ignore sysrq setting - this boot parameter will
			neutralize any effect of /proc/sys/kernel/sysrq.
			Useful for debugging.

	tdfx=		[HW,DRM]

	test_suspend=	[SUSPEND]
			Specify "mem" (for Suspend-to-RAM) or "standby" (for
			standby suspend) as the system sleep state to briefly
			enter during system startup.  The system is woken from
			this state using a wakeup-capable RTC alarm.

	thash_entries=	[KNL,NET]
			Set number of hash buckets for TCP connection

	thermal.act=	[HW,ACPI]
			-1: disable all active trip points in all thermal zones
			<degrees C>: override all lowest active trip points

	thermal.crt=	[HW,ACPI]
			-1: disable all critical trip points in all thermal zones
			<degrees C>: override all critical trip points

	thermal.nocrt=	[HW,ACPI]
			Set to disable actions on ACPI thermal zone
			critical and hot trip points.

	thermal.off=	[HW,ACPI]
			1: disable ACPI thermal control

	thermal.psv=	[HW,ACPI]
			-1: disable all passive trip points
			<degrees C>: override all passive trip points to this
			value

	thermal.tzp=	[HW,ACPI]
			Specify global default ACPI thermal zone polling rate
			<deci-seconds>: poll all this frequency
			0: no polling (default)

	threadirqs	[KNL]
			Force threading of all interrupt handlers except those
			marked explicitely IRQF_NO_THREAD.

	topology=	[S390]
			Format: {off | on}
			Specify if the kernel should make use of the cpu
			topology information if the hardware supports this.
			The scheduler will make use of this information and
			e.g. base its process migration decisions on it.
			Default is on.

	tp720=		[HW,PS2]

	tpm_suspend_pcr=[HW,TPM]
			Format: integer pcr id
			Specify that at suspend time, the tpm driver
			should extend the specified pcr with zeros,
			as a workaround for some chips which fail to
			flush the last written pcr on TPM_SaveState.
			This will guarantee that all the other pcrs
			are saved.

	trace_buf_size=nn[KMG]
			[FTRACE] will set tracing buffer size.

	trace_event=[event-list]
			[FTRACE] Set and start specified trace events in order
			to facilitate early boot debugging.
			See also Documentation/trace/events.txt

	tsc=		Disable clocksource stability checks for TSC.
			Format: <string>
			[x86] reliable: mark tsc clocksource as reliable, this
			disables clocksource verification at runtime, as well
			as the stability checks done at bootup.	Used to enable
			high-resolution timer mode on older hardware, and in
			virtualized environment.
			[x86] noirqtime: Do not use TSC to do irq accounting.
			Used to run time disable IRQ_TIME_ACCOUNTING on any
			platforms where RDTSC is slow and this accounting
			can add overhead.

	turbografx.map[2|3]=	[HW,JOY]
			TurboGraFX parallel port interface
			Format:
			<port#>,<js1>,<js2>,<js3>,<js4>,<js5>,<js6>,<js7>
			See also Documentation/input/joystick-parport.txt

	uhash_entries=	[KNL,NET]
			Set number of hash buckets for UDP/UDP-Lite connections

	uhci-hcd.ignore_oc=
			[USB] Ignore overcurrent events (default N).
			Some badly-designed motherboards generate lots of
			bogus events, for ports that aren't wired to
			anything.  Set this parameter to avoid log spamming.
			Note that genuine overcurrent events won't be
			reported either.

	unknown_nmi_panic
			[X86] Cause panic on unknown NMI.

	usbcore.autosuspend=
			[USB] The autosuspend time delay (in seconds) used
			for newly-detected USB devices (default 2).  This
			is the time required before an idle device will be
			autosuspended.  Devices for which the delay is set
			to a negative value won't be autosuspended at all.

	usbcore.usbfs_snoop=
			[USB] Set to log all usbfs traffic (default 0 = off).

	usbcore.blinkenlights=
			[USB] Set to cycle leds on hubs (default 0 = off).

	usbcore.old_scheme_first=
			[USB] Start with the old device initialization
			scheme (default 0 = off).

	usbcore.use_both_schemes=
			[USB] Try the other device initialization scheme
			if the first one fails (default 1 = enabled).

	usbcore.initial_descriptor_timeout=
			[USB] Specifies timeout for the initial 64-byte
                        USB_REQ_GET_DESCRIPTOR request in milliseconds
			(default 5000 = 5.0 seconds).

	usbhid.mousepoll=
			[USBHID] The interval which mice are to be polled at.

	usb-storage.delay_use=
			[UMS] The delay in seconds before a new device is
			scanned for Logical Units (default 5).

	usb-storage.quirks=
			[UMS] A list of quirks entries to supplement or
			override the built-in unusual_devs list.  List
			entries are separated by commas.  Each entry has
			the form VID:PID:Flags where VID and PID are Vendor
			and Product ID values (4-digit hex numbers) and
			Flags is a set of characters, each corresponding
			to a common usb-storage quirk flag as follows:
				a = SANE_SENSE (collect more than 18 bytes
					of sense data);
				b = BAD_SENSE (don't collect more than 18
					bytes of sense data);
				c = FIX_CAPACITY (decrease the reported
					device capacity by one sector);
				d = NO_READ_DISC_INFO (don't use
					READ_DISC_INFO command);
				e = NO_READ_CAPACITY_16 (don't use
					READ_CAPACITY_16 command);
				h = CAPACITY_HEURISTICS (decrease the
					reported device capacity by one
					sector if the number is odd);
				i = IGNORE_DEVICE (don't bind to this
					device);
				l = NOT_LOCKABLE (don't try to lock and
					unlock ejectable media);
				m = MAX_SECTORS_64 (don't transfer more
					than 64 sectors = 32 KB at a time);
				n = INITIAL_READ10 (force a retry of the
					initial READ(10) command);
				o = CAPACITY_OK (accept the capacity
					reported by the device);
				r = IGNORE_RESIDUE (the device reports
					bogus residue values);
				s = SINGLE_LUN (the device has only one
					Logical Unit);
				w = NO_WP_DETECT (don't test whether the
					medium is write-protected).
			Example: quirks=0419:aaf5:rl,0421:0433:rc

	userpte=
			[X86] Flags controlling user PTE allocations.

				nohigh = do not allocate PTE pages in
					HIGHMEM regardless of setting
					of CONFIG_HIGHPTE.

	vdso=		[X86,SH]
			vdso=2: enable compat VDSO (default with COMPAT_VDSO)
			vdso=1: enable VDSO (default)
			vdso=0: disable VDSO mapping

	vdso32=		[X86]
			vdso32=2: enable compat VDSO (default with COMPAT_VDSO)
			vdso32=1: enable 32-bit VDSO (default)
			vdso32=0: disable 32-bit VDSO mapping

	vector=		[IA-64,SMP]
			vector=percpu: enable percpu vector domain

	video=		[FB] Frame buffer configuration
			See Documentation/fb/modedb.txt.

	vga=		[BOOT,X86-32] Select a particular video mode
			See Documentation/x86/boot.txt and
			Documentation/svga.txt.
			Use vga=ask for menu.
			This is actually a boot loader parameter; the value is
			passed to the kernel using a special protocol.

	vmalloc=nn[KMG]	[KNL,BOOT] Forces the vmalloc area to have an exact
			size of <nn>. This can be used to increase the
			minimum size (128MB on x86). It can also be used to
			decrease the size and leave more room for directly
			mapped kernel RAM.

	vmhalt=		[KNL,S390] Perform z/VM CP command after system halt.
			Format: <command>

	vmpanic=	[KNL,S390] Perform z/VM CP command after kernel panic.
			Format: <command>

	vmpoff=		[KNL,S390] Perform z/VM CP command after power off.
			Format: <command>

	vt.cur_default=	[VT] Default cursor shape.
			Format: 0xCCBBAA, where AA, BB, and CC are the same as
			the parameters of the <Esc>[?A;B;Cc escape sequence;
			see VGA-softcursor.txt. Default: 2 = underline.

	vt.default_blu=	[VT]
			Format: <blue0>,<blue1>,<blue2>,...,<blue15>
			Change the default blue palette of the console.
			This is a 16-member array composed of values
			ranging from 0-255.

	vt.default_grn=	[VT]
			Format: <green0>,<green1>,<green2>,...,<green15>
			Change the default green palette of the console.
			This is a 16-member array composed of values
			ranging from 0-255.

	vt.default_red=	[VT]
			Format: <red0>,<red1>,<red2>,...,<red15>
			Change the default red palette of the console.
			This is a 16-member array composed of values
			ranging from 0-255.

	vt.default_utf8=
			[VT]
			Format=<0|1>
			Set system-wide default UTF-8 mode for all tty's.
			Default is 1, i.e. UTF-8 mode is enabled for all
			newly opened terminals.

	vt.global_cursor_default=
			[VT]
			Format=<-1|0|1>
			Set system-wide default for whether a cursor
			is shown on new VTs. Default is -1,
			i.e. cursors will be created by default unless
			overridden by individual drivers. 0 will hide
			cursors, 1 will display them.

	watchdog timers	[HW,WDT] For information on watchdog timers,
			see Documentation/watchdog/watchdog-parameters.txt
			or other driver-specific files in the
			Documentation/watchdog/ directory.

	x2apic_phys	[X86-64,APIC] Use x2apic physical mode instead of
			default x2apic cluster mode on platforms
			supporting x2apic.

	x86_mrst_timer= [X86-32,APBT]
			Choose timer option for x86 Moorestown MID platform.
			Two valid options are apbt timer only and lapic timer
			plus one apbt timer for broadcast timer.
			x86_mrst_timer=apbt_only | lapic_and_apbt

	xd=		[HW,XT] Original XT pre-IDE (RLL encoded) disks.
	xd_geo=		See header of drivers/block/xd.c.

	xen_emul_unplug=		[HW,X86,XEN]
			Unplug Xen emulated devices
			Format: [unplug0,][unplug1]
			ide-disks -- unplug primary master IDE devices
			aux-ide-disks -- unplug non-primary-master IDE devices
			nics -- unplug network devices
			all -- unplug all emulated devices (NICs and IDE disks)
			unnecessary -- unplugging emulated devices is
				unnecessary even if the host did not respond to
				the unplug protocol
			never -- do not unplug even if version check succeeds

	xirc2ps_cs=	[NET,PCMCIA]
			Format:
			<irq>,<irq_mask>,<io>,<full_duplex>,<do_sound>,<lockup_hack>[,<irq2>[,<irq3>[,<irq4>]]]

______________________________________________________________________

TODO:

	Add more DRM drivers.
GETTING STARTED WITH KMEMCHECK
==============================

Vegard Nossum <vegardno@ifi.uio.no>


Contents
========
0. Introduction
1. Downloading
2. Configuring and compiling
3. How to use
3.1. Booting
3.2. Run-time enable/disable
3.3. Debugging
3.4. Annotating false positives
4. Reporting errors
5. Technical description


0. Introduction
===============

kmemcheck is a debugging feature for the Linux Kernel. More specifically, it
is a dynamic checker that detects and warns about some uses of uninitialized
memory.

Userspace programmers might be familiar with Valgrind's memcheck. The main
difference between memcheck and kmemcheck is that memcheck works for userspace
programs only, and kmemcheck works for the kernel only. The implementations
are of course vastly different. Because of this, kmemcheck is not as accurate
as memcheck, but it turns out to be good enough in practice to discover real
programmer errors that the compiler is not able to find through static
analysis.

Enabling kmemcheck on a kernel will probably slow it down to the extent that
the machine will not be usable for normal workloads such as e.g. an
interactive desktop. kmemcheck will also cause the kernel to use about twice
as much memory as normal. For this reason, kmemcheck is strictly a debugging
feature.


1. Downloading
==============

As of version 2.6.31-rc1, kmemcheck is included in the mainline kernel.


2. Configuring and compiling
============================

kmemcheck only works for the x86 (both 32- and 64-bit) platform. A number of
configuration variables must have specific settings in order for the kmemcheck
menu to even appear in "menuconfig". These are:

  o CONFIG_CC_OPTIMIZE_FOR_SIZE=n

	This option is located under "General setup" / "Optimize for size".

	Without this, gcc will use certain optimizations that usually lead to
	false positive warnings from kmemcheck. An example of this is a 16-bit
	field in a struct, where gcc may load 32 bits, then discard the upper
	16 bits. kmemcheck sees only the 32-bit load, and may trigger a
	warning for the upper 16 bits (if they're uninitialized).

  o CONFIG_SLAB=y or CONFIG_SLUB=y

	This option is located under "General setup" / "Choose SLAB
	allocator".

  o CONFIG_FUNCTION_TRACER=n

	This option is located under "Kernel hacking" / "Tracers" / "Kernel
	Function Tracer"

	When function tracing is compiled in, gcc emits a call to another
	function at the beginning of every function. This means that when the
	page fault handler is called, the ftrace framework will be called
	before kmemcheck has had a chance to handle the fault. If ftrace then
	modifies memory that was tracked by kmemcheck, the result is an
	endless recursive page fault.

  o CONFIG_DEBUG_PAGEALLOC=n

	This option is located under "Kernel hacking" / "Debug page memory
	allocations".

In addition, I highly recommend turning on CONFIG_DEBUG_INFO=y. This is also
located under "Kernel hacking". With this, you will be able to get line number
information from the kmemcheck warnings, which is extremely valuable in
debugging a problem. This option is not mandatory, however, because it slows
down the compilation process and produces a much bigger kernel image.

Now the kmemcheck menu should be visible (under "Kernel hacking" / "kmemcheck:
trap use of uninitialized memory"). Here follows a description of the
kmemcheck configuration variables:

  o CONFIG_KMEMCHECK

	This must be enabled in order to use kmemcheck at all...

  o CONFIG_KMEMCHECK_[DISABLED | ENABLED | ONESHOT]_BY_DEFAULT

	This option controls the status of kmemcheck at boot-time. "Enabled"
	will enable kmemcheck right from the start, "disabled" will boot the
	kernel as normal (but with the kmemcheck code compiled in, so it can
	be enabled at run-time after the kernel has booted), and "one-shot" is
	a special mode which will turn kmemcheck off automatically after
	detecting the first use of uninitialized memory.

	If you are using kmemcheck to actively debug a problem, then you
	probably want to choose "enabled" here.

	The one-shot mode is mostly useful in automated test setups because it
	can prevent floods of warnings and increase the chances of the machine
	surviving in case something is really wrong. In other cases, the one-
	shot mode could actually be counter-productive because it would turn
	itself off at the very first error -- in the case of a false positive
	too -- and this would come in the way of debugging the specific
	problem you were interested in.

	If you would like to use your kernel as normal, but with a chance to
	enable kmemcheck in case of some problem, it might be a good idea to
	choose "disabled" here. When kmemcheck is disabled, most of the run-
	time overhead is not incurred, and the kernel will be almost as fast
	as normal.

  o CONFIG_KMEMCHECK_QUEUE_SIZE

	Select the maximum number of error reports to store in an internal
	(fixed-size) buffer. Since errors can occur virtually anywhere and in
	any context, we need a temporary storage area which is guaranteed not
	to generate any other page faults when accessed. The queue will be
	emptied as soon as a tasklet may be scheduled. If the queue is full,
	new error reports will be lost.

	The default value of 64 is probably fine. If some code produces more
	than 64 errors within an irqs-off section, then the code is likely to
	produce many, many more, too, and these additional reports seldom give
	any more information (the first report is usually the most valuable
	anyway).

	This number might have to be adjusted if you are not using serial
	console or similar to capture the kernel log. If you are using the
	"dmesg" command to save the log, then getting a lot of kmemcheck
	warnings might overflow the kernel log itself, and the earlier reports
	will get lost in that way instead. Try setting this to 10 or so on
	such a setup.

  o CONFIG_KMEMCHECK_SHADOW_COPY_SHIFT

	Select the number of shadow bytes to save along with each entry of the
	error-report queue. These bytes indicate what parts of an allocation
	are initialized, uninitialized, etc. and will be displayed when an
	error is detected to help the debugging of a particular problem.

	The number entered here is actually the logarithm of the number of
	bytes that will be saved. So if you pick for example 5 here, kmemcheck
	will save 2^5 = 32 bytes.

	The default value should be fine for debugging most problems. It also
	fits nicely within 80 columns.

  o CONFIG_KMEMCHECK_PARTIAL_OK

	This option (when enabled) works around certain GCC optimizations that
	produce 32-bit reads from 16-bit variables where the upper 16 bits are
	thrown away afterwards.

	The default value (enabled) is recommended. This may of course hide
	some real errors, but disabling it would probably produce a lot of
	false positives.

  o CONFIG_KMEMCHECK_BITOPS_OK

	This option silences warnings that would be generated for bit-field
	accesses where not all the bits are initialized at the same time. This
	may also hide some real bugs.

	This option is probably obsolete, or it should be replaced with
	the kmemcheck-/bitfield-annotations for the code in question. The
	default value is therefore fine.

Now compile the kernel as usual.


3. How to use
=============

3.1. Booting
============

First some information about the command-line options. There is only one
option specific to kmemcheck, and this is called "kmemcheck". It can be used
to override the default mode as chosen by the CONFIG_KMEMCHECK_*_BY_DEFAULT
option. Its possible settings are:

  o kmemcheck=0 (disabled)
  o kmemcheck=1 (enabled)
  o kmemcheck=2 (one-shot mode)

If SLUB debugging has been enabled in the kernel, it may take precedence over
kmemcheck in such a way that the slab caches which are under SLUB debugging
will not be tracked by kmemcheck. In order to ensure that this doesn't happen
(even though it shouldn't by default), use SLUB's boot option "slub_debug",
like this: slub_debug=-

In fact, this option may also be used for fine-grained control over SLUB vs.
kmemcheck. For example, if the command line includes "kmemcheck=1
slub_debug=,dentry", then SLUB debugging will be used only for the "dentry"
slab cache, and with kmemcheck tracking all the other caches. This is advanced
usage, however, and is not generally recommended.


3.2. Run-time enable/disable
============================

When the kernel has booted, it is possible to enable or disable kmemcheck at
run-time. WARNING: This feature is still experimental and may cause false
positive warnings to appear. Therefore, try not to use this. If you find that
it doesn't work properly (e.g. you see an unreasonable amount of warnings), I
will be happy to take bug reports.

Use the file /proc/sys/kernel/kmemcheck for this purpose, e.g.:

	$ echo 0 > /proc/sys/kernel/kmemcheck # disables kmemcheck

The numbers are the same as for the kmemcheck= command-line option.


3.3. Debugging
==============

A typical report will look something like this:

WARNING: kmemcheck: Caught 32-bit read from uninitialized memory (ffff88003e4a2024)
80000000000000000000000000000000000000000088ffff0000000000000000
 i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u
         ^

Pid: 1856, comm: ntpdate Not tainted 2.6.29-rc5 #264 945P-A
RIP: 0010:[<ffffffff8104ede8>]  [<ffffffff8104ede8>] __dequeue_signal+0xc8/0x190
RSP: 0018:ffff88003cdf7d98  EFLAGS: 00210002
RAX: 0000000000000030 RBX: ffff88003d4ea968 RCX: 0000000000000009
RDX: ffff88003e5d6018 RSI: ffff88003e5d6024 RDI: ffff88003cdf7e84
RBP: ffff88003cdf7db8 R08: ffff88003e5d6000 R09: 0000000000000000
R10: 0000000000000080 R11: 0000000000000000 R12: 000000000000000e
R13: ffff88003cdf7e78 R14: ffff88003d530710 R15: ffff88003d5a98c8
FS:  0000000000000000(0000) GS:ffff880001982000(0063) knlGS:00000
CS:  0010 DS: 002b ES: 002b CR0: 0000000080050033
CR2: ffff88003f806ea0 CR3: 000000003c036000 CR4: 00000000000006a0
DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
DR3: 0000000000000000 DR6: 00000000ffff4ff0 DR7: 0000000000000400
 [<ffffffff8104f04e>] dequeue_signal+0x8e/0x170
 [<ffffffff81050bd8>] get_signal_to_deliver+0x98/0x390
 [<ffffffff8100b87d>] do_notify_resume+0xad/0x7d0
 [<ffffffff8100c7b5>] int_signal+0x12/0x17
 [<ffffffffffffffff>] 0xffffffffffffffff

The single most valuable information in this report is the RIP (or EIP on 32-
bit) value. This will help us pinpoint exactly which instruction that caused
the warning.

If your kernel was compiled with CONFIG_DEBUG_INFO=y, then all we have to do
is give this address to the addr2line program, like this:

	$ addr2line -e vmlinux -i ffffffff8104ede8
	arch/x86/include/asm/string_64.h:12
	include/asm-generic/siginfo.h:287
	kernel/signal.c:380
	kernel/signal.c:410

The "-e vmlinux" tells addr2line which file to look in. IMPORTANT: This must
be the vmlinux of the kernel that produced the warning in the first place! If
not, the line number information will almost certainly be wrong.

The "-i" tells addr2line to also print the line numbers of inlined functions.
In this case, the flag was very important, because otherwise, it would only
have printed the first line, which is just a call to memcpy(), which could be
called from a thousand places in the kernel, and is therefore not very useful.
These inlined functions would not show up in the stack trace above, simply
because the kernel doesn't load the extra debugging information. This
technique can of course be used with ordinary kernel oopses as well.

In this case, it's the caller of memcpy() that is interesting, and it can be
found in include/asm-generic/siginfo.h, line 287:

281 static inline void copy_siginfo(struct siginfo *to, struct siginfo *from)
282 {
283         if (from->si_code < 0)
284                 memcpy(to, from, sizeof(*to));
285         else
286                 /* _sigchld is currently the largest know union member */
287                 memcpy(to, from, __ARCH_SI_PREAMBLE_SIZE + sizeof(from->_sifields._sigchld));
288 }

Since this was a read (kmemcheck usually warns about reads only, though it can
warn about writes to unallocated or freed memory as well), it was probably the
"from" argument which contained some uninitialized bytes. Following the chain
of calls, we move upwards to see where "from" was allocated or initialized,
kernel/signal.c, line 380:

359 static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)
360 {
...
367         list_for_each_entry(q, &list->list, list) {
368                 if (q->info.si_signo == sig) {
369                         if (first)
370                                 goto still_pending;
371                         first = q;
...
377         if (first) {
378 still_pending:
379                 list_del_init(&first->list);
380                 copy_siginfo(info, &first->info);
381                 __sigqueue_free(first);
...
392         }
393 }

Here, it is &first->info that is being passed on to copy_siginfo(). The
variable "first" was found on a list -- passed in as the second argument to
collect_signal(). We  continue our journey through the stack, to figure out
where the item on "list" was allocated or initialized. We move to line 410:

395 static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,
396                         siginfo_t *info)
397 {
...
410                 collect_signal(sig, pending, info);
...
414 }

Now we need to follow the "pending" pointer, since that is being passed on to
collect_signal() as "list". At this point, we've run out of lines from the
"addr2line" output. Not to worry, we just paste the next addresses from the
kmemcheck stack dump, i.e.:

 [<ffffffff8104f04e>] dequeue_signal+0x8e/0x170
 [<ffffffff81050bd8>] get_signal_to_deliver+0x98/0x390
 [<ffffffff8100b87d>] do_notify_resume+0xad/0x7d0
 [<ffffffff8100c7b5>] int_signal+0x12/0x17

	$ addr2line -e vmlinux -i ffffffff8104f04e ffffffff81050bd8 \
		ffffffff8100b87d ffffffff8100c7b5
	kernel/signal.c:446
	kernel/signal.c:1806
	arch/x86/kernel/signal.c:805
	arch/x86/kernel/signal.c:871
	arch/x86/kernel/entry_64.S:694

Remember that since these addresses were found on the stack and not as the
RIP value, they actually point to the _next_ instruction (they are return
addresses). This becomes obvious when we look at the code for line 446:

422 int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
423 {
...
431                 signr = __dequeue_signal(&tsk->signal->shared_pending,
432                                          mask, info);
433                 /*
434                  * itimer signal ?
435                  *
436                  * itimers are process shared and we restart periodic
437                  * itimers in the signal delivery path to prevent DoS
438                  * attacks in the high resolution timer case. This is
439                  * compliant with the old way of self restarting
440                  * itimers, as the SIGALRM is a legacy signal and only
441                  * queued once. Changing the restart behaviour to
442                  * restart the timer in the signal dequeue path is
443                  * reducing the timer noise on heavy loaded !highres
444                  * systems too.
445                  */
446                 if (unlikely(signr == SIGALRM)) {
...
489 }

So instead of looking at 446, we should be looking at 431, which is the line
that executes just before 446. Here we see that what we are looking for is
&tsk->signal->shared_pending.

Our next task is now to figure out which function that puts items on this
"shared_pending" list. A crude, but efficient tool, is git grep:

	$ git grep -n 'shared_pending' kernel/
	...
	kernel/signal.c:828:    pending = group ? &t->signal->shared_pending : &t->pending;
	kernel/signal.c:1339:   pending = group ? &t->signal->shared_pending : &t->pending;
	...

There were more results, but none of them were related to list operations,
and these were the only assignments. We inspect the line numbers more closely
and find that this is indeed where items are being added to the list:

816 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
817                         int group)
818 {
...
828         pending = group ? &t->signal->shared_pending : &t->pending;
...
851         q = __sigqueue_alloc(t, GFP_ATOMIC, (sig < SIGRTMIN &&
852                                              (is_si_special(info) ||
853                                               info->si_code >= 0)));
854         if (q) {
855                 list_add_tail(&q->list, &pending->list);
...
890 }

and:

1309 int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)
1310 {
....
1339         pending = group ? &t->signal->shared_pending : &t->pending;
1340         list_add_tail(&q->list, &pending->list);
....
1347 }

In the first case, the list element we are looking for, "q", is being returned
from the function __sigqueue_alloc(), which looks like an allocation function.
Let's take a look at it:

187 static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,
188                                          int override_rlimit)
189 {
190         struct sigqueue *q = NULL;
191         struct user_struct *user;
192 
193         /*
194          * We won't get problems with the target's UID changing under us
195          * because changing it requires RCU be used, and if t != current, the
196          * caller must be holding the RCU readlock (by way of a spinlock) and
197          * we use RCU protection here
198          */
199         user = get_uid(__task_cred(t)->user);
200         atomic_inc(&user->sigpending);
201         if (override_rlimit ||
202             atomic_read(&user->sigpending) <=
203                         t->signal->rlim[RLIMIT_SIGPENDING].rlim_cur)
204                 q = kmem_cache_alloc(sigqueue_cachep, flags);
205         if (unlikely(q == NULL)) {
206                 atomic_dec(&user->sigpending);
207                 free_uid(user);
208         } else {
209                 INIT_LIST_HEAD(&q->list);
210                 q->flags = 0;
211                 q->user = user;
212         }
213 
214         return q;
215 }

We see that this function initializes q->list, q->flags, and q->user. It seems
that now is the time to look at the definition of "struct sigqueue", e.g.:

14 struct sigqueue {
15         struct list_head list;
16         int flags;
17         siginfo_t info;
18         struct user_struct *user;
19 };

And, you might remember, it was a memcpy() on &first->info that caused the
warning, so this makes perfect sense. It also seems reasonable to assume that
it is the caller of __sigqueue_alloc() that has the responsibility of filling
out (initializing) this member.

But just which fields of the struct were uninitialized? Let's look at
kmemcheck's report again:

WARNING: kmemcheck: Caught 32-bit read from uninitialized memory (ffff88003e4a2024)
80000000000000000000000000000000000000000088ffff0000000000000000
 i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u
         ^

These first two lines are the memory dump of the memory object itself, and the
shadow bytemap, respectively. The memory object itself is in this case
&first->info. Just beware that the start of this dump is NOT the start of the
object itself! The position of the caret (^) corresponds with the address of
the read (ffff88003e4a2024).

The shadow bytemap dump legend is as follows:

  i - initialized
  u - uninitialized
  a - unallocated (memory has been allocated by the slab layer, but has not
      yet been handed off to anybody)
  f - freed (memory has been allocated by the slab layer, but has been freed
      by the previous owner)

In order to figure out where (relative to the start of the object) the
uninitialized memory was located, we have to look at the disassembly. For
that, we'll need the RIP address again:

RIP: 0010:[<ffffffff8104ede8>]  [<ffffffff8104ede8>] __dequeue_signal+0xc8/0x190

	$ objdump -d --no-show-raw-insn vmlinux | grep -C 8 ffffffff8104ede8:
	ffffffff8104edc8:       mov    %r8,0x8(%r8)
	ffffffff8104edcc:       test   %r10d,%r10d
	ffffffff8104edcf:       js     ffffffff8104ee88 <__dequeue_signal+0x168>
	ffffffff8104edd5:       mov    %rax,%rdx
	ffffffff8104edd8:       mov    $0xc,%ecx
	ffffffff8104eddd:       mov    %r13,%rdi
	ffffffff8104ede0:       mov    $0x30,%eax
	ffffffff8104ede5:       mov    %rdx,%rsi
	ffffffff8104ede8:       rep movsl %ds:(%rsi),%es:(%rdi)
	ffffffff8104edea:       test   $0x2,%al
	ffffffff8104edec:       je     ffffffff8104edf0 <__dequeue_signal+0xd0>
	ffffffff8104edee:       movsw  %ds:(%rsi),%es:(%rdi)
	ffffffff8104edf0:       test   $0x1,%al
	ffffffff8104edf2:       je     ffffffff8104edf5 <__dequeue_signal+0xd5>
	ffffffff8104edf4:       movsb  %ds:(%rsi),%es:(%rdi)
	ffffffff8104edf5:       mov    %r8,%rdi
	ffffffff8104edf8:       callq  ffffffff8104de60 <__sigqueue_free>

As expected, it's the "rep movsl" instruction from the memcpy() that causes
the warning. We know about REP MOVSL that it uses the register RCX to count
the number of remaining iterations. By taking a look at the register dump
again (from the kmemcheck report), we can figure out how many bytes were left
to copy:

RAX: 0000000000000030 RBX: ffff88003d4ea968 RCX: 0000000000000009

By looking at the disassembly, we also see that %ecx is being loaded with the
value $0xc just before (ffffffff8104edd8), so we are very lucky. Keep in mind
that this is the number of iterations, not bytes. And since this is a "long"
operation, we need to multiply by 4 to get the number of bytes. So this means
that the uninitialized value was encountered at 4 * (0xc - 0x9) = 12 bytes
from the start of the object.

We can now try to figure out which field of the "struct siginfo" that was not
initialized. This is the beginning of the struct:

40 typedef struct siginfo {
41         int si_signo;
42         int si_errno;
43         int si_code;
44                 
45         union {
..
92         } _sifields;
93 } siginfo_t;

On 64-bit, the int is 4 bytes long, so it must the the union member that has
not been initialized. We can verify this using gdb:

	$ gdb vmlinux
	...
	(gdb) p &((struct siginfo *) 0)->_sifields
	$1 = (union {...} *) 0x10

Actually, it seems that the union member is located at offset 0x10 -- which
means that gcc has inserted 4 bytes of padding between the members si_code
and _sifields. We can now get a fuller picture of the memory dump:

         _----------------------------=> si_code
        /        _--------------------=> (padding)
       |        /        _------------=> _sifields(._kill._pid)
       |       |        /        _----=> _sifields(._kill._uid)
       |       |       |        / 
-------|-------|-------|-------|
80000000000000000000000000000000000000000088ffff0000000000000000
 i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u

This allows us to realize another important fact: si_code contains the value
0x80. Remember that x86 is little endian, so the first 4 bytes "80000000" are
really the number 0x00000080. With a bit of research, we find that this is
actually the constant SI_KERNEL defined in include/asm-generic/siginfo.h:

144 #define SI_KERNEL       0x80            /* sent by the kernel from somewhere     */

This macro is used in exactly one place in the x86 kernel: In send_signal()
in kernel/signal.c:

816 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,
817                         int group)
818 {
...
828         pending = group ? &t->signal->shared_pending : &t->pending;
...
851         q = __sigqueue_alloc(t, GFP_ATOMIC, (sig < SIGRTMIN &&
852                                              (is_si_special(info) ||
853                                               info->si_code >= 0)));
854         if (q) {
855                 list_add_tail(&q->list, &pending->list);
856                 switch ((unsigned long) info) {
...
865                 case (unsigned long) SEND_SIG_PRIV:
866                         q->info.si_signo = sig;
867                         q->info.si_errno = 0;
868                         q->info.si_code = SI_KERNEL;
869                         q->info.si_pid = 0;
870                         q->info.si_uid = 0;
871                         break;
...
890 }

Not only does this match with the .si_code member, it also matches the place
we found earlier when looking for where siginfo_t objects are enqueued on the
"shared_pending" list.

So to sum up: It seems that it is the padding introduced by the compiler
between two struct fields that is uninitialized, and this gets reported when
we do a memcpy() on the struct. This means that we have identified a false
positive warning.

Normally, kmemcheck will not report uninitialized accesses in memcpy() calls
when both the source and destination addresses are tracked. (Instead, we copy
the shadow bytemap as well). In this case, the destination address clearly
was not tracked. We can dig a little deeper into the stack trace from above:

	arch/x86/kernel/signal.c:805
	arch/x86/kernel/signal.c:871
	arch/x86/kernel/entry_64.S:694

And we clearly see that the destination siginfo object is located on the
stack:

782 static void do_signal(struct pt_regs *regs)
783 {
784         struct k_sigaction ka;
785         siginfo_t info;
...
804         signr = get_signal_to_deliver(&info, &ka, regs, NULL);
...
854 }

And this &info is what eventually gets passed to copy_siginfo() as the
destination argument.

Now, even though we didn't find an actual error here, the example is still a
good one, because it shows how one would go about to find out what the report
was all about.


3.4. Annotating false positives
===============================

There are a few different ways to make annotations in the source code that
will keep kmemcheck from checking and reporting certain allocations. Here
they are:

  o __GFP_NOTRACK_FALSE_POSITIVE

	This flag can be passed to kmalloc() or kmem_cache_alloc() (therefore
	also to other functions that end up calling one of these) to indicate
	that the allocation should not be tracked because it would lead to
	a false positive report. This is a "big hammer" way of silencing
	kmemcheck; after all, even if the false positive pertains to 
	particular field in a struct, for example, we will now lose the
	ability to find (real) errors in other parts of the same struct.

	Example:

	    /* No warnings will ever trigger on accessing any part of x */
	    x = kmalloc(sizeof *x, GFP_KERNEL | __GFP_NOTRACK_FALSE_POSITIVE);

  o kmemcheck_bitfield_begin(name)/kmemcheck_bitfield_end(name) and
	kmemcheck_annotate_bitfield(ptr, name)

	The first two of these three macros can be used inside struct
	definitions to signal, respectively, the beginning and end of a
	bitfield. Additionally, this will assign the bitfield a name, which
	is given as an argument to the macros.

	Having used these markers, one can later use
	kmemcheck_annotate_bitfield() at the point of allocation, to indicate
	which parts of the allocation is part of a bitfield.

	Example:

	    struct foo {
		int x;

		kmemcheck_bitfield_begin(flags);
		int flag_a:1;
		int flag_b:1;
		kmemcheck_bitfield_end(flags);

		int y;
	    };

	    struct foo *x = kmalloc(sizeof *x);

	    /* No warnings will trigger on accessing the bitfield of x */
	    kmemcheck_annotate_bitfield(x, flags);

	Note that kmemcheck_annotate_bitfield() can be used even before the
	return value of kmalloc() is checked -- in other words, passing NULL
	as the first argument is legal (and will do nothing).


4. Reporting errors
===================

As we have seen, kmemcheck will produce false positive reports. Therefore, it
is not very wise to blindly post kmemcheck warnings to mailing lists and
maintainers. Instead, I encourage maintainers and developers to find errors
in their own code. If you get a warning, you can try to work around it, try
to figure out if it's a real error or not, or simply ignore it. Most
developers know their own code and will quickly and efficiently determine the
root cause of a kmemcheck report. This is therefore also the most efficient
way to work with kmemcheck.

That said, we (the kmemcheck maintainers) will always be on the lookout for
false positives that we can annotate and silence. So whatever you find,
please drop us a note privately! Kernel configs and steps to reproduce (if
available) are of course a great help too.

Happy hacking!


5. Technical description
========================

kmemcheck works by marking memory pages non-present. This means that whenever
somebody attempts to access the page, a page fault is generated. The page
fault handler notices that the page was in fact only hidden, and so it calls
on the kmemcheck code to make further investigations.

When the investigations are completed, kmemcheck "shows" the page by marking
it present (as it would be under normal circumstances). This way, the
interrupted code can continue as usual.

But after the instruction has been executed, we should hide the page again, so
that we can catch the next access too! Now kmemcheck makes use of a debugging
feature of the processor, namely single-stepping. When the processor has
finished the one instruction that generated the memory access, a debug
exception is raised. From here, we simply hide the page again and continue
execution, this time with the single-stepping feature turned off.

kmemcheck requires some assistance from the memory allocator in order to work.
The memory allocator needs to

  1. Tell kmemcheck about newly allocated pages and pages that are about to
     be freed. This allows kmemcheck to set up and tear down the shadow memory
     for the pages in question. The shadow memory stores the status of each
     byte in the allocation proper, e.g. whether it is initialized or
     uninitialized.

  2. Tell kmemcheck which parts of memory should be marked uninitialized.
     There are actually a few more states, such as "not yet allocated" and
     "recently freed".

If a slab cache is set up using the SLAB_NOTRACK flag, it will never return
memory that can take page faults because of kmemcheck.

If a slab cache is NOT set up using the SLAB_NOTRACK flag, callers can still
request memory with the __GFP_NOTRACK or __GFP_NOTRACK_FALSE_POSITIVE flags.
This does not prevent the page faults from occurring, however, but marks the
object in question as being initialized so that no warnings will ever be
produced for this object.

Currently, the SLAB and SLUB allocators are supported by kmemcheck.
Kernel Memory Leak Detector
===========================

Introduction
------------

Kmemleak provides a way of detecting possible kernel memory leaks in a
way similar to a tracing garbage collector
(http://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29#Tracing_garbage_collectors),
with the difference that the orphan objects are not freed but only
reported via /sys/kernel/debug/kmemleak. A similar method is used by the
Valgrind tool (memcheck --leak-check) to detect the memory leaks in
user-space applications.

Please check DEBUG_KMEMLEAK dependencies in lib/Kconfig.debug for supported
architectures.

Usage
-----

CONFIG_DEBUG_KMEMLEAK in "Kernel hacking" has to be enabled. A kernel
thread scans the memory every 10 minutes (by default) and prints the
number of new unreferenced objects found. To display the details of all
the possible memory leaks:

  # mount -t debugfs nodev /sys/kernel/debug/
  # cat /sys/kernel/debug/kmemleak

To trigger an intermediate memory scan:

  # echo scan > /sys/kernel/debug/kmemleak

To clear the list of all current possible memory leaks:

  # echo clear > /sys/kernel/debug/kmemleak

New leaks will then come up upon reading /sys/kernel/debug/kmemleak
again.

Note that the orphan objects are listed in the order they were allocated
and one object at the beginning of the list may cause other subsequent
objects to be reported as orphan.

Memory scanning parameters can be modified at run-time by writing to the
/sys/kernel/debug/kmemleak file. The following parameters are supported:

  off		- disable kmemleak (irreversible)
  stack=on	- enable the task stacks scanning (default)
  stack=off	- disable the tasks stacks scanning
  scan=on	- start the automatic memory scanning thread (default)
  scan=off	- stop the automatic memory scanning thread
  scan=<secs>	- set the automatic memory scanning period in seconds
		  (default 600, 0 to stop the automatic scanning)
  scan		- trigger a memory scan
  clear		- clear list of current memory leak suspects, done by
		  marking all current reported unreferenced objects grey
  dump=<addr>	- dump information about the object found at <addr>

Kmemleak can also be disabled at boot-time by passing "kmemleak=off" on
the kernel command line.

Memory may be allocated or freed before kmemleak is initialised and
these actions are stored in an early log buffer. The size of this buffer
is configured via the CONFIG_DEBUG_KMEMLEAK_EARLY_LOG_SIZE option.

Basic Algorithm
---------------

The memory allocations via kmalloc, vmalloc, kmem_cache_alloc and
friends are traced and the pointers, together with additional
information like size and stack trace, are stored in a prio search tree.
The corresponding freeing function calls are tracked and the pointers
removed from the kmemleak data structures.

An allocated block of memory is considered orphan if no pointer to its
start address or to any location inside the block can be found by
scanning the memory (including saved registers). This means that there
might be no way for the kernel to pass the address of the allocated
block to a freeing function and therefore the block is considered a
memory leak.

The scanning algorithm steps:

  1. mark all objects as white (remaining white objects will later be
     considered orphan)
  2. scan the memory starting with the data section and stacks, checking
     the values against the addresses stored in the prio search tree. If
     a pointer to a white object is found, the object is added to the
     gray list
  3. scan the gray objects for matching addresses (some white objects
     can become gray and added at the end of the gray list) until the
     gray set is finished
  4. the remaining white objects are considered orphan and reported via
     /sys/kernel/debug/kmemleak

Some allocated memory blocks have pointers stored in the kernel's
internal data structures and they cannot be detected as orphans. To
avoid this, kmemleak can also store the number of values pointing to an
address inside the block address range that need to be found so that the
block is not considered a leak. One example is __vmalloc().

Testing specific sections with kmemleak
---------------------------------------

Upon initial bootup your /sys/kernel/debug/kmemleak output page may be
quite extensive. This can also be the case if you have very buggy code
when doing development. To work around these situations you can use the
'clear' command to clear all reported unreferenced objects from the
/sys/kernel/debug/kmemleak output. By issuing a 'scan' after a 'clear'
you can find new unreferenced objects; this should help with testing
specific sections of code.

To test a critical section on demand with a clean kmemleak do:

  # echo clear > /sys/kernel/debug/kmemleak
  ... test your kernel or modules ...
  # echo scan > /sys/kernel/debug/kmemleak

Then as usual to get your report with:

  # cat /sys/kernel/debug/kmemleak

Kmemleak API
------------

See the include/linux/kmemleak.h header for the functions prototype.

kmemleak_init		 - initialize kmemleak
kmemleak_alloc		 - notify of a memory block allocation
kmemleak_free		 - notify of a memory block freeing
kmemleak_not_leak	 - mark an object as not a leak
kmemleak_ignore		 - do not scan or report an object as leak
kmemleak_scan_area	 - add scan areas inside a memory block
kmemleak_no_scan	 - do not scan a memory block
kmemleak_erase		 - erase an old value in a pointer variable
kmemleak_alloc_recursive - as kmemleak_alloc but checks the recursiveness
kmemleak_free_recursive	 - as kmemleak_free but checks the recursiveness

Dealing with false positives/negatives
--------------------------------------

The false negatives are real memory leaks (orphan objects) but not
reported by kmemleak because values found during the memory scanning
point to such objects. To reduce the number of false negatives, kmemleak
provides the kmemleak_ignore, kmemleak_scan_area, kmemleak_no_scan and
kmemleak_erase functions (see above). The task stacks also increase the
amount of false negatives and their scanning is not enabled by default.

The false positives are objects wrongly reported as being memory leaks
(orphan). For objects known not to be leaks, kmemleak provides the
kmemleak_not_leak function. The kmemleak_ignore could also be used if
the memory block is known not to contain other pointers and it will no
longer be scanned.

Some of the reported leaks are only transient, especially on SMP
systems, because of pointers temporarily stored in CPU registers or
stacks. Kmemleak defines MSECS_MIN_AGE (defaulting to 1000) representing
the minimum age of an object to be reported as a memory leak.

Limitations and Drawbacks
-------------------------

The main drawback is the reduced performance of memory allocation and
freeing. To avoid other penalties, the memory scanning is only performed
when the /sys/kernel/debug/kmemleak file is read. Anyway, this tool is
intended for debugging purposes where the performance might not be the
most important requirement.

To keep the algorithm simple, kmemleak scans for values pointing to any
address inside a block's address range. This may lead to an increased
number of false negatives. However, it is likely that a real memory leak
will eventually become visible.

Another source of false negatives is the data stored in non-pointer
values. In a future version, kmemleak could only scan the pointer
members in the allocated structures. This feature would solve many of
the false negative cases described above.

The tool can report false positives. These are cases where an allocated
block doesn't need to be freed (some cases in the init_call functions),
the pointer is calculated by other methods than the usual container_of
macro or the pointer is stored in a location not scanned by kmemleak.

Page allocations and ioremap are not tracked.
Everything you never wanted to know about kobjects, ksets, and ktypes

Greg Kroah-Hartman <gregkh@suse.de>

Based on an original article by Jon Corbet for lwn.net written October 1,
2003 and located at http://lwn.net/Articles/51437/

Last updated December 19, 2007


Part of the difficulty in understanding the driver model - and the kobject
abstraction upon which it is built - is that there is no obvious starting
place. Dealing with kobjects requires understanding a few different types,
all of which make reference to each other. In an attempt to make things
easier, we'll take a multi-pass approach, starting with vague terms and
adding detail as we go. To that end, here are some quick definitions of
some terms we will be working with.

 - A kobject is an object of type struct kobject.  Kobjects have a name
   and a reference count.  A kobject also has a parent pointer (allowing
   objects to be arranged into hierarchies), a specific type, and,
   usually, a representation in the sysfs virtual filesystem.

   Kobjects are generally not interesting on their own; instead, they are
   usually embedded within some other structure which contains the stuff
   the code is really interested in.

   No structure should EVER have more than one kobject embedded within it.
   If it does, the reference counting for the object is sure to be messed
   up and incorrect, and your code will be buggy.  So do not do this.

 - A ktype is the type of object that embeds a kobject.  Every structure
   that embeds a kobject needs a corresponding ktype.  The ktype controls
   what happens to the kobject when it is created and destroyed.

 - A kset is a group of kobjects.  These kobjects can be of the same ktype
   or belong to different ktypes.  The kset is the basic container type for
   collections of kobjects. Ksets contain their own kobjects, but you can
   safely ignore that implementation detail as the kset core code handles
   this kobject automatically.

   When you see a sysfs directory full of other directories, generally each
   of those directories corresponds to a kobject in the same kset.

We'll look at how to create and manipulate all of these types. A bottom-up
approach will be taken, so we'll go back to kobjects.


Embedding kobjects

It is rare for kernel code to create a standalone kobject, with one major
exception explained below.  Instead, kobjects are used to control access to
a larger, domain-specific object.  To this end, kobjects will be found
embedded in other structures.  If you are used to thinking of things in
object-oriented terms, kobjects can be seen as a top-level, abstract class
from which other classes are derived.  A kobject implements a set of
capabilities which are not particularly useful by themselves, but which are
nice to have in other objects.  The C language does not allow for the
direct expression of inheritance, so other techniques - such as structure
embedding - must be used.

(As an aside, for those familiar with the kernel linked list implementation,
this is analogous as to how "list_head" structs are rarely useful on
their own, but are invariably found embedded in the larger objects of
interest.)

So, for example, the UIO code in drivers/uio/uio.c has a structure that
defines the memory region associated with a uio device:

    struct uio_map {
	struct kobject kobj;
	struct uio_mem *mem;
    };

If you have a struct uio_map structure, finding its embedded kobject is
just a matter of using the kobj member.  Code that works with kobjects will
often have the opposite problem, however: given a struct kobject pointer,
what is the pointer to the containing structure?  You must avoid tricks
(such as assuming that the kobject is at the beginning of the structure)
and, instead, use the container_of() macro, found in <linux/kernel.h>:

    container_of(pointer, type, member)

where:

  * "pointer" is the pointer to the embedded kobject,
  * "type" is the type of the containing structure, and
  * "member" is the name of the structure field to which "pointer" points.

The return value from container_of() is a pointer to the corresponding
container type. So, for example, a pointer "kp" to a struct kobject
embedded *within* a struct uio_map could be converted to a pointer to the
*containing* uio_map structure with:

    struct uio_map *u_map = container_of(kp, struct uio_map, kobj);

For convenience, programmers often define a simple macro for "back-casting"
kobject pointers to the containing type.  Exactly this happens in the
earlier drivers/uio/uio.c, as you can see here:

    struct uio_map {
        struct kobject kobj;
        struct uio_mem *mem;
    };

    #define to_map(map) container_of(map, struct uio_map, kobj)

where the macro argument "map" is a pointer to the struct kobject in
question.  That macro is subsequently invoked with:

    struct uio_map *map = to_map(kobj);


Initialization of kobjects

Code which creates a kobject must, of course, initialize that object. Some
of the internal fields are setup with a (mandatory) call to kobject_init():

    void kobject_init(struct kobject *kobj, struct kobj_type *ktype);

The ktype is required for a kobject to be created properly, as every kobject
must have an associated kobj_type.  After calling kobject_init(), to
register the kobject with sysfs, the function kobject_add() must be called:

    int kobject_add(struct kobject *kobj, struct kobject *parent, const char *fmt, ...);

This sets up the parent of the kobject and the name for the kobject
properly.  If the kobject is to be associated with a specific kset,
kobj->kset must be assigned before calling kobject_add().  If a kset is
associated with a kobject, then the parent for the kobject can be set to
NULL in the call to kobject_add() and then the kobject's parent will be the
kset itself.

As the name of the kobject is set when it is added to the kernel, the name
of the kobject should never be manipulated directly.  If you must change
the name of the kobject, call kobject_rename():

    int kobject_rename(struct kobject *kobj, const char *new_name);

kobject_rename does not perform any locking or have a solid notion of
what names are valid so the caller must provide their own sanity checking
and serialization.

There is a function called kobject_set_name() but that is legacy cruft and
is being removed.  If your code needs to call this function, it is
incorrect and needs to be fixed.

To properly access the name of the kobject, use the function
kobject_name():

    const char *kobject_name(const struct kobject * kobj);

There is a helper function to both initialize and add the kobject to the
kernel at the same time, called surprisingly enough kobject_init_and_add():

    int kobject_init_and_add(struct kobject *kobj, struct kobj_type *ktype,
                             struct kobject *parent, const char *fmt, ...);

The arguments are the same as the individual kobject_init() and
kobject_add() functions described above.


Uevents

After a kobject has been registered with the kobject core, you need to
announce to the world that it has been created.  This can be done with a
call to kobject_uevent():

    int kobject_uevent(struct kobject *kobj, enum kobject_action action);

Use the KOBJ_ADD action for when the kobject is first added to the kernel.
This should be done only after any attributes or children of the kobject
have been initialized properly, as userspace will instantly start to look
for them when this call happens.

When the kobject is removed from the kernel (details on how to do that is
below), the uevent for KOBJ_REMOVE will be automatically created by the
kobject core, so the caller does not have to worry about doing that by
hand.


Reference counts

One of the key functions of a kobject is to serve as a reference counter
for the object in which it is embedded. As long as references to the object
exist, the object (and the code which supports it) must continue to exist.
The low-level functions for manipulating a kobject's reference counts are:

    struct kobject *kobject_get(struct kobject *kobj);
    void kobject_put(struct kobject *kobj);

A successful call to kobject_get() will increment the kobject's reference
counter and return the pointer to the kobject.

When a reference is released, the call to kobject_put() will decrement the
reference count and, possibly, free the object. Note that kobject_init()
sets the reference count to one, so the code which sets up the kobject will
need to do a kobject_put() eventually to release that reference.

Because kobjects are dynamic, they must not be declared statically or on
the stack, but instead, always allocated dynamically.  Future versions of
the kernel will contain a run-time check for kobjects that are created
statically and will warn the developer of this improper usage.

If all that you want to use a kobject for is to provide a reference counter
for your structure, please use the struct kref instead; a kobject would be
overkill.  For more information on how to use struct kref, please see the
file Documentation/kref.txt in the Linux kernel source tree.


Creating "simple" kobjects

Sometimes all that a developer wants is a way to create a simple directory
in the sysfs hierarchy, and not have to mess with the whole complication of
ksets, show and store functions, and other details.  This is the one
exception where a single kobject should be created.  To create such an
entry, use the function:

    struct kobject *kobject_create_and_add(char *name, struct kobject *parent);

This function will create a kobject and place it in sysfs in the location
underneath the specified parent kobject.  To create simple attributes
associated with this kobject, use:

    int sysfs_create_file(struct kobject *kobj, struct attribute *attr);
or
    int sysfs_create_group(struct kobject *kobj, struct attribute_group *grp);

Both types of attributes used here, with a kobject that has been created
with the kobject_create_and_add(), can be of type kobj_attribute, so no
special custom attribute is needed to be created.

See the example module, samples/kobject/kobject-example.c for an
implementation of a simple kobject and attributes.



ktypes and release methods

One important thing still missing from the discussion is what happens to a
kobject when its reference count reaches zero. The code which created the
kobject generally does not know when that will happen; if it did, there
would be little point in using a kobject in the first place. Even
predictable object lifecycles become more complicated when sysfs is brought
in as other portions of the kernel can get a reference on any kobject that
is registered in the system.

The end result is that a structure protected by a kobject cannot be freed
before its reference count goes to zero. The reference count is not under
the direct control of the code which created the kobject. So that code must
be notified asynchronously whenever the last reference to one of its
kobjects goes away.

Once you registered your kobject via kobject_add(), you must never use
kfree() to free it directly. The only safe way is to use kobject_put(). It
is good practice to always use kobject_put() after kobject_init() to avoid
errors creeping in.

This notification is done through a kobject's release() method. Usually
such a method has a form like:

    void my_object_release(struct kobject *kobj)
    {
    	    struct my_object *mine = container_of(kobj, struct my_object, kobj);

	    /* Perform any additional cleanup on this object, then... */
	    kfree(mine);
    }

One important point cannot be overstated: every kobject must have a
release() method, and the kobject must persist (in a consistent state)
until that method is called. If these constraints are not met, the code is
flawed.  Note that the kernel will warn you if you forget to provide a
release() method.  Do not try to get rid of this warning by providing an
"empty" release function; you will be mocked mercilessly by the kobject
maintainer if you attempt this.

Note, the name of the kobject is available in the release function, but it
must NOT be changed within this callback.  Otherwise there will be a memory
leak in the kobject core, which makes people unhappy.

Interestingly, the release() method is not stored in the kobject itself;
instead, it is associated with the ktype. So let us introduce struct
kobj_type:

    struct kobj_type {
	    void (*release)(struct kobject *);
	    const struct sysfs_ops *sysfs_ops;
	    struct attribute	**default_attrs;
    };

This structure is used to describe a particular type of kobject (or, more
correctly, of containing object). Every kobject needs to have an associated
kobj_type structure; a pointer to that structure must be specified when you
call kobject_init() or kobject_init_and_add().

The release field in struct kobj_type is, of course, a pointer to the
release() method for this type of kobject. The other two fields (sysfs_ops
and default_attrs) control how objects of this type are represented in
sysfs; they are beyond the scope of this document.

The default_attrs pointer is a list of default attributes that will be
automatically created for any kobject that is registered with this ktype.


ksets

A kset is merely a collection of kobjects that want to be associated with
each other.  There is no restriction that they be of the same ktype, but be
very careful if they are not.

A kset serves these functions:

 - It serves as a bag containing a group of objects. A kset can be used by
   the kernel to track "all block devices" or "all PCI device drivers."

 - A kset is also a subdirectory in sysfs, where the associated kobjects
   with the kset can show up.  Every kset contains a kobject which can be
   set up to be the parent of other kobjects; the top-level directories of
   the sysfs hierarchy are constructed in this way.

 - Ksets can support the "hotplugging" of kobjects and influence how
   uevent events are reported to user space.

In object-oriented terms, "kset" is the top-level container class; ksets
contain their own kobject, but that kobject is managed by the kset code and
should not be manipulated by any other user.

A kset keeps its children in a standard kernel linked list.  Kobjects point
back to their containing kset via their kset field. In almost all cases,
the kobjects belonging to a kset have that kset (or, strictly, its embedded
kobject) in their parent.

As a kset contains a kobject within it, it should always be dynamically
created and never declared statically or on the stack.  To create a new
kset use:
  struct kset *kset_create_and_add(const char *name,
				   struct kset_uevent_ops *u,
				   struct kobject *parent);

When you are finished with the kset, call:
  void kset_unregister(struct kset *kset);
to destroy it.

An example of using a kset can be seen in the
samples/kobject/kset-example.c file in the kernel tree.

If a kset wishes to control the uevent operations of the kobjects
associated with it, it can use the struct kset_uevent_ops to handle it:

struct kset_uevent_ops {
        int (*filter)(struct kset *kset, struct kobject *kobj);
        const char *(*name)(struct kset *kset, struct kobject *kobj);
        int (*uevent)(struct kset *kset, struct kobject *kobj,
                      struct kobj_uevent_env *env);
};


The filter function allows a kset to prevent a uevent from being emitted to
userspace for a specific kobject.  If the function returns 0, the uevent
will not be emitted.

The name function will be called to override the default name of the kset
that the uevent sends to userspace.  By default, the name will be the same
as the kset itself, but this function, if present, can override that name.

The uevent function will be called when the uevent is about to be sent to
userspace to allow more environment variables to be added to the uevent.

One might ask how, exactly, a kobject is added to a kset, given that no
functions which perform that function have been presented.  The answer is
that this task is handled by kobject_add().  When a kobject is passed to
kobject_add(), its kset member should point to the kset to which the
kobject will belong.  kobject_add() will handle the rest.

If the kobject belonging to a kset has no parent kobject set, it will be
added to the kset's directory.  Not all members of a kset do necessarily
live in the kset directory.  If an explicit parent kobject is assigned
before the kobject is added, the kobject is registered with the kset, but
added below the parent kobject.


Kobject removal

After a kobject has been registered with the kobject core successfully, it
must be cleaned up when the code is finished with it.  To do that, call
kobject_put().  By doing this, the kobject core will automatically clean up
all of the memory allocated by this kobject.  If a KOBJ_ADD uevent has been
sent for the object, a corresponding KOBJ_REMOVE uevent will be sent, and
any other sysfs housekeeping will be handled for the caller properly.

If you need to do a two-stage delete of the kobject (say you are not
allowed to sleep when you need to destroy the object), then call
kobject_del() which will unregister the kobject from sysfs.  This makes the
kobject "invisible", but it is not cleaned up, and the reference count of
the object is still the same.  At a later time call kobject_put() to finish
the cleanup of the memory associated with the kobject.

kobject_del() can be used to drop the reference to the parent object, if
circular references are constructed.  It is valid in some cases, that a
parent objects references a child.  Circular references _must_ be broken
with an explicit call to kobject_del(), so that a release functions will be
called, and the objects in the former circle release each other.


Example code to copy from

For a more complete example of using ksets and kobjects properly, see the
example programs samples/kobject/{kobject-example.c,kset-example.c},
which will be built as loadable modules if you select CONFIG_SAMPLE_KOBJECT.
Title	: Kernel Probes (Kprobes)
Authors	: Jim Keniston <jkenisto@us.ibm.com>
	: Prasanna S Panchamukhi <prasanna.panchamukhi@gmail.com>
	: Masami Hiramatsu <mhiramat@redhat.com>

CONTENTS

1. Concepts: Kprobes, Jprobes, Return Probes
2. Architectures Supported
3. Configuring Kprobes
4. API Reference
5. Kprobes Features and Limitations
6. Probe Overhead
7. TODO
8. Kprobes Example
9. Jprobes Example
10. Kretprobes Example
Appendix A: The kprobes debugfs interface
Appendix B: The kprobes sysctl interface

1. Concepts: Kprobes, Jprobes, Return Probes

Kprobes enables you to dynamically break into any kernel routine and
collect debugging and performance information non-disruptively. You
can trap at almost any kernel code address, specifying a handler
routine to be invoked when the breakpoint is hit.

There are currently three types of probes: kprobes, jprobes, and
kretprobes (also called return probes).  A kprobe can be inserted
on virtually any instruction in the kernel.  A jprobe is inserted at
the entry to a kernel function, and provides convenient access to the
function's arguments.  A return probe fires when a specified function
returns.

In the typical case, Kprobes-based instrumentation is packaged as
a kernel module.  The module's init function installs ("registers")
one or more probes, and the exit function unregisters them.  A
registration function such as register_kprobe() specifies where
the probe is to be inserted and what handler is to be called when
the probe is hit.

There are also register_/unregister_*probes() functions for batch
registration/unregistration of a group of *probes. These functions
can speed up unregistration process when you have to unregister
a lot of probes at once.

The next four subsections explain how the different types of
probes work and how jump optimization works.  They explain certain
things that you'll need to know in order to make the best use of
Kprobes -- e.g., the difference between a pre_handler and
a post_handler, and how to use the maxactive and nmissed fields of
a kretprobe.  But if you're in a hurry to start using Kprobes, you
can skip ahead to section 2.

1.1 How Does a Kprobe Work?

When a kprobe is registered, Kprobes makes a copy of the probed
instruction and replaces the first byte(s) of the probed instruction
with a breakpoint instruction (e.g., int3 on i386 and x86_64).

When a CPU hits the breakpoint instruction, a trap occurs, the CPU's
registers are saved, and control passes to Kprobes via the
notifier_call_chain mechanism.  Kprobes executes the "pre_handler"
associated with the kprobe, passing the handler the addresses of the
kprobe struct and the saved registers.

Next, Kprobes single-steps its copy of the probed instruction.
(It would be simpler to single-step the actual instruction in place,
but then Kprobes would have to temporarily remove the breakpoint
instruction.  This would open a small time window when another CPU
could sail right past the probepoint.)

After the instruction is single-stepped, Kprobes executes the
"post_handler," if any, that is associated with the kprobe.
Execution then continues with the instruction following the probepoint.

1.2 How Does a Jprobe Work?

A jprobe is implemented using a kprobe that is placed on a function's
entry point.  It employs a simple mirroring principle to allow
seamless access to the probed function's arguments.  The jprobe
handler routine should have the same signature (arg list and return
type) as the function being probed, and must always end by calling
the Kprobes function jprobe_return().

Here's how it works.  When the probe is hit, Kprobes makes a copy of
the saved registers and a generous portion of the stack (see below).
Kprobes then points the saved instruction pointer at the jprobe's
handler routine, and returns from the trap.  As a result, control
passes to the handler, which is presented with the same register and
stack contents as the probed function.  When it is done, the handler
calls jprobe_return(), which traps again to restore the original stack
contents and processor state and switch to the probed function.

By convention, the callee owns its arguments, so gcc may produce code
that unexpectedly modifies that portion of the stack.  This is why
Kprobes saves a copy of the stack and restores it after the jprobe
handler has run.  Up to MAX_STACK_SIZE bytes are copied -- e.g.,
64 bytes on i386.

Note that the probed function's args may be passed on the stack
or in registers.  The jprobe will work in either case, so long as the
handler's prototype matches that of the probed function.

1.3 Return Probes

1.3.1 How Does a Return Probe Work?

When you call register_kretprobe(), Kprobes establishes a kprobe at
the entry to the function.  When the probed function is called and this
probe is hit, Kprobes saves a copy of the return address, and replaces
the return address with the address of a "trampoline."  The trampoline
is an arbitrary piece of code -- typically just a nop instruction.
At boot time, Kprobes registers a kprobe at the trampoline.

When the probed function executes its return instruction, control
passes to the trampoline and that probe is hit.  Kprobes' trampoline
handler calls the user-specified return handler associated with the
kretprobe, then sets the saved instruction pointer to the saved return
address, and that's where execution resumes upon return from the trap.

While the probed function is executing, its return address is
stored in an object of type kretprobe_instance.  Before calling
register_kretprobe(), the user sets the maxactive field of the
kretprobe struct to specify how many instances of the specified
function can be probed simultaneously.  register_kretprobe()
pre-allocates the indicated number of kretprobe_instance objects.

For example, if the function is non-recursive and is called with a
spinlock held, maxactive = 1 should be enough.  If the function is
non-recursive and can never relinquish the CPU (e.g., via a semaphore
or preemption), NR_CPUS should be enough.  If maxactive <= 0, it is
set to a default value.  If CONFIG_PREEMPT is enabled, the default
is max(10, 2*NR_CPUS).  Otherwise, the default is NR_CPUS.

It's not a disaster if you set maxactive too low; you'll just miss
some probes.  In the kretprobe struct, the nmissed field is set to
zero when the return probe is registered, and is incremented every
time the probed function is entered but there is no kretprobe_instance
object available for establishing the return probe.

1.3.2 Kretprobe entry-handler

Kretprobes also provides an optional user-specified handler which runs
on function entry. This handler is specified by setting the entry_handler
field of the kretprobe struct. Whenever the kprobe placed by kretprobe at the
function entry is hit, the user-defined entry_handler, if any, is invoked.
If the entry_handler returns 0 (success) then a corresponding return handler
is guaranteed to be called upon function return. If the entry_handler
returns a non-zero error then Kprobes leaves the return address as is, and
the kretprobe has no further effect for that particular function instance.

Multiple entry and return handler invocations are matched using the unique
kretprobe_instance object associated with them. Additionally, a user
may also specify per return-instance private data to be part of each
kretprobe_instance object. This is especially useful when sharing private
data between corresponding user entry and return handlers. The size of each
private data object can be specified at kretprobe registration time by
setting the data_size field of the kretprobe struct. This data can be
accessed through the data field of each kretprobe_instance object.

In case probed function is entered but there is no kretprobe_instance
object available, then in addition to incrementing the nmissed count,
the user entry_handler invocation is also skipped.

1.4 How Does Jump Optimization Work?

If your kernel is built with CONFIG_OPTPROBES=y (currently this flag
is automatically set 'y' on x86/x86-64, non-preemptive kernel) and
the "debug.kprobes_optimization" kernel parameter is set to 1 (see
sysctl(8)), Kprobes tries to reduce probe-hit overhead by using a jump
instruction instead of a breakpoint instruction at each probepoint.

1.4.1 Init a Kprobe

When a probe is registered, before attempting this optimization,
Kprobes inserts an ordinary, breakpoint-based kprobe at the specified
address. So, even if it's not possible to optimize this particular
probepoint, there'll be a probe there.

1.4.2 Safety Check

Before optimizing a probe, Kprobes performs the following safety checks:

- Kprobes verifies that the region that will be replaced by the jump
instruction (the "optimized region") lies entirely within one function.
(A jump instruction is multiple bytes, and so may overlay multiple
instructions.)

- Kprobes analyzes the entire function and verifies that there is no
jump into the optimized region.  Specifically:
  - the function contains no indirect jump;
  - the function contains no instruction that causes an exception (since
  the fixup code triggered by the exception could jump back into the
  optimized region -- Kprobes checks the exception tables to verify this);
  and
  - there is no near jump to the optimized region (other than to the first
  byte).

- For each instruction in the optimized region, Kprobes verifies that
the instruction can be executed out of line.

1.4.3 Preparing Detour Buffer

Next, Kprobes prepares a "detour" buffer, which contains the following
instruction sequence:
- code to push the CPU's registers (emulating a breakpoint trap)
- a call to the trampoline code which calls user's probe handlers.
- code to restore registers
- the instructions from the optimized region
- a jump back to the original execution path.

1.4.4 Pre-optimization

After preparing the detour buffer, Kprobes verifies that none of the
following situations exist:
- The probe has either a break_handler (i.e., it's a jprobe) or a
post_handler.
- Other instructions in the optimized region are probed.
- The probe is disabled.
In any of the above cases, Kprobes won't start optimizing the probe.
Since these are temporary situations, Kprobes tries to start
optimizing it again if the situation is changed.

If the kprobe can be optimized, Kprobes enqueues the kprobe to an
optimizing list, and kicks the kprobe-optimizer workqueue to optimize
it.  If the to-be-optimized probepoint is hit before being optimized,
Kprobes returns control to the original instruction path by setting
the CPU's instruction pointer to the copied code in the detour buffer
-- thus at least avoiding the single-step.

1.4.5 Optimization

The Kprobe-optimizer doesn't insert the jump instruction immediately;
rather, it calls synchronize_sched() for safety first, because it's
possible for a CPU to be interrupted in the middle of executing the
optimized region(*).  As you know, synchronize_sched() can ensure
that all interruptions that were active when synchronize_sched()
was called are done, but only if CONFIG_PREEMPT=n.  So, this version
of kprobe optimization supports only kernels with CONFIG_PREEMPT=n.(**)

After that, the Kprobe-optimizer calls stop_machine() to replace
the optimized region with a jump instruction to the detour buffer,
using text_poke_smp().

1.4.6 Unoptimization

When an optimized kprobe is unregistered, disabled, or blocked by
another kprobe, it will be unoptimized.  If this happens before
the optimization is complete, the kprobe is just dequeued from the
optimized list.  If the optimization has been done, the jump is
replaced with the original code (except for an int3 breakpoint in
the first byte) by using text_poke_smp().

(*)Please imagine that the 2nd instruction is interrupted and then
the optimizer replaces the 2nd instruction with the jump *address*
while the interrupt handler is running. When the interrupt
returns to original address, there is no valid instruction,
and it causes an unexpected result.

(**)This optimization-safety checking may be replaced with the
stop-machine method that ksplice uses for supporting a CONFIG_PREEMPT=y
kernel.

NOTE for geeks:
The jump optimization changes the kprobe's pre_handler behavior.
Without optimization, the pre_handler can change the kernel's execution
path by changing regs->ip and returning 1.  However, when the probe
is optimized, that modification is ignored.  Thus, if you want to
tweak the kernel's execution path, you need to suppress optimization,
using one of the following techniques:
- Specify an empty function for the kprobe's post_handler or break_handler.
 or
- Execute 'sysctl -w debug.kprobes_optimization=n'

2. Architectures Supported

Kprobes, jprobes, and return probes are implemented on the following
architectures:

- i386 (Supports jump optimization)
- x86_64 (AMD-64, EM64T) (Supports jump optimization)
- ppc64
- ia64 (Does not support probes on instruction slot1.)
- sparc64 (Return probes not yet implemented.)
- arm
- ppc
- mips

3. Configuring Kprobes

When configuring the kernel using make menuconfig/xconfig/oldconfig,
ensure that CONFIG_KPROBES is set to "y".  Under "Instrumentation
Support", look for "Kprobes".

So that you can load and unload Kprobes-based instrumentation modules,
make sure "Loadable module support" (CONFIG_MODULES) and "Module
unloading" (CONFIG_MODULE_UNLOAD) are set to "y".

Also make sure that CONFIG_KALLSYMS and perhaps even CONFIG_KALLSYMS_ALL
are set to "y", since kallsyms_lookup_name() is used by the in-kernel
kprobe address resolution code.

If you need to insert a probe in the middle of a function, you may find
it useful to "Compile the kernel with debug info" (CONFIG_DEBUG_INFO),
so you can use "objdump -d -l vmlinux" to see the source-to-object
code mapping.

4. API Reference

The Kprobes API includes a "register" function and an "unregister"
function for each type of probe. The API also includes "register_*probes"
and "unregister_*probes" functions for (un)registering arrays of probes.
Here are terse, mini-man-page specifications for these functions and
the associated probe handlers that you'll write. See the files in the
samples/kprobes/ sub-directory for examples.

4.1 register_kprobe

#include <linux/kprobes.h>
int register_kprobe(struct kprobe *kp);

Sets a breakpoint at the address kp->addr.  When the breakpoint is
hit, Kprobes calls kp->pre_handler.  After the probed instruction
is single-stepped, Kprobe calls kp->post_handler.  If a fault
occurs during execution of kp->pre_handler or kp->post_handler,
or during single-stepping of the probed instruction, Kprobes calls
kp->fault_handler.  Any or all handlers can be NULL. If kp->flags
is set KPROBE_FLAG_DISABLED, that kp will be registered but disabled,
so, its handlers aren't hit until calling enable_kprobe(kp).

NOTE:
1. With the introduction of the "symbol_name" field to struct kprobe,
the probepoint address resolution will now be taken care of by the kernel.
The following will now work:

	kp.symbol_name = "symbol_name";

(64-bit powerpc intricacies such as function descriptors are handled
transparently)

2. Use the "offset" field of struct kprobe if the offset into the symbol
to install a probepoint is known. This field is used to calculate the
probepoint.

3. Specify either the kprobe "symbol_name" OR the "addr". If both are
specified, kprobe registration will fail with -EINVAL.

4. With CISC architectures (such as i386 and x86_64), the kprobes code
does not validate if the kprobe.addr is at an instruction boundary.
Use "offset" with caution.

register_kprobe() returns 0 on success, or a negative errno otherwise.

User's pre-handler (kp->pre_handler):
#include <linux/kprobes.h>
#include <linux/ptrace.h>
int pre_handler(struct kprobe *p, struct pt_regs *regs);

Called with p pointing to the kprobe associated with the breakpoint,
and regs pointing to the struct containing the registers saved when
the breakpoint was hit.  Return 0 here unless you're a Kprobes geek.

User's post-handler (kp->post_handler):
#include <linux/kprobes.h>
#include <linux/ptrace.h>
void post_handler(struct kprobe *p, struct pt_regs *regs,
	unsigned long flags);

p and regs are as described for the pre_handler.  flags always seems
to be zero.

User's fault-handler (kp->fault_handler):
#include <linux/kprobes.h>
#include <linux/ptrace.h>
int fault_handler(struct kprobe *p, struct pt_regs *regs, int trapnr);

p and regs are as described for the pre_handler.  trapnr is the
architecture-specific trap number associated with the fault (e.g.,
on i386, 13 for a general protection fault or 14 for a page fault).
Returns 1 if it successfully handled the exception.

4.2 register_jprobe

#include <linux/kprobes.h>
int register_jprobe(struct jprobe *jp)

Sets a breakpoint at the address jp->kp.addr, which must be the address
of the first instruction of a function.  When the breakpoint is hit,
Kprobes runs the handler whose address is jp->entry.

The handler should have the same arg list and return type as the probed
function; and just before it returns, it must call jprobe_return().
(The handler never actually returns, since jprobe_return() returns
control to Kprobes.)  If the probed function is declared asmlinkage
or anything else that affects how args are passed, the handler's
declaration must match.

register_jprobe() returns 0 on success, or a negative errno otherwise.

4.3 register_kretprobe

#include <linux/kprobes.h>
int register_kretprobe(struct kretprobe *rp);

Establishes a return probe for the function whose address is
rp->kp.addr.  When that function returns, Kprobes calls rp->handler.
You must set rp->maxactive appropriately before you call
register_kretprobe(); see "How Does a Return Probe Work?" for details.

register_kretprobe() returns 0 on success, or a negative errno
otherwise.

User's return-probe handler (rp->handler):
#include <linux/kprobes.h>
#include <linux/ptrace.h>
int kretprobe_handler(struct kretprobe_instance *ri, struct pt_regs *regs);

regs is as described for kprobe.pre_handler.  ri points to the
kretprobe_instance object, of which the following fields may be
of interest:
- ret_addr: the return address
- rp: points to the corresponding kretprobe object
- task: points to the corresponding task struct
- data: points to per return-instance private data; see "Kretprobe
	entry-handler" for details.

The regs_return_value(regs) macro provides a simple abstraction to
extract the return value from the appropriate register as defined by
the architecture's ABI.

The handler's return value is currently ignored.

4.4 unregister_*probe

#include <linux/kprobes.h>
void unregister_kprobe(struct kprobe *kp);
void unregister_jprobe(struct jprobe *jp);
void unregister_kretprobe(struct kretprobe *rp);

Removes the specified probe.  The unregister function can be called
at any time after the probe has been registered.

NOTE:
If the functions find an incorrect probe (ex. an unregistered probe),
they clear the addr field of the probe.

4.5 register_*probes

#include <linux/kprobes.h>
int register_kprobes(struct kprobe **kps, int num);
int register_kretprobes(struct kretprobe **rps, int num);
int register_jprobes(struct jprobe **jps, int num);

Registers each of the num probes in the specified array.  If any
error occurs during registration, all probes in the array, up to
the bad probe, are safely unregistered before the register_*probes
function returns.
- kps/rps/jps: an array of pointers to *probe data structures
- num: the number of the array entries.

NOTE:
You have to allocate(or define) an array of pointers and set all
of the array entries before using these functions.

4.6 unregister_*probes

#include <linux/kprobes.h>
void unregister_kprobes(struct kprobe **kps, int num);
void unregister_kretprobes(struct kretprobe **rps, int num);
void unregister_jprobes(struct jprobe **jps, int num);

Removes each of the num probes in the specified array at once.

NOTE:
If the functions find some incorrect probes (ex. unregistered
probes) in the specified array, they clear the addr field of those
incorrect probes. However, other probes in the array are
unregistered correctly.

4.7 disable_*probe

#include <linux/kprobes.h>
int disable_kprobe(struct kprobe *kp);
int disable_kretprobe(struct kretprobe *rp);
int disable_jprobe(struct jprobe *jp);

Temporarily disables the specified *probe. You can enable it again by using
enable_*probe(). You must specify the probe which has been registered.

4.8 enable_*probe

#include <linux/kprobes.h>
int enable_kprobe(struct kprobe *kp);
int enable_kretprobe(struct kretprobe *rp);
int enable_jprobe(struct jprobe *jp);

Enables *probe which has been disabled by disable_*probe(). You must specify
the probe which has been registered.

5. Kprobes Features and Limitations

Kprobes allows multiple probes at the same address.  Currently,
however, there cannot be multiple jprobes on the same function at
the same time.  Also, a probepoint for which there is a jprobe or
a post_handler cannot be optimized.  So if you install a jprobe,
or a kprobe with a post_handler, at an optimized probepoint, the
probepoint will be unoptimized automatically.

In general, you can install a probe anywhere in the kernel.
In particular, you can probe interrupt handlers.  Known exceptions
are discussed in this section.

The register_*probe functions will return -EINVAL if you attempt
to install a probe in the code that implements Kprobes (mostly
kernel/kprobes.c and arch/*/kernel/kprobes.c, but also functions such
as do_page_fault and notifier_call_chain).

If you install a probe in an inline-able function, Kprobes makes
no attempt to chase down all inline instances of the function and
install probes there.  gcc may inline a function without being asked,
so keep this in mind if you're not seeing the probe hits you expect.

A probe handler can modify the environment of the probed function
-- e.g., by modifying kernel data structures, or by modifying the
contents of the pt_regs struct (which are restored to the registers
upon return from the breakpoint).  So Kprobes can be used, for example,
to install a bug fix or to inject faults for testing.  Kprobes, of
course, has no way to distinguish the deliberately injected faults
from the accidental ones.  Don't drink and probe.

Kprobes makes no attempt to prevent probe handlers from stepping on
each other -- e.g., probing printk() and then calling printk() from a
probe handler.  If a probe handler hits a probe, that second probe's
handlers won't be run in that instance, and the kprobe.nmissed member
of the second probe will be incremented.

As of Linux v2.6.15-rc1, multiple handlers (or multiple instances of
the same handler) may run concurrently on different CPUs.

Kprobes does not use mutexes or allocate memory except during
registration and unregistration.

Probe handlers are run with preemption disabled.  Depending on the
architecture and optimization state, handlers may also run with
interrupts disabled (e.g., kretprobe handlers and optimized kprobe
handlers run without interrupt disabled on x86/x86-64).  In any case,
your handler should not yield the CPU (e.g., by attempting to acquire
a semaphore).

Since a return probe is implemented by replacing the return
address with the trampoline's address, stack backtraces and calls
to __builtin_return_address() will typically yield the trampoline's
address instead of the real return address for kretprobed functions.
(As far as we can tell, __builtin_return_address() is used only
for instrumentation and error reporting.)

If the number of times a function is called does not match the number
of times it returns, registering a return probe on that function may
produce undesirable results. In such a case, a line:
kretprobe BUG!: Processing kretprobe d000000000041aa8 @ c00000000004f48c
gets printed. With this information, one will be able to correlate the
exact instance of the kretprobe that caused the problem. We have the
do_exit() case covered. do_execve() and do_fork() are not an issue.
We're unaware of other specific cases where this could be a problem.

If, upon entry to or exit from a function, the CPU is running on
a stack other than that of the current task, registering a return
probe on that function may produce undesirable results.  For this
reason, Kprobes doesn't support return probes (or kprobes or jprobes)
on the x86_64 version of __switch_to(); the registration functions
return -EINVAL.

On x86/x86-64, since the Jump Optimization of Kprobes modifies
instructions widely, there are some limitations to optimization. To
explain it, we introduce some terminology. Imagine a 3-instruction
sequence consisting of a two 2-byte instructions and one 3-byte
instruction.

        IA
         |
[-2][-1][0][1][2][3][4][5][6][7]
        [ins1][ins2][  ins3 ]
	[<-     DCR       ->]
	   [<- JTPR ->]

ins1: 1st Instruction
ins2: 2nd Instruction
ins3: 3rd Instruction
IA:  Insertion Address
JTPR: Jump Target Prohibition Region
DCR: Detoured Code Region

The instructions in DCR are copied to the out-of-line buffer
of the kprobe, because the bytes in DCR are replaced by
a 5-byte jump instruction. So there are several limitations.

a) The instructions in DCR must be relocatable.
b) The instructions in DCR must not include a call instruction.
c) JTPR must not be targeted by any jump or call instruction.
d) DCR must not straddle the border between functions.

Anyway, these limitations are checked by the in-kernel instruction
decoder, so you don't need to worry about that.

6. Probe Overhead

On a typical CPU in use in 2005, a kprobe hit takes 0.5 to 1.0
microseconds to process.  Specifically, a benchmark that hits the same
probepoint repeatedly, firing a simple handler each time, reports 1-2
million hits per second, depending on the architecture.  A jprobe or
return-probe hit typically takes 50-75% longer than a kprobe hit.
When you have a return probe set on a function, adding a kprobe at
the entry to that function adds essentially no overhead.

Here are sample overhead figures (in usec) for different architectures.
k = kprobe; j = jprobe; r = return probe; kr = kprobe + return probe
on same function; jr = jprobe + return probe on same function

i386: Intel Pentium M, 1495 MHz, 2957.31 bogomips
k = 0.57 usec; j = 1.00; r = 0.92; kr = 0.99; jr = 1.40

x86_64: AMD Opteron 246, 1994 MHz, 3971.48 bogomips
k = 0.49 usec; j = 0.76; r = 0.80; kr = 0.82; jr = 1.07

ppc64: POWER5 (gr), 1656 MHz (SMT disabled, 1 virtual CPU per physical CPU)
k = 0.77 usec; j = 1.31; r = 1.26; kr = 1.45; jr = 1.99

6.1 Optimized Probe Overhead

Typically, an optimized kprobe hit takes 0.07 to 0.1 microseconds to
process. Here are sample overhead figures (in usec) for x86 architectures.
k = unoptimized kprobe, b = boosted (single-step skipped), o = optimized kprobe,
r = unoptimized kretprobe, rb = boosted kretprobe, ro = optimized kretprobe.

i386: Intel(R) Xeon(R) E5410, 2.33GHz, 4656.90 bogomips
k = 0.80 usec; b = 0.33; o = 0.05; r = 1.10; rb = 0.61; ro = 0.33

x86-64: Intel(R) Xeon(R) E5410, 2.33GHz, 4656.90 bogomips
k = 0.99 usec; b = 0.43; o = 0.06; r = 1.24; rb = 0.68; ro = 0.30

7. TODO

a. SystemTap (http://sourceware.org/systemtap): Provides a simplified
programming interface for probe-based instrumentation.  Try it out.
b. Kernel return probes for sparc64.
c. Support for other architectures.
d. User-space probes.
e. Watchpoint probes (which fire on data references).

8. Kprobes Example

See samples/kprobes/kprobe_example.c

9. Jprobes Example

See samples/kprobes/jprobe_example.c

10. Kretprobes Example

See samples/kprobes/kretprobe_example.c

For additional information on Kprobes, refer to the following URLs:
http://www-106.ibm.com/developerworks/library/l-kprobes.html?ca=dgr-lnxw42Kprobe
http://www.redhat.com/magazine/005mar05/features/kprobes/
http://www-users.cs.umn.edu/~boutcher/kprobes/
http://www.linuxsymposium.org/2006/linuxsymposium_procv2.pdf (pages 101-115)


Appendix A: The kprobes debugfs interface

With recent kernels (> 2.6.20) the list of registered kprobes is visible
under the /sys/kernel/debug/kprobes/ directory (assuming debugfs is mounted at //sys/kernel/debug).

/sys/kernel/debug/kprobes/list: Lists all registered probes on the system

c015d71a  k  vfs_read+0x0
c011a316  j  do_fork+0x0
c03dedc5  r  tcp_v4_rcv+0x0

The first column provides the kernel address where the probe is inserted.
The second column identifies the type of probe (k - kprobe, r - kretprobe
and j - jprobe), while the third column specifies the symbol+offset of
the probe. If the probed function belongs to a module, the module name
is also specified. Following columns show probe status. If the probe is on
a virtual address that is no longer valid (module init sections, module
virtual addresses that correspond to modules that've been unloaded),
such probes are marked with [GONE]. If the probe is temporarily disabled,
such probes are marked with [DISABLED]. If the probe is optimized, it is
marked with [OPTIMIZED].

/sys/kernel/debug/kprobes/enabled: Turn kprobes ON/OFF forcibly.

Provides a knob to globally and forcibly turn registered kprobes ON or OFF.
By default, all kprobes are enabled. By echoing "0" to this file, all
registered probes will be disarmed, till such time a "1" is echoed to this
file. Note that this knob just disarms and arms all kprobes and doesn't
change each probe's disabling state. This means that disabled kprobes (marked
[DISABLED]) will be not enabled if you turn ON all kprobes by this knob.


Appendix B: The kprobes sysctl interface

/proc/sys/debug/kprobes-optimization: Turn kprobes optimization ON/OFF.

When CONFIG_OPTPROBES=y, this sysctl interface appears and it provides
a knob to globally and forcibly turn jump optimization (see section
1.4) ON or OFF. By default, jump optimization is allowed (ON).
If you echo "0" to this file or set "debug.kprobes_optimization" to
0 via sysctl, all optimized probes will be unoptimized, and any new
probes registered after that will not be optimized.  Note that this
knob *changes* the optimized state. This means that optimized probes
(marked [OPTIMIZED]) will be unoptimized ([OPTIMIZED] tag will be
removed). If the knob is turned on, they will be optimized again.


            LDM - Logical Disk Manager (Dynamic Disks)
            ------------------------------------------

Originally Written by FlatCap - Richard Russon <ldm@flatcap.org>.
Last Updated by Anton Altaparmakov on 30 March 2007 for Windows Vista.

Overview
--------

Windows 2000, XP, and Vista use a new partitioning scheme.  It is a complete
replacement for the MSDOS style partitions.  It stores its information in a
1MiB journalled database at the end of the physical disk.  The size of
partitions is limited only by disk space.  The maximum number of partitions is
nearly 2000.

Any partitions created under the LDM are called "Dynamic Disks".  There are no
longer any primary or extended partitions.  Normal MSDOS style partitions are
now known as Basic Disks.

If you wish to use Spanned, Striped, Mirrored or RAID 5 Volumes, you must use
Dynamic Disks.  The journalling allows Windows to make changes to these
partitions and filesystems without the need to reboot.

Once the LDM driver has divided up the disk, you can use the MD driver to
assemble any multi-partition volumes, e.g.  Stripes, RAID5.

To prevent legacy applications from repartitioning the disk, the LDM creates a
dummy MSDOS partition containing one disk-sized partition.  This is what is
supported with the Linux LDM driver.

A newer approach that has been implemented with Vista is to put LDM on top of a
GPT label disk.  This is not supported by the Linux LDM driver yet.


Example
-------

Below we have a 50MiB disk, divided into seven partitions.
N.B.  The missing 1MiB at the end of the disk is where the LDM database is
      stored.

  Device | Offset Bytes  Sectors  MiB | Size   Bytes  Sectors  MiB
  -------+----------------------------+---------------------------
  hda    |            0        0    0 |     52428800   102400   50
  hda1   |     51380224   100352   49 |      1048576     2048    1
  hda2   |        16384       32    0 |      6979584    13632    6
  hda3   |      6995968    13664    6 |     10485760    20480   10
  hda4   |     17481728    34144   16 |      4194304     8192    4
  hda5   |     21676032    42336   20 |      5242880    10240    5
  hda6   |     26918912    52576   25 |     10485760    20480   10
  hda7   |     37404672    73056   35 |     13959168    27264   13

The LDM Database may not store the partitions in the order that they appear on
disk, but the driver will sort them.

When Linux boots, you will see something like:

  hda: 102400 sectors w/32KiB Cache, CHS=50/64/32
  hda: [LDM] hda1 hda2 hda3 hda4 hda5 hda6 hda7


Compiling LDM Support
---------------------

To enable LDM, choose the following two options: 

  "Advanced partition selection" CONFIG_PARTITION_ADVANCED
  "Windows Logical Disk Manager (Dynamic Disk) support" CONFIG_LDM_PARTITION

If you believe the driver isn't working as it should, you can enable the extra
debugging code.  This will produce a LOT of output.  The option is:

  "Windows LDM extra logging" CONFIG_LDM_DEBUG

N.B. The partition code cannot be compiled as a module.

As with all the partition code, if the driver doesn't see signs of its type of
partition, it will pass control to another driver, so there is no harm in
enabling it.

If you have Dynamic Disks but don't enable the driver, then all you will see
is a dummy MSDOS partition filling the whole disk.  You won't be able to mount
any of the volumes on the disk.


Booting
-------

If you enable LDM support, then lilo is capable of booting from any of the
discovered partitions.  However, grub does not understand the LDM partitioning
and cannot boot from a Dynamic Disk.


More Documentation
------------------

There is an Overview of the LDM together with complete Technical Documentation.
It is available for download.

  http://www.linux-ntfs.org/

If you have any LDM questions that aren't answered in the documentation, email
me.

Cheers,
    FlatCap - Richard Russon
    ldm@flatcap.org

	     Semantics and Behavior of Local Atomic Operations

			    Mathieu Desnoyers


	This document explains the purpose of the local atomic operations, how
to implement them for any given architecture and shows how they can be used
properly. It also stresses on the precautions that must be taken when reading
those local variables across CPUs when the order of memory writes matters.



* Purpose of local atomic operations

Local atomic operations are meant to provide fast and highly reentrant per CPU
counters. They minimize the performance cost of standard atomic operations by
removing the LOCK prefix and memory barriers normally required to synchronize
across CPUs.

Having fast per CPU atomic counters is interesting in many cases : it does not
require disabling interrupts to protect from interrupt handlers and it permits
coherent counters in NMI handlers. It is especially useful for tracing purposes
and for various performance monitoring counters.

Local atomic operations only guarantee variable modification atomicity wrt the
CPU which owns the data. Therefore, care must taken to make sure that only one
CPU writes to the local_t data. This is done by using per cpu data and making
sure that we modify it from within a preemption safe context. It is however
permitted to read local_t data from any CPU : it will then appear to be written
out of order wrt other memory writes by the owner CPU.


* Implementation for a given architecture

It can be done by slightly modifying the standard atomic operations : only
their UP variant must be kept. It typically means removing LOCK prefix (on
i386 and x86_64) and any SMP synchronization barrier. If the architecture does
not have a different behavior between SMP and UP, including asm-generic/local.h
in your architecture's local.h is sufficient.

The local_t type is defined as an opaque signed long by embedding an
atomic_long_t inside a structure. This is made so a cast from this type to a
long fails. The definition looks like :

typedef struct { atomic_long_t a; } local_t;


* Rules to follow when using local atomic operations

- Variables touched by local ops must be per cpu variables.
- _Only_ the CPU owner of these variables must write to them.
- This CPU can use local ops from any context (process, irq, softirq, nmi, ...)
  to update its local_t variables.
- Preemption (or interrupts) must be disabled when using local ops in
  process context to   make sure the process won't be migrated to a
  different CPU between getting the per-cpu variable and doing the
  actual local op.
- When using local ops in interrupt context, no special care must be
  taken on a mainline kernel, since they will run on the local CPU with
  preemption already disabled. I suggest, however, to explicitly
  disable preemption anyway to make sure it will still work correctly on
  -rt kernels.
- Reading the local cpu variable will provide the current copy of the
  variable.
- Reads of these variables can be done from any CPU, because updates to
  "long", aligned, variables are always atomic. Since no memory
  synchronization is done by the writer CPU, an outdated copy of the
  variable can be read when reading some _other_ cpu's variables.


* How to use local atomic operations

#include <linux/percpu.h>
#include <asm/local.h>

static DEFINE_PER_CPU(local_t, counters) = LOCAL_INIT(0);


* Counting

Counting is done on all the bits of a signed long.

In preemptible context, use get_cpu_var() and put_cpu_var() around local atomic
operations : it makes sure that preemption is disabled around write access to
the per cpu variable. For instance :

	local_inc(&get_cpu_var(counters));
	put_cpu_var(counters);

If you are already in a preemption-safe context, you can directly use
__get_cpu_var() instead.

	local_inc(&__get_cpu_var(counters));



* Reading the counters

Those local counters can be read from foreign CPUs to sum the count. Note that
the data seen by local_read across CPUs must be considered to be out of order
relatively to other memory writes happening on the CPU that owns the data.

	long sum = 0;
	for_each_online_cpu(cpu)
		sum += local_read(&per_cpu(counters, cpu));

If you want to use a remote local_read to synchronize access to a resource
between CPUs, explicit smp_wmb() and smp_rmb() memory barriers must be used
respectively on the writer and the reader CPUs. It would be the case if you use
the local_t variable as a counter of bytes written in a buffer : there should
be a smp_wmb() between the buffer write and the counter increment and also a
smp_rmb() between the counter read and the buffer read.


Here is a sample module which implements a basic per cpu counter using local.h.

--- BEGIN ---
/* test-local.c
 *
 * Sample module for local.h usage.
 */


#include <asm/local.h>
#include <linux/module.h>
#include <linux/timer.h>

static DEFINE_PER_CPU(local_t, counters) = LOCAL_INIT(0);

static struct timer_list test_timer;

/* IPI called on each CPU. */
static void test_each(void *info)
{
	/* Increment the counter from a non preemptible context */
	printk("Increment on cpu %d\n", smp_processor_id());
	local_inc(&__get_cpu_var(counters));

	/* This is what incrementing the variable would look like within a
	 * preemptible context (it disables preemption) :
	 *
	 * local_inc(&get_cpu_var(counters));
	 * put_cpu_var(counters);
	 */
}

static void do_test_timer(unsigned long data)
{
	int cpu;

	/* Increment the counters */
	on_each_cpu(test_each, NULL, 1);
	/* Read all the counters */
	printk("Counters read from CPU %d\n", smp_processor_id());
	for_each_online_cpu(cpu) {
		printk("Read : CPU %d, count %ld\n", cpu,
			local_read(&per_cpu(counters, cpu)));
	}
	del_timer(&test_timer);
	test_timer.expires = jiffies + 1000;
	add_timer(&test_timer);
}

static int __init test_init(void)
{
	/* initialize the timer that will increment the counter */
	init_timer(&test_timer);
	test_timer.function = do_test_timer;
	test_timer.expires = jiffies + 1;
	add_timer(&test_timer);

	return 0;
}

static void __exit test_exit(void)
{
	del_timer_sync(&test_timer);
}

module_init(test_init);
module_exit(test_exit);

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Mathieu Desnoyers");
MODULE_DESCRIPTION("Local Atomic Ops");
--- END ---
Runtime locking correctness validator
=====================================

started by Ingo Molnar <mingo@redhat.com>
additions by Arjan van de Ven <arjan@linux.intel.com>

Lock-class
----------

The basic object the validator operates upon is a 'class' of locks.

A class of locks is a group of locks that are logically the same with
respect to locking rules, even if the locks may have multiple (possibly
tens of thousands of) instantiations. For example a lock in the inode
struct is one class, while each inode has its own instantiation of that
lock class.

The validator tracks the 'state' of lock-classes, and it tracks
dependencies between different lock-classes. The validator maintains a
rolling proof that the state and the dependencies are correct.

Unlike an lock instantiation, the lock-class itself never goes away: when
a lock-class is used for the first time after bootup it gets registered,
and all subsequent uses of that lock-class will be attached to this
lock-class.

State
-----

The validator tracks lock-class usage history into 4n + 1 separate state bits:

- 'ever held in STATE context'
- 'ever held as readlock in STATE context'
- 'ever held with STATE enabled'
- 'ever held as readlock with STATE enabled'

Where STATE can be either one of (kernel/lockdep_states.h)
 - hardirq
 - softirq
 - reclaim_fs

- 'ever used'                                       [ == !unused        ]

When locking rules are violated, these state bits are presented in the
locking error messages, inside curlies. A contrived example:

   modprobe/2287 is trying to acquire lock:
    (&sio_locks[i].lock){-.-...}, at: [<c02867fd>] mutex_lock+0x21/0x24

   but task is already holding lock:
    (&sio_locks[i].lock){-.-...}, at: [<c02867fd>] mutex_lock+0x21/0x24


The bit position indicates STATE, STATE-read, for each of the states listed
above, and the character displayed in each indicates:

   '.'  acquired while irqs disabled and not in irq context
   '-'  acquired in irq context
   '+'  acquired with irqs enabled
   '?'  acquired in irq context with irqs enabled.

Unused mutexes cannot be part of the cause of an error.


Single-lock state rules:
------------------------

A softirq-unsafe lock-class is automatically hardirq-unsafe as well. The
following states are exclusive, and only one of them is allowed to be
set for any lock-class:

 <hardirq-safe> and <hardirq-unsafe>
 <softirq-safe> and <softirq-unsafe>

The validator detects and reports lock usage that violate these
single-lock state rules.

Multi-lock dependency rules:
----------------------------

The same lock-class must not be acquired twice, because this could lead
to lock recursion deadlocks.

Furthermore, two locks may not be taken in different order:

 <L1> -> <L2>
 <L2> -> <L1>

because this could lead to lock inversion deadlocks. (The validator
finds such dependencies in arbitrary complexity, i.e. there can be any
other locking sequence between the acquire-lock operations, the
validator will still track all dependencies between locks.)

Furthermore, the following usage based lock dependencies are not allowed
between any two lock-classes:

   <hardirq-safe>   ->  <hardirq-unsafe>
   <softirq-safe>   ->  <softirq-unsafe>

The first rule comes from the fact the a hardirq-safe lock could be
taken by a hardirq context, interrupting a hardirq-unsafe lock - and
thus could result in a lock inversion deadlock. Likewise, a softirq-safe
lock could be taken by an softirq context, interrupting a softirq-unsafe
lock.

The above rules are enforced for any locking sequence that occurs in the
kernel: when acquiring a new lock, the validator checks whether there is
any rule violation between the new lock and any of the held locks.

When a lock-class changes its state, the following aspects of the above
dependency rules are enforced:

- if a new hardirq-safe lock is discovered, we check whether it
  took any hardirq-unsafe lock in the past.

- if a new softirq-safe lock is discovered, we check whether it took
  any softirq-unsafe lock in the past.

- if a new hardirq-unsafe lock is discovered, we check whether any
  hardirq-safe lock took it in the past.

- if a new softirq-unsafe lock is discovered, we check whether any
  softirq-safe lock took it in the past.

(Again, we do these checks too on the basis that an interrupt context
could interrupt _any_ of the irq-unsafe or hardirq-unsafe locks, which
could lead to a lock inversion deadlock - even if that lock scenario did
not trigger in practice yet.)

Exception: Nested data dependencies leading to nested locking
-------------------------------------------------------------

There are a few cases where the Linux kernel acquires more than one
instance of the same lock-class. Such cases typically happen when there
is some sort of hierarchy within objects of the same type. In these
cases there is an inherent "natural" ordering between the two objects
(defined by the properties of the hierarchy), and the kernel grabs the
locks in this fixed order on each of the objects.

An example of such an object hierarchy that results in "nested locking"
is that of a "whole disk" block-dev object and a "partition" block-dev
object; the partition is "part of" the whole device and as long as one
always takes the whole disk lock as a higher lock than the partition
lock, the lock ordering is fully correct. The validator does not
automatically detect this natural ordering, as the locking rule behind
the ordering is not static.

In order to teach the validator about this correct usage model, new
versions of the various locking primitives were added that allow you to
specify a "nesting level". An example call, for the block device mutex,
looks like this:

enum bdev_bd_mutex_lock_class
{
       BD_MUTEX_NORMAL,
       BD_MUTEX_WHOLE,
       BD_MUTEX_PARTITION
};

 mutex_lock_nested(&bdev->bd_contains->bd_mutex, BD_MUTEX_PARTITION);

In this case the locking is done on a bdev object that is known to be a
partition.

The validator treats a lock that is taken in such a nested fashion as a
separate (sub)class for the purposes of validation.

Note: When changing code to use the _nested() primitives, be careful and
check really thoroughly that the hierarchy is correctly mapped; otherwise
you can get false positives or false negatives.

Proof of 100% correctness:
--------------------------

The validator achieves perfect, mathematical 'closure' (proof of locking
correctness) in the sense that for every simple, standalone single-task
locking sequence that occurred at least once during the lifetime of the
kernel, the validator proves it with a 100% certainty that no
combination and timing of these locking sequences can cause any class of
lock related deadlock. [*]

I.e. complex multi-CPU and multi-task locking scenarios do not have to
occur in practice to prove a deadlock: only the simple 'component'
locking chains have to occur at least once (anytime, in any
task/context) for the validator to be able to prove correctness. (For
example, complex deadlocks that would normally need more than 3 CPUs and
a very unlikely constellation of tasks, irq-contexts and timings to
occur, can be detected on a plain, lightly loaded single-CPU system as
well!)

This radically decreases the complexity of locking related QA of the
kernel: what has to be done during QA is to trigger as many "simple"
single-task locking dependencies in the kernel as possible, at least
once, to prove locking correctness - instead of having to trigger every
possible combination of locking interaction between CPUs, combined with
every possible hardirq and softirq nesting scenario (which is impossible
to do in practice).

[*] assuming that the validator itself is 100% correct, and no other
    part of the system corrupts the state of the validator in any way.
    We also assume that all NMI/SMM paths [which could interrupt
    even hardirq-disabled codepaths] are correct and do not interfere
    with the validator. We also assume that the 64-bit 'chain hash'
    value is unique for every lock-chain in the system. Also, lock
    recursion must not be higher than 20.

Performance:
------------

The above rules require _massive_ amounts of runtime checking. If we did
that for every lock taken and for every irqs-enable event, it would
render the system practically unusably slow. The complexity of checking
is O(N^2), so even with just a few hundred lock-classes we'd have to do
tens of thousands of checks for every event.

This problem is solved by checking any given 'locking scenario' (unique
sequence of locks taken after each other) only once. A simple stack of
held locks is maintained, and a lightweight 64-bit hash value is
calculated, which hash is unique for every lock chain. The hash value,
when the chain is validated for the first time, is then put into a hash
table, which hash-table can be checked in a lockfree manner. If the
locking chain occurs again later on, the hash table tells us that we
dont have to validate the chain again.

LOCK STATISTICS

- WHAT

As the name suggests, it provides statistics on locks.

- WHY

Because things like lock contention can severely impact performance.

- HOW

Lockdep already has hooks in the lock functions and maps lock instances to
lock classes. We build on that (see Documentation/lockdep-design.txt).
The graph below shows the relation between the lock functions and the various
hooks therein.

        __acquire
            |
           lock _____
            |        \
            |    __contended
            |         |
            |       <wait>
            | _______/
            |/
            |
       __acquired
            |
            .
          <hold>
            .
            |
       __release
            |
         unlock

lock, unlock	- the regular lock functions
__*		- the hooks
<> 		- states

With these hooks we provide the following statistics:

 con-bounces       - number of lock contention that involved x-cpu data
 contentions       - number of lock acquisitions that had to wait
 wait time min     - shortest (non-0) time we ever had to wait for a lock
           max     - longest time we ever had to wait for a lock
           total   - total time we spend waiting on this lock
 acq-bounces       - number of lock acquisitions that involved x-cpu data
 acquisitions      - number of times we took the lock
 hold time min     - shortest (non-0) time we ever held the lock
           max     - longest time we ever held the lock
           total   - total time this lock was held

From these number various other statistics can be derived, such as:

 hold time average = hold time total / acquisitions

These numbers are gathered per lock class, per read/write state (when
applicable).

It also tracks 4 contention points per class. A contention point is a call site
that had to wait on lock acquisition.

 - CONFIGURATION

Lock statistics are enabled via CONFIG_LOCK_STATS.

 - USAGE

Enable collection of statistics:

# echo 1 >/proc/sys/kernel/lock_stat

Disable collection of statistics:

# echo 0 >/proc/sys/kernel/lock_stat

Look at the current lock statistics:

( line numbers not part of actual output, done for clarity in the explanation
  below )

# less /proc/lock_stat

01 lock_stat version 0.3
02 -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
03                               class name    con-bounces    contentions   waittime-min   waittime-max waittime-total    acq-bounces   acquisitions   holdtime-min   holdtime-max holdtime-total
04 -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
05
06                          &mm->mmap_sem-W:           233            538 18446744073708       22924.27      607243.51           1342          45806           1.71        8595.89     1180582.34
07                          &mm->mmap_sem-R:           205            587 18446744073708       28403.36      731975.00           1940         412426           0.58      187825.45     6307502.88
08                          ---------------
09                            &mm->mmap_sem            487          [<ffffffff8053491f>] do_page_fault+0x466/0x928
10                            &mm->mmap_sem            179          [<ffffffff802a6200>] sys_mprotect+0xcd/0x21d
11                            &mm->mmap_sem            279          [<ffffffff80210a57>] sys_mmap+0x75/0xce
12                            &mm->mmap_sem             76          [<ffffffff802a490b>] sys_munmap+0x32/0x59
13                          ---------------
14                            &mm->mmap_sem            270          [<ffffffff80210a57>] sys_mmap+0x75/0xce
15                            &mm->mmap_sem            431          [<ffffffff8053491f>] do_page_fault+0x466/0x928
16                            &mm->mmap_sem            138          [<ffffffff802a490b>] sys_munmap+0x32/0x59
17                            &mm->mmap_sem            145          [<ffffffff802a6200>] sys_mprotect+0xcd/0x21d
18
19 ...............................................................................................................................................................................................
20
21                              dcache_lock:           621            623           0.52         118.26        1053.02           6745          91930           0.29         316.29      118423.41
22                              -----------
23                              dcache_lock            179          [<ffffffff80378274>] _atomic_dec_and_lock+0x34/0x54
24                              dcache_lock            113          [<ffffffff802cc17b>] d_alloc+0x19a/0x1eb
25                              dcache_lock             99          [<ffffffff802ca0dc>] d_rehash+0x1b/0x44
26                              dcache_lock            104          [<ffffffff802cbca0>] d_instantiate+0x36/0x8a
27                              -----------
28                              dcache_lock            192          [<ffffffff80378274>] _atomic_dec_and_lock+0x34/0x54
29                              dcache_lock             98          [<ffffffff802ca0dc>] d_rehash+0x1b/0x44
30                              dcache_lock             72          [<ffffffff802cc17b>] d_alloc+0x19a/0x1eb
31                              dcache_lock            112          [<ffffffff802cbca0>] d_instantiate+0x36/0x8a

This excerpt shows the first two lock class statistics. Line 01 shows the
output version - each time the format changes this will be updated. Line 02-04
show the header with column descriptions. Lines 05-18 and 20-31 show the actual
statistics. These statistics come in two parts; the actual stats separated by a
short separator (line 08, 13) from the contention points.

The first lock (05-18) is a read/write lock, and shows two lines above the
short separator. The contention points don't match the column descriptors,
they have two: contentions and [<IP>] symbol. The second set of contention
points are the points we're contending with.

The integer part of the time values is in us.

Dealing with nested locks, subclasses may appear:

32...............................................................................................................................................................................................
33
34                               &rq->lock:         13128          13128           0.43         190.53      103881.26          97454        3453404           0.00         401.11    13224683.11
35                               ---------
36                               &rq->lock            645          [<ffffffff8103bfc4>] task_rq_lock+0x43/0x75
37                               &rq->lock            297          [<ffffffff8104ba65>] try_to_wake_up+0x127/0x25a
38                               &rq->lock            360          [<ffffffff8103c4c5>] select_task_rq_fair+0x1f0/0x74a
39                               &rq->lock            428          [<ffffffff81045f98>] scheduler_tick+0x46/0x1fb
40                               ---------
41                               &rq->lock             77          [<ffffffff8103bfc4>] task_rq_lock+0x43/0x75
42                               &rq->lock            174          [<ffffffff8104ba65>] try_to_wake_up+0x127/0x25a
43                               &rq->lock           4715          [<ffffffff8103ed4b>] double_rq_lock+0x42/0x54
44                               &rq->lock            893          [<ffffffff81340524>] schedule+0x157/0x7b8
45
46...............................................................................................................................................................................................
47
48                             &rq->lock/1:         11526          11488           0.33         388.73      136294.31          21461          38404           0.00          37.93      109388.53
49                             -----------
50                             &rq->lock/1          11526          [<ffffffff8103ed58>] double_rq_lock+0x4f/0x54
51                             -----------
52                             &rq->lock/1           5645          [<ffffffff8103ed4b>] double_rq_lock+0x42/0x54
53                             &rq->lock/1           1224          [<ffffffff81340524>] schedule+0x157/0x7b8
54                             &rq->lock/1           4336          [<ffffffff8103ed58>] double_rq_lock+0x4f/0x54
55                             &rq->lock/1            181          [<ffffffff8104ba65>] try_to_wake_up+0x127/0x25a

Line 48 shows statistics for the second subclass (/1) of &rq->lock class
(subclass starts from 0), since in this case, as line 50 suggests,
double_rq_lock actually acquires a nested lock of two spinlocks.

View the top contending locks:

# grep : /proc/lock_stat | head
              &inode->i_data.tree_lock-W:            15          21657           0.18     1093295.30 11547131054.85             58          10415           0.16          87.51        6387.60
              &inode->i_data.tree_lock-R:             0              0           0.00           0.00           0.00          23302         231198           0.25           8.45       98023.38
                             dcache_lock:          1037           1161           0.38          45.32         774.51           6611         243371           0.15         306.48       77387.24
                         &inode->i_mutex:           161            286 18446744073709       62882.54     1244614.55           3653          20598 18446744073709       62318.60     1693822.74
                         &zone->lru_lock:            94             94           0.53           7.33          92.10           4366          32690           0.29          59.81       16350.06
              &inode->i_data.i_mmap_mutex:            79             79           0.40           3.77          53.03          11779          87755           0.28         116.93       29898.44
                        &q->__queue_lock:            48             50           0.52          31.62          86.31            774          13131           0.17         113.08       12277.52
                        &rq->rq_lock_key:            43             47           0.74          68.50         170.63           3706          33929           0.22         107.99       17460.62
                      &rq->rq_lock_key#2:            39             46           0.75           6.68          49.03           2979          32292           0.17         125.17       17137.63
                         tasklist_lock-W:            15             15           1.45          10.87          32.70           1201           7390           0.58          62.55       13648.47

Clear the statistics:

# echo 0 > /proc/lock_stat
This is the full-colour version of the currently unofficial Linux logo
("currently unofficial" just means that there has been no paperwork and
that I have not really announced it yet).  It was created by Larry Ewing,
and is freely usable as long as you acknowledge Larry as the original
artist. 

Note that there are black-and-white versions of this available that
scale down to smaller sizes and are better for letterheads or whatever
you want to use it for: for the full range of logos take a look at
Larry's web-page:

	http://www.isc.tamu.edu/~lewing/linux/

This file is a registry of magic numbers which are in use.  When you
add a magic number to a structure, you should also add it to this
file, since it is best if the magic numbers used by various structures
are unique.

It is a *very* good idea to protect kernel data structures with magic
numbers.  This allows you to check at run time whether (a) a structure
has been clobbered, or (b) you've passed the wrong structure to a
routine.  This last is especially useful --- particularly when you are
passing pointers to structures via a void * pointer.  The tty code,
for example, does this frequently to pass driver-specific and line
discipline-specific structures back and forth.

The way to use magic numbers is to declare then at the beginning of
the structure, like so:

struct tty_ldisc {
	int	magic;
	...
};

Please follow this discipline when you are adding future enhancements
to the kernel!  It has saved me countless hours of debugging,
especially in the screwy cases where an array has been overrun and
structures following the array have been overwritten.  Using this
discipline, these cases get detected quickly and safely.

					Theodore Ts'o
					31 Mar 94

The magic table is current to Linux 2.1.55.

					Michael Chastain
					<mailto:mec@shout.net>
					22 Sep 1997

Now it should be up to date with Linux 2.1.112. Because
we are in feature freeze time it is very unlikely that
something will change before 2.2.x. The entries are
sorted by number field.

					Krzysztof G. Baranowski
					<mailto: kgb@knm.org.pl>
					29 Jul 1998

Updated the magic table to Linux 2.5.45. Right over the feature freeze,
but it is possible that some new magic numbers will sneak into the
kernel before 2.6.x yet.

					Petr Baudis
					<pasky@ucw.cz>
					03 Nov 2002

Updated the magic table to Linux 2.5.74.

					Fabian Frederick
					<ffrederick@users.sourceforge.net>
					09 Jul 2003


Magic Name            Number      Structure            File
===========================================================================
PG_MAGIC              'P'         pg_{read,write}_hdr include/linux/pg.h
CMAGIC                0x0111      user              include/linux/a.out.h
MKISS_DRIVER_MAGIC    0x04bf      mkiss_channel     drivers/net/mkiss.h
RISCOM8_MAGIC         0x0907      riscom_port       drivers/char/riscom8.h
SPECIALIX_MAGIC       0x0907      specialix_port    drivers/char/specialix_io8.h
HDLC_MAGIC            0x239e      n_hdlc            drivers/char/n_hdlc.c
APM_BIOS_MAGIC        0x4101      apm_user          arch/i386/kernel/apm.c
CYCLADES_MAGIC        0x4359      cyclades_port     include/linux/cyclades.h
DB_MAGIC              0x4442      fc_info           drivers/net/iph5526_novram.c
DL_MAGIC              0x444d      fc_info           drivers/net/iph5526_novram.c
FASYNC_MAGIC          0x4601      fasync_struct     include/linux/fs.h
FF_MAGIC              0x4646      fc_info           drivers/net/iph5526_novram.c
ISICOM_MAGIC          0x4d54      isi_port          include/linux/isicom.h
PTY_MAGIC             0x5001                        drivers/char/pty.c
PPP_MAGIC             0x5002      ppp               include/linux/if_pppvar.h
SERIAL_MAGIC          0x5301      async_struct      include/linux/serial.h
SSTATE_MAGIC          0x5302      serial_state      include/linux/serial.h
SLIP_MAGIC            0x5302      slip              drivers/net/slip.h
STRIP_MAGIC           0x5303      strip             drivers/net/strip.c
X25_ASY_MAGIC         0x5303      x25_asy           drivers/net/x25_asy.h
SIXPACK_MAGIC         0x5304      sixpack           drivers/net/hamradio/6pack.h
AX25_MAGIC            0x5316      ax_disp           drivers/net/mkiss.h
ESP_MAGIC             0x53ee      esp_struct        drivers/char/esp.h
TTY_MAGIC             0x5401      tty_struct        include/linux/tty.h
MGSL_MAGIC            0x5401      mgsl_info         drivers/char/synclink.c
TTY_DRIVER_MAGIC      0x5402      tty_driver        include/linux/tty_driver.h
MGSLPC_MAGIC          0x5402      mgslpc_info       drivers/char/pcmcia/synclink_cs.c
TTY_LDISC_MAGIC       0x5403      tty_ldisc         include/linux/tty_ldisc.h
USB_SERIAL_MAGIC      0x6702      usb_serial        drivers/usb/serial/usb-serial.h
FULL_DUPLEX_MAGIC     0x6969                        drivers/net/tulip/de2104x.c
USB_BLUETOOTH_MAGIC   0x6d02      usb_bluetooth     drivers/usb/class/bluetty.c
RFCOMM_TTY_MAGIC      0x6d02                        net/bluetooth/rfcomm/tty.c
USB_SERIAL_PORT_MAGIC 0x7301      usb_serial_port   drivers/usb/serial/usb-serial.h
CG_MAGIC              0x00090255  ufs_cylinder_group include/linux/ufs_fs.h
A2232_MAGIC           0x000a2232  gs_port           drivers/char/ser_a2232.h
RPORT_MAGIC           0x00525001  r_port            drivers/char/rocket_int.h
LSEMAGIC              0x05091998  lse               drivers/fc4/fc.c
GDTIOCTL_MAGIC        0x06030f07  gdth_iowr_str     drivers/scsi/gdth_ioctl.h
RIEBL_MAGIC           0x09051990                    drivers/net/atarilance.c
RIO_MAGIC             0x12345678  gs_port           drivers/char/rio/rio_linux.c
SX_MAGIC              0x12345678  gs_port           drivers/char/sx.h
NBD_REQUEST_MAGIC     0x12560953  nbd_request       include/linux/nbd.h
RED_MAGIC2            0x170fc2a5  (any)             mm/slab.c
BAYCOM_MAGIC          0x19730510  baycom_state      drivers/net/baycom_epp.c
ISDN_X25IFACE_MAGIC   0x1e75a2b9  isdn_x25iface_proto_data
                                                    drivers/isdn/isdn_x25iface.h
ECP_MAGIC             0x21504345  cdkecpsig         include/linux/cdk.h
LSOMAGIC              0x27091997  lso               drivers/fc4/fc.c
LSMAGIC               0x2a3b4d2a  ls                drivers/fc4/fc.c
WANPIPE_MAGIC         0x414C4453  sdla_{dump,exec}  include/linux/wanpipe.h
CS_CARD_MAGIC         0x43525553  cs_card           sound/oss/cs46xx.c
LABELCL_MAGIC         0x4857434c  labelcl_info_s    include/asm/ia64/sn/labelcl.h
ISDN_ASYNC_MAGIC      0x49344C01  modem_info        include/linux/isdn.h
CTC_ASYNC_MAGIC       0x49344C01  ctc_tty_info      drivers/s390/net/ctctty.c
ISDN_NET_MAGIC        0x49344C02  isdn_net_local_s  drivers/isdn/i4l/isdn_net_lib.h
SAVEKMSG_MAGIC2       0x4B4D5347  savekmsg          arch/*/amiga/config.c
STLI_BOARDMAGIC       0x4bc6c825  stlibrd           include/linux/istallion.h
CS_STATE_MAGIC        0x4c4f4749  cs_state          sound/oss/cs46xx.c
SLAB_C_MAGIC          0x4f17a36d  kmem_cache        mm/slab.c
COW_MAGIC             0x4f4f4f4d  cow_header_v1     arch/um/drivers/ubd_user.c
I810_CARD_MAGIC       0x5072696E  i810_card         sound/oss/i810_audio.c
TRIDENT_CARD_MAGIC    0x5072696E  trident_card      sound/oss/trident.c
ROUTER_MAGIC          0x524d4157  wan_device        include/linux/wanrouter.h
SCC_MAGIC             0x52696368  gs_port           drivers/char/scc.h
SAVEKMSG_MAGIC1       0x53415645  savekmsg          arch/*/amiga/config.c
GDA_MAGIC             0x58464552  gda               arch/mips/include/asm/sn/gda.h
RED_MAGIC1            0x5a2cf071  (any)             mm/slab.c
STL_PORTMAGIC         0x5a7182c9  stlport           include/linux/stallion.h
EEPROM_MAGIC_VALUE    0x5ab478d2  lanai_dev         drivers/atm/lanai.c
HDLCDRV_MAGIC         0x5ac6e778  hdlcdrv_state     include/linux/hdlcdrv.h
EPCA_MAGIC            0x5c6df104  channel           include/linux/epca.h
PCXX_MAGIC            0x5c6df104  channel           drivers/char/pcxx.h
KV_MAGIC              0x5f4b565f  kernel_vars_s     arch/mips/include/asm/sn/klkernvars.h
I810_STATE_MAGIC      0x63657373  i810_state        sound/oss/i810_audio.c
TRIDENT_STATE_MAGIC   0x63657373  trient_state      sound/oss/trident.c
M3_CARD_MAGIC         0x646e6f50  m3_card           sound/oss/maestro3.c
FW_HEADER_MAGIC       0x65726F66  fw_header         drivers/atm/fore200e.h
SLOT_MAGIC            0x67267321  slot              drivers/hotplug/cpqphp.h
SLOT_MAGIC            0x67267322  slot              drivers/hotplug/acpiphp.h
LO_MAGIC              0x68797548  nbd_device        include/linux/nbd.h
OPROFILE_MAGIC        0x6f70726f  super_block       drivers/oprofile/oprofilefs.h
M3_STATE_MAGIC        0x734d724d  m3_state          sound/oss/maestro3.c
STL_PANELMAGIC        0x7ef621a1  stlpanel          include/linux/stallion.h
VMALLOC_MAGIC         0x87654320  snd_alloc_track   sound/core/memory.c
KMALLOC_MAGIC         0x87654321  snd_alloc_track   sound/core/memory.c
PWC_MAGIC             0x89DC10AB  pwc_device        drivers/usb/media/pwc.h
NBD_REPLY_MAGIC       0x96744668  nbd_reply         include/linux/nbd.h
STL_BOARDMAGIC        0xa2267f52  stlbrd            include/linux/stallion.h
ENI155_MAGIC          0xa54b872d  midway_eprom	    drivers/atm/eni.h
SCI_MAGIC             0xbabeface  gs_port           drivers/char/sh-sci.h
CODA_MAGIC            0xC0DAC0DA  coda_file_info    fs/coda/coda_fs_i.h
DPMEM_MAGIC           0xc0ffee11  gdt_pci_sram      drivers/scsi/gdth.h
STLI_PORTMAGIC        0xe671c7a1  stliport          include/linux/istallion.h
YAM_MAGIC             0xF10A7654  yam_port          drivers/net/hamradio/yam.c
CCB_MAGIC             0xf2691ad2  ccb               drivers/scsi/ncr53c8xx.c
QUEUE_MAGIC_FREE      0xf7e1c9a3  queue_entry       drivers/scsi/arm/queue.c
QUEUE_MAGIC_USED      0xf7e1cc33  queue_entry       drivers/scsi/arm/queue.c
HTB_CMAGIC            0xFEFAFEF1  htb_class         net/sched/sch_htb.c
NMI_MAGIC             0x48414d4d455201 nmi_s        arch/mips/include/asm/sn/nmi.h

Note that there are also defined special per-driver magic numbers in sound
memory management. See include/sound/sndmagic.h for complete list of them. Many
OSS sound drivers have their magic numbers constructed from the soundcard PCI
ID - these are not listed here as well.

IrDA subsystem also uses large number of own magic numbers, see
include/net/irda/irda.h for a complete list of them.

HFS is another larger user of magic numbers - you can find them in
fs/hfs/hfs.h.

                Linux kernel management style

This is a short document describing the preferred (or made up, depending
on who you ask) management style for the linux kernel.  It's meant to
mirror the CodingStyle document to some degree, and mainly written to
avoid answering (*) the same (or similar) questions over and over again. 

Management style is very personal and much harder to quantify than
simple coding style rules, so this document may or may not have anything
to do with reality.  It started as a lark, but that doesn't mean that it
might not actually be true. You'll have to decide for yourself.

Btw, when talking about "kernel manager", it's all about the technical
lead persons, not the people who do traditional management inside
companies.  If you sign purchase orders or you have any clue about the
budget of your group, you're almost certainly not a kernel manager. 
These suggestions may or may not apply to you. 

First off, I'd suggest buying "Seven Habits of Highly Effective
People", and NOT read it.  Burn it, it's a great symbolic gesture. 

(*) This document does so not so much by answering the question, but by
making it painfully obvious to the questioner that we don't have a clue
to what the answer is. 

Anyway, here goes:


		Chapter 1: Decisions

Everybody thinks managers make decisions, and that decision-making is
important.  The bigger and more painful the decision, the bigger the
manager must be to make it.  That's very deep and obvious, but it's not
actually true. 

The name of the game is to _avoid_ having to make a decision.  In
particular, if somebody tells you "choose (a) or (b), we really need you
to decide on this", you're in trouble as a manager.  The people you
manage had better know the details better than you, so if they come to
you for a technical decision, you're screwed.  You're clearly not
competent to make that decision for them. 

(Corollary:if the people you manage don't know the details better than
you, you're also screwed, although for a totally different reason. 
Namely that you are in the wrong job, and that _they_ should be managing
your brilliance instead). 

So the name of the game is to _avoid_ decisions, at least the big and
painful ones.  Making small and non-consequential decisions is fine, and
makes you look like you know what you're doing, so what a kernel manager
needs to do is to turn the big and painful ones into small things where
nobody really cares. 

It helps to realize that the key difference between a big decision and a
small one is whether you can fix your decision afterwards.  Any decision
can be made small by just always making sure that if you were wrong (and
you _will_ be wrong), you can always undo the damage later by
backtracking.  Suddenly, you get to be doubly managerial for making
_two_ inconsequential decisions - the wrong one _and_ the right one. 

And people will even see that as true leadership (*cough* bullshit
*cough*).

Thus the key to avoiding big decisions becomes to just avoiding to do
things that can't be undone.  Don't get ushered into a corner from which
you cannot escape.  A cornered rat may be dangerous - a cornered manager
is just pitiful. 

It turns out that since nobody would be stupid enough to ever really let
a kernel manager have huge fiscal responsibility _anyway_, it's usually
fairly easy to backtrack.  Since you're not going to be able to waste
huge amounts of money that you might not be able to repay, the only
thing you can backtrack on is a technical decision, and there
back-tracking is very easy: just tell everybody that you were an
incompetent nincompoop, say you're sorry, and undo all the worthless
work you had people work on for the last year.  Suddenly the decision
you made a year ago wasn't a big decision after all, since it could be
easily undone. 

It turns out that some people have trouble with this approach, for two
reasons:
 - admitting you were an idiot is harder than it looks.  We all like to
   maintain appearances, and coming out in public to say that you were
   wrong is sometimes very hard indeed. 
 - having somebody tell you that what you worked on for the last year
   wasn't worthwhile after all can be hard on the poor lowly engineers
   too, and while the actual _work_ was easy enough to undo by just
   deleting it, you may have irrevocably lost the trust of that
   engineer.  And remember: "irrevocable" was what we tried to avoid in
   the first place, and your decision ended up being a big one after
   all. 

Happily, both of these reasons can be mitigated effectively by just
admitting up-front that you don't have a friggin' clue, and telling
people ahead of the fact that your decision is purely preliminary, and
might be the wrong thing.  You should always reserve the right to change
your mind, and make people very _aware_ of that.  And it's much easier
to admit that you are stupid when you haven't _yet_ done the really
stupid thing.

Then, when it really does turn out to be stupid, people just roll their
eyes and say "Oops, he did it again".  

This preemptive admission of incompetence might also make the people who
actually do the work also think twice about whether it's worth doing or
not.  After all, if _they_ aren't certain whether it's a good idea, you
sure as hell shouldn't encourage them by promising them that what they
work on will be included.  Make them at least think twice before they
embark on a big endeavor. 

Remember: they'd better know more about the details than you do, and
they usually already think they have the answer to everything.  The best
thing you can do as a manager is not to instill confidence, but rather a
healthy dose of critical thinking on what they do. 

Btw, another way to avoid a decision is to plaintively just whine "can't
we just do both?" and look pitiful.  Trust me, it works.  If it's not
clear which approach is better, they'll eventually figure it out.  The
answer may end up being that both teams get so frustrated by the
situation that they just give up. 

That may sound like a failure, but it's usually a sign that there was
something wrong with both projects, and the reason the people involved
couldn't decide was that they were both wrong.  You end up coming up
smelling like roses, and you avoided yet another decision that you could
have screwed up on. 


		Chapter 2: People

Most people are idiots, and being a manager means you'll have to deal
with it, and perhaps more importantly, that _they_ have to deal with
_you_. 

It turns out that while it's easy to undo technical mistakes, it's not
as easy to undo personality disorders.  You just have to live with
theirs - and yours. 

However, in order to prepare yourself as a kernel manager, it's best to
remember not to burn any bridges, bomb any innocent villagers, or
alienate too many kernel developers. It turns out that alienating people
is fairly easy, and un-alienating them is hard. Thus "alienating"
immediately falls under the heading of "not reversible", and becomes a
no-no according to Chapter 1.

There's just a few simple rules here:
 (1) don't call people d*ckheads (at least not in public)
 (2) learn how to apologize when you forgot rule (1)

The problem with #1 is that it's very easy to do, since you can say
"you're a d*ckhead" in millions of different ways (*), sometimes without
even realizing it, and almost always with a white-hot conviction that
you are right. 

And the more convinced you are that you are right (and let's face it,
you can call just about _anybody_ a d*ckhead, and you often _will_ be
right), the harder it ends up being to apologize afterwards. 

To solve this problem, you really only have two options:
 - get really good at apologies
 - spread the "love" out so evenly that nobody really ends up feeling
   like they get unfairly targeted.  Make it inventive enough, and they
   might even be amused. 

The option of being unfailingly polite really doesn't exist. Nobody will
trust somebody who is so clearly hiding his true character.

(*) Paul Simon sang "Fifty Ways to Leave Your Lover", because quite
frankly, "A Million Ways to Tell a Developer He Is a D*ckhead" doesn't
scan nearly as well.  But I'm sure he thought about it. 


		Chapter 3: People II - the Good Kind

While it turns out that most people are idiots, the corollary to that is
sadly that you are one too, and that while we can all bask in the secure
knowledge that we're better than the average person (let's face it,
nobody ever believes that they're average or below-average), we should
also admit that we're not the sharpest knife around, and there will be
other people that are less of an idiot that you are. 

Some people react badly to smart people.  Others take advantage of them. 

Make sure that you, as a kernel maintainer, are in the second group. 
Suck up to them, because they are the people who will make your job
easier. In particular, they'll be able to make your decisions for you,
which is what the game is all about.

So when you find somebody smarter than you are, just coast along.  Your
management responsibilities largely become ones of saying "Sounds like a
good idea - go wild", or "That sounds good, but what about xxx?".  The
second version in particular is a great way to either learn something
new about "xxx" or seem _extra_ managerial by pointing out something the
smarter person hadn't thought about.  In either case, you win.

One thing to look out for is to realize that greatness in one area does
not necessarily translate to other areas.  So you might prod people in
specific directions, but let's face it, they might be good at what they
do, and suck at everything else.  The good news is that people tend to
naturally gravitate back to what they are good at, so it's not like you
are doing something irreversible when you _do_ prod them in some
direction, just don't push too hard.


		Chapter 4: Placing blame

Things will go wrong, and people want somebody to blame. Tag, you're it.

It's not actually that hard to accept the blame, especially if people
kind of realize that it wasn't _all_ your fault.  Which brings us to the
best way of taking the blame: do it for another guy. You'll feel good
for taking the fall, he'll feel good about not getting blamed, and the
guy who lost his whole 36GB porn-collection because of your incompetence
will grudgingly admit that you at least didn't try to weasel out of it.

Then make the developer who really screwed up (if you can find him) know
_in_private_ that he screwed up.  Not just so he can avoid it in the
future, but so that he knows he owes you one.  And, perhaps even more
importantly, he's also likely the person who can fix it.  Because, let's
face it, it sure ain't you. 

Taking the blame is also why you get to be manager in the first place. 
It's part of what makes people trust you, and allow you the potential
glory, because you're the one who gets to say "I screwed up".  And if
you've followed the previous rules, you'll be pretty good at saying that
by now. 


		Chapter 5: Things to avoid

There's one thing people hate even more than being called "d*ckhead",
and that is being called a "d*ckhead" in a sanctimonious voice.  The
first you can apologize for, the second one you won't really get the
chance.  They likely will no longer be listening even if you otherwise
do a good job. 

We all think we're better than anybody else, which means that when
somebody else puts on airs, it _really_ rubs us the wrong way.  You may
be morally and intellectually superior to everybody around you, but
don't try to make it too obvious unless you really _intend_ to irritate
somebody (*). 

Similarly, don't be too polite or subtle about things. Politeness easily
ends up going overboard and hiding the problem, and as they say, "On the
internet, nobody can hear you being subtle". Use a big blunt object to
hammer the point in, because you can't really depend on people getting
your point otherwise.

Some humor can help pad both the bluntness and the moralizing.  Going
overboard to the point of being ridiculous can drive a point home
without making it painful to the recipient, who just thinks you're being
silly.  It can thus help get through the personal mental block we all
have about criticism. 

(*) Hint: internet newsgroups that are not directly related to your work
are great ways to take out your frustrations at other people. Write
insulting posts with a sneer just to get into a good flame every once in
a while, and you'll feel cleansed. Just don't crap too close to home.


		Chapter 6: Why me?

Since your main responsibility seems to be to take the blame for other
peoples mistakes, and make it painfully obvious to everybody else that
you're incompetent, the obvious question becomes one of why do it in the
first place?

First off, while you may or may not get screaming teenage girls (or
boys, let's not be judgmental or sexist here) knocking on your dressing
room door, you _will_ get an immense feeling of personal accomplishment
for being "in charge".  Never mind the fact that you're really leading
by trying to keep up with everybody else and running after them as fast
as you can.  Everybody will still think you're the person in charge. 

It's a great job if you can hack it.
i386 Micro Channel Architecture Support
=======================================

MCA support is enabled using the CONFIG_MCA define.  A machine with a MCA
bus will have the kernel variable MCA_bus set, assuming the BIOS feature
bits are set properly (see arch/i386/boot/setup.S for information on
how this detection is done).

Adapter Detection
=================

The ideal MCA adapter detection is done through the use of the
Programmable Option Select registers.  Generic functions for doing
this have been added in include/linux/mca.h and arch/i386/kernel/mca.c.
Everything needed to detect adapters and read (and write) configuration
information is there.  A number of MCA-specific drivers already use
this.  The typical probe code looks like the following:

	#include <linux/mca.h>

	unsigned char pos2, pos3, pos4, pos5;
	struct net_device* dev;
	int slot;

	if( MCA_bus ) {
		slot = mca_find_adapter( ADAPTER_ID, 0 );
		if( slot == MCA_NOTFOUND ) {
			return -ENODEV;
		}
		/* optional - see below */
		mca_set_adapter_name( slot, "adapter name & description" );
		mca_set_adapter_procfn( slot, dev_getinfo, dev );

		/* read the POS registers.  Most devices only use 2 and 3 */
		pos2 = mca_read_stored_pos( slot, 2 );
		pos3 = mca_read_stored_pos( slot, 3 );
		pos4 = mca_read_stored_pos( slot, 4 );
		pos5 = mca_read_stored_pos( slot, 5 );
	} else {
		return -ENODEV;
	}

	/* extract configuration from pos[2345] and set everything up */

Loadable modules should modify this to test that the specified IRQ and
IO ports (plus whatever other stuff) match.  See 3c523.c for example
code (actually, smc-mca.c has a slightly more complex example that can
handle a list of adapter ids).

Keep in mind that devices should never directly access the POS registers
(via inb(), outb(), etc).  While it's generally safe, there is a small
potential for blowing up hardware when it's done at the wrong time.
Furthermore, accessing a POS register disables a device temporarily.
This is usually okay during startup, but do _you_ want to rely on it?
During initial configuration, mca_init() reads all the POS registers
into memory.  mca_read_stored_pos() accesses that data.  mca_read_pos()
and mca_write_pos() are also available for (safer) direct POS access,
but their use is _highly_ discouraged.  mca_write_pos() is particularly
dangerous, as it is possible for adapters to be put in inconsistent
states (i.e. sharing IO address, etc) and may result in crashes, toasted
hardware, and blindness.

User level drivers (such as the AGX X server) can use /proc/mca/pos to
find adapters (see below).

Some MCA adapters can also be detected via the usual ISA-style device
probing (many SCSI adapters, for example).  This sort of thing is highly
discouraged.  Perfectly good information is available telling you what's
there, so there's no excuse for messing with random IO ports.  However,
we MCA people still appreciate any ISA-style driver that will work with
our hardware.  You take what you can get...

Level-Triggered Interrupts
==========================

Because MCA uses level-triggered interrupts, a few problems arise with
what might best be described as the ISA mindset and its effects on
drivers.  These sorts of problems are expected to become less common as
more people use shared IRQs on PCI machines.

In general, an interrupt must be acknowledged not only at the ICU (which
is done automagically by the kernel), but at the device level.  In
particular, IRQ 0 must be reset after a timer interrupt (now done in
arch/i386/kernel/time.c) or the first timer interrupt hangs the system.
There were also problems with the 1.3.x floppy drivers, but that seems
to have been fixed.

IRQs are also shareable, and most MCA-specific devices should be coded
with shared IRQs in mind.

/proc/mca
=========

/proc/mca is a directory containing various files for adapters and
other stuff.

	/proc/mca/pos		Straight listing of POS registers
	/proc/mca/slot[1-8]	Information on adapter in specific slot
	/proc/mca/video		Same for integrated video
	/proc/mca/scsi		Same for integrated SCSI
	/proc/mca/machine	Machine information

See Appendix A for a sample.

Device drivers can easily add their own information function for
specific slots (including integrated ones) via the
mca_set_adapter_procfn() call.  Drivers that support this are ESDI, IBM
SCSI, and 3c523.  If a device is also a module, make sure that the proc
function is removed in the module cleanup.  This will require storing
the slot information in a private structure somewhere.  See the 3c523
driver for details.

Your typical proc function will look something like this:

	static int
	dev_getinfo( char* buf, int slot, void* d ) {
		struct net_device* dev = (struct net_device*) d;
		int len = 0;

		len += sprintf( buf+len, "Device: %s\n", dev->name );
		len += sprintf( buf+len, "IRQ: %d\n", dev->irq );
		len += sprintf( buf+len, "IO Port: %#lx-%#lx\n", ... );
		...

		return len;
	}

Some of the standard MCA information will already be printed, so don't
bother repeating it.  Don't try putting in more than 3K of information.

Enable this function with:
	mca_set_adapter_procfn( slot, dev_getinfo, dev );

Disable it with:
	mca_set_adapter_procfn( slot, NULL, NULL );

It is also recommended that, even if you don't write a proc function, to
set the name of the adapter (i.e. "PS/2 ESDI Controller") via
mca_set_adapter_name( int slot, char* name ).

MCA Device Drivers
==================

Currently, there are a number of MCA-specific device drivers.

1) PS/2 SCSI
	drivers/scsi/ibmmca.c
	drivers/scsi/ibmmca.h
   The driver for the IBM SCSI subsystem.  Includes both integrated
   controllers and adapter cards.  May require command-line arg
   "ibmmcascsi=io_port" to force detection of an adapter.  If you have a
   machine with a front-panel display (i.e. model 95), you can use
   "ibmmcascsi=display" to enable a drive activity indicator.

2) 3c523
	drivers/net/3c523.c
	drivers/net/3c523.h
   3Com 3c523 Etherlink/MC ethernet driver.

3) SMC Ultra/MCA and IBM Adapter/A
	drivers/net/smc-mca.c
	drivers/net/smc-mca.h
	Driver for the MCA version of the SMC Ultra and various other
	OEM'ed and work-alike cards (Elite, Adapter/A, etc).

4) NE/2
	driver/net/ne2.c
	driver/net/ne2.h
	The NE/2 is the MCA version of the NE2000.  This may not work
	with clones that have a different adapter id than the original
	NE/2.

5) Future Domain MCS-600/700, OEM'd IBM Fast SCSI Adapter/A and
   Reply Sound Blaster/SCSI (SCSI part)
	Better support for these cards than the driver for ISA.
   Supports multiple cards with IRQ sharing.

Also added boot time option of scsi-probe, which can do reordering of
SCSI host adapters. This will direct the kernel on the order which
SCSI adapter should be detected. Example:
  scsi-probe=ibmmca,fd_mcs,adaptec1542,buslogic

The serial drivers were modified to support the extended IO port range
of the typical MCA system (also #ifdef CONFIG_MCA).

The following devices work with existing drivers:
1) Token-ring
2) Future Domain SCSI (MCS-600, MCS-700, not MCS-350, OEM'ed IBM SCSI)
3) Adaptec 1640 SCSI (using the aha1542 driver)
4) Bustek/Buslogic SCSI (various)
5) Probably all Arcnet cards.
6) Some, possibly all, MCA IDE controllers.
7) 3Com 3c529 (MCA version of 3c509) (patched)

8) Intel EtherExpressMC  (patched version)
   You need to have CONFIG_MCA defined to have EtherExpressMC support.
9) Reply Sound Blaster/SCSI (SB part) (patched version)

Bugs & Other Weirdness
======================

NMIs tend to occur with MCA machines because of various hardware
weirdness, bus timeouts, and many other non-critical things.  Some basic
code to handle them (inspired by the NetBSD MCA code) has been added to
detect the guilty device, but it's pretty incomplete.  If NMIs are a
persistent problem (on some model 70 or 80s, they occur every couple
shell commands), the CONFIG_IGNORE_NMI flag will take care of that.

Various Pentium machines have had serious problems with the FPU test in
bugs.h.  Basically, the machine hangs after the HLT test.  This occurs,
as far as we know, on the Pentium-equipped 85s, 95s, and some PC Servers.
The PCI/MCA PC 750s are fine as far as I can tell.  The ``mca-pentium''
boot-prompt flag will disable the FPU bug check if this is a problem
with your machine.

The model 80 has a raft of problems that are just too weird and unique
to get into here.  Some people have no trouble while others have nothing
but problems.  I'd suspect some problems are related to the age of the
average 80 and accompanying hardware deterioration, although others
are definitely design problems with the hardware.  Among the problems
include SCSI controller problems, ESDI controller problems, and serious
screw-ups in the floppy controller.  Oh, and the parallel port is also
pretty flaky.  There were about 5 or 6 different model 80 motherboards
produced to fix various obscure problems.  As far as I know, it's pretty
much impossible to tell which bugs a particular model 80 has (other than
triggering them, that is).

Drivers are required for some MCA memory adapters.  If you're suddenly
short a few megs of RAM, this might be the reason.  The (I think) Enhanced
Memory Adapter commonly found on the model 70 is one.  There's a very
alpha driver floating around, but it's pretty ugly (disassembled from
the DOS driver, actually).  See the MCA Linux web page (URL below)
for more current memory info.

The Thinkpad 700 and 720 will work, but various components are either
non-functional, flaky, or we don't know anything about them.  The
graphics controller is supposed to be some WD, but we can't get things
working properly.  The PCMCIA slots don't seem to work.  Ditto for APM.
The serial ports work, but detection seems to be flaky.

Credits
=======
A whole pile of people have contributed to the MCA code.  I'd include
their names here, but I don't have a list handy.  Check the MCA Linux
home page (URL below) for a perpetually out-of-date list.

=====================================================================
MCA Linux Home Page: http://www.dgmicro.com/mca/

Christophe Beauregard
chrisb@truespectra.com
cpbeaure@calum.csclub.uwaterloo.ca

=====================================================================
Appendix A: Sample /proc/mca

This is from my model 8595.  Slot 1 contains the standard IBM SCSI
adapter, slot 3 is an Adaptec AHA-1640, slot 5 is a XGA-1 video adapter,
and slot 7 is the 3c523 Etherlink/MC.

/proc/mca/machine:
Model Id: 0xf8
Submodel Id: 0x14
BIOS Revision: 0x5

/proc/mca/pos:
Slot 1: ff 8e f1 fc a0 ff ff ff  IBM SCSI Adapter w/Cache
Slot 2: ff ff ff ff ff ff ff ff  
Slot 3: 1f 0f 81 3b bf b6 ff ff  
Slot 4: ff ff ff ff ff ff ff ff  
Slot 5: db 8f 1d 5e fd c0 00 00  
Slot 6: ff ff ff ff ff ff ff ff  
Slot 7: 42 60 ff 08 ff ff ff ff  3Com 3c523 Etherlink/MC
Slot 8: ff ff ff ff ff ff ff ff  
Video : ff ff ff ff ff ff ff ff  
SCSI  : ff ff ff ff ff ff ff ff  

/proc/mca/slot1:
Slot: 1
Adapter Name: IBM SCSI Adapter w/Cache
Id: 8eff
Enabled: Yes
POS: ff 8e f1 fc a0 ff ff ff 
Subsystem PUN: 7
Detected at boot: Yes

/proc/mca/slot3:
Slot: 3
Adapter Name: Unknown
Id: 0f1f
Enabled: Yes
POS: 1f 0f 81 3b bf b6 ff ff 

/proc/mca/slot5:
Slot: 5
Adapter Name: Unknown
Id: 8fdb
Enabled: Yes
POS: db 8f 1d 5e fd c0 00 00 

/proc/mca/slot7:
Slot: 7
Adapter Name: 3Com 3c523 Etherlink/MC
Id: 6042
Enabled: Yes
POS: 42 60 ff 08 ff ff ff ff 
Revision: 0xe
IRQ: 9
IO Address: 0x3300-0x3308
Memory: 0xd8000-0xdbfff
Transceiver: External
Device: eth0
Hardware Address: 02 60 8c 45 c4 2a
Tools that manage md devices can be found at
   http://www.kernel.org/pub/linux/utils/raid/ 


Boot time assembly of RAID arrays
---------------------------------

You can boot with your md device with the following kernel command
lines:

for old raid arrays without persistent superblocks:
  md=<md device no.>,<raid level>,<chunk size factor>,<fault level>,dev0,dev1,...,devn

for raid arrays with persistent superblocks
  md=<md device no.>,dev0,dev1,...,devn
or, to assemble a partitionable array:
  md=d<md device no.>,dev0,dev1,...,devn
  
md device no. = the number of the md device ... 
              0 means md0, 
	      1 md1,
	      2 md2,
	      3 md3,
	      4 md4

raid level = -1 linear mode
              0 striped mode
	      other modes are only supported with persistent super blocks

chunk size factor = (raid-0 and raid-1 only)
              Set  the chunk size as 4k << n.
	      
fault level = totally ignored
			    
dev0-devn: e.g. /dev/hda1,/dev/hdc1,/dev/sda1,/dev/sdb1
			    
A possible loadlin line (Harald Hoyer <HarryH@Royal.Net>)  looks like this:

e:\loadlin\loadlin e:\zimage root=/dev/md0 md=0,0,4,0,/dev/hdb2,/dev/hdc3 ro


Boot time autodetection of RAID arrays
--------------------------------------

When md is compiled into the kernel (not as module), partitions of
type 0xfd are scanned and automatically assembled into RAID arrays.
This autodetection may be suppressed with the kernel parameter
"raid=noautodetect".  As of kernel 2.6.9, only drives with a type 0
superblock can be autodetected and run at boot time.

The kernel parameter "raid=partitionable" (or "raid=part") means
that all auto-detected arrays are assembled as partitionable.

Boot time assembly of degraded/dirty arrays
-------------------------------------------

If a raid5 or raid6 array is both dirty and degraded, it could have
undetectable data corruption.  This is because the fact that it is
'dirty' means that the parity cannot be trusted, and the fact that it
is degraded means that some datablocks are missing and cannot reliably
be reconstructed (due to no parity).

For this reason, md will normally refuse to start such an array.  This
requires the sysadmin to take action to explicitly start the array
despite possible corruption.  This is normally done with
   mdadm --assemble --force ....

This option is not really available if the array has the root
filesystem on it.  In order to support this booting from such an
array, md supports a module parameter "start_dirty_degraded" which,
when set to 1, bypassed the checks and will allows dirty degraded
arrays to be started.

So, to boot with a root filesystem of a dirty degraded raid[56], use

   md-mod.start_dirty_degraded=1


Superblock formats
------------------

The md driver can support a variety of different superblock formats.
Currently, it supports superblock formats "0.90.0" and the "md-1" format
introduced in the 2.5 development series.

The kernel will autodetect which format superblock is being used.

Superblock format '0' is treated differently to others for legacy
reasons - it is the original superblock format.


General Rules - apply for all superblock formats
------------------------------------------------

An array is 'created' by writing appropriate superblocks to all
devices.

It is 'assembled' by associating each of these devices with an
particular md virtual device.  Once it is completely assembled, it can
be accessed.

An array should be created by a user-space tool.  This will write
superblocks to all devices.  It will usually mark the array as
'unclean', or with some devices missing so that the kernel md driver
can create appropriate redundancy (copying in raid1, parity
calculation in raid4/5).

When an array is assembled, it is first initialized with the
SET_ARRAY_INFO ioctl.  This contains, in particular, a major and minor
version number.  The major version number selects which superblock
format is to be used.  The minor number might be used to tune handling
of the format, such as suggesting where on each device to look for the
superblock.

Then each device is added using the ADD_NEW_DISK ioctl.  This
provides, in particular, a major and minor number identifying the
device to add.

The array is started with the RUN_ARRAY ioctl.

Once started, new devices can be added.  They should have an
appropriate superblock written to them, and then passed be in with
ADD_NEW_DISK.

Devices that have failed or are not yet active can be detached from an
array using HOT_REMOVE_DISK.


Specific Rules that apply to format-0 super block arrays, and
       arrays with no superblock (non-persistent).
-------------------------------------------------------------

An array can be 'created' by describing the array (level, chunksize
etc) in a SET_ARRAY_INFO ioctl.  This must has major_version==0 and
raid_disks != 0.

Then uninitialized devices can be added with ADD_NEW_DISK.  The
structure passed to ADD_NEW_DISK must specify the state of the device
and its role in the array.

Once started with RUN_ARRAY, uninitialized spares can be added with
HOT_ADD_DISK.



MD devices in sysfs
-------------------
md devices appear in sysfs (/sys) as regular block devices,
e.g.
   /sys/block/md0

Each 'md' device will contain a subdirectory called 'md' which
contains further md-specific information about the device.

All md devices contain:
  level
     a text file indicating the 'raid level'. e.g. raid0, raid1,
     raid5, linear, multipath, faulty.
     If no raid level has been set yet (array is still being
     assembled), the value will reflect whatever has been written
     to it, which may be a name like the above, or may be a number
     such as '0', '5', etc.

  raid_disks
     a text file with a simple number indicating the number of devices
     in a fully functional array.  If this is not yet known, the file
     will be empty.  If an array is being resized this will contain
     the new number of devices.
     Some raid levels allow this value to be set while the array is
     active.  This will reconfigure the array.   Otherwise it can only
     be set while assembling an array.
     A change to this attribute will not be permitted if it would
     reduce the size of the array.  To reduce the number of drives
     in an e.g. raid5, the array size must first be reduced by
     setting the 'array_size' attribute.

  chunk_size
     This is the size in bytes for 'chunks' and is only relevant to
     raid levels that involve striping (0,4,5,6,10). The address space
     of the array is conceptually divided into chunks and consecutive
     chunks are striped onto neighbouring devices.
     The size should be at least PAGE_SIZE (4k) and should be a power
     of 2.  This can only be set while assembling an array

  layout
     The "layout" for the array for the particular level.  This is
     simply a number that is interpretted differently by different
     levels.  It can be written while assembling an array.

  array_size
     This can be used to artificially constrain the available space in
     the array to be less than is actually available on the combined
     devices.  Writing a number (in Kilobytes) which is less than
     the available size will set the size.  Any reconfiguration of the
     array (e.g. adding devices) will not cause the size to change.
     Writing the word 'default' will cause the effective size of the
     array to be whatever size is actually available based on
     'level', 'chunk_size' and 'component_size'.

     This can be used to reduce the size of the array before reducing
     the number of devices in a raid4/5/6, or to support external
     metadata formats which mandate such clipping.

  reshape_position
     This is either "none" or a sector number within the devices of
     the array where "reshape" is up to.  If this is set, the three
     attributes mentioned above (raid_disks, chunk_size, layout) can
     potentially have 2 values, an old and a new value.  If these
     values differ, reading the attribute returns
        new (old)
     and writing will effect the 'new' value, leaving the 'old'
     unchanged.

  component_size
     For arrays with data redundancy (i.e. not raid0, linear, faulty,
     multipath), all components must be the same size - or at least
     there must a size that they all provide space for.  This is a key
     part or the geometry of the array.  It is measured in sectors
     and can be read from here.  Writing to this value may resize
     the array if the personality supports it (raid1, raid5, raid6),
     and if the component drives are large enough.

  metadata_version
     This indicates the format that is being used to record metadata
     about the array.  It can be 0.90 (traditional format), 1.0, 1.1,
     1.2 (newer format in varying locations) or "none" indicating that
     the kernel isn't managing metadata at all.
     Alternately it can be "external:" followed by a string which
     is set by user-space.  This indicates that metadata is managed
     by a user-space program.  Any device failure or other event that
     requires a metadata update will cause array activity to be
     suspended until the event is acknowledged.

  resync_start
     The point at which resync should start.  If no resync is needed,
     this will be a very large number (or 'none' since 2.6.30-rc1).  At
     array creation it will default to 0, though starting the array as
     'clean' will set it much larger.

   new_dev
     This file can be written but not read.  The value written should
     be a block device number as major:minor.  e.g. 8:0
     This will cause that device to be attached to the array, if it is
     available.  It will then appear at md/dev-XXX (depending on the
     name of the device) and further configuration is then possible.

   safe_mode_delay
     When an md array has seen no write requests for a certain period
     of time, it will be marked as 'clean'.  When another write
     request arrives, the array is marked as 'dirty' before the write
     commences.  This is known as 'safe_mode'.
     The 'certain period' is controlled by this file which stores the
     period as a number of seconds.  The default is 200msec (0.200).
     Writing a value of 0 disables safemode.

   array_state
     This file contains a single word which describes the current
     state of the array.  In many cases, the state can be set by
     writing the word for the desired state, however some states
     cannot be explicitly set, and some transitions are not allowed.

     Select/poll works on this file.  All changes except between
     	active_idle and active (which can be frequent and are not
	very interesting) are notified.  active->active_idle is
	reported if the metadata is externally managed.

     clear
         No devices, no size, no level
         Writing is equivalent to STOP_ARRAY ioctl
     inactive
         May have some settings, but array is not active
            all IO results in error
         When written, doesn't tear down array, but just stops it
     suspended (not supported yet)
         All IO requests will block. The array can be reconfigured.
         Writing this, if accepted, will block until array is quiessent
     readonly
         no resync can happen.  no superblocks get written.
         write requests fail
     read-auto
         like readonly, but behaves like 'clean' on a write request.

     clean - no pending writes, but otherwise active.
         When written to inactive array, starts without resync
         If a write request arrives then
           if metadata is known, mark 'dirty' and switch to 'active'.
           if not known, block and switch to write-pending
         If written to an active array that has pending writes, then fails.
     active
         fully active: IO and resync can be happening.
         When written to inactive array, starts with resync

     write-pending
         clean, but writes are blocked waiting for 'active' to be written.

     active-idle
         like active, but no writes have been seen for a while (safe_mode_delay).

  bitmap/location
     This indicates where the write-intent bitmap for the array is
     stored.
     It can be one of "none", "file" or "[+-]N".
     "file" may later be extended to "file:/file/name"
     "[+-]N" means that many sectors from the start of the metadata.
       This is replicated on all devices.  For arrays with externally
       managed metadata, the offset is from the beginning of the
       device.
  bitmap/chunksize
     The size, in bytes, of the chunk which will be represented by a
     single bit.  For RAID456, it is a portion of an individual
     device. For RAID10, it is a portion of the array.  For RAID1, it
     is both (they come to the same thing).
  bitmap/time_base
     The time, in seconds, between looking for bits in the bitmap to
     be cleared. In the current implementation, a bit will be cleared
     between 2 and 3 times "time_base" after all the covered blocks
     are known to be in-sync.
  bitmap/backlog
     When write-mostly devices are active in a RAID1, write requests
     to those devices proceed in the background - the filesystem (or
     other user of the device) does not have to wait for them.
     'backlog' sets a limit on the number of concurrent background
     writes.  If there are more than this, new writes will by
     synchronous.
  bitmap/metadata
     This can be either 'internal' or 'external'.
     'internal' is the default and means the metadata for the bitmap
     is stored in the first 256 bytes of the allocated space and is
     managed by the md module.
     'external' means that bitmap metadata is managed externally to
     the kernel (i.e. by some userspace program)
  bitmap/can_clear
     This is either 'true' or 'false'.  If 'true', then bits in the
     bitmap will be cleared when the corresponding blocks are thought
     to be in-sync.  If 'false', bits will never be cleared.
     This is automatically set to 'false' if a write happens on a
     degraded array, or if the array becomes degraded during a write.
     When metadata is managed externally, it should be set to true
     once the array becomes non-degraded, and this fact has been
     recorded in the metadata.
     
     
     

As component devices are added to an md array, they appear in the 'md'
directory as new directories named
      dev-XXX
where XXX is a name that the kernel knows for the device, e.g. hdb1.
Each directory contains:

      block
        a symlink to the block device in /sys/block, e.g.
	     /sys/block/md0/md/dev-hdb1/block -> ../../../../block/hdb/hdb1

      super
        A file containing an image of the superblock read from, or
        written to, that device.

      state
        A file recording the current state of the device in the array
	which can be a comma separated list of
	      faulty   - device has been kicked from active use due to
                         a detected fault
	      in_sync  - device is a fully in-sync member of the array
	      writemostly - device will only be subject to read
		         requests if there are no other options.
			 This applies only to raid1 arrays.
	      blocked  - device has failed, metadata is "external",
	                 and the failure hasn't been acknowledged yet.
			 Writes that would write to this device if
			 it were not faulty are blocked.
	      spare    - device is working, but not a full member.
			 This includes spares that are in the process
			 of being recovered to
	This list may grow in future.
	This can be written to.
	Writing "faulty"  simulates a failure on the device.
	Writing "remove" removes the device from the array.
	Writing "writemostly" sets the writemostly flag.
	Writing "-writemostly" clears the writemostly flag.
	Writing "blocked" sets the "blocked" flag.
	Writing "-blocked" clears the "blocked" flag and allows writes
		to complete.
	Writing "in_sync" sets the in_sync flag.

	This file responds to select/poll. Any change to 'faulty'
	or 'blocked' causes an event.

      errors
	An approximate count of read errors that have been detected on
	this device but have not caused the device to be evicted from
	the array (either because they were corrected or because they
	happened while the array was read-only).  When using version-1
	metadata, this value persists across restarts of the array.

	This value can be written while assembling an array thus
	providing an ongoing count for arrays with metadata managed by
	userspace.

      slot
        This gives the role that the device has in the array.  It will
	either be 'none' if the device is not active in the array
        (i.e. is a spare or has failed) or an integer less than the
	'raid_disks' number for the array indicating which position
	it currently fills.  This can only be set while assembling an
	array.  A device for which this is set is assumed to be working.

      offset
        This gives the location in the device (in sectors from the
        start) where data from the array will be stored.  Any part of
        the device before this offset us not touched, unless it is
        used for storing metadata (Formats 1.1 and 1.2).

      size
        The amount of the device, after the offset, that can be used
        for storage of data.  This will normally be the same as the
	component_size.  This can be written while assembling an
        array.  If a value less than the current component_size is
        written, it will be rejected.

      recovery_start

        When the device is not 'in_sync', this records the number of
	sectors from the start of the device which are known to be
	correct.  This is normally zero, but during a recovery
	operation is will steadily increase, and if the recovery is
	interrupted, restoring this value can cause recovery to
	avoid repeating the earlier blocks.  With v1.x metadata, this
	value is saved and restored automatically.

	This can be set whenever the device is not an active member of
	the array, either before the array is activated, or before
	the 'slot' is set.

	Setting this to 'none' is equivalent to setting 'in_sync'.
	Setting to any other value also clears the 'in_sync' flag.
	


An active md device will also contain and entry for each active device
in the array.  These are named

    rdNN

where 'NN' is the position in the array, starting from 0.
So for a 3 drive array there will be rd0, rd1, rd2.
These are symbolic links to the appropriate 'dev-XXX' entry.
Thus, for example,
       cat /sys/block/md*/md/rd*/state
will show 'in_sync' on every line.



Active md devices for levels that support data redundancy (1,4,5,6)
also have

   sync_action
     a text file that can be used to monitor and control the rebuild
     process.  It contains one word which can be one of:
       resync        - redundancy is being recalculated after unclean
                       shutdown or creation
       recover       - a hot spare is being built to replace a
                       failed/missing device
       idle          - nothing is happening
       check         - A full check of redundancy was requested and is
                       happening.  This reads all block and checks
                       them. A repair may also happen for some raid
                       levels.
       repair        - A full check and repair is happening.  This is
                       similar to 'resync', but was requested by the
                       user, and the write-intent bitmap is NOT used to
		       optimise the process.

      This file is writable, and each of the strings that could be
      read are meaningful for writing.

       'idle' will stop an active resync/recovery etc.  There is no
           guarantee that another resync/recovery may not be automatically
	   started again, though some event will be needed to trigger
           this.
	'resync' or 'recovery' can be used to restart the
           corresponding operation if it was stopped with 'idle'.
	'check' and 'repair' will start the appropriate process
           providing the current state is 'idle'.

      This file responds to select/poll.  Any important change in the value
      triggers a poll event.  Sometimes the value will briefly be
      "recover" if a recovery seems to be needed, but cannot be
      achieved. In that case, the transition to "recover" isn't
      notified, but the transition away is.

   degraded
      This contains a count of the number of devices by which the
      arrays is degraded.  So an optimal array with show '0'.  A
      single failed/missing drive will show '1', etc.
      This file responds to select/poll, any increase or decrease
      in the count of missing devices will trigger an event.

   mismatch_count
      When performing 'check' and 'repair', and possibly when
      performing 'resync', md will count the number of errors that are
      found.  The count in 'mismatch_cnt' is the number of sectors
      that were re-written, or (for 'check') would have been
      re-written.  As most raid levels work in units of pages rather
      than sectors, this my be larger than the number of actual errors
      by a factor of the number of sectors in a page.

   bitmap_set_bits
      If the array has a write-intent bitmap, then writing to this
      attribute can set bits in the bitmap, indicating that a resync
      would need to check the corresponding blocks. Either individual
      numbers or start-end pairs can be written.  Multiple numbers
      can be separated by a space.
      Note that the numbers are 'bit' numbers, not 'block' numbers.
      They should be scaled by the bitmap_chunksize.

   sync_speed_min
   sync_speed_max
     This are similar to /proc/sys/dev/raid/speed_limit_{min,max}
     however they only apply to the particular array.
     If no value has been written to these, of if the word 'system'
     is written, then the system-wide value is used.  If a value,
     in kibibytes-per-second is written, then it is used.
     When the files are read, they show the currently active value
     followed by "(local)" or "(system)" depending on whether it is
     a locally set or system-wide value.

   sync_completed
     This shows the number of sectors that have been completed of
     whatever the current sync_action is, followed by the number of
     sectors in total that could need to be processed.  The two
     numbers are separated by a '/'  thus effectively showing one
     value, a fraction of the process that is complete.
     A 'select' on this attribute will return when resync completes,
     when it reaches the current sync_max (below) and possibly at
     other times.

   sync_max
     This is a number of sectors at which point a resync/recovery
     process will pause.  When a resync is active, the value can
     only ever be increased, never decreased.  The value of 'max'
     effectively disables the limit.


   sync_speed
     This shows the current actual speed, in K/sec, of the current
     sync_action.  It is averaged over the last 30 seconds.

   suspend_lo
   suspend_hi
     The two values, given as numbers of sectors, indicate a range
     within the array where IO will be blocked.  This is currently
     only supported for raid4/5/6.

   sync_min
   sync_max
     The two values, given as numbers of sectors, indicate a range
     within the array where 'check'/'repair' will operate. Must be
     a multiple of chunk_size. When it reaches "sync_max" it will
     pause, rather than complete.
     You can use 'select' or 'poll' on "sync_completed" to wait for
     that number to reach sync_max.  Then you can either increase
     "sync_max", or can write 'idle' to "sync_action".


Each active md device may also have attributes specific to the
personality module that manages it.
These are specific to the implementation of the module and could
change substantially if the implementation changes.

These currently include

  stripe_cache_size  (currently raid5 only)
      number of entries in the stripe cache.  This is writable, but
      there are upper and lower limits (32768, 16).  Default is 128.
  strip_cache_active (currently raid5 only)
      number of active entries in the stripe cache
  preread_bypass_threshold (currently raid5 only)
      number of times a stripe requiring preread will be bypassed by
      a stripe that does not require preread.  For fairness defaults
      to 1.  Setting this to 0 disables bypass accounting and
      requires preread stripes to wait until all full-width stripe-
      writes are complete.  Valid values are 0 to stripe_cache_size.
Linux kernel media framework
============================

This document describes the Linux kernel media framework, its data structures,
functions and their usage.


Introduction
------------

The media controller API is documented in DocBook format in
Documentation/DocBook/v4l/media-controller.xml. This document will focus on
the kernel-side implementation of the media framework.


Abstract media device model
---------------------------

Discovering a device internal topology, and configuring it at runtime, is one
of the goals of the media framework. To achieve this, hardware devices are
modeled as an oriented graph of building blocks called entities connected
through pads.

An entity is a basic media hardware building block. It can correspond to
a large variety of logical blocks such as physical hardware devices
(CMOS sensor for instance), logical hardware devices (a building block
in a System-on-Chip image processing pipeline), DMA channels or physical
connectors.

A pad is a connection endpoint through which an entity can interact with
other entities. Data (not restricted to video) produced by an entity
flows from the entity's output to one or more entity inputs. Pads should
not be confused with physical pins at chip boundaries.

A link is a point-to-point oriented connection between two pads, either
on the same entity or on different entities. Data flows from a source
pad to a sink pad.


Media device
------------

A media device is represented by a struct media_device instance, defined in
include/media/media-device.h. Allocation of the structure is handled by the
media device driver, usually by embedding the media_device instance in a
larger driver-specific structure.

Drivers register media device instances by calling

	media_device_register(struct media_device *mdev);

The caller is responsible for initializing the media_device structure before
registration. The following fields must be set:

 - dev must point to the parent device (usually a pci_dev, usb_interface or
   platform_device instance).

 - model must be filled with the device model name as a NUL-terminated UTF-8
   string. The device/model revision must not be stored in this field.

The following fields are optional:

 - serial is a unique serial number stored as a NUL-terminated ASCII string.
   The field is big enough to store a GUID in text form. If the hardware
   doesn't provide a unique serial number this field must be left empty.

 - bus_info represents the location of the device in the system as a
   NUL-terminated ASCII string. For PCI/PCIe devices bus_info must be set to
   "PCI:" (or "PCIe:") followed by the value of pci_name(). For USB devices,
   the usb_make_path() function must be used. This field is used by
   applications to distinguish between otherwise identical devices that don't
   provide a serial number.

 - hw_revision is the hardware device revision in a driver-specific format.
   When possible the revision should be formatted with the KERNEL_VERSION
   macro.

 - driver_version is formatted with the KERNEL_VERSION macro. The version
   minor must be incremented when new features are added to the userspace API
   without breaking binary compatibility. The version major must be
   incremented when binary compatibility is broken.

Upon successful registration a character device named media[0-9]+ is created.
The device major and minor numbers are dynamic. The model name is exported as
a sysfs attribute.

Drivers unregister media device instances by calling

	media_device_unregister(struct media_device *mdev);

Unregistering a media device that hasn't been registered is *NOT* safe.


Entities, pads and links
------------------------

- Entities

Entities are represented by a struct media_entity instance, defined in
include/media/media-entity.h. The structure is usually embedded into a
higher-level structure, such as a v4l2_subdev or video_device instance,
although drivers can allocate entities directly.

Drivers initialize entities by calling

	media_entity_init(struct media_entity *entity, u16 num_pads,
			  struct media_pad *pads, u16 extra_links);

The media_entity name, type, flags, revision and group_id fields can be
initialized before or after calling media_entity_init. Entities embedded in
higher-level standard structures can have some of those fields set by the
higher-level framework.

As the number of pads is known in advance, the pads array is not allocated
dynamically but is managed by the entity driver. Most drivers will embed the
pads array in a driver-specific structure, avoiding dynamic allocation.

Drivers must set the direction of every pad in the pads array before calling
media_entity_init. The function will initialize the other pads fields.

Unlike the number of pads, the total number of links isn't always known in
advance by the entity driver. As an initial estimate, media_entity_init
pre-allocates a number of links equal to the number of pads plus an optional
number of extra links. The links array will be reallocated if it grows beyond
the initial estimate.

Drivers register entities with a media device by calling

	media_device_register_entity(struct media_device *mdev,
				     struct media_entity *entity);

Entities are identified by a unique positive integer ID. Drivers can provide an
ID by filling the media_entity id field prior to registration, or request the
media controller framework to assign an ID automatically. Drivers that provide
IDs manually must ensure that all IDs are unique. IDs are not guaranteed to be
contiguous even when they are all assigned automatically by the framework.

Drivers unregister entities by calling

	media_device_unregister_entity(struct media_entity *entity);

Unregistering an entity will not change the IDs of the other entities, and the
ID will never be reused for a newly registered entity.

When a media device is unregistered, all its entities are unregistered
automatically. No manual entities unregistration is then required.

Drivers free resources associated with an entity by calling

	media_entity_cleanup(struct media_entity *entity);

This function must be called during the cleanup phase after unregistering the
entity. Note that the media_entity instance itself must be freed explicitly by
the driver if required.

Entities have flags that describe the entity capabilities and state.

	MEDIA_ENT_FL_DEFAULT indicates the default entity for a given type.
	This can be used to report the default audio and video devices or the
	default camera sensor.

Logical entity groups can be defined by setting the group ID of all member
entities to the same non-zero value. An entity group serves no purpose in the
kernel, but is reported to userspace during entities enumeration. The group_id
field belongs to the media device driver and must not by touched by entity
drivers.

Media device drivers should define groups if several entities are logically
bound together. Example usages include reporting

	- ALSA, VBI and video nodes that carry the same media stream
	- lens and flash controllers associated with a sensor

- Pads

Pads are represented by a struct media_pad instance, defined in
include/media/media-entity.h. Each entity stores its pads in a pads array
managed by the entity driver. Drivers usually embed the array in a
driver-specific structure.

Pads are identified by their entity and their 0-based index in the pads array.
Both information are stored in the media_pad structure, making the media_pad
pointer the canonical way to store and pass link references.

Pads have flags that describe the pad capabilities and state.

	MEDIA_PAD_FL_SINK indicates that the pad supports sinking data.
	MEDIA_PAD_FL_SOURCE indicates that the pad supports sourcing data.

One and only one of MEDIA_PAD_FL_SINK and MEDIA_PAD_FL_SOURCE must be set for
each pad.

- Links

Links are represented by a struct media_link instance, defined in
include/media/media-entity.h. Each entity stores all links originating at or
targeting any of its pads in a links array. A given link is thus stored
twice, once in the source entity and once in the target entity. The array is
pre-allocated and grows dynamically as needed.

Drivers create links by calling

	media_entity_create_link(struct media_entity *source, u16 source_pad,
				 struct media_entity *sink,   u16 sink_pad,
				 u32 flags);

An entry in the link array of each entity is allocated and stores pointers
to source and sink pads.

Links have flags that describe the link capabilities and state.

	MEDIA_LNK_FL_ENABLED indicates that the link is enabled and can be used
	to transfer media data. When two or more links target a sink pad, only
	one of them can be enabled at a time.
	MEDIA_LNK_FL_IMMUTABLE indicates that the link enabled state can't be
	modified at runtime. If MEDIA_LNK_FL_IMMUTABLE is set, then
	MEDIA_LNK_FL_ENABLED must also be set since an immutable link is always
	enabled.


Graph traversal
---------------

The media framework provides APIs to iterate over entities in a graph.

To iterate over all entities belonging to a media device, drivers can use the
media_device_for_each_entity macro, defined in include/media/media-device.h.

	struct media_entity *entity;

	media_device_for_each_entity(entity, mdev) {
		/* entity will point to each entity in turn */
		...
	}

Drivers might also need to iterate over all entities in a graph that can be
reached only through enabled links starting at a given entity. The media
framework provides a depth-first graph traversal API for that purpose.

Note that graphs with cycles (whether directed or undirected) are *NOT*
supported by the graph traversal API. To prevent infinite loops, the graph
traversal code limits the maximum depth to MEDIA_ENTITY_ENUM_MAX_DEPTH,
currently defined as 16.

Drivers initiate a graph traversal by calling

	media_entity_graph_walk_start(struct media_entity_graph *graph,
				      struct media_entity *entity);

The graph structure, provided by the caller, is initialized to start graph
traversal at the given entity.

Drivers can then retrieve the next entity by calling

	media_entity_graph_walk_next(struct media_entity_graph *graph);

When the graph traversal is complete the function will return NULL.

Graph traversal can be interrupted at any moment. No cleanup function call is
required and the graph structure can be freed normally.

Helper functions can be used to find a link between two given pads, or a pad
connected to another pad through an enabled link

	media_entity_find_link(struct media_pad *source,
			       struct media_pad *sink);

	media_entity_remote_source(struct media_pad *pad);

Refer to the kerneldoc documentation for more information.


Use count and power handling
----------------------------

Due to the wide differences between drivers regarding power management needs,
the media controller does not implement power management. However, the
media_entity structure includes a use_count field that media drivers can use to
track the number of users of every entity for power management needs.

The use_count field is owned by media drivers and must not be touched by entity
drivers. Access to the field must be protected by the media device graph_mutex
lock.


Links setup
-----------

Link properties can be modified at runtime by calling

	media_entity_setup_link(struct media_link *link, u32 flags);

The flags argument contains the requested new link flags.

The only configurable property is the ENABLED link flag to enable/disable a
link. Links marked with the IMMUTABLE link flag can not be enabled or disabled.

When a link is enabled or disabled, the media framework calls the
link_setup operation for the two entities at the source and sink of the link,
in that order. If the second link_setup call fails, another link_setup call is
made on the first entity to restore the original link flags.

Media device drivers can be notified of link setup operations by setting the
media_device::link_notify pointer to a callback function. If provided, the
notification callback will be called before enabling and after disabling
links.

Entity drivers must implement the link_setup operation if any of their links
is non-immutable. The operation must either configure the hardware or store
the configuration information to be applied later.

Link configuration must not have any side effect on other links. If an enabled
link at a sink pad prevents another link at the same pad from being disabled,
the link_setup operation must return -EBUSY and can't implicitly disable the
first enabled link.


Pipelines and media streams
---------------------------

When starting streaming, drivers must notify all entities in the pipeline to
prevent link states from being modified during streaming by calling

	media_entity_pipeline_start(struct media_entity *entity,
				    struct media_pipeline *pipe);

The function will mark all entities connected to the given entity through
enabled links, either directly or indirectly, as streaming.

The media_pipeline instance pointed to by the pipe argument will be stored in
every entity in the pipeline. Drivers should embed the media_pipeline structure
in higher-level pipeline structures and can then access the pipeline through
the media_entity pipe field.

Calls to media_entity_pipeline_start() can be nested. The pipeline pointer must
be identical for all nested calls to the function.

When stopping the stream, drivers must notify the entities with

	media_entity_pipeline_stop(struct media_entity *entity);

If multiple calls to media_entity_pipeline_start() have been made the same
number of media_entity_pipeline_stop() calls are required to stop streaming. The
media_entity pipe field is reset to NULL on the last nested stop call.

Link configuration will fail with -EBUSY by default if either end of the link is
a streaming entity. Links that can be modified while streaming must be marked
with the MEDIA_LNK_FL_DYNAMIC flag.

If other operations need to be disallowed on streaming entities (such as
changing entities configuration parameters) drivers can explicitly check the
media_entity stream_count field to find out if an entity is streaming. This
operation must be done with the media_device graph_mutex held.
			 ============================
			 LINUX KERNEL MEMORY BARRIERS
			 ============================

By: David Howells <dhowells@redhat.com>
    Paul E. McKenney <paulmck@linux.vnet.ibm.com>

Contents:

 (*) Abstract memory access model.

     - Device operations.
     - Guarantees.

 (*) What are memory barriers?

     - Varieties of memory barrier.
     - What may not be assumed about memory barriers?
     - Data dependency barriers.
     - Control dependencies.
     - SMP barrier pairing.
     - Examples of memory barrier sequences.
     - Read memory barriers vs load speculation.
     - Transitivity

 (*) Explicit kernel barriers.

     - Compiler barrier.
     - CPU memory barriers.
     - MMIO write barrier.

 (*) Implicit kernel memory barriers.

     - Locking functions.
     - Interrupt disabling functions.
     - Sleep and wake-up functions.
     - Miscellaneous functions.

 (*) Inter-CPU locking barrier effects.

     - Locks vs memory accesses.
     - Locks vs I/O accesses.

 (*) Where are memory barriers needed?

     - Interprocessor interaction.
     - Atomic operations.
     - Accessing devices.
     - Interrupts.

 (*) Kernel I/O barrier effects.

 (*) Assumed minimum execution ordering model.

 (*) The effects of the cpu cache.

     - Cache coherency.
     - Cache coherency vs DMA.
     - Cache coherency vs MMIO.

 (*) The things CPUs get up to.

     - And then there's the Alpha.

 (*) Example uses.

     - Circular buffers.

 (*) References.


============================
ABSTRACT MEMORY ACCESS MODEL
============================

Consider the following abstract model of the system:

		            :                :
		            :                :
		            :                :
		+-------+   :   +--------+   :   +-------+
		|       |   :   |        |   :   |       |
		|       |   :   |        |   :   |       |
		| CPU 1 |<----->| Memory |<----->| CPU 2 |
		|       |   :   |        |   :   |       |
		|       |   :   |        |   :   |       |
		+-------+   :   +--------+   :   +-------+
		    ^       :       ^        :       ^
		    |       :       |        :       |
		    |       :       |        :       |
		    |       :       v        :       |
		    |       :   +--------+   :       |
		    |       :   |        |   :       |
		    |       :   |        |   :       |
		    +---------->| Device |<----------+
		            :   |        |   :
		            :   |        |   :
		            :   +--------+   :
		            :                :

Each CPU executes a program that generates memory access operations.  In the
abstract CPU, memory operation ordering is very relaxed, and a CPU may actually
perform the memory operations in any order it likes, provided program causality
appears to be maintained.  Similarly, the compiler may also arrange the
instructions it emits in any order it likes, provided it doesn't affect the
apparent operation of the program.

So in the above diagram, the effects of the memory operations performed by a
CPU are perceived by the rest of the system as the operations cross the
interface between the CPU and rest of the system (the dotted lines).


For example, consider the following sequence of events:

	CPU 1		CPU 2
	===============	===============
	{ A == 1; B == 2 }
	A = 3;		x = A;
	B = 4;		y = B;

The set of accesses as seen by the memory system in the middle can be arranged
in 24 different combinations:

	STORE A=3,	STORE B=4,	x=LOAD A->3,	y=LOAD B->4
	STORE A=3,	STORE B=4,	y=LOAD B->4,	x=LOAD A->3
	STORE A=3,	x=LOAD A->3,	STORE B=4,	y=LOAD B->4
	STORE A=3,	x=LOAD A->3,	y=LOAD B->2,	STORE B=4
	STORE A=3,	y=LOAD B->2,	STORE B=4,	x=LOAD A->3
	STORE A=3,	y=LOAD B->2,	x=LOAD A->3,	STORE B=4
	STORE B=4,	STORE A=3,	x=LOAD A->3,	y=LOAD B->4
	STORE B=4, ...
	...

and can thus result in four different combinations of values:

	x == 1, y == 2
	x == 1, y == 4
	x == 3, y == 2
	x == 3, y == 4


Furthermore, the stores committed by a CPU to the memory system may not be
perceived by the loads made by another CPU in the same order as the stores were
committed.


As a further example, consider this sequence of events:

	CPU 1		CPU 2
	===============	===============
	{ A == 1, B == 2, C = 3, P == &A, Q == &C }
	B = 4;		Q = P;
	P = &B		D = *Q;

There is an obvious data dependency here, as the value loaded into D depends on
the address retrieved from P by CPU 2.  At the end of the sequence, any of the
following results are possible:

	(Q == &A) and (D == 1)
	(Q == &B) and (D == 2)
	(Q == &B) and (D == 4)

Note that CPU 2 will never try and load C into D because the CPU will load P
into Q before issuing the load of *Q.


DEVICE OPERATIONS
-----------------

Some devices present their control interfaces as collections of memory
locations, but the order in which the control registers are accessed is very
important.  For instance, imagine an ethernet card with a set of internal
registers that are accessed through an address port register (A) and a data
port register (D).  To read internal register 5, the following code might then
be used:

	*A = 5;
	x = *D;

but this might show up as either of the following two sequences:

	STORE *A = 5, x = LOAD *D
	x = LOAD *D, STORE *A = 5

the second of which will almost certainly result in a malfunction, since it set
the address _after_ attempting to read the register.


GUARANTEES
----------

There are some minimal guarantees that may be expected of a CPU:

 (*) On any given CPU, dependent memory accesses will be issued in order, with
     respect to itself.  This means that for:

	Q = P; D = *Q;

     the CPU will issue the following memory operations:

	Q = LOAD P, D = LOAD *Q

     and always in that order.

 (*) Overlapping loads and stores within a particular CPU will appear to be
     ordered within that CPU.  This means that for:

	a = *X; *X = b;

     the CPU will only issue the following sequence of memory operations:

	a = LOAD *X, STORE *X = b

     And for:

	*X = c; d = *X;

     the CPU will only issue:

	STORE *X = c, d = LOAD *X

     (Loads and stores overlap if they are targeted at overlapping pieces of
     memory).

And there are a number of things that _must_ or _must_not_ be assumed:

 (*) It _must_not_ be assumed that independent loads and stores will be issued
     in the order given.  This means that for:

	X = *A; Y = *B; *D = Z;

     we may get any of the following sequences:

	X = LOAD *A,  Y = LOAD *B,  STORE *D = Z
	X = LOAD *A,  STORE *D = Z, Y = LOAD *B
	Y = LOAD *B,  X = LOAD *A,  STORE *D = Z
	Y = LOAD *B,  STORE *D = Z, X = LOAD *A
	STORE *D = Z, X = LOAD *A,  Y = LOAD *B
	STORE *D = Z, Y = LOAD *B,  X = LOAD *A

 (*) It _must_ be assumed that overlapping memory accesses may be merged or
     discarded.  This means that for:

	X = *A; Y = *(A + 4);

     we may get any one of the following sequences:

	X = LOAD *A; Y = LOAD *(A + 4);
	Y = LOAD *(A + 4); X = LOAD *A;
	{X, Y} = LOAD {*A, *(A + 4) };

     And for:

	*A = X; Y = *A;

     we may get either of:

	STORE *A = X; Y = LOAD *A;
	STORE *A = Y = X;


=========================
WHAT ARE MEMORY BARRIERS?
=========================

As can be seen above, independent memory operations are effectively performed
in random order, but this can be a problem for CPU-CPU interaction and for I/O.
What is required is some way of intervening to instruct the compiler and the
CPU to restrict the order.

Memory barriers are such interventions.  They impose a perceived partial
ordering over the memory operations on either side of the barrier.

Such enforcement is important because the CPUs and other devices in a system
can use a variety of tricks to improve performance, including reordering,
deferral and combination of memory operations; speculative loads; speculative
branch prediction and various types of caching.  Memory barriers are used to
override or suppress these tricks, allowing the code to sanely control the
interaction of multiple CPUs and/or devices.


VARIETIES OF MEMORY BARRIER
---------------------------

Memory barriers come in four basic varieties:

 (1) Write (or store) memory barriers.

     A write memory barrier gives a guarantee that all the STORE operations
     specified before the barrier will appear to happen before all the STORE
     operations specified after the barrier with respect to the other
     components of the system.

     A write barrier is a partial ordering on stores only; it is not required
     to have any effect on loads.

     A CPU can be viewed as committing a sequence of store operations to the
     memory system as time progresses.  All stores before a write barrier will
     occur in the sequence _before_ all the stores after the write barrier.

     [!] Note that write barriers should normally be paired with read or data
     dependency barriers; see the "SMP barrier pairing" subsection.


 (2) Data dependency barriers.

     A data dependency barrier is a weaker form of read barrier.  In the case
     where two loads are performed such that the second depends on the result
     of the first (eg: the first load retrieves the address to which the second
     load will be directed), a data dependency barrier would be required to
     make sure that the target of the second load is updated before the address
     obtained by the first load is accessed.

     A data dependency barrier is a partial ordering on interdependent loads
     only; it is not required to have any effect on stores, independent loads
     or overlapping loads.

     As mentioned in (1), the other CPUs in the system can be viewed as
     committing sequences of stores to the memory system that the CPU being
     considered can then perceive.  A data dependency barrier issued by the CPU
     under consideration guarantees that for any load preceding it, if that
     load touches one of a sequence of stores from another CPU, then by the
     time the barrier completes, the effects of all the stores prior to that
     touched by the load will be perceptible to any loads issued after the data
     dependency barrier.

     See the "Examples of memory barrier sequences" subsection for diagrams
     showing the ordering constraints.

     [!] Note that the first load really has to have a _data_ dependency and
     not a control dependency.  If the address for the second load is dependent
     on the first load, but the dependency is through a conditional rather than
     actually loading the address itself, then it's a _control_ dependency and
     a full read barrier or better is required.  See the "Control dependencies"
     subsection for more information.

     [!] Note that data dependency barriers should normally be paired with
     write barriers; see the "SMP barrier pairing" subsection.


 (3) Read (or load) memory barriers.

     A read barrier is a data dependency barrier plus a guarantee that all the
     LOAD operations specified before the barrier will appear to happen before
     all the LOAD operations specified after the barrier with respect to the
     other components of the system.

     A read barrier is a partial ordering on loads only; it is not required to
     have any effect on stores.

     Read memory barriers imply data dependency barriers, and so can substitute
     for them.

     [!] Note that read barriers should normally be paired with write barriers;
     see the "SMP barrier pairing" subsection.


 (4) General memory barriers.

     A general memory barrier gives a guarantee that all the LOAD and STORE
     operations specified before the barrier will appear to happen before all
     the LOAD and STORE operations specified after the barrier with respect to
     the other components of the system.

     A general memory barrier is a partial ordering over both loads and stores.

     General memory barriers imply both read and write memory barriers, and so
     can substitute for either.


And a couple of implicit varieties:

 (5) LOCK operations.

     This acts as a one-way permeable barrier.  It guarantees that all memory
     operations after the LOCK operation will appear to happen after the LOCK
     operation with respect to the other components of the system.

     Memory operations that occur before a LOCK operation may appear to happen
     after it completes.

     A LOCK operation should almost always be paired with an UNLOCK operation.


 (6) UNLOCK operations.

     This also acts as a one-way permeable barrier.  It guarantees that all
     memory operations before the UNLOCK operation will appear to happen before
     the UNLOCK operation with respect to the other components of the system.

     Memory operations that occur after an UNLOCK operation may appear to
     happen before it completes.

     LOCK and UNLOCK operations are guaranteed to appear with respect to each
     other strictly in the order specified.

     The use of LOCK and UNLOCK operations generally precludes the need for
     other sorts of memory barrier (but note the exceptions mentioned in the
     subsection "MMIO write barrier").


Memory barriers are only required where there's a possibility of interaction
between two CPUs or between a CPU and a device.  If it can be guaranteed that
there won't be any such interaction in any particular piece of code, then
memory barriers are unnecessary in that piece of code.


Note that these are the _minimum_ guarantees.  Different architectures may give
more substantial guarantees, but they may _not_ be relied upon outside of arch
specific code.


WHAT MAY NOT BE ASSUMED ABOUT MEMORY BARRIERS?
----------------------------------------------

There are certain things that the Linux kernel memory barriers do not guarantee:

 (*) There is no guarantee that any of the memory accesses specified before a
     memory barrier will be _complete_ by the completion of a memory barrier
     instruction; the barrier can be considered to draw a line in that CPU's
     access queue that accesses of the appropriate type may not cross.

 (*) There is no guarantee that issuing a memory barrier on one CPU will have
     any direct effect on another CPU or any other hardware in the system.  The
     indirect effect will be the order in which the second CPU sees the effects
     of the first CPU's accesses occur, but see the next point:

 (*) There is no guarantee that a CPU will see the correct order of effects
     from a second CPU's accesses, even _if_ the second CPU uses a memory
     barrier, unless the first CPU _also_ uses a matching memory barrier (see
     the subsection on "SMP Barrier Pairing").

 (*) There is no guarantee that some intervening piece of off-the-CPU
     hardware[*] will not reorder the memory accesses.  CPU cache coherency
     mechanisms should propagate the indirect effects of a memory barrier
     between CPUs, but might not do so in order.

	[*] For information on bus mastering DMA and coherency please read:

	    Documentation/PCI/pci.txt
	    Documentation/PCI/PCI-DMA-mapping.txt
	    Documentation/DMA-API.txt


DATA DEPENDENCY BARRIERS
------------------------

The usage requirements of data dependency barriers are a little subtle, and
it's not always obvious that they're needed.  To illustrate, consider the
following sequence of events:

	CPU 1		CPU 2
	===============	===============
	{ A == 1, B == 2, C = 3, P == &A, Q == &C }
	B = 4;
	<write barrier>
	P = &B
			Q = P;
			D = *Q;

There's a clear data dependency here, and it would seem that by the end of the
sequence, Q must be either &A or &B, and that:

	(Q == &A) implies (D == 1)
	(Q == &B) implies (D == 4)

But!  CPU 2's perception of P may be updated _before_ its perception of B, thus
leading to the following situation:

	(Q == &B) and (D == 2) ????

Whilst this may seem like a failure of coherency or causality maintenance, it
isn't, and this behaviour can be observed on certain real CPUs (such as the DEC
Alpha).

To deal with this, a data dependency barrier or better must be inserted
between the address load and the data load:

	CPU 1		CPU 2
	===============	===============
	{ A == 1, B == 2, C = 3, P == &A, Q == &C }
	B = 4;
	<write barrier>
	P = &B
			Q = P;
			<data dependency barrier>
			D = *Q;

This enforces the occurrence of one of the two implications, and prevents the
third possibility from arising.

[!] Note that this extremely counterintuitive situation arises most easily on
machines with split caches, so that, for example, one cache bank processes
even-numbered cache lines and the other bank processes odd-numbered cache
lines.  The pointer P might be stored in an odd-numbered cache line, and the
variable B might be stored in an even-numbered cache line.  Then, if the
even-numbered bank of the reading CPU's cache is extremely busy while the
odd-numbered bank is idle, one can see the new value of the pointer P (&B),
but the old value of the variable B (2).


Another example of where data dependency barriers might by required is where a
number is read from memory and then used to calculate the index for an array
access:

	CPU 1		CPU 2
	===============	===============
	{ M[0] == 1, M[1] == 2, M[3] = 3, P == 0, Q == 3 }
	M[1] = 4;
	<write barrier>
	P = 1
			Q = P;
			<data dependency barrier>
			D = M[Q];


The data dependency barrier is very important to the RCU system, for example.
See rcu_dereference() in include/linux/rcupdate.h.  This permits the current
target of an RCU'd pointer to be replaced with a new modified target, without
the replacement target appearing to be incompletely initialised.

See also the subsection on "Cache Coherency" for a more thorough example.


CONTROL DEPENDENCIES
--------------------

A control dependency requires a full read memory barrier, not simply a data
dependency barrier to make it work correctly.  Consider the following bit of
code:

	q = &a;
	if (p)
		q = &b;
	<data dependency barrier>
	x = *q;

This will not have the desired effect because there is no actual data
dependency, but rather a control dependency that the CPU may short-circuit by
attempting to predict the outcome in advance.  In such a case what's actually
required is:

	q = &a;
	if (p)
		q = &b;
	<read barrier>
	x = *q;


SMP BARRIER PAIRING
-------------------

When dealing with CPU-CPU interactions, certain types of memory barrier should
always be paired.  A lack of appropriate pairing is almost certainly an error.

A write barrier should always be paired with a data dependency barrier or read
barrier, though a general barrier would also be viable.  Similarly a read
barrier or a data dependency barrier should always be paired with at least an
write barrier, though, again, a general barrier is viable:

	CPU 1		CPU 2
	===============	===============
	a = 1;
	<write barrier>
	b = 2;		x = b;
			<read barrier>
			y = a;

Or:

	CPU 1		CPU 2
	===============	===============================
	a = 1;
	<write barrier>
	b = &a;		x = b;
			<data dependency barrier>
			y = *x;

Basically, the read barrier always has to be there, even though it can be of
the "weaker" type.

[!] Note that the stores before the write barrier would normally be expected to
match the loads after the read barrier or the data dependency barrier, and vice
versa:

	CPU 1                           CPU 2
	===============                 ===============
	a = 1;           }----   --->{  v = c
	b = 2;           }    \ /    {  w = d
	<write barrier>        \        <read barrier>
	c = 3;           }    / \    {  x = a;
	d = 4;           }----   --->{  y = b;


EXAMPLES OF MEMORY BARRIER SEQUENCES
------------------------------------

Firstly, write barriers act as partial orderings on store operations.
Consider the following sequence of events:

	CPU 1
	=======================
	STORE A = 1
	STORE B = 2
	STORE C = 3
	<write barrier>
	STORE D = 4
	STORE E = 5

This sequence of events is committed to the memory coherence system in an order
that the rest of the system might perceive as the unordered set of { STORE A,
STORE B, STORE C } all occurring before the unordered set of { STORE D, STORE E
}:

	+-------+       :      :
	|       |       +------+
	|       |------>| C=3  |     }     /\
	|       |  :    +------+     }-----  \  -----> Events perceptible to
	|       |  :    | A=1  |     }        \/       the rest of the system
	|       |  :    +------+     }
	| CPU 1 |  :    | B=2  |     }
	|       |       +------+     }
	|       |   wwwwwwwwwwwwwwww }   <--- At this point the write barrier
	|       |       +------+     }        requires all stores prior to the
	|       |  :    | E=5  |     }        barrier to be committed before
	|       |  :    +------+     }        further stores may take place
	|       |------>| D=4  |     }
	|       |       +------+
	+-------+       :      :
	                   |
	                   | Sequence in which stores are committed to the
	                   | memory system by CPU 1
	                   V


Secondly, data dependency barriers act as partial orderings on data-dependent
loads.  Consider the following sequence of events:

	CPU 1			CPU 2
	=======================	=======================
		{ B = 7; X = 9; Y = 8; C = &Y }
	STORE A = 1
	STORE B = 2
	<write barrier>
	STORE C = &B		LOAD X
	STORE D = 4		LOAD C (gets &B)
				LOAD *C (reads B)

Without intervention, CPU 2 may perceive the events on CPU 1 in some
effectively random order, despite the write barrier issued by CPU 1:

	+-------+       :      :                :       :
	|       |       +------+                +-------+  | Sequence of update
	|       |------>| B=2  |-----       --->| Y->8  |  | of perception on
	|       |  :    +------+     \          +-------+  | CPU 2
	| CPU 1 |  :    | A=1  |      \     --->| C->&Y |  V
	|       |       +------+       |        +-------+
	|       |   wwwwwwwwwwwwwwww   |        :       :
	|       |       +------+       |        :       :
	|       |  :    | C=&B |---    |        :       :       +-------+
	|       |  :    +------+   \   |        +-------+       |       |
	|       |------>| D=4  |    ----------->| C->&B |------>|       |
	|       |       +------+       |        +-------+       |       |
	+-------+       :      :       |        :       :       |       |
	                               |        :       :       |       |
	                               |        :       :       | CPU 2 |
	                               |        +-------+       |       |
	    Apparently incorrect --->  |        | B->7  |------>|       |
	    perception of B (!)        |        +-------+       |       |
	                               |        :       :       |       |
	                               |        +-------+       |       |
	    The load of X holds --->    \       | X->9  |------>|       |
	    up the maintenance           \      +-------+       |       |
	    of coherence of B             ----->| B->2  |       +-------+
	                                        +-------+
	                                        :       :


In the above example, CPU 2 perceives that B is 7, despite the load of *C
(which would be B) coming after the LOAD of C.

If, however, a data dependency barrier were to be placed between the load of C
and the load of *C (ie: B) on CPU 2:

	CPU 1			CPU 2
	=======================	=======================
		{ B = 7; X = 9; Y = 8; C = &Y }
	STORE A = 1
	STORE B = 2
	<write barrier>
	STORE C = &B		LOAD X
	STORE D = 4		LOAD C (gets &B)
				<data dependency barrier>
				LOAD *C (reads B)

then the following will occur:

	+-------+       :      :                :       :
	|       |       +------+                +-------+
	|       |------>| B=2  |-----       --->| Y->8  |
	|       |  :    +------+     \          +-------+
	| CPU 1 |  :    | A=1  |      \     --->| C->&Y |
	|       |       +------+       |        +-------+
	|       |   wwwwwwwwwwwwwwww   |        :       :
	|       |       +------+       |        :       :
	|       |  :    | C=&B |---    |        :       :       +-------+
	|       |  :    +------+   \   |        +-------+       |       |
	|       |------>| D=4  |    ----------->| C->&B |------>|       |
	|       |       +------+       |        +-------+       |       |
	+-------+       :      :       |        :       :       |       |
	                               |        :       :       |       |
	                               |        :       :       | CPU 2 |
	                               |        +-------+       |       |
	                               |        | X->9  |------>|       |
	                               |        +-------+       |       |
	  Makes sure all effects --->   \   ddddddddddddddddd   |       |
	  prior to the store of C        \      +-------+       |       |
	  are perceptible to              ----->| B->2  |------>|       |
	  subsequent loads                      +-------+       |       |
	                                        :       :       +-------+


And thirdly, a read barrier acts as a partial order on loads.  Consider the
following sequence of events:

	CPU 1			CPU 2
	=======================	=======================
		{ A = 0, B = 9 }
	STORE A=1
	<write barrier>
	STORE B=2
				LOAD B
				LOAD A

Without intervention, CPU 2 may then choose to perceive the events on CPU 1 in
some effectively random order, despite the write barrier issued by CPU 1:

	+-------+       :      :                :       :
	|       |       +------+                +-------+
	|       |------>| A=1  |------      --->| A->0  |
	|       |       +------+      \         +-------+
	| CPU 1 |   wwwwwwwwwwwwwwww   \    --->| B->9  |
	|       |       +------+        |       +-------+
	|       |------>| B=2  |---     |       :       :
	|       |       +------+   \    |       :       :       +-------+
	+-------+       :      :    \   |       +-------+       |       |
	                             ---------->| B->2  |------>|       |
	                                |       +-------+       | CPU 2 |
	                                |       | A->0  |------>|       |
	                                |       +-------+       |       |
	                                |       :       :       +-------+
	                                 \      :       :
	                                  \     +-------+
	                                   ---->| A->1  |
	                                        +-------+
	                                        :       :


If, however, a read barrier were to be placed between the load of B and the
load of A on CPU 2:

	CPU 1			CPU 2
	=======================	=======================
		{ A = 0, B = 9 }
	STORE A=1
	<write barrier>
	STORE B=2
				LOAD B
				<read barrier>
				LOAD A

then the partial ordering imposed by CPU 1 will be perceived correctly by CPU
2:

	+-------+       :      :                :       :
	|       |       +------+                +-------+
	|       |------>| A=1  |------      --->| A->0  |
	|       |       +------+      \         +-------+
	| CPU 1 |   wwwwwwwwwwwwwwww   \    --->| B->9  |
	|       |       +------+        |       +-------+
	|       |------>| B=2  |---     |       :       :
	|       |       +------+   \    |       :       :       +-------+
	+-------+       :      :    \   |       +-------+       |       |
	                             ---------->| B->2  |------>|       |
	                                |       +-------+       | CPU 2 |
	                                |       :       :       |       |
	                                |       :       :       |       |
	  At this point the read ---->   \  rrrrrrrrrrrrrrrrr   |       |
	  barrier causes all effects      \     +-------+       |       |
	  prior to the storage of B        ---->| A->1  |------>|       |
	  to be perceptible to CPU 2            +-------+       |       |
	                                        :       :       +-------+


To illustrate this more completely, consider what could happen if the code
contained a load of A either side of the read barrier:

	CPU 1			CPU 2
	=======================	=======================
		{ A = 0, B = 9 }
	STORE A=1
	<write barrier>
	STORE B=2
				LOAD B
				LOAD A [first load of A]
				<read barrier>
				LOAD A [second load of A]

Even though the two loads of A both occur after the load of B, they may both
come up with different values:

	+-------+       :      :                :       :
	|       |       +------+                +-------+
	|       |------>| A=1  |------      --->| A->0  |
	|       |       +------+      \         +-------+
	| CPU 1 |   wwwwwwwwwwwwwwww   \    --->| B->9  |
	|       |       +------+        |       +-------+
	|       |------>| B=2  |---     |       :       :
	|       |       +------+   \    |       :       :       +-------+
	+-------+       :      :    \   |       +-------+       |       |
	                             ---------->| B->2  |------>|       |
	                                |       +-------+       | CPU 2 |
	                                |       :       :       |       |
	                                |       :       :       |       |
	                                |       +-------+       |       |
	                                |       | A->0  |------>| 1st   |
	                                |       +-------+       |       |
	  At this point the read ---->   \  rrrrrrrrrrrrrrrrr   |       |
	  barrier causes all effects      \     +-------+       |       |
	  prior to the storage of B        ---->| A->1  |------>| 2nd   |
	  to be perceptible to CPU 2            +-------+       |       |
	                                        :       :       +-------+


But it may be that the update to A from CPU 1 becomes perceptible to CPU 2
before the read barrier completes anyway:

	+-------+       :      :                :       :
	|       |       +------+                +-------+
	|       |------>| A=1  |------      --->| A->0  |
	|       |       +------+      \         +-------+
	| CPU 1 |   wwwwwwwwwwwwwwww   \    --->| B->9  |
	|       |       +------+        |       +-------+
	|       |------>| B=2  |---     |       :       :
	|       |       +------+   \    |       :       :       +-------+
	+-------+       :      :    \   |       +-------+       |       |
	                             ---------->| B->2  |------>|       |
	                                |       +-------+       | CPU 2 |
	                                |       :       :       |       |
	                                 \      :       :       |       |
	                                  \     +-------+       |       |
	                                   ---->| A->1  |------>| 1st   |
	                                        +-------+       |       |
	                                    rrrrrrrrrrrrrrrrr   |       |
	                                        +-------+       |       |
	                                        | A->1  |------>| 2nd   |
	                                        +-------+       |       |
	                                        :       :       +-------+


The guarantee is that the second load will always come up with A == 1 if the
load of B came up with B == 2.  No such guarantee exists for the first load of
A; that may come up with either A == 0 or A == 1.


READ MEMORY BARRIERS VS LOAD SPECULATION
----------------------------------------

Many CPUs speculate with loads: that is they see that they will need to load an
item from memory, and they find a time where they're not using the bus for any
other loads, and so do the load in advance - even though they haven't actually
got to that point in the instruction execution flow yet.  This permits the
actual load instruction to potentially complete immediately because the CPU
already has the value to hand.

It may turn out that the CPU didn't actually need the value - perhaps because a
branch circumvented the load - in which case it can discard the value or just
cache it for later use.

Consider:

	CPU 1	   		CPU 2
	=======================	=======================
	 	   		LOAD B
	 	   		DIVIDE		} Divide instructions generally
	 	   		DIVIDE		} take a long time to perform
	 	   		LOAD A

Which might appear as this:

	                                        :       :       +-------+
	                                        +-------+       |       |
	                                    --->| B->2  |------>|       |
	                                        +-------+       | CPU 2 |
	                                        :       :DIVIDE |       |
	                                        +-------+       |       |
	The CPU being busy doing a --->     --->| A->0  |~~~~   |       |
	division speculates on the              +-------+   ~   |       |
	LOAD of A                               :       :   ~   |       |
	                                        :       :DIVIDE |       |
	                                        :       :   ~   |       |
	Once the divisions are complete -->     :       :   ~-->|       |
	the CPU can then perform the            :       :       |       |
	LOAD with immediate effect              :       :       +-------+


Placing a read barrier or a data dependency barrier just before the second
load:

	CPU 1	   		CPU 2
	=======================	=======================
	 	   		LOAD B
	 	   		DIVIDE
	 	   		DIVIDE
				<read barrier>
	 	   		LOAD A

will force any value speculatively obtained to be reconsidered to an extent
dependent on the type of barrier used.  If there was no change made to the
speculated memory location, then the speculated value will just be used:

	                                        :       :       +-------+
	                                        +-------+       |       |
	                                    --->| B->2  |------>|       |
	                                        +-------+       | CPU 2 |
	                                        :       :DIVIDE |       |
	                                        +-------+       |       |
	The CPU being busy doing a --->     --->| A->0  |~~~~   |       |
	division speculates on the              +-------+   ~   |       |
	LOAD of A                               :       :   ~   |       |
	                                        :       :DIVIDE |       |
	                                        :       :   ~   |       |
	                                        :       :   ~   |       |
	                                    rrrrrrrrrrrrrrrr~   |       |
	                                        :       :   ~   |       |
	                                        :       :   ~-->|       |
	                                        :       :       |       |
	                                        :       :       +-------+


but if there was an update or an invalidation from another CPU pending, then
the speculation will be cancelled and the value reloaded:

	                                        :       :       +-------+
	                                        +-------+       |       |
	                                    --->| B->2  |------>|       |
	                                        +-------+       | CPU 2 |
	                                        :       :DIVIDE |       |
	                                        +-------+       |       |
	The CPU being busy doing a --->     --->| A->0  |~~~~   |       |
	division speculates on the              +-------+   ~   |       |
	LOAD of A                               :       :   ~   |       |
	                                        :       :DIVIDE |       |
	                                        :       :   ~   |       |
	                                        :       :   ~   |       |
	                                    rrrrrrrrrrrrrrrrr   |       |
	                                        +-------+       |       |
	The speculation is discarded --->   --->| A->1  |------>|       |
	and an updated value is                 +-------+       |       |
	retrieved                               :       :       +-------+


TRANSITIVITY
------------

Transitivity is a deeply intuitive notion about ordering that is not
always provided by real computer systems.  The following example
demonstrates transitivity (also called "cumulativity"):

	CPU 1			CPU 2			CPU 3
	=======================	=======================	=======================
		{ X = 0, Y = 0 }
	STORE X=1		LOAD X			STORE Y=1
				<general barrier>	<general barrier>
				LOAD Y			LOAD X

Suppose that CPU 2's load from X returns 1 and its load from Y returns 0.
This indicates that CPU 2's load from X in some sense follows CPU 1's
store to X and that CPU 2's load from Y in some sense preceded CPU 3's
store to Y.  The question is then "Can CPU 3's load from X return 0?"

Because CPU 2's load from X in some sense came after CPU 1's store, it
is natural to expect that CPU 3's load from X must therefore return 1.
This expectation is an example of transitivity: if a load executing on
CPU A follows a load from the same variable executing on CPU B, then
CPU A's load must either return the same value that CPU B's load did,
or must return some later value.

In the Linux kernel, use of general memory barriers guarantees
transitivity.  Therefore, in the above example, if CPU 2's load from X
returns 1 and its load from Y returns 0, then CPU 3's load from X must
also return 1.

However, transitivity is -not- guaranteed for read or write barriers.
For example, suppose that CPU 2's general barrier in the above example
is changed to a read barrier as shown below:

	CPU 1			CPU 2			CPU 3
	=======================	=======================	=======================
		{ X = 0, Y = 0 }
	STORE X=1		LOAD X			STORE Y=1
				<read barrier>		<general barrier>
				LOAD Y			LOAD X

This substitution destroys transitivity: in this example, it is perfectly
legal for CPU 2's load from X to return 1, its load from Y to return 0,
and CPU 3's load from X to return 0.

The key point is that although CPU 2's read barrier orders its pair
of loads, it does not guarantee to order CPU 1's store.  Therefore, if
this example runs on a system where CPUs 1 and 2 share a store buffer
or a level of cache, CPU 2 might have early access to CPU 1's writes.
General barriers are therefore required to ensure that all CPUs agree
on the combined order of CPU 1's and CPU 2's accesses.

To reiterate, if your code requires transitivity, use general barriers
throughout.


========================
EXPLICIT KERNEL BARRIERS
========================

The Linux kernel has a variety of different barriers that act at different
levels:

  (*) Compiler barrier.

  (*) CPU memory barriers.

  (*) MMIO write barrier.


COMPILER BARRIER
----------------

The Linux kernel has an explicit compiler barrier function that prevents the
compiler from moving the memory accesses either side of it to the other side:

	barrier();

This is a general barrier - lesser varieties of compiler barrier do not exist.

The compiler barrier has no direct effect on the CPU, which may then reorder
things however it wishes.


CPU MEMORY BARRIERS
-------------------

The Linux kernel has eight basic CPU memory barriers:

	TYPE		MANDATORY		SMP CONDITIONAL
	===============	=======================	===========================
	GENERAL		mb()			smp_mb()
	WRITE		wmb()			smp_wmb()
	READ		rmb()			smp_rmb()
	DATA DEPENDENCY	read_barrier_depends()	smp_read_barrier_depends()


All memory barriers except the data dependency barriers imply a compiler
barrier. Data dependencies do not impose any additional compiler ordering.

Aside: In the case of data dependencies, the compiler would be expected to
issue the loads in the correct order (eg. `a[b]` would have to load the value
of b before loading a[b]), however there is no guarantee in the C specification
that the compiler may not speculate the value of b (eg. is equal to 1) and load
a before b (eg. tmp = a[1]; if (b != 1) tmp = a[b]; ). There is also the
problem of a compiler reloading b after having loaded a[b], thus having a newer
copy of b than a[b]. A consensus has not yet been reached about these problems,
however the ACCESS_ONCE macro is a good place to start looking.

SMP memory barriers are reduced to compiler barriers on uniprocessor compiled
systems because it is assumed that a CPU will appear to be self-consistent,
and will order overlapping accesses correctly with respect to itself.

[!] Note that SMP memory barriers _must_ be used to control the ordering of
references to shared memory on SMP systems, though the use of locking instead
is sufficient.

Mandatory barriers should not be used to control SMP effects, since mandatory
barriers unnecessarily impose overhead on UP systems. They may, however, be
used to control MMIO effects on accesses through relaxed memory I/O windows.
These are required even on non-SMP systems as they affect the order in which
memory operations appear to a device by prohibiting both the compiler and the
CPU from reordering them.


There are some more advanced barrier functions:

 (*) set_mb(var, value)

     This assigns the value to the variable and then inserts a full memory
     barrier after it, depending on the function.  It isn't guaranteed to
     insert anything more than a compiler barrier in a UP compilation.


 (*) smp_mb__before_atomic_dec();
 (*) smp_mb__after_atomic_dec();
 (*) smp_mb__before_atomic_inc();
 (*) smp_mb__after_atomic_inc();

     These are for use with atomic add, subtract, increment and decrement
     functions that don't return a value, especially when used for reference
     counting.  These functions do not imply memory barriers.

     As an example, consider a piece of code that marks an object as being dead
     and then decrements the object's reference count:

	obj->dead = 1;
	smp_mb__before_atomic_dec();
	atomic_dec(&obj->ref_count);

     This makes sure that the death mark on the object is perceived to be set
     *before* the reference counter is decremented.

     See Documentation/atomic_ops.txt for more information.  See the "Atomic
     operations" subsection for information on where to use these.


 (*) smp_mb__before_clear_bit(void);
 (*) smp_mb__after_clear_bit(void);

     These are for use similar to the atomic inc/dec barriers.  These are
     typically used for bitwise unlocking operations, so care must be taken as
     there are no implicit memory barriers here either.

     Consider implementing an unlock operation of some nature by clearing a
     locking bit.  The clear_bit() would then need to be barriered like this:

	smp_mb__before_clear_bit();
	clear_bit( ... );

     This prevents memory operations before the clear leaking to after it.  See
     the subsection on "Locking Functions" with reference to UNLOCK operation
     implications.

     See Documentation/atomic_ops.txt for more information.  See the "Atomic
     operations" subsection for information on where to use these.


MMIO WRITE BARRIER
------------------

The Linux kernel also has a special barrier for use with memory-mapped I/O
writes:

	mmiowb();

This is a variation on the mandatory write barrier that causes writes to weakly
ordered I/O regions to be partially ordered.  Its effects may go beyond the
CPU->Hardware interface and actually affect the hardware at some level.

See the subsection "Locks vs I/O accesses" for more information.


===============================
IMPLICIT KERNEL MEMORY BARRIERS
===============================

Some of the other functions in the linux kernel imply memory barriers, amongst
which are locking and scheduling functions.

This specification is a _minimum_ guarantee; any particular architecture may
provide more substantial guarantees, but these may not be relied upon outside
of arch specific code.


LOCKING FUNCTIONS
-----------------

The Linux kernel has a number of locking constructs:

 (*) spin locks
 (*) R/W spin locks
 (*) mutexes
 (*) semaphores
 (*) R/W semaphores
 (*) RCU

In all cases there are variants on "LOCK" operations and "UNLOCK" operations
for each construct.  These operations all imply certain barriers:

 (1) LOCK operation implication:

     Memory operations issued after the LOCK will be completed after the LOCK
     operation has completed.

     Memory operations issued before the LOCK may be completed after the LOCK
     operation has completed.

 (2) UNLOCK operation implication:

     Memory operations issued before the UNLOCK will be completed before the
     UNLOCK operation has completed.

     Memory operations issued after the UNLOCK may be completed before the
     UNLOCK operation has completed.

 (3) LOCK vs LOCK implication:

     All LOCK operations issued before another LOCK operation will be completed
     before that LOCK operation.

 (4) LOCK vs UNLOCK implication:

     All LOCK operations issued before an UNLOCK operation will be completed
     before the UNLOCK operation.

     All UNLOCK operations issued before a LOCK operation will be completed
     before the LOCK operation.

 (5) Failed conditional LOCK implication:

     Certain variants of the LOCK operation may fail, either due to being
     unable to get the lock immediately, or due to receiving an unblocked
     signal whilst asleep waiting for the lock to become available.  Failed
     locks do not imply any sort of barrier.

Therefore, from (1), (2) and (4) an UNLOCK followed by an unconditional LOCK is
equivalent to a full barrier, but a LOCK followed by an UNLOCK is not.

[!] Note: one of the consequences of LOCKs and UNLOCKs being only one-way
    barriers is that the effects of instructions outside of a critical section
    may seep into the inside of the critical section.

A LOCK followed by an UNLOCK may not be assumed to be full memory barrier
because it is possible for an access preceding the LOCK to happen after the
LOCK, and an access following the UNLOCK to happen before the UNLOCK, and the
two accesses can themselves then cross:

	*A = a;
	LOCK
	UNLOCK
	*B = b;

may occur as:

	LOCK, STORE *B, STORE *A, UNLOCK

Locks and semaphores may not provide any guarantee of ordering on UP compiled
systems, and so cannot be counted on in such a situation to actually achieve
anything at all - especially with respect to I/O accesses - unless combined
with interrupt disabling operations.

See also the section on "Inter-CPU locking barrier effects".


As an example, consider the following:

	*A = a;
	*B = b;
	LOCK
	*C = c;
	*D = d;
	UNLOCK
	*E = e;
	*F = f;

The following sequence of events is acceptable:

	LOCK, {*F,*A}, *E, {*C,*D}, *B, UNLOCK

	[+] Note that {*F,*A} indicates a combined access.

But none of the following are:

	{*F,*A}, *B,	LOCK, *C, *D,	UNLOCK, *E
	*A, *B, *C,	LOCK, *D,	UNLOCK, *E, *F
	*A, *B,		LOCK, *C,	UNLOCK, *D, *E, *F
	*B,		LOCK, *C, *D,	UNLOCK, {*F,*A}, *E



INTERRUPT DISABLING FUNCTIONS
-----------------------------

Functions that disable interrupts (LOCK equivalent) and enable interrupts
(UNLOCK equivalent) will act as compiler barriers only.  So if memory or I/O
barriers are required in such a situation, they must be provided from some
other means.


SLEEP AND WAKE-UP FUNCTIONS
---------------------------

Sleeping and waking on an event flagged in global data can be viewed as an
interaction between two pieces of data: the task state of the task waiting for
the event and the global data used to indicate the event.  To make sure that
these appear to happen in the right order, the primitives to begin the process
of going to sleep, and the primitives to initiate a wake up imply certain
barriers.

Firstly, the sleeper normally follows something like this sequence of events:

	for (;;) {
		set_current_state(TASK_UNINTERRUPTIBLE);
		if (event_indicated)
			break;
		schedule();
	}

A general memory barrier is interpolated automatically by set_current_state()
after it has altered the task state:

	CPU 1
	===============================
	set_current_state();
	  set_mb();
	    STORE current->state
	    <general barrier>
	LOAD event_indicated

set_current_state() may be wrapped by:

	prepare_to_wait();
	prepare_to_wait_exclusive();

which therefore also imply a general memory barrier after setting the state.
The whole sequence above is available in various canned forms, all of which
interpolate the memory barrier in the right place:

	wait_event();
	wait_event_interruptible();
	wait_event_interruptible_exclusive();
	wait_event_interruptible_timeout();
	wait_event_killable();
	wait_event_timeout();
	wait_on_bit();
	wait_on_bit_lock();


Secondly, code that performs a wake up normally follows something like this:

	event_indicated = 1;
	wake_up(&event_wait_queue);

or:

	event_indicated = 1;
	wake_up_process(event_daemon);

A write memory barrier is implied by wake_up() and co. if and only if they wake
something up.  The barrier occurs before the task state is cleared, and so sits
between the STORE to indicate the event and the STORE to set TASK_RUNNING:

	CPU 1				CPU 2
	===============================	===============================
	set_current_state();		STORE event_indicated
	  set_mb();			wake_up();
	    STORE current->state	  <write barrier>
	    <general barrier>		  STORE current->state
	LOAD event_indicated

The available waker functions include:

	complete();
	wake_up();
	wake_up_all();
	wake_up_bit();
	wake_up_interruptible();
	wake_up_interruptible_all();
	wake_up_interruptible_nr();
	wake_up_interruptible_poll();
	wake_up_interruptible_sync();
	wake_up_interruptible_sync_poll();
	wake_up_locked();
	wake_up_locked_poll();
	wake_up_nr();
	wake_up_poll();
	wake_up_process();


[!] Note that the memory barriers implied by the sleeper and the waker do _not_
order multiple stores before the wake-up with respect to loads of those stored
values after the sleeper has called set_current_state().  For instance, if the
sleeper does:

	set_current_state(TASK_INTERRUPTIBLE);
	if (event_indicated)
		break;
	__set_current_state(TASK_RUNNING);
	do_something(my_data);

and the waker does:

	my_data = value;
	event_indicated = 1;
	wake_up(&event_wait_queue);

there's no guarantee that the change to event_indicated will be perceived by
the sleeper as coming after the change to my_data.  In such a circumstance, the
code on both sides must interpolate its own memory barriers between the
separate data accesses.  Thus the above sleeper ought to do:

	set_current_state(TASK_INTERRUPTIBLE);
	if (event_indicated) {
		smp_rmb();
		do_something(my_data);
	}

and the waker should do:

	my_data = value;
	smp_wmb();
	event_indicated = 1;
	wake_up(&event_wait_queue);


MISCELLANEOUS FUNCTIONS
-----------------------

Other functions that imply barriers:

 (*) schedule() and similar imply full memory barriers.


=================================
INTER-CPU LOCKING BARRIER EFFECTS
=================================

On SMP systems locking primitives give a more substantial form of barrier: one
that does affect memory access ordering on other CPUs, within the context of
conflict on any particular lock.


LOCKS VS MEMORY ACCESSES
------------------------

Consider the following: the system has a pair of spinlocks (M) and (Q), and
three CPUs; then should the following sequence of events occur:

	CPU 1				CPU 2
	===============================	===============================
	*A = a;				*E = e;
	LOCK M				LOCK Q
	*B = b;				*F = f;
	*C = c;				*G = g;
	UNLOCK M			UNLOCK Q
	*D = d;				*H = h;

Then there is no guarantee as to what order CPU 3 will see the accesses to *A
through *H occur in, other than the constraints imposed by the separate locks
on the separate CPUs. It might, for example, see:

	*E, LOCK M, LOCK Q, *G, *C, *F, *A, *B, UNLOCK Q, *D, *H, UNLOCK M

But it won't see any of:

	*B, *C or *D preceding LOCK M
	*A, *B or *C following UNLOCK M
	*F, *G or *H preceding LOCK Q
	*E, *F or *G following UNLOCK Q


However, if the following occurs:

	CPU 1				CPU 2
	===============================	===============================
	*A = a;
	LOCK M		[1]
	*B = b;
	*C = c;
	UNLOCK M	[1]
	*D = d;				*E = e;
					LOCK M		[2]
					*F = f;
					*G = g;
					UNLOCK M	[2]
					*H = h;

CPU 3 might see:

	*E, LOCK M [1], *C, *B, *A, UNLOCK M [1],
		LOCK M [2], *H, *F, *G, UNLOCK M [2], *D

But assuming CPU 1 gets the lock first, CPU 3 won't see any of:

	*B, *C, *D, *F, *G or *H preceding LOCK M [1]
	*A, *B or *C following UNLOCK M [1]
	*F, *G or *H preceding LOCK M [2]
	*A, *B, *C, *E, *F or *G following UNLOCK M [2]


LOCKS VS I/O ACCESSES
---------------------

Under certain circumstances (especially involving NUMA), I/O accesses within
two spinlocked sections on two different CPUs may be seen as interleaved by the
PCI bridge, because the PCI bridge does not necessarily participate in the
cache-coherence protocol, and is therefore incapable of issuing the required
read memory barriers.

For example:

	CPU 1				CPU 2
	===============================	===============================
	spin_lock(Q)
	writel(0, ADDR)
	writel(1, DATA);
	spin_unlock(Q);
					spin_lock(Q);
					writel(4, ADDR);
					writel(5, DATA);
					spin_unlock(Q);

may be seen by the PCI bridge as follows:

	STORE *ADDR = 0, STORE *ADDR = 4, STORE *DATA = 1, STORE *DATA = 5

which would probably cause the hardware to malfunction.


What is necessary here is to intervene with an mmiowb() before dropping the
spinlock, for example:

	CPU 1				CPU 2
	===============================	===============================
	spin_lock(Q)
	writel(0, ADDR)
	writel(1, DATA);
	mmiowb();
	spin_unlock(Q);
					spin_lock(Q);
					writel(4, ADDR);
					writel(5, DATA);
					mmiowb();
					spin_unlock(Q);

this will ensure that the two stores issued on CPU 1 appear at the PCI bridge
before either of the stores issued on CPU 2.


Furthermore, following a store by a load from the same device obviates the need
for the mmiowb(), because the load forces the store to complete before the load
is performed:

	CPU 1				CPU 2
	===============================	===============================
	spin_lock(Q)
	writel(0, ADDR)
	a = readl(DATA);
	spin_unlock(Q);
					spin_lock(Q);
					writel(4, ADDR);
					b = readl(DATA);
					spin_unlock(Q);


See Documentation/DocBook/deviceiobook.tmpl for more information.


=================================
WHERE ARE MEMORY BARRIERS NEEDED?
=================================

Under normal operation, memory operation reordering is generally not going to
be a problem as a single-threaded linear piece of code will still appear to
work correctly, even if it's in an SMP kernel.  There are, however, four
circumstances in which reordering definitely _could_ be a problem:

 (*) Interprocessor interaction.

 (*) Atomic operations.

 (*) Accessing devices.

 (*) Interrupts.


INTERPROCESSOR INTERACTION
--------------------------

When there's a system with more than one processor, more than one CPU in the
system may be working on the same data set at the same time.  This can cause
synchronisation problems, and the usual way of dealing with them is to use
locks.  Locks, however, are quite expensive, and so it may be preferable to
operate without the use of a lock if at all possible.  In such a case
operations that affect both CPUs may have to be carefully ordered to prevent
a malfunction.

Consider, for example, the R/W semaphore slow path.  Here a waiting process is
queued on the semaphore, by virtue of it having a piece of its stack linked to
the semaphore's list of waiting processes:

	struct rw_semaphore {
		...
		spinlock_t lock;
		struct list_head waiters;
	};

	struct rwsem_waiter {
		struct list_head list;
		struct task_struct *task;
	};

To wake up a particular waiter, the up_read() or up_write() functions have to:

 (1) read the next pointer from this waiter's record to know as to where the
     next waiter record is;

 (2) read the pointer to the waiter's task structure;

 (3) clear the task pointer to tell the waiter it has been given the semaphore;

 (4) call wake_up_process() on the task; and

 (5) release the reference held on the waiter's task struct.

In other words, it has to perform this sequence of events:

	LOAD waiter->list.next;
	LOAD waiter->task;
	STORE waiter->task;
	CALL wakeup
	RELEASE task

and if any of these steps occur out of order, then the whole thing may
malfunction.

Once it has queued itself and dropped the semaphore lock, the waiter does not
get the lock again; it instead just waits for its task pointer to be cleared
before proceeding.  Since the record is on the waiter's stack, this means that
if the task pointer is cleared _before_ the next pointer in the list is read,
another CPU might start processing the waiter and might clobber the waiter's
stack before the up*() function has a chance to read the next pointer.

Consider then what might happen to the above sequence of events:

	CPU 1				CPU 2
	===============================	===============================
					down_xxx()
					Queue waiter
					Sleep
	up_yyy()
	LOAD waiter->task;
	STORE waiter->task;
					Woken up by other event
	<preempt>
					Resume processing
					down_xxx() returns
					call foo()
					foo() clobbers *waiter
	</preempt>
	LOAD waiter->list.next;
	--- OOPS ---

This could be dealt with using the semaphore lock, but then the down_xxx()
function has to needlessly get the spinlock again after being woken up.

The way to deal with this is to insert a general SMP memory barrier:

	LOAD waiter->list.next;
	LOAD waiter->task;
	smp_mb();
	STORE waiter->task;
	CALL wakeup
	RELEASE task

In this case, the barrier makes a guarantee that all memory accesses before the
barrier will appear to happen before all the memory accesses after the barrier
with respect to the other CPUs on the system.  It does _not_ guarantee that all
the memory accesses before the barrier will be complete by the time the barrier
instruction itself is complete.

On a UP system - where this wouldn't be a problem - the smp_mb() is just a
compiler barrier, thus making sure the compiler emits the instructions in the
right order without actually intervening in the CPU.  Since there's only one
CPU, that CPU's dependency ordering logic will take care of everything else.


ATOMIC OPERATIONS
-----------------

Whilst they are technically interprocessor interaction considerations, atomic
operations are noted specially as some of them imply full memory barriers and
some don't, but they're very heavily relied on as a group throughout the
kernel.

Any atomic operation that modifies some state in memory and returns information
about the state (old or new) implies an SMP-conditional general memory barrier
(smp_mb()) on each side of the actual operation (with the exception of
explicit lock operations, described later).  These include:

	xchg();
	cmpxchg();
	atomic_cmpxchg();
	atomic_inc_return();
	atomic_dec_return();
	atomic_add_return();
	atomic_sub_return();
	atomic_inc_and_test();
	atomic_dec_and_test();
	atomic_sub_and_test();
	atomic_add_negative();
	atomic_add_unless();	/* when succeeds (returns 1) */
	test_and_set_bit();
	test_and_clear_bit();
	test_and_change_bit();

These are used for such things as implementing LOCK-class and UNLOCK-class
operations and adjusting reference counters towards object destruction, and as
such the implicit memory barrier effects are necessary.


The following operations are potential problems as they do _not_ imply memory
barriers, but might be used for implementing such things as UNLOCK-class
operations:

	atomic_set();
	set_bit();
	clear_bit();
	change_bit();

With these the appropriate explicit memory barrier should be used if necessary
(smp_mb__before_clear_bit() for instance).


The following also do _not_ imply memory barriers, and so may require explicit
memory barriers under some circumstances (smp_mb__before_atomic_dec() for
instance):

	atomic_add();
	atomic_sub();
	atomic_inc();
	atomic_dec();

If they're used for statistics generation, then they probably don't need memory
barriers, unless there's a coupling between statistical data.

If they're used for reference counting on an object to control its lifetime,
they probably don't need memory barriers because either the reference count
will be adjusted inside a locked section, or the caller will already hold
sufficient references to make the lock, and thus a memory barrier unnecessary.

If they're used for constructing a lock of some description, then they probably
do need memory barriers as a lock primitive generally has to do things in a
specific order.

Basically, each usage case has to be carefully considered as to whether memory
barriers are needed or not.

The following operations are special locking primitives:

	test_and_set_bit_lock();
	clear_bit_unlock();
	__clear_bit_unlock();

These implement LOCK-class and UNLOCK-class operations. These should be used in
preference to other operations when implementing locking primitives, because
their implementations can be optimised on many architectures.

[!] Note that special memory barrier primitives are available for these
situations because on some CPUs the atomic instructions used imply full memory
barriers, and so barrier instructions are superfluous in conjunction with them,
and in such cases the special barrier primitives will be no-ops.

See Documentation/atomic_ops.txt for more information.


ACCESSING DEVICES
-----------------

Many devices can be memory mapped, and so appear to the CPU as if they're just
a set of memory locations.  To control such a device, the driver usually has to
make the right memory accesses in exactly the right order.

However, having a clever CPU or a clever compiler creates a potential problem
in that the carefully sequenced accesses in the driver code won't reach the
device in the requisite order if the CPU or the compiler thinks it is more
efficient to reorder, combine or merge accesses - something that would cause
the device to malfunction.

Inside of the Linux kernel, I/O should be done through the appropriate accessor
routines - such as inb() or writel() - which know how to make such accesses
appropriately sequential.  Whilst this, for the most part, renders the explicit
use of memory barriers unnecessary, there are a couple of situations where they
might be needed:

 (1) On some systems, I/O stores are not strongly ordered across all CPUs, and
     so for _all_ general drivers locks should be used and mmiowb() must be
     issued prior to unlocking the critical section.

 (2) If the accessor functions are used to refer to an I/O memory window with
     relaxed memory access properties, then _mandatory_ memory barriers are
     required to enforce ordering.

See Documentation/DocBook/deviceiobook.tmpl for more information.


INTERRUPTS
----------

A driver may be interrupted by its own interrupt service routine, and thus the
two parts of the driver may interfere with each other's attempts to control or
access the device.

This may be alleviated - at least in part - by disabling local interrupts (a
form of locking), such that the critical operations are all contained within
the interrupt-disabled section in the driver.  Whilst the driver's interrupt
routine is executing, the driver's core may not run on the same CPU, and its
interrupt is not permitted to happen again until the current interrupt has been
handled, thus the interrupt handler does not need to lock against that.

However, consider a driver that was talking to an ethernet card that sports an
address register and a data register.  If that driver's core talks to the card
under interrupt-disablement and then the driver's interrupt handler is invoked:

	LOCAL IRQ DISABLE
	writew(ADDR, 3);
	writew(DATA, y);
	LOCAL IRQ ENABLE
	<interrupt>
	writew(ADDR, 4);
	q = readw(DATA);
	</interrupt>

The store to the data register might happen after the second store to the
address register if ordering rules are sufficiently relaxed:

	STORE *ADDR = 3, STORE *ADDR = 4, STORE *DATA = y, q = LOAD *DATA


If ordering rules are relaxed, it must be assumed that accesses done inside an
interrupt disabled section may leak outside of it and may interleave with
accesses performed in an interrupt - and vice versa - unless implicit or
explicit barriers are used.

Normally this won't be a problem because the I/O accesses done inside such
sections will include synchronous load operations on strictly ordered I/O
registers that form implicit I/O barriers. If this isn't sufficient then an
mmiowb() may need to be used explicitly.


A similar situation may occur between an interrupt routine and two routines
running on separate CPUs that communicate with each other. If such a case is
likely, then interrupt-disabling locks should be used to guarantee ordering.


==========================
KERNEL I/O BARRIER EFFECTS
==========================

When accessing I/O memory, drivers should use the appropriate accessor
functions:

 (*) inX(), outX():

     These are intended to talk to I/O space rather than memory space, but
     that's primarily a CPU-specific concept. The i386 and x86_64 processors do
     indeed have special I/O space access cycles and instructions, but many
     CPUs don't have such a concept.

     The PCI bus, amongst others, defines an I/O space concept which - on such
     CPUs as i386 and x86_64 - readily maps to the CPU's concept of I/O
     space.  However, it may also be mapped as a virtual I/O space in the CPU's
     memory map, particularly on those CPUs that don't support alternate I/O
     spaces.

     Accesses to this space may be fully synchronous (as on i386), but
     intermediary bridges (such as the PCI host bridge) may not fully honour
     that.

     They are guaranteed to be fully ordered with respect to each other.

     They are not guaranteed to be fully ordered with respect to other types of
     memory and I/O operation.

 (*) readX(), writeX():

     Whether these are guaranteed to be fully ordered and uncombined with
     respect to each other on the issuing CPU depends on the characteristics
     defined for the memory window through which they're accessing. On later
     i386 architecture machines, for example, this is controlled by way of the
     MTRR registers.

     Ordinarily, these will be guaranteed to be fully ordered and uncombined,
     provided they're not accessing a prefetchable device.

     However, intermediary hardware (such as a PCI bridge) may indulge in
     deferral if it so wishes; to flush a store, a load from the same location
     is preferred[*], but a load from the same device or from configuration
     space should suffice for PCI.

     [*] NOTE! attempting to load from the same location as was written to may
     	 cause a malfunction - consider the 16550 Rx/Tx serial registers for
     	 example.

     Used with prefetchable I/O memory, an mmiowb() barrier may be required to
     force stores to be ordered.

     Please refer to the PCI specification for more information on interactions
     between PCI transactions.

 (*) readX_relaxed()

     These are similar to readX(), but are not guaranteed to be ordered in any
     way. Be aware that there is no I/O read barrier available.

 (*) ioreadX(), iowriteX()

     These will perform appropriately for the type of access they're actually
     doing, be it inX()/outX() or readX()/writeX().


========================================
ASSUMED MINIMUM EXECUTION ORDERING MODEL
========================================

It has to be assumed that the conceptual CPU is weakly-ordered but that it will
maintain the appearance of program causality with respect to itself.  Some CPUs
(such as i386 or x86_64) are more constrained than others (such as powerpc or
frv), and so the most relaxed case (namely DEC Alpha) must be assumed outside
of arch-specific code.

This means that it must be considered that the CPU will execute its instruction
stream in any order it feels like - or even in parallel - provided that if an
instruction in the stream depends on an earlier instruction, then that
earlier instruction must be sufficiently complete[*] before the later
instruction may proceed; in other words: provided that the appearance of
causality is maintained.

 [*] Some instructions have more than one effect - such as changing the
     condition codes, changing registers or changing memory - and different
     instructions may depend on different effects.

A CPU may also discard any instruction sequence that winds up having no
ultimate effect.  For example, if two adjacent instructions both load an
immediate value into the same register, the first may be discarded.


Similarly, it has to be assumed that compiler might reorder the instruction
stream in any way it sees fit, again provided the appearance of causality is
maintained.


============================
THE EFFECTS OF THE CPU CACHE
============================

The way cached memory operations are perceived across the system is affected to
a certain extent by the caches that lie between CPUs and memory, and by the
memory coherence system that maintains the consistency of state in the system.

As far as the way a CPU interacts with another part of the system through the
caches goes, the memory system has to include the CPU's caches, and memory
barriers for the most part act at the interface between the CPU and its cache
(memory barriers logically act on the dotted line in the following diagram):

	    <--- CPU --->         :       <----------- Memory ----------->
	                          :
	+--------+    +--------+  :   +--------+    +-----------+
	|        |    |        |  :   |        |    |           |    +--------+
	|  CPU   |    | Memory |  :   | CPU    |    |           |    |	      |
	|  Core  |--->| Access |----->| Cache  |<-->|           |    |	      |
	|        |    | Queue  |  :   |        |    |           |--->| Memory |
	|        |    |        |  :   |        |    |           |    |	      |
	+--------+    +--------+  :   +--------+    |           |    | 	      |
	                          :                 | Cache     |    +--------+
	                          :                 | Coherency |
	                          :                 | Mechanism |    +--------+
	+--------+    +--------+  :   +--------+    |           |    |	      |
	|        |    |        |  :   |        |    |           |    |        |
	|  CPU   |    | Memory |  :   | CPU    |    |           |--->| Device |
	|  Core  |--->| Access |----->| Cache  |<-->|           |    | 	      |
	|        |    | Queue  |  :   |        |    |           |    | 	      |
	|        |    |        |  :   |        |    |           |    +--------+
	+--------+    +--------+  :   +--------+    +-----------+
	                          :
	                          :

Although any particular load or store may not actually appear outside of the
CPU that issued it since it may have been satisfied within the CPU's own cache,
it will still appear as if the full memory access had taken place as far as the
other CPUs are concerned since the cache coherency mechanisms will migrate the
cacheline over to the accessing CPU and propagate the effects upon conflict.

The CPU core may execute instructions in any order it deems fit, provided the
expected program causality appears to be maintained.  Some of the instructions
generate load and store operations which then go into the queue of memory
accesses to be performed.  The core may place these in the queue in any order
it wishes, and continue execution until it is forced to wait for an instruction
to complete.

What memory barriers are concerned with is controlling the order in which
accesses cross from the CPU side of things to the memory side of things, and
the order in which the effects are perceived to happen by the other observers
in the system.

[!] Memory barriers are _not_ needed within a given CPU, as CPUs always see
their own loads and stores as if they had happened in program order.

[!] MMIO or other device accesses may bypass the cache system.  This depends on
the properties of the memory window through which devices are accessed and/or
the use of any special device communication instructions the CPU may have.


CACHE COHERENCY
---------------

Life isn't quite as simple as it may appear above, however: for while the
caches are expected to be coherent, there's no guarantee that that coherency
will be ordered.  This means that whilst changes made on one CPU will
eventually become visible on all CPUs, there's no guarantee that they will
become apparent in the same order on those other CPUs.


Consider dealing with a system that has a pair of CPUs (1 & 2), each of which
has a pair of parallel data caches (CPU 1 has A/B, and CPU 2 has C/D):

	            :
	            :                          +--------+
	            :      +---------+         |        |
	+--------+  : +--->| Cache A |<------->|        |
	|        |  : |    +---------+         |        |
	|  CPU 1 |<---+                        |        |
	|        |  : |    +---------+         |        |
	+--------+  : +--->| Cache B |<------->|        |
	            :      +---------+         |        |
	            :                          | Memory |
	            :      +---------+         | System |
	+--------+  : +--->| Cache C |<------->|        |
	|        |  : |    +---------+         |        |
	|  CPU 2 |<---+                        |        |
	|        |  : |    +---------+         |        |
	+--------+  : +--->| Cache D |<------->|        |
	            :      +---------+         |        |
	            :                          +--------+
	            :

Imagine the system has the following properties:

 (*) an odd-numbered cache line may be in cache A, cache C or it may still be
     resident in memory;

 (*) an even-numbered cache line may be in cache B, cache D or it may still be
     resident in memory;

 (*) whilst the CPU core is interrogating one cache, the other cache may be
     making use of the bus to access the rest of the system - perhaps to
     displace a dirty cacheline or to do a speculative load;

 (*) each cache has a queue of operations that need to be applied to that cache
     to maintain coherency with the rest of the system;

 (*) the coherency queue is not flushed by normal loads to lines already
     present in the cache, even though the contents of the queue may
     potentially affect those loads.

Imagine, then, that two writes are made on the first CPU, with a write barrier
between them to guarantee that they will appear to reach that CPU's caches in
the requisite order:

	CPU 1		CPU 2		COMMENT
	===============	===============	=======================================
					u == 0, v == 1 and p == &u, q == &u
	v = 2;
	smp_wmb();			Make sure change to v is visible before
					 change to p
	<A:modify v=2>			v is now in cache A exclusively
	p = &v;
	<B:modify p=&v>			p is now in cache B exclusively

The write memory barrier forces the other CPUs in the system to perceive that
the local CPU's caches have apparently been updated in the correct order.  But
now imagine that the second CPU wants to read those values:

	CPU 1		CPU 2		COMMENT
	===============	===============	=======================================
	...
			q = p;
			x = *q;

The above pair of reads may then fail to happen in the expected order, as the
cacheline holding p may get updated in one of the second CPU's caches whilst
the update to the cacheline holding v is delayed in the other of the second
CPU's caches by some other cache event:

	CPU 1		CPU 2		COMMENT
	===============	===============	=======================================
					u == 0, v == 1 and p == &u, q == &u
	v = 2;
	smp_wmb();
	<A:modify v=2>	<C:busy>
			<C:queue v=2>
	p = &v;		q = p;
			<D:request p>
	<B:modify p=&v>	<D:commit p=&v>
		  	<D:read p>
			x = *q;
			<C:read *q>	Reads from v before v updated in cache
			<C:unbusy>
			<C:commit v=2>

Basically, whilst both cachelines will be updated on CPU 2 eventually, there's
no guarantee that, without intervention, the order of update will be the same
as that committed on CPU 1.


To intervene, we need to interpolate a data dependency barrier or a read
barrier between the loads.  This will force the cache to commit its coherency
queue before processing any further requests:

	CPU 1		CPU 2		COMMENT
	===============	===============	=======================================
					u == 0, v == 1 and p == &u, q == &u
	v = 2;
	smp_wmb();
	<A:modify v=2>	<C:busy>
			<C:queue v=2>
	p = &v;		q = p;
			<D:request p>
	<B:modify p=&v>	<D:commit p=&v>
		  	<D:read p>
			smp_read_barrier_depends()
			<C:unbusy>
			<C:commit v=2>
			x = *q;
			<C:read *q>	Reads from v after v updated in cache


This sort of problem can be encountered on DEC Alpha processors as they have a
split cache that improves performance by making better use of the data bus.
Whilst most CPUs do imply a data dependency barrier on the read when a memory
access depends on a read, not all do, so it may not be relied on.

Other CPUs may also have split caches, but must coordinate between the various
cachelets for normal memory accesses.  The semantics of the Alpha removes the
need for coordination in the absence of memory barriers.


CACHE COHERENCY VS DMA
----------------------

Not all systems maintain cache coherency with respect to devices doing DMA.  In
such cases, a device attempting DMA may obtain stale data from RAM because
dirty cache lines may be resident in the caches of various CPUs, and may not
have been written back to RAM yet.  To deal with this, the appropriate part of
the kernel must flush the overlapping bits of cache on each CPU (and maybe
invalidate them as well).

In addition, the data DMA'd to RAM by a device may be overwritten by dirty
cache lines being written back to RAM from a CPU's cache after the device has
installed its own data, or cache lines present in the CPU's cache may simply
obscure the fact that RAM has been updated, until at such time as the cacheline
is discarded from the CPU's cache and reloaded.  To deal with this, the
appropriate part of the kernel must invalidate the overlapping bits of the
cache on each CPU.

See Documentation/cachetlb.txt for more information on cache management.


CACHE COHERENCY VS MMIO
-----------------------

Memory mapped I/O usually takes place through memory locations that are part of
a window in the CPU's memory space that has different properties assigned than
the usual RAM directed window.

Amongst these properties is usually the fact that such accesses bypass the
caching entirely and go directly to the device buses.  This means MMIO accesses
may, in effect, overtake accesses to cached memory that were emitted earlier.
A memory barrier isn't sufficient in such a case, but rather the cache must be
flushed between the cached memory write and the MMIO access if the two are in
any way dependent.


=========================
THE THINGS CPUS GET UP TO
=========================

A programmer might take it for granted that the CPU will perform memory
operations in exactly the order specified, so that if the CPU is, for example,
given the following piece of code to execute:

	a = *A;
	*B = b;
	c = *C;
	d = *D;
	*E = e;

they would then expect that the CPU will complete the memory operation for each
instruction before moving on to the next one, leading to a definite sequence of
operations as seen by external observers in the system:

	LOAD *A, STORE *B, LOAD *C, LOAD *D, STORE *E.


Reality is, of course, much messier.  With many CPUs and compilers, the above
assumption doesn't hold because:

 (*) loads are more likely to need to be completed immediately to permit
     execution progress, whereas stores can often be deferred without a
     problem;

 (*) loads may be done speculatively, and the result discarded should it prove
     to have been unnecessary;

 (*) loads may be done speculatively, leading to the result having been fetched
     at the wrong time in the expected sequence of events;

 (*) the order of the memory accesses may be rearranged to promote better use
     of the CPU buses and caches;

 (*) loads and stores may be combined to improve performance when talking to
     memory or I/O hardware that can do batched accesses of adjacent locations,
     thus cutting down on transaction setup costs (memory and PCI devices may
     both be able to do this); and

 (*) the CPU's data cache may affect the ordering, and whilst cache-coherency
     mechanisms may alleviate this - once the store has actually hit the cache
     - there's no guarantee that the coherency management will be propagated in
     order to other CPUs.

So what another CPU, say, might actually observe from the above piece of code
is:

	LOAD *A, ..., LOAD {*C,*D}, STORE *E, STORE *B

	(Where "LOAD {*C,*D}" is a combined load)


However, it is guaranteed that a CPU will be self-consistent: it will see its
_own_ accesses appear to be correctly ordered, without the need for a memory
barrier.  For instance with the following code:

	U = *A;
	*A = V;
	*A = W;
	X = *A;
	*A = Y;
	Z = *A;

and assuming no intervention by an external influence, it can be assumed that
the final result will appear to be:

	U == the original value of *A
	X == W
	Z == Y
	*A == Y

The code above may cause the CPU to generate the full sequence of memory
accesses:

	U=LOAD *A, STORE *A=V, STORE *A=W, X=LOAD *A, STORE *A=Y, Z=LOAD *A

in that order, but, without intervention, the sequence may have almost any
combination of elements combined or discarded, provided the program's view of
the world remains consistent.

The compiler may also combine, discard or defer elements of the sequence before
the CPU even sees them.

For instance:

	*A = V;
	*A = W;

may be reduced to:

	*A = W;

since, without a write barrier, it can be assumed that the effect of the
storage of V to *A is lost.  Similarly:

	*A = Y;
	Z = *A;

may, without a memory barrier, be reduced to:

	*A = Y;
	Z = Y;

and the LOAD operation never appear outside of the CPU.


AND THEN THERE'S THE ALPHA
--------------------------

The DEC Alpha CPU is one of the most relaxed CPUs there is.  Not only that,
some versions of the Alpha CPU have a split data cache, permitting them to have
two semantically-related cache lines updated at separate times.  This is where
the data dependency barrier really becomes necessary as this synchronises both
caches with the memory coherence system, thus making it seem like pointer
changes vs new data occur in the right order.

The Alpha defines the Linux kernel's memory barrier model.

See the subsection on "Cache Coherency" above.


============
EXAMPLE USES
============

CIRCULAR BUFFERS
----------------

Memory barriers can be used to implement circular buffering without the need
of a lock to serialise the producer with the consumer.  See:

	Documentation/circular-buffers.txt

for details.


==========
REFERENCES
==========

Alpha AXP Architecture Reference Manual, Second Edition (Sites & Witek,
Digital Press)
	Chapter 5.2: Physical Address Space Characteristics
	Chapter 5.4: Caches and Write Buffers
	Chapter 5.5: Data Sharing
	Chapter 5.6: Read/Write Ordering

AMD64 Architecture Programmer's Manual Volume 2: System Programming
	Chapter 7.1: Memory-Access Ordering
	Chapter 7.4: Buffering and Combining Memory Writes

IA-32 Intel Architecture Software Developer's Manual, Volume 3:
System Programming Guide
	Chapter 7.1: Locked Atomic Operations
	Chapter 7.2: Memory Ordering
	Chapter 7.4: Serializing Instructions

The SPARC Architecture Manual, Version 9
	Chapter 8: Memory Models
	Appendix D: Formal Specification of the Memory Models
	Appendix J: Programming with the Memory Models

UltraSPARC Programmer Reference Manual
	Chapter 5: Memory Accesses and Cacheability
	Chapter 15: Sparc-V9 Memory Models

UltraSPARC III Cu User's Manual
	Chapter 9: Memory Models

UltraSPARC IIIi Processor User's Manual
	Chapter 8: Memory Models

UltraSPARC Architecture 2005
	Chapter 9: Memory
	Appendix D: Formal Specifications of the Memory Models

UltraSPARC T1 Supplement to the UltraSPARC Architecture 2005
	Chapter 8: Memory Models
	Appendix F: Caches and Cache Coherency

Solaris Internals, Core Kernel Architecture, p63-68:
	Chapter 3.3: Hardware Considerations for Locks and
			Synchronization

Unix Systems for Modern Architectures, Symmetric Multiprocessing and Caching
for Kernel Programmers:
	Chapter 13: Other Memory Models

Intel Itanium Architecture Software Developer's Manual: Volume 1:
	Section 2.6: Speculation
	Section 4.4: Memory Access
==============
Memory Hotplug
==============

Created:					Jul 28 2007
Add description of notifier of memory hotplug	Oct 11 2007

This document is about memory hotplug including how-to-use and current status.
Because Memory Hotplug is still under development, contents of this text will
be changed often.

1. Introduction
  1.1 purpose of memory hotplug
  1.2. Phases of memory hotplug
  1.3. Unit of Memory online/offline operation
2. Kernel Configuration
3. sysfs files for memory hotplug
4. Physical memory hot-add phase
  4.1 Hardware(Firmware) Support
  4.2 Notify memory hot-add event by hand
5. Logical Memory hot-add phase
  5.1. State of memory
  5.2. How to online memory
6. Logical memory remove
  6.1 Memory offline and ZONE_MOVABLE
  6.2. How to offline memory
7. Physical memory remove
8. Memory hotplug event notifier
9. Future Work List

Note(1): x86_64's has special implementation for memory hotplug.
         This text does not describe it.
Note(2): This text assumes that sysfs is mounted at /sys.


---------------
1. Introduction
---------------

1.1 purpose of memory hotplug
------------
Memory Hotplug allows users to increase/decrease the amount of memory.
Generally, there are two purposes.

(A) For changing the amount of memory.
    This is to allow a feature like capacity on demand.
(B) For installing/removing DIMMs or NUMA-nodes physically.
    This is to exchange DIMMs/NUMA-nodes, reduce power consumption, etc.

(A) is required by highly virtualized environments and (B) is required by
hardware which supports memory power management.

Linux memory hotplug is designed for both purpose.


1.2. Phases of memory hotplug
---------------
There are 2 phases in Memory Hotplug.
  1) Physical Memory Hotplug phase
  2) Logical Memory Hotplug phase.

The First phase is to communicate hardware/firmware and make/erase
environment for hotplugged memory. Basically, this phase is necessary
for the purpose (B), but this is good phase for communication between
highly virtualized environments too.

When memory is hotplugged, the kernel recognizes new memory, makes new memory
management tables, and makes sysfs files for new memory's operation.

If firmware supports notification of connection of new memory to OS,
this phase is triggered automatically. ACPI can notify this event. If not,
"probe" operation by system administration is used instead.
(see Section 4.).

Logical Memory Hotplug phase is to change memory state into
available/unavailable for users. Amount of memory from user's view is
changed by this phase. The kernel makes all memory in it as free pages
when a memory range is available.

In this document, this phase is described as online/offline.

Logical Memory Hotplug phase is triggered by write of sysfs file by system
administrator. For the hot-add case, it must be executed after Physical Hotplug
phase by hand.
(However, if you writes udev's hotplug scripts for memory hotplug, these
 phases can be execute in seamless way.)


1.3. Unit of Memory online/offline operation
------------
Memory hotplug uses SPARSEMEM memory model. SPARSEMEM divides the whole memory
into chunks of the same size. The chunk is called a "section". The size of
a section is architecture dependent. For example, power uses 16MiB, ia64 uses
1GiB. The unit of online/offline operation is "one section". (see Section 3.)

To determine the size of sections, please read this file:

/sys/devices/system/memory/block_size_bytes

This file shows the size of sections in byte.

-----------------------
2. Kernel Configuration
-----------------------
To use memory hotplug feature, kernel must be compiled with following
config options.

- For all memory hotplug
    Memory model -> Sparse Memory  (CONFIG_SPARSEMEM)
    Allow for memory hot-add       (CONFIG_MEMORY_HOTPLUG)

- To enable memory removal, the followings are also necessary
    Allow for memory hot remove    (CONFIG_MEMORY_HOTREMOVE)
    Page Migration                 (CONFIG_MIGRATION)

- For ACPI memory hotplug, the followings are also necessary
    Memory hotplug (under ACPI Support menu) (CONFIG_ACPI_HOTPLUG_MEMORY)
    This option can be kernel module.

- As a related configuration, if your box has a feature of NUMA-node hotplug
  via ACPI, then this option is necessary too.
    ACPI0004,PNP0A05 and PNP0A06 Container Driver (under ACPI Support menu)
    (CONFIG_ACPI_CONTAINER).
    This option can be kernel module too.

--------------------------------
4 sysfs files for memory hotplug
--------------------------------
All sections have their device information in sysfs.  Each section is part of
a memory block under /sys/devices/system/memory as

/sys/devices/system/memory/memoryXXX
(XXX is the section id.)

Now, XXX is defined as (start_address_of_section / section_size) of the first
section contained in the memory block.  The files 'phys_index' and
'end_phys_index' under each directory report the beginning and end section id's
for the memory block covered by the sysfs directory.  It is expected that all
memory sections in this range are present and no memory holes exist in the
range. Currently there is no way to determine if there is a memory hole, but
the existence of one should not affect the hotplug capabilities of the memory
block.

For example, assume 1GiB section size. A device for a memory starting at
0x100000000 is /sys/device/system/memory/memory4
(0x100000000 / 1Gib = 4)
This device covers address range [0x100000000 ... 0x140000000)

Under each section, you can see 4 or 5 files, the end_phys_index file being
a recent addition and not present on older kernels.

/sys/devices/system/memory/memoryXXX/start_phys_index
/sys/devices/system/memory/memoryXXX/end_phys_index
/sys/devices/system/memory/memoryXXX/phys_device
/sys/devices/system/memory/memoryXXX/state
/sys/devices/system/memory/memoryXXX/removable

'phys_index'      : read-only and contains section id of the first section
		    in the memory block, same as XXX.
'end_phys_index'  : read-only and contains section id of the last section
		    in the memory block.
'state'           : read-write
                    at read:  contains online/offline state of memory.
                    at write: user can specify "online", "offline" command
                    which will be performed on al sections in the block.
'phys_device'     : read-only: designed to show the name of physical memory
                    device.  This is not well implemented now.
'removable'       : read-only: contains an integer value indicating
                    whether the memory block is removable or not
                    removable.  A value of 1 indicates that the memory
                    block is removable and a value of 0 indicates that
                    it is not removable. A memory block is removable only if
                    every section in the block is removable.

NOTE:
  These directories/files appear after physical memory hotplug phase.

If CONFIG_NUMA is enabled the memoryXXX/ directories can also be accessed
via symbolic links located in the /sys/devices/system/node/node* directories.

For example:
/sys/devices/system/node/node0/memory9 -> ../../memory/memory9

A backlink will also be created:
/sys/devices/system/memory/memory9/node0 -> ../../node/node0

--------------------------------
4. Physical memory hot-add phase
--------------------------------

4.1 Hardware(Firmware) Support
------------
On x86_64/ia64 platform, memory hotplug by ACPI is supported.

In general, the firmware (ACPI) which supports memory hotplug defines
memory class object of _HID "PNP0C80". When a notify is asserted to PNP0C80,
Linux's ACPI handler does hot-add memory to the system and calls a hotplug udev
script. This will be done automatically.

But scripts for memory hotplug are not contained in generic udev package(now).
You may have to write it by yourself or online/offline memory by hand.
Please see "How to online memory", "How to offline memory" in this text.

If firmware supports NUMA-node hotplug, and defines an object _HID "ACPI0004",
"PNP0A05", or "PNP0A06", notification is asserted to it, and ACPI handler
calls hotplug code for all of objects which are defined in it.
If memory device is found, memory hotplug code will be called.


4.2 Notify memory hot-add event by hand
------------
In some environments, especially virtualized environment, firmware will not
notify memory hotplug event to the kernel. For such environment, "probe"
interface is supported. This interface depends on CONFIG_ARCH_MEMORY_PROBE.

Now, CONFIG_ARCH_MEMORY_PROBE is supported only by powerpc but it does not
contain highly architecture codes. Please add config if you need "probe"
interface.

Probe interface is located at
/sys/devices/system/memory/probe

You can tell the physical address of new memory to the kernel by

% echo start_address_of_new_memory > /sys/devices/system/memory/probe

Then, [start_address_of_new_memory, start_address_of_new_memory + section_size)
memory range is hot-added. In this case, hotplug script is not called (in
current implementation). You'll have to online memory by yourself.
Please see "How to online memory" in this text.



------------------------------
5. Logical Memory hot-add phase
------------------------------

5.1. State of memory
------------
To see (online/offline) state of memory section, read 'state' file.

% cat /sys/device/system/memory/memoryXXX/state


If the memory section is online, you'll read "online".
If the memory section is offline, you'll read "offline".


5.2. How to online memory
------------
Even if the memory is hot-added, it is not at ready-to-use state.
For using newly added memory, you have to "online" the memory section.

For onlining, you have to write "online" to the section's state file as:

% echo online > /sys/devices/system/memory/memoryXXX/state

After this, section memoryXXX's state will be 'online' and the amount of
available memory will be increased.

Currently, newly added memory is added as ZONE_NORMAL (for powerpc, ZONE_DMA).
This may be changed in future.



------------------------
6. Logical memory remove
------------------------

6.1 Memory offline and ZONE_MOVABLE
------------
Memory offlining is more complicated than memory online. Because memory offline
has to make the whole memory section be unused, memory offline can fail if
the section includes memory which cannot be freed.

In general, memory offline can use 2 techniques.

(1) reclaim and free all memory in the section.
(2) migrate all pages in the section.

In the current implementation, Linux's memory offline uses method (2), freeing
all  pages in the section by page migration. But not all pages are
migratable. Under current Linux, migratable pages are anonymous pages and
page caches. For offlining a section by migration, the kernel has to guarantee
that the section contains only migratable pages.

Now, a boot option for making a section which consists of migratable pages is
supported. By specifying "kernelcore=" or "movablecore=" boot option, you can
create ZONE_MOVABLE...a zone which is just used for movable pages.
(See also Documentation/kernel-parameters.txt)

Assume the system has "TOTAL" amount of memory at boot time, this boot option
creates ZONE_MOVABLE as following.

1) When kernelcore=YYYY boot option is used,
  Size of memory not for movable pages (not for offline) is YYYY.
  Size of memory for movable pages (for offline) is TOTAL-YYYY.

2) When movablecore=ZZZZ boot option is used,
  Size of memory not for movable pages (not for offline) is TOTAL - ZZZZ.
  Size of memory for movable pages (for offline) is ZZZZ.


Note) Unfortunately, there is no information to show which section belongs
to ZONE_MOVABLE. This is TBD.


6.2. How to offline memory
------------
You can offline a section by using the same sysfs interface that was used in
memory onlining.

% echo offline > /sys/devices/system/memory/memoryXXX/state

If offline succeeds, the state of the memory section is changed to be "offline".
If it fails, some error core (like -EBUSY) will be returned by the kernel.
Even if a section does not belong to ZONE_MOVABLE, you can try to offline it.
If it doesn't contain 'unmovable' memory, you'll get success.

A section under ZONE_MOVABLE is considered to be able to be offlined easily.
But under some busy state, it may return -EBUSY. Even if a memory section
cannot be offlined due to -EBUSY, you can retry offlining it and may be able to
offline it (or not).
(For example, a page is referred to by some kernel internal call and released
 soon.)

Consideration:
Memory hotplug's design direction is to make the possibility of memory offlining
higher and to guarantee unplugging memory under any situation. But it needs
more work. Returning -EBUSY under some situation may be good because the user
can decide to retry more or not by himself. Currently, memory offlining code
does some amount of retry with 120 seconds timeout.

-------------------------
7. Physical memory remove
-------------------------
Need more implementation yet....
 - Notification completion of remove works by OS to firmware.
 - Guard from remove if not yet.

--------------------------------
8. Memory hotplug event notifier
--------------------------------
Memory hotplug has event notifer. There are 6 types of notification.

MEMORY_GOING_ONLINE
  Generated before new memory becomes available in order to be able to
  prepare subsystems to handle memory. The page allocator is still unable
  to allocate from the new memory.

MEMORY_CANCEL_ONLINE
  Generated if MEMORY_GOING_ONLINE fails.

MEMORY_ONLINE
  Generated when memory has successfully brought online. The callback may
  allocate pages from the new memory.

MEMORY_GOING_OFFLINE
  Generated to begin the process of offlining memory. Allocations are no
  longer possible from the memory but some of the memory to be offlined
  is still in use. The callback can be used to free memory known to a
  subsystem from the indicated memory section.

MEMORY_CANCEL_OFFLINE
  Generated if MEMORY_GOING_OFFLINE fails. Memory is available again from
  the section that we attempted to offline.

MEMORY_OFFLINE
  Generated after offlining memory is complete.

A callback routine can be registered by
  hotplug_memory_notifier(callback_func, priority)

The second argument of callback function (action) is event types of above.
The third argument is passed by pointer of struct memory_notify.

struct memory_notify {
       unsigned long start_pfn;
       unsigned long nr_pages;
       int status_change_nid;
}

start_pfn is start_pfn of online/offline memory.
nr_pages is # of pages of online/offline memory.
status_change_nid is set node id when N_HIGH_MEMORY of nodemask is (will be)
set/clear. It means a new(memoryless) node gets new memory by online and a
node loses all memory. If this is -1, then nodemask status is not changed.
If status_changed_nid >= 0, callback should create/discard structures for the
node if necessary.

--------------
9. Future Work
--------------
  - allowing memory hot-add to ZONE_MOVABLE. maybe we need some switch like
    sysctl or new control file.
  - showing memory section and physical device relationship.
  - showing memory section is under ZONE_MOVABLE or not
  - test and make it better memory offlining.
  - support HugeTLB page migration and offlining.
  - memmap removing at memory offline.
  - physical remove memory.

There are several classic problems related to memory on Linux
systems.

	1) There are some motherboards that will not cache above
	   a certain quantity of memory.  If you have one of these
	   motherboards, your system will be SLOWER, not faster
	   as you add more memory.  Consider exchanging your 
           motherboard.

All of these problems can be addressed with the "mem=XXXM" boot option
(where XXX is the size of RAM to use in megabytes).  
It can also tell Linux to use less memory than is actually installed.
If you use "mem=" on a machine with PCI, consider using "memmap=" to avoid
physical address space collisions.

See the documentation of your boot loader (LILO, grub, loadlin, etc.) about
how to pass options to the kernel.

There are other memory problems which Linux cannot deal with.  Random
corruption of memory is usually a sign of serious hardware trouble.
Try:

	* Reducing memory settings in the BIOS to the most conservative 
          timings.

	* Adding a cooling fan.

	* Not overclocking your CPU.

	* Having the memory tested in a memory tester or exchanged
	  with the vendor. Consider testing it with memtest86 yourself.
	
	* Exchanging your CPU, cache, or motherboard for one that works.
               Mono(tm) Binary Kernel Support for Linux
               -----------------------------------------

To configure Linux to automatically execute Mono-based .NET binaries
(in the form of .exe files) without the need to use the mono CLR
wrapper, you can use the BINFMT_MISC kernel support.

This will allow you to execute Mono-based .NET binaries just like any
other program after you have done the following:

1) You MUST FIRST install the Mono CLR support, either by downloading
   a binary package, a source tarball or by installing from CVS. Binary
   packages for several distributions can be found at:

	http://go-mono.com/download.html

   Instructions for compiling Mono can be found at:

	http://www.go-mono.com/compiling.html

   Once the Mono CLR support has been installed, just check that
   /usr/bin/mono (which could be located elsewhere, for example
   /usr/local/bin/mono) is working.

2) You have to compile BINFMT_MISC either as a module or into
   the kernel (CONFIG_BINFMT_MISC) and set it up properly.
   If you choose to compile it as a module, you will have
   to insert it manually with modprobe/insmod, as kmod
   cannot be easily supported with binfmt_misc. 
   Read the file 'binfmt_misc.txt' in this directory to know
   more about the configuration process.

3) Add the following entries to /etc/rc.local or similar script
   to be run at system startup:

# Insert BINFMT_MISC module into the kernel
if [ ! -e /proc/sys/fs/binfmt_misc/register ]; then
        /sbin/modprobe binfmt_misc
	# Some distributions, like Fedora Core, perform
	# the following command automatically when the
	# binfmt_misc module is loaded into the kernel.
	# Thus, it is possible that the following line
	# is not needed at all. Look at /etc/modprobe.conf
	# to check whether this is applicable or not.
        mount -t binfmt_misc none /proc/sys/fs/binfmt_misc
fi

# Register support for .NET CLR binaries
if [ -e /proc/sys/fs/binfmt_misc/register ]; then
	# Replace /usr/bin/mono with the correct pathname to
	# the Mono CLR runtime (usually /usr/local/bin/mono
	# when compiling from sources or CVS).
        echo ':CLR:M::MZ::/usr/bin/mono:' > /proc/sys/fs/binfmt_misc/register
else
        echo "No binfmt_misc support"
        exit 1
fi

4) Check that .exe binaries can be ran without the need of a
   wrapper script, simply by launching the .exe file directly
   from a command prompt, for example:

	/usr/bin/xsd.exe

   NOTE: If this fails with a permission denied error, check
         that the .exe file has execute permissions.
Generic Mutex Subsystem

started by Ingo Molnar <mingo@redhat.com>

  "Why on earth do we need a new mutex subsystem, and what's wrong
   with semaphores?"

firstly, there's nothing wrong with semaphores. But if the simpler
mutex semantics are sufficient for your code, then there are a couple
of advantages of mutexes:

 - 'struct mutex' is smaller on most architectures: E.g. on x86,
   'struct semaphore' is 20 bytes, 'struct mutex' is 16 bytes.
   A smaller structure size means less RAM footprint, and better
   CPU-cache utilization.

 - tighter code. On x86 i get the following .text sizes when
   switching all mutex-alike semaphores in the kernel to the mutex
   subsystem:

        text    data     bss     dec     hex filename
     3280380  868188  396860 4545428  455b94 vmlinux-semaphore
     3255329  865296  396732 4517357  44eded vmlinux-mutex

   that's 25051 bytes of code saved, or a 0.76% win - off the hottest
   codepaths of the kernel. (The .data savings are 2892 bytes, or 0.33%)
   Smaller code means better icache footprint, which is one of the
   major optimization goals in the Linux kernel currently.

 - the mutex subsystem is slightly faster and has better scalability for
   contended workloads. On an 8-way x86 system, running a mutex-based
   kernel and testing creat+unlink+close (of separate, per-task files)
   in /tmp with 16 parallel tasks, the average number of ops/sec is:

    Semaphores:                        Mutexes:

    $ ./test-mutex V 16 10             $ ./test-mutex V 16 10
    8 CPUs, running 16 tasks.          8 CPUs, running 16 tasks.
    checking VFS performance.          checking VFS performance.
    avg loops/sec:      34713          avg loops/sec:      84153
    CPU utilization:    63%            CPU utilization:    22%

   i.e. in this workload, the mutex based kernel was 2.4 times faster
   than the semaphore based kernel, _and_ it also had 2.8 times less CPU
   utilization. (In terms of 'ops per CPU cycle', the semaphore kernel
   performed 551 ops/sec per 1% of CPU time used, while the mutex kernel
   performed 3825 ops/sec per 1% of CPU time used - it was 6.9 times
   more efficient.)

   the scalability difference is visible even on a 2-way P4 HT box:

    Semaphores:                        Mutexes:

    $ ./test-mutex V 16 10             $ ./test-mutex V 16 10
    4 CPUs, running 16 tasks.          8 CPUs, running 16 tasks.
    checking VFS performance.          checking VFS performance.
    avg loops/sec:      127659         avg loops/sec:      181082
    CPU utilization:    100%           CPU utilization:    34%

   (the straight performance advantage of mutexes is 41%, the per-cycle
    efficiency of mutexes is 4.1 times better.)

 - there are no fastpath tradeoffs, the mutex fastpath is just as tight
   as the semaphore fastpath. On x86, the locking fastpath is 2
   instructions:

    c0377ccb <mutex_lock>:
    c0377ccb:       f0 ff 08                lock decl (%eax)
    c0377cce:       78 0e                   js     c0377cde <.text..lock.mutex>
    c0377cd0:       c3                      ret

   the unlocking fastpath is equally tight:

    c0377cd1 <mutex_unlock>:
    c0377cd1:       f0 ff 00                lock incl (%eax)
    c0377cd4:       7e 0f                   jle    c0377ce5 <.text..lock.mutex+0x7>
    c0377cd6:       c3                      ret

 - 'struct mutex' semantics are well-defined and are enforced if
   CONFIG_DEBUG_MUTEXES is turned on. Semaphores on the other hand have
   virtually no debugging code or instrumentation. The mutex subsystem
   checks and enforces the following rules:

   * - only one task can hold the mutex at a time
   * - only the owner can unlock the mutex
   * - multiple unlocks are not permitted
   * - recursive locking is not permitted
   * - a mutex object must be initialized via the API
   * - a mutex object must not be initialized via memset or copying
   * - task may not exit with mutex held
   * - memory areas where held locks reside must not be freed
   * - held mutexes must not be reinitialized
   * - mutexes may not be used in hardware or software interrupt
   *   contexts such as tasklets and timers

   furthermore, there are also convenience features in the debugging
   code:

   * - uses symbolic names of mutexes, whenever they are printed in debug output
   * - point-of-acquire tracking, symbolic lookup of function names
   * - list of all locks held in the system, printout of them
   * - owner tracking
   * - detects self-recursing locks and prints out all relevant info
   * - detects multi-task circular deadlocks and prints out all affected
   *   locks and tasks (and only those tasks)

Disadvantages
-------------

The stricter mutex API means you cannot use mutexes the same way you
can use semaphores: e.g. they cannot be used from an interrupt context,
nor can they be unlocked from a different context that which acquired
it. [ I'm not aware of any other (e.g. performance) disadvantages from
using mutexes at the moment, please let me know if you find any. ]

Implementation of mutexes
-------------------------

'struct mutex' is the new mutex type, defined in include/linux/mutex.h
and implemented in kernel/mutex.c. It is a counter-based mutex with a
spinlock and a wait-list. The counter has 3 states: 1 for "unlocked",
0 for "locked" and negative numbers (usually -1) for "locked, potential
waiters queued".

the APIs of 'struct mutex' have been streamlined:

 DEFINE_MUTEX(name);

 mutex_init(mutex);

 void mutex_lock(struct mutex *lock);
 int  mutex_lock_interruptible(struct mutex *lock);
 int  mutex_trylock(struct mutex *lock);
 void mutex_unlock(struct mutex *lock);
 int  mutex_is_locked(struct mutex *lock);
 void mutex_lock_nested(struct mutex *lock, unsigned int subclass);
 int  mutex_lock_interruptible_nested(struct mutex *lock,
                                      unsigned int subclass);
 int atomic_dec_and_mutex_lock(atomic_t *cnt, struct mutex *lock);

[NMI watchdog is available for x86 and x86-64 architectures]

Is your system locking up unpredictably? No keyboard activity, just
a frustrating complete hard lockup? Do you want to help us debugging
such lockups? If all yes then this document is definitely for you.

On many x86/x86-64 type hardware there is a feature that enables
us to generate 'watchdog NMI interrupts'.  (NMI: Non Maskable Interrupt
which get executed even if the system is otherwise locked up hard).
This can be used to debug hard kernel lockups.  By executing periodic
NMI interrupts, the kernel can monitor whether any CPU has locked up,
and print out debugging messages if so.

In order to use the NMI watchdog, you need to have APIC support in your
kernel. For SMP kernels, APIC support gets compiled in automatically. For
UP, enable either CONFIG_X86_UP_APIC (Processor type and features -> Local
APIC support on uniprocessors) or CONFIG_X86_UP_IOAPIC (Processor type and
features -> IO-APIC support on uniprocessors) in your kernel config.
CONFIG_X86_UP_APIC is for uniprocessor machines without an IO-APIC.
CONFIG_X86_UP_IOAPIC is for uniprocessor with an IO-APIC. [Note: certain
kernel debugging options, such as Kernel Stack Meter or Kernel Tracer,
may implicitly disable the NMI watchdog.]

For x86-64, the needed APIC is always compiled in.

Using local APIC (nmi_watchdog=2) needs the first performance register, so
you can't use it for other purposes (such as high precision performance
profiling.) However, at least oprofile and the perfctr driver disable the
local APIC NMI watchdog automatically.

To actually enable the NMI watchdog, use the 'nmi_watchdog=N' boot
parameter.  Eg. the relevant lilo.conf entry:

        append="nmi_watchdog=1"

For SMP machines and UP machines with an IO-APIC use nmi_watchdog=1.
For UP machines without an IO-APIC use nmi_watchdog=2, this only works
for some processor types.  If in doubt, boot with nmi_watchdog=1 and
check the NMI count in /proc/interrupts; if the count is zero then
reboot with nmi_watchdog=2 and check the NMI count.  If it is still
zero then log a problem, you probably have a processor that needs to be
added to the nmi code.

A 'lockup' is the following scenario: if any CPU in the system does not
execute the period local timer interrupt for more than 5 seconds, then
the NMI handler generates an oops and kills the process. This
'controlled crash' (and the resulting kernel messages) can be used to
debug the lockup. Thus whenever the lockup happens, wait 5 seconds and
the oops will show up automatically. If the kernel produces no messages
then the system has crashed so hard (eg. hardware-wise) that either it
cannot even accept NMI interrupts, or the crash has made the kernel
unable to print messages.

Be aware that when using local APIC, the frequency of NMI interrupts
it generates, depends on the system load. The local APIC NMI watchdog,
lacking a better source, uses the "cycles unhalted" event. As you may
guess it doesn't tick when the CPU is in the halted state (which happens
when the system is idle), but if your system locks up on anything but the
"hlt" processor instruction, the watchdog will trigger very soon as the
"cycles unhalted" event will happen every clock tick. If it locks up on
"hlt", then you are out of luck -- the event will not happen at all and the
watchdog won't trigger. This is a shortcoming of the local APIC watchdog
-- unfortunately there is no "clock ticks" event that would work all the
time. The I/O APIC watchdog is driven externally and has no such shortcoming.
But its NMI frequency is much higher, resulting in a more significant hit
to the overall system performance.

On x86 nmi_watchdog is disabled by default so you have to enable it with
a boot time parameter.

It's possible to disable the NMI watchdog in run-time by writing "0" to
/proc/sys/kernel/nmi_watchdog. Writing "1" to the same file will re-enable
the NMI watchdog. Notice that you still need to use "nmi_watchdog=" parameter
at boot time.

NOTE: In kernels prior to 2.4.2-ac18 the NMI-oopser is enabled unconditionally
on x86 SMP boxes.

[ feel free to send bug reports, suggestions and patches to
  Ingo Molnar <mingo@redhat.com> or the Linux SMP mailing
  list at <linux-smp@vger.kernel.org> ]

			 =============================
			 NO-MMU MEMORY MAPPING SUPPORT
			 =============================

The kernel has limited support for memory mapping under no-MMU conditions, such
as are used in uClinux environments. From the userspace point of view, memory
mapping is made use of in conjunction with the mmap() system call, the shmat()
call and the execve() system call. From the kernel's point of view, execve()
mapping is actually performed by the binfmt drivers, which call back into the
mmap() routines to do the actual work.

Memory mapping behaviour also involves the way fork(), vfork(), clone() and
ptrace() work. Under uClinux there is no fork(), and clone() must be supplied
the CLONE_VM flag.

The behaviour is similar between the MMU and no-MMU cases, but not identical;
and it's also much more restricted in the latter case:

 (*) Anonymous mapping, MAP_PRIVATE

	In the MMU case: VM regions backed by arbitrary pages; copy-on-write
	across fork.

	In the no-MMU case: VM regions backed by arbitrary contiguous runs of
	pages.

 (*) Anonymous mapping, MAP_SHARED

	These behave very much like private mappings, except that they're
	shared across fork() or clone() without CLONE_VM in the MMU case. Since
	the no-MMU case doesn't support these, behaviour is identical to
	MAP_PRIVATE there.

 (*) File, MAP_PRIVATE, PROT_READ / PROT_EXEC, !PROT_WRITE

	In the MMU case: VM regions backed by pages read from file; changes to
	the underlying file are reflected in the mapping; copied across fork.

	In the no-MMU case:

         - If one exists, the kernel will re-use an existing mapping to the
           same segment of the same file if that has compatible permissions,
           even if this was created by another process.

         - If possible, the file mapping will be directly on the backing device
           if the backing device has the BDI_CAP_MAP_DIRECT capability and
           appropriate mapping protection capabilities. Ramfs, romfs, cramfs
           and mtd might all permit this.

	 - If the backing device device can't or won't permit direct sharing,
           but does have the BDI_CAP_MAP_COPY capability, then a copy of the
           appropriate bit of the file will be read into a contiguous bit of
           memory and any extraneous space beyond the EOF will be cleared

	 - Writes to the file do not affect the mapping; writes to the mapping
	   are visible in other processes (no MMU protection), but should not
	   happen.

 (*) File, MAP_PRIVATE, PROT_READ / PROT_EXEC, PROT_WRITE

	In the MMU case: like the non-PROT_WRITE case, except that the pages in
	question get copied before the write actually happens. From that point
	on writes to the file underneath that page no longer get reflected into
	the mapping's backing pages. The page is then backed by swap instead.

	In the no-MMU case: works much like the non-PROT_WRITE case, except
	that a copy is always taken and never shared.

 (*) Regular file / blockdev, MAP_SHARED, PROT_READ / PROT_EXEC / PROT_WRITE

	In the MMU case: VM regions backed by pages read from file; changes to
	pages written back to file; writes to file reflected into pages backing
	mapping; shared across fork.

	In the no-MMU case: not supported.

 (*) Memory backed regular file, MAP_SHARED, PROT_READ / PROT_EXEC / PROT_WRITE

	In the MMU case: As for ordinary regular files.

	In the no-MMU case: The filesystem providing the memory-backed file
	(such as ramfs or tmpfs) may choose to honour an open, truncate, mmap
	sequence by providing a contiguous sequence of pages to map. In that
	case, a shared-writable memory mapping will be possible. It will work
	as for the MMU case. If the filesystem does not provide any such
	support, then the mapping request will be denied.

 (*) Memory backed blockdev, MAP_SHARED, PROT_READ / PROT_EXEC / PROT_WRITE

	In the MMU case: As for ordinary regular files.

	In the no-MMU case: As for memory backed regular files, but the
	blockdev must be able to provide a contiguous run of pages without
	truncate being called. The ramdisk driver could do this if it allocated
	all its memory as a contiguous array upfront.

 (*) Memory backed chardev, MAP_SHARED, PROT_READ / PROT_EXEC / PROT_WRITE

	In the MMU case: As for ordinary regular files.

	In the no-MMU case: The character device driver may choose to honour
	the mmap() by providing direct access to the underlying device if it
	provides memory or quasi-memory that can be accessed directly. Examples
	of such are frame buffers and flash devices. If the driver does not
	provide any such support, then the mapping request will be denied.


============================
FURTHER NOTES ON NO-MMU MMAP
============================

 (*) A request for a private mapping of a file may return a buffer that is not
     page-aligned.  This is because XIP may take place, and the data may not be
     paged aligned in the backing store.

 (*) A request for an anonymous mapping will always be page aligned.  If
     possible the size of the request should be a power of two otherwise some
     of the space may be wasted as the kernel must allocate a power-of-2
     granule but will only discard the excess if appropriately configured as
     this has an effect on fragmentation.

 (*) The memory allocated by a request for an anonymous mapping will normally
     be cleared by the kernel before being returned in accordance with the
     Linux man pages (ver 2.22 or later).

     In the MMU case this can be achieved with reasonable performance as
     regions are backed by virtual pages, with the contents only being mapped
     to cleared physical pages when a write happens on that specific page
     (prior to which, the pages are effectively mapped to the global zero page
     from which reads can take place).  This spreads out the time it takes to
     initialize the contents of a page - depending on the write-usage of the
     mapping.

     In the no-MMU case, however, anonymous mappings are backed by physical
     pages, and the entire map is cleared at allocation time.  This can cause
     significant delays during a userspace malloc() as the C library does an
     anonymous mapping and the kernel then does a memset for the entire map.

     However, for memory that isn't required to be precleared - such as that
     returned by malloc() - mmap() can take a MAP_UNINITIALIZED flag to
     indicate to the kernel that it shouldn't bother clearing the memory before
     returning it.  Note that CONFIG_MMAP_ALLOW_UNINITIALIZED must be enabled
     to permit this, otherwise the flag will be ignored.

     uClibc uses this to speed up malloc(), and the ELF-FDPIC binfmt uses this
     to allocate the brk and stack region.

 (*) A list of all the private copy and anonymous mappings on the system is
     visible through /proc/maps in no-MMU mode.

 (*) A list of all the mappings in use by a process is visible through
     /proc/<pid>/maps in no-MMU mode.

 (*) Supplying MAP_FIXED or a requesting a particular mapping address will
     result in an error.

 (*) Files mapped privately usually have to have a read method provided by the
     driver or filesystem so that the contents can be read into the memory
     allocated if mmap() chooses not to map the backing device directly. An
     error will result if they don't. This is most likely to be encountered
     with character device files, pipes, fifos and sockets.


==========================
INTERPROCESS SHARED MEMORY
==========================

Both SYSV IPC SHM shared memory and POSIX shared memory is supported in NOMMU
mode.  The former through the usual mechanism, the latter through files created
on ramfs or tmpfs mounts.


=======
FUTEXES
=======

Futexes are supported in NOMMU mode if the arch supports them.  An error will
be given if an address passed to the futex system call lies outside the
mappings made by a process or if the mapping in which the address lies does not
support futexes (such as an I/O chardev mapping).


=============
NO-MMU MREMAP
=============

The mremap() function is partially supported.  It may change the size of a
mapping, and may move it[*] if MREMAP_MAYMOVE is specified and if the new size
of the mapping exceeds the size of the slab object currently occupied by the
memory to which the mapping refers, or if a smaller slab object could be used.

MREMAP_FIXED is not supported, though it is ignored if there's no change of
address and the object does not need to be moved.

Shared mappings may not be moved.  Shareable mappings may not be moved either,
even if they are not currently shared.

The mremap() function must be given an exact match for base address and size of
a previously mapped object.  It may not be used to create holes in existing
mappings, move parts of existing mappings or resize parts of mappings.  It must
act on a complete mapping.

[*] Not currently supported.


============================================
PROVIDING SHAREABLE CHARACTER DEVICE SUPPORT
============================================

To provide shareable character device support, a driver must provide a
file->f_op->get_unmapped_area() operation. The mmap() routines will call this
to get a proposed address for the mapping. This may return an error if it
doesn't wish to honour the mapping because it's too long, at a weird offset,
under some unsupported combination of flags or whatever.

The driver should also provide backing device information with capabilities set
to indicate the permitted types of mapping on such devices. The default is
assumed to be readable and writable, not executable, and only shareable
directly (can't be copied).

The file->f_op->mmap() operation will be called to actually inaugurate the
mapping. It can be rejected at that point. Returning the ENOSYS error will
cause the mapping to be copied instead if BDI_CAP_MAP_COPY is specified.

The vm_ops->close() routine will be invoked when the last mapping on a chardev
is removed. An existing mapping will be shared, partially or not, if possible
without notifying the driver.

It is permitted also for the file->f_op->get_unmapped_area() operation to
return -ENOSYS. This will be taken to mean that this operation just doesn't
want to handle it, despite the fact it's got an operation. For instance, it
might try directing the call to a secondary driver which turns out not to
implement it. Such is the case for the framebuffer driver which attempts to
direct the call to the device-specific driver. Under such circumstances, the
mapping request will be rejected if BDI_CAP_MAP_COPY is not specified, and a
copy mapped otherwise.

IMPORTANT NOTE:

	Some types of device may present a different appearance to anyone
	looking at them in certain modes. Flash chips can be like this; for
	instance if they're in programming or erase mode, you might see the
	status reflected in the mapping, instead of the data.

	In such a case, care must be taken lest userspace see a shared or a
	private mapping showing such information when the driver is busy
	controlling the device. Remember especially: private executable
	mappings may still be mapped directly off the device under some
	circumstances!


==============================================
PROVIDING SHAREABLE MEMORY-BACKED FILE SUPPORT
==============================================

Provision of shared mappings on memory backed files is similar to the provision
of support for shared mapped character devices. The main difference is that the
filesystem providing the service will probably allocate a contiguous collection
of pages and permit mappings to be made on that.

It is recommended that a truncate operation applied to such a file that
increases the file size, if that file is empty, be taken as a request to gather
enough pages to honour a mapping. This is required to support POSIX shared
memory.

Memory backed devices are indicated by the mapping's backing device info having
the memory_backed flag set.


========================================
PROVIDING SHAREABLE BLOCK DEVICE SUPPORT
========================================

Provision of shared mappings on block device files is exactly the same as for
character devices. If there isn't a real device underneath, then the driver
should allocate sufficient contiguous memory to honour any supported mapping.


=================================
ADJUSTING PAGE TRIMMING BEHAVIOUR
=================================

NOMMU mmap automatically rounds up to the nearest power-of-2 number of pages
when performing an allocation.  This can have adverse effects on memory
fragmentation, and as such, is left configurable.  The default behaviour is to
aggressively trim allocations and discard any excess pages back in to the page
allocator.  In order to retain finer-grained control over fragmentation, this
behaviour can either be disabled completely, or bumped up to a higher page
watermark where trimming begins.

Page trimming behaviour is configurable via the sysctl `vm.nr_trim_pages'.

Numa policy hit/miss statistics

/sys/devices/system/node/node*/numastat

All units are pages. Hugepages have separate counters.

numa_hit			A process wanted to allocate memory from this node,
					and succeeded.
numa_miss			A process wanted to allocate memory from another node,
					but ended up with memory from this node.
numa_foreign		A process wanted to allocate on this node,
				    but ended up with memory from another one.
local_node			A process ran on this node and got memory from it.
other_node			A process ran on this node and got memory from another node.
interleave_hit 		Interleaving wanted to allocate from this node
					and succeeded.

For easier reading you can use the numastat utility from the numactl package
(ftp://ftp.suse.com/pub/people/ak/numa/numactl*). Note that it only works
well right now on machines with a small number of CPUs.

NOTE: ksymoops is useless on 2.6.  Please use the Oops in its original format
(from dmesg, etc).  Ignore any references in this or other docs to "decoding
the Oops" or "running it through ksymoops".  If you post an Oops from 2.6 that
has been run through ksymoops, people will just tell you to repost it.

Quick Summary
-------------

Find the Oops and send it to the maintainer of the kernel area that seems to be
involved with the problem.  Don't worry too much about getting the wrong person.
If you are unsure send it to the person responsible for the code relevant to
what you were doing.  If it occurs repeatably try and describe how to recreate
it.  That's worth even more than the oops.

If you are totally stumped as to whom to send the report, send it to 
linux-kernel@vger.kernel.org. Thanks for your help in making Linux as
stable as humanly possible.

Where is the Oops?
----------------------

Normally the Oops text is read from the kernel buffers by klogd and
handed to syslogd which writes it to a syslog file, typically
/var/log/messages (depends on /etc/syslog.conf).  Sometimes klogd dies,
in which case you can run dmesg > file to read the data from the kernel
buffers and save it.  Or you can cat /proc/kmsg > file, however you
have to break in to stop the transfer, kmsg is a "never ending file".
If the machine has crashed so badly that you cannot enter commands or
the disk is not available then you have three options :-

(1) Hand copy the text from the screen and type it in after the machine
    has restarted.  Messy but it is the only option if you have not
    planned for a crash. Alternatively, you can take a picture of
    the screen with a digital camera - not nice, but better than
    nothing.  If the messages scroll off the top of the console, you
    may find that booting with a higher resolution (eg, vga=791)
    will allow you to read more of the text. (Caveat: This needs vesafb,
    so won't help for 'early' oopses)

(2) Boot with a serial console (see Documentation/serial-console.txt),
    run a null modem to a second machine and capture the output there
    using your favourite communication program.  Minicom works well.

(3) Use Kdump (see Documentation/kdump/kdump.txt),
    extract the kernel ring buffer from old memory with using dmesg
    gdbmacro in Documentation/kdump/gdbmacros.txt.


Full Information
----------------

NOTE: the message from Linus below applies to 2.4 kernel.  I have preserved it
for historical reasons, and because some of the information in it still
applies.  Especially, please ignore any references to ksymoops. 

From: Linus Torvalds <torvalds@osdl.org>

How to track down an Oops.. [originally a mail to linux-kernel]

The main trick is having 5 years of experience with those pesky oops 
messages ;-)

Actually, there are things you can do that make this easier. I have two 
separate approaches:

	gdb /usr/src/linux/vmlinux
	gdb> disassemble <offending_function>

That's the easy way to find the problem, at least if the bug-report is 
well made (like this one was - run through ksymoops to get the 
information of which function and the offset in the function that it 
happened in).

Oh, it helps if the report happens on a kernel that is compiled with the 
same compiler and similar setups.

The other thing to do is disassemble the "Code:" part of the bug report: 
ksymoops will do this too with the correct tools, but if you don't have
the tools you can just do a silly program:

	char str[] = "\xXX\xXX\xXX...";
	main(){}

and compile it with gcc -g and then do "disassemble str" (where the "XX" 
stuff are the values reported by the Oops - you can just cut-and-paste 
and do a replace of spaces to "\x" - that's what I do, as I'm too lazy 
to write a program to automate this all).

Alternatively, you can use the shell script in scripts/decodecode.
Its usage is:  decodecode < oops.txt

The hex bytes that follow "Code:" may (in some architectures) have a series
of bytes that precede the current instruction pointer as well as bytes at and
following the current instruction pointer.  In some cases, one instruction
byte or word is surrounded by <> or (), as in "<86>" or "(f00d)".  These
<> or () markings indicate the current instruction pointer.  Example from
i386, split into multiple lines for readability:

Code: f9 0f 8d f9 00 00 00 8d 42 0c e8 dd 26 11 c7 a1 60 ea 2b f9 8b 50 08 a1
64 ea 2b f9 8d 34 82 8b 1e 85 db 74 6d 8b 15 60 ea 2b f9 <8b> 43 04 39 42 54
7e 04 40 89 42 54 8b 43 04 3b 05 00 f6 52 c0

Finally, if you want to see where the code comes from, you can do

	cd /usr/src/linux
	make fs/buffer.s 	# or whatever file the bug happened in

and then you get a better idea of what happens than with the gdb 
disassembly.

Now, the trick is just then to combine all the data you have: the C 
sources (and general knowledge of what it _should_ do), the assembly 
listing and the code disassembly (and additionally the register dump you 
also get from the "oops" message - that can be useful to see _what_ the 
corrupted pointers were, and when you have the assembler listing you can 
also match the other registers to whatever C expressions they were used 
for).

Essentially, you just look at what doesn't match (in this case it was the 
"Code" disassembly that didn't match with what the compiler generated). 
Then you need to find out _why_ they don't match. Often it's simple - you 
see that the code uses a NULL pointer and then you look at the code and 
wonder how the NULL pointer got there, and if it's a valid thing to do 
you just check against it..

Now, if somebody gets the idea that this is time-consuming and requires 
some small amount of concentration, you're right. Which is why I will 
mostly just ignore any panic reports that don't have the symbol table 
info etc looked up: it simply gets too hard to look it up (I have some 
programs to search for specific patterns in the kernel code segment, and 
sometimes I have been able to look up those kinds of panics too, but 
that really requires pretty good knowledge of the kernel just to be able 
to pick out the right sequences etc..)

_Sometimes_ it happens that I just see the disassembled code sequence 
from the panic, and I know immediately where it's coming from. That's when 
I get worried that I've been doing this for too long ;-)

		Linus


---------------------------------------------------------------------------
Notes on Oops tracing with klogd:

In order to help Linus and the other kernel developers there has been
substantial support incorporated into klogd for processing protection
faults.  In order to have full support for address resolution at least
version 1.3-pl3 of the sysklogd package should be used.

When a protection fault occurs the klogd daemon automatically
translates important addresses in the kernel log messages to their
symbolic equivalents.  This translated kernel message is then
forwarded through whatever reporting mechanism klogd is using.  The
protection fault message can be simply cut out of the message files
and forwarded to the kernel developers.

Two types of address resolution are performed by klogd.  The first is
static translation and the second is dynamic translation.  Static
translation uses the System.map file in much the same manner that
ksymoops does.  In order to do static translation the klogd daemon
must be able to find a system map file at daemon initialization time.
See the klogd man page for information on how klogd searches for map
files.

Dynamic address translation is important when kernel loadable modules
are being used.  Since memory for kernel modules is allocated from the
kernel's dynamic memory pools there are no fixed locations for either
the start of the module or for functions and symbols in the module.

The kernel supports system calls which allow a program to determine
which modules are loaded and their location in memory.  Using these
system calls the klogd daemon builds a symbol table which can be used
to debug a protection fault which occurs in a loadable kernel module.

At the very minimum klogd will provide the name of the module which
generated the protection fault.  There may be additional symbolic
information available if the developer of the loadable module chose to
export symbol information from the module.

Since the kernel module environment can be dynamic there must be a
mechanism for notifying the klogd daemon when a change in module
environment occurs.  There are command line options available which
allow klogd to signal the currently executing daemon that symbol
information should be refreshed.  See the klogd manual page for more
information.

A patch is included with the sysklogd distribution which modifies the
modules-2.0.0 package to automatically signal klogd whenever a module
is loaded or unloaded.  Applying this patch provides essentially
seamless support for debugging protection faults which occur with
kernel loadable modules.

The following is an example of a protection fault in a loadable module
processed by klogd:
---------------------------------------------------------------------------
Aug 29 09:51:01 blizard kernel: Unable to handle kernel paging request at virtual address f15e97cc
Aug 29 09:51:01 blizard kernel: current->tss.cr3 = 0062d000, %cr3 = 0062d000
Aug 29 09:51:01 blizard kernel: *pde = 00000000
Aug 29 09:51:01 blizard kernel: Oops: 0002
Aug 29 09:51:01 blizard kernel: CPU:    0
Aug 29 09:51:01 blizard kernel: EIP:    0010:[oops:_oops+16/3868]
Aug 29 09:51:01 blizard kernel: EFLAGS: 00010212
Aug 29 09:51:01 blizard kernel: eax: 315e97cc   ebx: 003a6f80   ecx: 001be77b   edx: 00237c0c
Aug 29 09:51:01 blizard kernel: esi: 00000000   edi: bffffdb3   ebp: 00589f90   esp: 00589f8c
Aug 29 09:51:01 blizard kernel: ds: 0018   es: 0018   fs: 002b   gs: 002b   ss: 0018
Aug 29 09:51:01 blizard kernel: Process oops_test (pid: 3374, process nr: 21, stackpage=00589000)
Aug 29 09:51:01 blizard kernel: Stack: 315e97cc 00589f98 0100b0b4 bffffed4 0012e38e 00240c64 003a6f80 00000001 
Aug 29 09:51:01 blizard kernel:        00000000 00237810 bfffff00 0010a7fa 00000003 00000001 00000000 bfffff00 
Aug 29 09:51:01 blizard kernel:        bffffdb3 bffffed4 ffffffda 0000002b 0007002b 0000002b 0000002b 00000036 
Aug 29 09:51:01 blizard kernel: Call Trace: [oops:_oops_ioctl+48/80] [_sys_ioctl+254/272] [_system_call+82/128] 
Aug 29 09:51:01 blizard kernel: Code: c7 00 05 00 00 00 eb 08 90 90 90 90 90 90 90 90 89 ec 5d c3 
---------------------------------------------------------------------------

Dr. G.W. Wettstein           Oncology Research Div. Computing Facility
Roger Maris Cancer Center    INTERNET: greg@wind.rmcc.com
820 4th St. N.
Fargo, ND  58122
Phone: 701-234-7556


---------------------------------------------------------------------------
Tainted kernels:

Some oops reports contain the string 'Tainted: ' after the program
counter. This indicates that the kernel has been tainted by some
mechanism.  The string is followed by a series of position-sensitive
characters, each representing a particular tainted value.

  1: 'G' if all modules loaded have a GPL or compatible license, 'P' if
     any proprietary module has been loaded.  Modules without a
     MODULE_LICENSE or with a MODULE_LICENSE that is not recognised by
     insmod as GPL compatible are assumed to be proprietary.

  2: 'F' if any module was force loaded by "insmod -f", ' ' if all
     modules were loaded normally.

  3: 'S' if the oops occurred on an SMP kernel running on hardware that
     hasn't been certified as safe to run multiprocessor.
     Currently this occurs only on various Athlons that are not
     SMP capable.

  4: 'R' if a module was force unloaded by "rmmod -f", ' ' if all
     modules were unloaded normally.

  5: 'M' if any processor has reported a Machine Check Exception,
     ' ' if no Machine Check Exceptions have occurred.

  6: 'B' if a page-release function has found a bad page reference or
     some unexpected page flags.

  7: 'U' if a user or user application specifically requested that the
     Tainted flag be set, ' ' otherwise.

  8: 'D' if the kernel has died recently, i.e. there was an OOPS or BUG.

  9: 'A' if the ACPI table has been overridden.

 10: 'W' if a warning has previously been issued by the kernel.
     (Though some warnings may set more specific taint flags.)

 11: 'C' if a staging driver has been loaded.

 12: 'I' if the kernel is working around a severe bug in the platform
     firmware (BIOS or similar).

The primary reason for the 'Tainted: ' string is to tell kernel
debuggers if this is a clean kernel or if anything unusual has
occurred.  Tainting is permanent: even if an offending module is
unloaded, the tainted value remains to indicate that the kernel is not
trustworthy.
The padata parallel execution mechanism
Last updated for 2.6.36

Padata is a mechanism by which the kernel can farm work out to be done in
parallel on multiple CPUs while retaining the ordering of tasks.  It was
developed for use with the IPsec code, which needs to be able to perform
encryption and decryption on large numbers of packets without reordering
those packets.  The crypto developers made a point of writing padata in a
sufficiently general fashion that it could be put to other uses as well.

The first step in using padata is to set up a padata_instance structure for
overall control of how tasks are to be run:

    #include <linux/padata.h>

    struct padata_instance *padata_alloc(struct workqueue_struct *wq,
					 const struct cpumask *pcpumask,
					 const struct cpumask *cbcpumask);

The pcpumask describes which processors will be used to execute work
submitted to this instance in parallel. The cbcpumask defines which
processors are allowed to be used as the serialization callback processor.
The workqueue wq is where the work will actually be done; it should be
a multithreaded queue, naturally.

To allocate a padata instance with the cpu_possible_mask for both
cpumasks this helper function can be used:

    struct padata_instance *padata_alloc_possible(struct workqueue_struct *wq);

Note: Padata maintains two kinds of cpumasks internally. The user supplied
cpumasks, submitted by padata_alloc/padata_alloc_possible and the 'usable'
cpumasks. The usable cpumasks are always a subset of active CPUs in the
user supplied cpumasks; these are the cpumasks padata actually uses. So
it is legal to supply a cpumask to padata that contains offline CPUs.
Once an offline CPU in the user supplied cpumask comes online, padata
is going to use it.

There are functions for enabling and disabling the instance:

    int padata_start(struct padata_instance *pinst);
    void padata_stop(struct padata_instance *pinst);

These functions are setting or clearing the "PADATA_INIT" flag;
if that flag is not set, other functions will refuse to work.
padata_start returns zero on success (flag set) or -EINVAL if the
padata cpumask contains no active CPU (flag not set).
padata_stop clears the flag and blocks until the padata instance
is unused.

The list of CPUs to be used can be adjusted with these functions:

    int padata_set_cpumasks(struct padata_instance *pinst,
			    cpumask_var_t pcpumask,
			    cpumask_var_t cbcpumask);
    int padata_set_cpumask(struct padata_instance *pinst, int cpumask_type,
			   cpumask_var_t cpumask);
    int padata_add_cpu(struct padata_instance *pinst, int cpu, int mask);
    int padata_remove_cpu(struct padata_instance *pinst, int cpu, int mask);

Changing the CPU masks are expensive operations, though, so it should not be
done with great frequency.

It's possible to change both cpumasks of a padata instance with
padata_set_cpumasks by specifying the cpumasks for parallel execution (pcpumask)
and for the serial callback function (cbcpumask). padata_set_cpumask is used to
change just one of the cpumasks. Here cpumask_type is one of PADATA_CPU_SERIAL,
PADATA_CPU_PARALLEL and cpumask specifies the new cpumask to use.
To simply add or remove one CPU from a certain cpumask the functions
padata_add_cpu/padata_remove_cpu are used. cpu specifies the CPU to add or
remove and mask is one of PADATA_CPU_SERIAL, PADATA_CPU_PARALLEL.

If a user is interested in padata cpumask changes, he can register to
the padata cpumask change notifier:

    int padata_register_cpumask_notifier(struct padata_instance *pinst,
					 struct notifier_block *nblock);

To unregister from that notifier:

    int padata_unregister_cpumask_notifier(struct padata_instance *pinst,
					   struct notifier_block *nblock);

The padata cpumask change notifier notifies about changes of the usable
cpumasks, i.e. the subset of active CPUs in the user supplied cpumask.

Padata calls the notifier chain with:

    blocking_notifier_call_chain(&pinst->cpumask_change_notifier,
				 notification_mask,
				 &pd_new->cpumask);

Here cpumask_change_notifier is registered notifier, notification_mask
is one of PADATA_CPU_SERIAL, PADATA_CPU_PARALLEL and cpumask is a pointer
to a struct padata_cpumask that contains the new cpumask information.

Actually submitting work to the padata instance requires the creation of a
padata_priv structure:

    struct padata_priv {
        /* Other stuff here... */
	void                    (*parallel)(struct padata_priv *padata);
	void                    (*serial)(struct padata_priv *padata);
    };

This structure will almost certainly be embedded within some larger
structure specific to the work to be done.  Most of its fields are private to
padata, but the structure should be zeroed at initialisation time, and the
parallel() and serial() functions should be provided.  Those functions will
be called in the process of getting the work done as we will see
momentarily.

The submission of work is done with:

    int padata_do_parallel(struct padata_instance *pinst,
		           struct padata_priv *padata, int cb_cpu);

The pinst and padata structures must be set up as described above; cb_cpu
specifies which CPU will be used for the final callback when the work is
done; it must be in the current instance's CPU mask.  The return value from
padata_do_parallel() is zero on success, indicating that the work is in
progress. -EBUSY means that somebody, somewhere else is messing with the
instance's CPU mask, while -EINVAL is a complaint about cb_cpu not being
in that CPU mask or about a not running instance.

Each task submitted to padata_do_parallel() will, in turn, be passed to
exactly one call to the above-mentioned parallel() function, on one CPU, so
true parallelism is achieved by submitting multiple tasks.  Despite the
fact that the workqueue is used to make these calls, parallel() is run with
software interrupts disabled and thus cannot sleep.  The parallel()
function gets the padata_priv structure pointer as its lone parameter;
information about the actual work to be done is probably obtained by using
container_of() to find the enclosing structure.

Note that parallel() has no return value; the padata subsystem assumes that
parallel() will take responsibility for the task from this point.  The work
need not be completed during this call, but, if parallel() leaves work
outstanding, it should be prepared to be called again with a new job before
the previous one completes.  When a task does complete, parallel() (or
whatever function actually finishes the job) should inform padata of the
fact with a call to:

    void padata_do_serial(struct padata_priv *padata);

At some point in the future, padata_do_serial() will trigger a call to the
serial() function in the padata_priv structure.  That call will happen on
the CPU requested in the initial call to padata_do_parallel(); it, too, is
done through the workqueue, but with local software interrupts disabled.
Note that this call may be deferred for a while since the padata code takes
pains to ensure that tasks are completed in the order in which they were
submitted.

The one remaining function in the padata API should be called to clean up
when a padata instance is no longer needed:

    void padata_free(struct padata_instance *pinst);

This function will busy-wait while any remaining tasks are completed, so it
might be best not to call it while there is work outstanding.  Shutting
down the workqueue, if necessary, should be done separately.
The `parport' code provides parallel-port support under Linux.  This
includes the ability to share one port between multiple device
drivers.

You can pass parameters to the parport code to override its automatic
detection of your hardware.  This is particularly useful if you want
to use IRQs, since in general these can't be autoprobed successfully.
By default IRQs are not used even if they _can_ be probed.  This is
because there are a lot of people using the same IRQ for their
parallel port and a sound card or network card.

The parport code is split into two parts: generic (which deals with
port-sharing) and architecture-dependent (which deals with actually
using the port).


Parport as modules
==================

If you load the parport code as a module, say

	# insmod parport

to load the generic parport code.  You then must load the
architecture-dependent code with (for example):

	# insmod parport_pc io=0x3bc,0x378,0x278 irq=none,7,auto

to tell the parport code that you want three PC-style ports, one at
0x3bc with no IRQ, one at 0x378 using IRQ 7, and one at 0x278 with an
auto-detected IRQ.  Currently, PC-style (parport_pc), Sun `bpp',
Amiga, Atari, and MFC3 hardware is supported.

PCI parallel I/O card support comes from parport_pc.  Base I/O
addresses should not be specified for supported PCI cards since they
are automatically detected.


KMod
----

If you use kmod, you will find it useful to edit /etc/modprobe.conf.
Here is an example of the lines that need to be added:

	alias parport_lowlevel parport_pc
	options parport_pc io=0x378,0x278 irq=7,auto

KMod will then automatically load parport_pc (with the options
"io=0x378,0x278 irq=7,auto") whenever a parallel port device driver
(such as lp) is loaded.

Note that these are example lines only!  You shouldn't in general need
to specify any options to parport_pc in order to be able to use a
parallel port.


Parport probe [optional]
-------------

In 2.2 kernels there was a module called parport_probe, which was used
for collecting IEEE 1284 device ID information.  This has now been
enhanced and now lives with the IEEE 1284 support.  When a parallel
port is detected, the devices that are connected to it are analysed,
and information is logged like this:

	parport0: Printer, BJC-210 (Canon)

The probe information is available from files in /proc/sys/dev/parport/.


Parport linked into the kernel statically
=========================================

If you compile the parport code into the kernel, then you can use
kernel boot parameters to get the same effect.  Add something like the
following to your LILO command line:

	parport=0x3bc parport=0x378,7 parport=0x278,auto,nofifo

You can have many `parport=...' statements, one for each port you want
to add.  Adding `parport=0' to the kernel command-line will disable
parport support entirely.  Adding `parport=auto' to the kernel
command-line will make parport use any IRQ lines or DMA channels that
it auto-detects.


Files in /proc
==============

If you have configured the /proc filesystem into your kernel, you will
see a new directory entry: /proc/sys/dev/parport.  In there will be a
directory entry for each parallel port for which parport is
configured.  In each of those directories are a collection of files
describing that parallel port.

The /proc/sys/dev/parport directory tree looks like:

parport
|-- default
|   |-- spintime
|   `-- timeslice
|-- parport0
|   |-- autoprobe
|   |-- autoprobe0
|   |-- autoprobe1
|   |-- autoprobe2
|   |-- autoprobe3
|   |-- devices
|   |   |-- active
|   |   `-- lp
|   |       `-- timeslice
|   |-- base-addr
|   |-- irq
|   |-- dma
|   |-- modes
|   `-- spintime
`-- parport1
    |-- autoprobe
    |-- autoprobe0
    |-- autoprobe1
    |-- autoprobe2
    |-- autoprobe3
    |-- devices
    |   |-- active
    |   `-- ppa
    |       `-- timeslice
    |-- base-addr
    |-- irq
    |-- dma
    |-- modes
    `-- spintime


File:		Contents:

devices/active	A list of the device drivers using that port.  A "+"
		will appear by the name of the device currently using
		the port (it might not appear against any).  The
		string "none" means that there are no device drivers
		using that port.

base-addr	Parallel port's base address, or addresses if the port
		has more than one in which case they are separated
		with tabs.  These values might not have any sensible
		meaning for some ports.

irq		Parallel port's IRQ, or -1 if none is being used.

dma		Parallel port's DMA channel, or -1 if none is being
		used.

modes		Parallel port's hardware modes, comma-separated,
		meaning:

		PCSPP		PC-style SPP registers are available.
		TRISTATE	Port is bidirectional.
		COMPAT		Hardware acceleration for printers is
				available and will be used.
		EPP		Hardware acceleration for EPP protocol
				is available and will be used.
		ECP		Hardware acceleration for ECP protocol
				is available and will be used.
		DMA		DMA is available and will be used.

		Note that the current implementation will only take
		advantage of COMPAT and ECP modes if it has an IRQ
		line to use.

autoprobe	Any IEEE-1284 device ID information that has been
		acquired from the (non-IEEE 1284.3) device.

autoprobe[0-3]	IEEE 1284 device ID information retrieved from
		daisy-chain devices that conform to IEEE 1284.3.

spintime	The number of microseconds to busy-loop while waiting
		for the peripheral to respond.  You might find that
		adjusting this improves performance, depending on your
		peripherals.  This is a port-wide setting, i.e. it
		applies to all devices on a particular port.

timeslice	The number of milliseconds that a device driver is
		allowed to keep a port claimed for.  This is advisory,
		and driver can ignore it if it must.

default/*	The defaults for spintime and timeslice. When a new
		port is	registered, it picks up the default spintime.
		When a new device is registered, it picks up the
		default timeslice.

Device drivers
==============

Once the parport code is initialised, you can attach device drivers to
specific ports.  Normally this happens automatically; if the lp driver
is loaded it will create one lp device for each port found.  You can
override this, though, by using parameters either when you load the lp
driver:

	# insmod lp parport=0,2

or on the LILO command line:

	lp=parport0 lp=parport2

Both the above examples would inform lp that you want /dev/lp0 to be
the first parallel port, and /dev/lp1 to be the _third_ parallel port,
with no lp device associated with the second port (parport1).  Note
that this is different to the way older kernels worked; there used to
be a static association between the I/O port address and the device
name, so /dev/lp0 was always the port at 0x3bc.  This is no longer the
case - if you only have one port, it will default to being /dev/lp0,
regardless of base address.

Also:

 * If you selected the IEEE 1284 support at compile time, you can say
   `lp=auto' on the kernel command line, and lp will create devices
   only for those ports that seem to have printers attached.

 * If you give PLIP the `timid' parameter, either with `plip=timid' on
   the command line, or with `insmod plip timid=1' when using modules,
   it will avoid any ports that seem to be in use by other devices.

 * IRQ autoprobing works only for a few port types at the moment.

Reporting printer problems with parport
=======================================

If you are having problems printing, please go through these steps to
try to narrow down where the problem area is.

When reporting problems with parport, really you need to give all of
the messages that parport_pc spits out when it initialises.  There are
several code paths:

o polling
o interrupt-driven, protocol in software
o interrupt-driven, protocol in hardware using PIO
o interrupt-driven, protocol in hardware using DMA

The kernel messages that parport_pc logs give an indication of which
code path is being used. (They could be a lot better actually..)

For normal printer protocol, having IEEE 1284 modes enabled or not
should not make a difference.

To turn off the 'protocol in hardware' code paths, disable
CONFIG_PARPORT_PC_FIFO.  Note that when they are enabled they are not
necessarily _used_; it depends on whether the hardware is available,
enabled by the BIOS, and detected by the driver.

So, to start with, disable CONFIG_PARPORT_PC_FIFO, and load parport_pc
with 'irq=none'. See if printing works then.  It really should,
because this is the simplest code path.

If that works fine, try with 'io=0x378 irq=7' (adjust for your
hardware), to make it use interrupt-driven in-software protocol.

If _that_ works fine, then one of the hardware modes isn't working
right.  Enable CONFIG_PARPORT_PC_FIFO (no, it isn't a module option,
and yes, it should be), set the port to ECP mode in the BIOS and note
the DMA channel, and try with:

    io=0x378 irq=7 dma=none (for PIO)
    io=0x378 irq=7 dma=3 (for DMA)
--
philb@gnu.org
tim@cyberelk.net
Lightweight PI-futexes
----------------------

We are calling them lightweight for 3 reasons:

 - in the user-space fastpath a PI-enabled futex involves no kernel work
   (or any other PI complexity) at all. No registration, no extra kernel
   calls - just pure fast atomic ops in userspace.

 - even in the slowpath, the system call and scheduling pattern is very
   similar to normal futexes.

 - the in-kernel PI implementation is streamlined around the mutex
   abstraction, with strict rules that keep the implementation
   relatively simple: only a single owner may own a lock (i.e. no
   read-write lock support), only the owner may unlock a lock, no
   recursive locking, etc.

Priority Inheritance - why?
---------------------------

The short reply: user-space PI helps achieving/improving determinism for
user-space applications. In the best-case, it can help achieve
determinism and well-bound latencies. Even in the worst-case, PI will
improve the statistical distribution of locking related application
delays.

The longer reply:
-----------------

Firstly, sharing locks between multiple tasks is a common programming
technique that often cannot be replaced with lockless algorithms. As we
can see it in the kernel [which is a quite complex program in itself],
lockless structures are rather the exception than the norm - the current
ratio of lockless vs. locky code for shared data structures is somewhere
between 1:10 and 1:100. Lockless is hard, and the complexity of lockless
algorithms often endangers to ability to do robust reviews of said code.
I.e. critical RT apps often choose lock structures to protect critical
data structures, instead of lockless algorithms. Furthermore, there are
cases (like shared hardware, or other resource limits) where lockless
access is mathematically impossible.

Media players (such as Jack) are an example of reasonable application
design with multiple tasks (with multiple priority levels) sharing
short-held locks: for example, a highprio audio playback thread is
combined with medium-prio construct-audio-data threads and low-prio
display-colory-stuff threads. Add video and decoding to the mix and
we've got even more priority levels.

So once we accept that synchronization objects (locks) are an
unavoidable fact of life, and once we accept that multi-task userspace
apps have a very fair expectation of being able to use locks, we've got
to think about how to offer the option of a deterministic locking
implementation to user-space.

Most of the technical counter-arguments against doing priority
inheritance only apply to kernel-space locks. But user-space locks are
different, there we cannot disable interrupts or make the task
non-preemptible in a critical section, so the 'use spinlocks' argument
does not apply (user-space spinlocks have the same priority inversion
problems as other user-space locking constructs). Fact is, pretty much
the only technique that currently enables good determinism for userspace
locks (such as futex-based pthread mutexes) is priority inheritance:

Currently (without PI), if a high-prio and a low-prio task shares a lock
[this is a quite common scenario for most non-trivial RT applications],
even if all critical sections are coded carefully to be deterministic
(i.e. all critical sections are short in duration and only execute a
limited number of instructions), the kernel cannot guarantee any
deterministic execution of the high-prio task: any medium-priority task
could preempt the low-prio task while it holds the shared lock and
executes the critical section, and could delay it indefinitely.

Implementation:
---------------

As mentioned before, the userspace fastpath of PI-enabled pthread
mutexes involves no kernel work at all - they behave quite similarly to
normal futex-based locks: a 0 value means unlocked, and a value==TID
means locked. (This is the same method as used by list-based robust
futexes.) Userspace uses atomic ops to lock/unlock these mutexes without
entering the kernel.

To handle the slowpath, we have added two new futex ops:

  FUTEX_LOCK_PI
  FUTEX_UNLOCK_PI

If the lock-acquire fastpath fails, [i.e. an atomic transition from 0 to
TID fails], then FUTEX_LOCK_PI is called. The kernel does all the
remaining work: if there is no futex-queue attached to the futex address
yet then the code looks up the task that owns the futex [it has put its
own TID into the futex value], and attaches a 'PI state' structure to
the futex-queue. The pi_state includes an rt-mutex, which is a PI-aware,
kernel-based synchronization object. The 'other' task is made the owner
of the rt-mutex, and the FUTEX_WAITERS bit is atomically set in the
futex value. Then this task tries to lock the rt-mutex, on which it
blocks. Once it returns, it has the mutex acquired, and it sets the
futex value to its own TID and returns. Userspace has no other work to
perform - it now owns the lock, and futex value contains
FUTEX_WAITERS|TID.

If the unlock side fastpath succeeds, [i.e. userspace manages to do a
TID -> 0 atomic transition of the futex value], then no kernel work is
triggered.

If the unlock fastpath fails (because the FUTEX_WAITERS bit is set),
then FUTEX_UNLOCK_PI is called, and the kernel unlocks the futex on the
behalf of userspace - and it also unlocks the attached
pi_state->rt_mutex and thus wakes up any potential waiters.

Note that under this approach, contrary to previous PI-futex approaches,
there is no prior 'registration' of a PI-futex. [which is not quite
possible anyway, due to existing ABI properties of pthread mutexes.]

Also, under this scheme, 'robustness' and 'PI' are two orthogonal
properties of futexes, and all four combinations are possible: futex,
robust-futex, PI-futex, robust+PI-futex.

More details about priority inheritance can be found in
Documentation/rt-mutex.txt.
Linux Plug and Play Documentation
by Adam Belay <ambx1@neo.rr.com>
last updated: Oct. 16, 2002
---------------------------------------------------------------------------------------



Overview
--------
	Plug and Play provides a means of detecting and setting resources for legacy or
otherwise unconfigurable devices.  The Linux Plug and Play Layer provides these 
services to compatible drivers.



The User Interface
------------------
	The Linux Plug and Play user interface provides a means to activate PnP devices
for legacy and user level drivers that do not support Linux Plug and Play.  The 
user interface is integrated into sysfs.

In addition to the standard sysfs file the following are created in each
device's directory:
id - displays a list of support EISA IDs
options - displays possible resource configurations
resources - displays currently allocated resources and allows resource changes

-activating a device

#echo "auto" > resources

this will invoke the automatic resource config system to activate the device

-manually activating a device

#echo "manual <depnum> <mode>" > resources
<depnum> - the configuration number
<mode> - static or dynamic
		static = for next boot
		dynamic = now

-disabling a device

#echo "disable" > resources


EXAMPLE:

Suppose you need to activate the floppy disk controller.
1.) change to the proper directory, in my case it is 
/driver/bus/pnp/devices/00:0f
# cd /driver/bus/pnp/devices/00:0f
# cat name
PC standard floppy disk controller

2.) check if the device is already active
# cat resources
DISABLED

- Notice the string "DISABLED".  This means the device is not active.

3.) check the device's possible configurations (optional)
# cat options
Dependent: 01 - Priority acceptable
    port 0x3f0-0x3f0, align 0x7, size 0x6, 16-bit address decoding
    port 0x3f7-0x3f7, align 0x0, size 0x1, 16-bit address decoding
    irq 6
    dma 2 8-bit compatible
Dependent: 02 - Priority acceptable
    port 0x370-0x370, align 0x7, size 0x6, 16-bit address decoding
    port 0x377-0x377, align 0x0, size 0x1, 16-bit address decoding
    irq 6
    dma 2 8-bit compatible

4.) now activate the device
# echo "auto" > resources

5.) finally check if the device is active
# cat resources
io 0x3f0-0x3f5
io 0x3f7-0x3f7
irq 6
dma 2

also there are a series of kernel parameters:
pnp_reserve_irq=irq1[,irq2] ....
pnp_reserve_dma=dma1[,dma2] ....
pnp_reserve_io=io1,size1[,io2,size2] ....
pnp_reserve_mem=mem1,size1[,mem2,size2] ....



The Unified Plug and Play Layer
-------------------------------
	All Plug and Play drivers, protocols, and services meet at a central location 
called the Plug and Play Layer.  This layer is responsible for the exchange of 
information between PnP drivers and PnP protocols.  Thus it automatically 
forwards commands to the proper protocol.  This makes writing PnP drivers 
significantly easier.

The following functions are available from the Plug and Play Layer:

pnp_get_protocol
- increments the number of uses by one

pnp_put_protocol
- deincrements the number of uses by one

pnp_register_protocol
- use this to register a new PnP protocol

pnp_unregister_protocol
- use this function to remove a PnP protocol from the Plug and Play Layer

pnp_register_driver
- adds a PnP driver to the Plug and Play Layer
- this includes driver model integration
- returns zero for success or a negative error number for failure; count
  calls to the .add() method if you need to know how many devices bind to
  the driver

pnp_unregister_driver
- removes a PnP driver from the Plug and Play Layer



Plug and Play Protocols
-----------------------
	This section contains information for PnP protocol developers.

The following Protocols are currently available in the computing world:
- PNPBIOS: used for system devices such as serial and parallel ports.
- ISAPNP: provides PnP support for the ISA bus
- ACPI: among its many uses, ACPI provides information about system level 
devices.
It is meant to replace the PNPBIOS.  It is not currently supported by Linux
Plug and Play but it is planned to be in the near future.


Requirements for a Linux PnP protocol:
1.) the protocol must use EISA IDs
2.) the protocol must inform the PnP Layer of a device's current configuration
- the ability to set resources is optional but preferred.

The following are PnP protocol related functions:

pnp_add_device
- use this function to add a PnP device to the PnP layer
- only call this function when all wanted values are set in the pnp_dev 
structure

pnp_init_device
- call this to initialize the PnP structure

pnp_remove_device
- call this to remove a device from the Plug and Play Layer.
- it will fail if the device is still in use.
- automatically will free mem used by the device and related structures

pnp_add_id
- adds an EISA ID to the list of supported IDs for the specified device

For more information consult the source of a protocol such as
/drivers/pnp/pnpbios/core.c.



Linux Plug and Play Drivers
---------------------------
	This section contains information for Linux PnP driver developers.

The New Way
...........
1.) first make a list of supported EISA IDS
ex:
static const struct pnp_id pnp_dev_table[] = {
	/* Standard LPT Printer Port */
	{.id = "PNP0400", .driver_data = 0},
	/* ECP Printer Port */
	{.id = "PNP0401", .driver_data = 0},
	{.id = ""}
};

Please note that the character 'X' can be used as a wild card in the function
portion (last four characters).
ex:
	/* Unknown PnP modems */
	{	"PNPCXXX",		UNKNOWN_DEV	},

Supported PnP card IDs can optionally be defined.
ex:
static const struct pnp_id pnp_card_table[] = {
	{	"ANYDEVS",		0	},
	{	"",			0	}
};

2.) Optionally define probe and remove functions.  It may make sense not to 
define these functions if the driver already has a reliable method of detecting
the resources, such as the parport_pc driver.
ex:
static int
serial_pnp_probe(struct pnp_dev * dev, const struct pnp_id *card_id, const 
                 struct pnp_id *dev_id)
{
. . .

ex:
static void serial_pnp_remove(struct pnp_dev * dev)
{
. . .

consult /drivers/serial/8250_pnp.c for more information.

3.) create a driver structure
ex:

static struct pnp_driver serial_pnp_driver = {
	.name		= "serial",
	.card_id_table	= pnp_card_table,
	.id_table	= pnp_dev_table,
	.probe		= serial_pnp_probe,
	.remove		= serial_pnp_remove,
};

* name and id_table cannot be NULL.

4.) register the driver
ex:

static int __init serial8250_pnp_init(void)
{
	return pnp_register_driver(&serial_pnp_driver);
}

The Old Way
...........

A series of compatibility functions have been created to make it easy to convert
ISAPNP drivers.  They should serve as a temporary solution only.

They are as follows:

struct pnp_card *pnp_find_card(unsigned short vendor,
				 unsigned short device,
				 struct pnp_card *from)

struct pnp_dev *pnp_find_dev(struct pnp_card *card,
				unsigned short vendor,
				unsigned short function,
				struct pnp_dev *from)

		  Proper Locking Under a Preemptible Kernel:
		       Keeping Kernel Code Preempt-Safe
			 Robert Love <rml@tech9.net>
			  Last Updated: 28 Aug 2002


INTRODUCTION


A preemptible kernel creates new locking issues.  The issues are the same as
those under SMP: concurrency and reentrancy.  Thankfully, the Linux preemptible
kernel model leverages existing SMP locking mechanisms.  Thus, the kernel
requires explicit additional locking for very few additional situations.

This document is for all kernel hackers.  Developing code in the kernel
requires protecting these situations.
 

RULE #1: Per-CPU data structures need explicit protection


Two similar problems arise. An example code snippet:

	struct this_needs_locking tux[NR_CPUS];
	tux[smp_processor_id()] = some_value;
	/* task is preempted here... */
	something = tux[smp_processor_id()];

First, since the data is per-CPU, it may not have explicit SMP locking, but
require it otherwise.  Second, when a preempted task is finally rescheduled,
the previous value of smp_processor_id may not equal the current.  You must
protect these situations by disabling preemption around them.

You can also use put_cpu() and get_cpu(), which will disable preemption.


RULE #2: CPU state must be protected.


Under preemption, the state of the CPU must be protected.  This is arch-
dependent, but includes CPU structures and state not preserved over a context
switch.  For example, on x86, entering and exiting FPU mode is now a critical
section that must occur while preemption is disabled.  Think what would happen
if the kernel is executing a floating-point instruction and is then preempted.
Remember, the kernel does not save FPU state except for user tasks.  Therefore,
upon preemption, the FPU registers will be sold to the lowest bidder.  Thus,
preemption must be disabled around such regions.

Note, some FPU functions are already explicitly preempt safe.  For example,
kernel_fpu_begin and kernel_fpu_end will disable and enable preemption.
However, math_state_restore must be called with preemption disabled.


RULE #3: Lock acquire and release must be performed by same task


A lock acquired in one task must be released by the same task.  This
means you can't do oddball things like acquire a lock and go off to
play while another task releases it.  If you want to do something
like this, acquire and release the task in the same code path and
have the caller wait on an event by the other task.


SOLUTION


Data protection under preemption is achieved by disabling preemption for the
duration of the critical region.

preempt_enable()		decrement the preempt counter
preempt_disable()		increment the preempt counter
preempt_enable_no_resched()	decrement, but do not immediately preempt
preempt_check_resched()		if needed, reschedule
preempt_count()			return the preempt counter

The functions are nestable.  In other words, you can call preempt_disable
n-times in a code path, and preemption will not be reenabled until the n-th
call to preempt_enable.  The preempt statements define to nothing if
preemption is not enabled.

Note that you do not need to explicitly prevent preemption if you are holding
any locks or interrupts are disabled, since preemption is implicitly disabled
in those cases.

But keep in mind that 'irqs disabled' is a fundamentally unsafe way of
disabling preemption - any spin_unlock() decreasing the preemption count
to 0 might trigger a reschedule. A simple printk() might trigger a reschedule.
So use this implicit preemption-disabling property only if you know that the
affected codepath does not do any of this. Best policy is to use this only for
small, atomic code that you wrote and which calls no complex functions.

Example:

	cpucache_t *cc; /* this is per-CPU */
	preempt_disable();
	cc = cc_data(searchp);
	if (cc && cc->avail) {
		__free_block(searchp, cc_entry(cc), cc->avail);
		cc->avail = 0;
	}
	preempt_enable();
	return 0;

Notice how the preemption statements must encompass every reference of the
critical variables.  Another example:

	int buf[NR_CPUS];
	set_cpu_val(buf);
	if (buf[smp_processor_id()] == -1) printf(KERN_INFO "wee!\n");
	spin_lock(&buf_lock);
	/* ... */

This code is not preempt-safe, but see how easily we can fix it by simply
moving the spin_lock up two lines.


PREVENTING PREEMPTION USING INTERRUPT DISABLING


It is possible to prevent a preemption event using local_irq_disable and
local_irq_save.  Note, when doing so, you must be very careful to not cause
an event that would set need_resched and result in a preemption check.  When
in doubt, rely on locking or explicit preemption disabling.

Note in 2.5 interrupt disabling is now only per-CPU (e.g. local).

An additional concern is proper usage of local_irq_disable and local_irq_save.
These may be used to protect from preemption, however, on exit, if preemption
may be enabled, a test to see if preemption is required should be done.  If
these are called from the spin_lock and read/write lock macros, the right thing
is done.  They may also be called within a spin-lock protected region, however,
if they are ever called outside of this context, a test for preemption should
be made. Do note that calls from interrupt context or bottom half/ tasklets
are also protected by preemption locks and so may use the versions which do
not check preemption.
If variable is of Type,		use printk format specifier:
---------------------------------------------------------
		int			%d or %x
		unsigned int		%u or %x
		long			%ld or %lx
		unsigned long		%lu or %lx
		long long		%lld or %llx
		unsigned long long	%llu or %llx
		size_t			%zu or %zx
		ssize_t			%zd or %zx

Raw pointer value SHOULD be printed with %p. The kernel supports
the following extended format specifiers for pointer types:

Symbols/Function Pointers:

	%pF	versatile_init+0x0/0x110
	%pf	versatile_init
	%pS	versatile_init+0x0/0x110
	%ps	versatile_init
	%pB	prev_fn_of_versatile_init+0x88/0x88

	For printing symbols and function pointers. The 'S' and 's' specifiers
	result in the symbol name with ('S') or without ('s') offsets. Where
	this is used on a kernel without KALLSYMS - the symbol address is
	printed instead.

	The 'B' specifier results in the symbol name with offsets and should be
	used when printing stack backtraces. The specifier takes into
	consideration the effect of compiler optimisations which may occur
	when tail-call's are used and marked with the noreturn GCC attribute.

	On ia64, ppc64 and parisc64 architectures function pointers are
	actually function descriptors which must first be resolved. The 'F' and
	'f' specifiers perform this resolution and then provide the same
	functionality as the 'S' and 's' specifiers.

Kernel Pointers:

	%pK	0x01234567 or 0x0123456789abcdef

	For printing kernel pointers which should be hidden from unprivileged
	users. The behaviour of %pK depends on the kptr_restrict sysctl - see
	Documentation/sysctl/kernel.txt for more details.

Struct Resources:

	%pr	[mem 0x60000000-0x6fffffff flags 0x2200] or
		[mem 0x0000000060000000-0x000000006fffffff flags 0x2200]
	%pR	[mem 0x60000000-0x6fffffff pref] or
		[mem 0x0000000060000000-0x000000006fffffff pref]

	For printing struct resources. The 'R' and 'r' specifiers result in a
	printed resource with ('R') or without ('r') a decoded flags member.

MAC/FDDI addresses:

	%pM	00:01:02:03:04:05
	%pMF	00-01-02-03-04-05
	%pm	000102030405

	For printing 6-byte MAC/FDDI addresses in hex notation. The 'M' and 'm'
	specifiers result in a printed address with ('M') or without ('m') byte
	separators. The default byte separator is the colon (':').

	Where FDDI addresses are concerned the 'F' specifier can be used after
	the 'M' specifier to use dash ('-') separators instead of the default
	separator.

IPv4 addresses:

	%pI4	1.2.3.4
	%pi4	001.002.003.004
	%p[Ii][hnbl]

	For printing IPv4 dot-separated decimal addresses. The 'I4' and 'i4'
	specifiers result in a printed address with ('i4') or without ('I4')
	leading zeros.

	The additional 'h', 'n', 'b', and 'l' specifiers are used to specify
	host, network, big or little endian order addresses respectively. Where
	no specifier is provided the default network/big endian order is used.

IPv6 addresses:

	%pI6	0001:0002:0003:0004:0005:0006:0007:0008
	%pi6	00010002000300040005000600070008
	%pI6c	1:2:3:4:5:6:7:8

	For printing IPv6 network-order 16-bit hex addresses. The 'I6' and 'i6'
	specifiers result in a printed address with ('I6') or without ('i6')
	colon-separators. Leading zeros are always used.

	The additional 'c' specifier can be used with the 'I' specifier to
	print a compressed IPv6 address as described by
	http://tools.ietf.org/html/rfc5952

UUID/GUID addresses:

	%pUb	00010203-0405-0607-0809-0a0b0c0d0e0f
	%pUB	00010203-0405-0607-0809-0A0B0C0D0E0F
	%pUl	03020100-0504-0706-0809-0a0b0c0e0e0f
	%pUL	03020100-0504-0706-0809-0A0B0C0E0E0F

	For printing 16-byte UUID/GUIDs addresses. The additional 'l', 'L',
	'b' and 'B' specifiers are used to specify a little endian order in
	lower ('l') or upper case ('L') hex characters - and big endian order
	in lower ('b') or upper case ('B') hex characters.

	Where no additional specifiers are used the default little endian
	order with lower case hex characters will be printed.

struct va_format:

	%pV

	For printing struct va_format structures. These contain a format string
	and va_list as follows:

	struct va_format {
		const char *fmt;
		va_list *va;
	};

	Do not use this feature without some mechanism to verify the
	correctness of the format string and va_list arguments.

u64 SHOULD be printed with %llu/%llx, (unsigned long long):

	printk("%llu", (unsigned long long)u64_var);

s64 SHOULD be printed with %lld/%llx, (long long):

	printk("%lld", (long long)s64_var);

If <type> is dependent on a config option for its size (e.g., sector_t,
blkcnt_t, phys_addr_t, resource_size_t) or is architecture-dependent
for its size (e.g., tcflag_t), use a format specifier of its largest
possible type and explicitly cast to it.  Example:

	printk("test: sector number/total blocks: %llu/%llu\n",
		(unsigned long long)sector, (unsigned long long)blockcount);

Reminder: sizeof() result is of type size_t.

Thank you for your cooperation and attention.


By Randy Dunlap <rdunlap@xenotime.net> and
Andrew Murray <amurray@mpc-data.co.uk>
The prio_tree.c code indexes vmas using 3 different indexes:
	* heap_index  = vm_pgoff + vm_size_in_pages : end_vm_pgoff
	* radix_index = vm_pgoff : start_vm_pgoff
	* size_index = vm_size_in_pages

A regular radix-priority-search-tree indexes vmas using only heap_index and
radix_index. The conditions for indexing are:
	* ->heap_index >= ->left->heap_index &&
		->heap_index >= ->right->heap_index
	* if (->heap_index == ->left->heap_index)
		then ->radix_index < ->left->radix_index;
	* if (->heap_index == ->right->heap_index)
		then ->radix_index < ->right->radix_index;
	* nodes are hashed to left or right subtree using radix_index
	  similar to a pure binary radix tree.

A regular radix-priority-search-tree helps to store and query
intervals (vmas). However, a regular radix-priority-search-tree is only
suitable for storing vmas with different radix indices (vm_pgoff).

Therefore, the prio_tree.c extends the regular radix-priority-search-tree
to handle many vmas with the same vm_pgoff. Such vmas are handled in
2 different ways: 1) All vmas with the same radix _and_ heap indices are
linked using vm_set.list, 2) if there are many vmas with the same radix
index, but different heap indices and if the regular radix-priority-search
tree cannot index them all, we build an overflow-sub-tree that indexes such
vmas using heap and size indices instead of heap and radix indices. For
example, in the figure below some vmas with vm_pgoff = 0 (zero) are
indexed by regular radix-priority-search-tree whereas others are pushed
into an overflow-subtree. Note that all vmas in an overflow-sub-tree have
the same vm_pgoff (radix_index) and if necessary we build different
overflow-sub-trees to handle each possible radix_index. For example,
in figure we have 3 overflow-sub-trees corresponding to radix indices
0, 2, and 4.

In the final tree the first few (prio_tree_root->index_bits) levels
are indexed using heap and radix indices whereas the overflow-sub-trees below
those levels (i.e. levels prio_tree_root->index_bits + 1 and higher) are
indexed using heap and size indices. In overflow-sub-trees the size_index
is used for hashing the nodes to appropriate places.

Now, an example prio_tree:

  vmas are represented [radix_index, size_index, heap_index]
                 i.e., [start_vm_pgoff, vm_size_in_pages, end_vm_pgoff]

level  prio_tree_root->index_bits = 3
-----
												_
  0			 				[0,7,7]					 |
  							/     \					 |
				      ------------------       ------------			 |     Regular
  				     /					   \			 |  radix priority
  1		 		[1,6,7]					  [4,3,7]		 |   search tree
  				/     \					  /     \		 |
			 -------       -----			    ------       -----		 |  heap-and-radix
			/		    \			   /		      \		 |      indexed
  2		    [0,6,6]	 	   [2,5,7]		[5,2,7]		    [6,1,7]	 |
		    /     \		   /     \		/     \		    /     \	 |
  3		[0,5,5]	[1,5,6]		[2,4,6]	[3,4,7]	    [4,2,6] [5,1,6]	[6,0,6]	[7,0,7]	 |
		   /			   /		       /		   		_
                  /		          /		      /					_
  4	      [0,4,4]		      [2,3,5]		   [4,1,5]				 |
  		 /			 /		      /					 |
  5	     [0,3,3]		     [2,2,4]		  [4,0,4]				 |  Overflow-sub-trees
  		/			/							 |
  6	    [0,2,2]		    [2,1,3]							 |    heap-and-size
  	       /		       /							 |       indexed
  7	   [0,1,1]		   [2,0,2]							 |
  	      /											 |
  8	  [0,0,0]										 |
  												_

Note that we use prio_tree_root->index_bits to optimize the height
of the heap-and-radix indexed tree. Since prio_tree_root->index_bits is
set according to the maximum end_vm_pgoff mapped, we are sure that all
bits (in vm_pgoff) above prio_tree_root->index_bits are 0 (zero). Therefore,
we only use the first prio_tree_root->index_bits as radix_index.
Whenever index_bits is increased in prio_tree_expand, we shuffle the tree
to make sure that the first prio_tree_root->index_bits levels of the tree
is indexed properly using heap and radix indices.

We do not optimize the height of overflow-sub-trees using index_bits.
The reason is: there can be many such overflow-sub-trees and all of
them have to be suffled whenever the index_bits increases. This may involve
walking the whole prio_tree in prio_tree_insert->prio_tree_expand code
path which is not desirable. Hence, we do not optimize the height of the
heap-and-size indexed overflow-sub-trees using prio_tree->index_bits.
Instead the overflow sub-trees are indexed using full BITS_PER_LONG bits
of size_index. This may lead to skewed sub-trees because most of the
higher significant bits of the size_index are likely to be 0 (zero). In
the example above, all 3 overflow-sub-trees are skewed. This may marginally
affect the performance. However, processes rarely map many vmas with the
same start_vm_pgoff but different end_vm_pgoffs. Therefore, we normally
do not require overflow-sub-trees to index all vmas.

From the above discussion it is clear that the maximum height of
a prio_tree can be prio_tree_root->index_bits + BITS_PER_LONG.
However, in most of the common cases we do not need overflow-sub-trees,
so the tree height in the common cases will be prio_tree_root->index_bits.

It is fair to mention here that the prio_tree_root->index_bits
is increased on demand, however, the index_bits is not decreased when
vmas are removed from the prio_tree. That's tricky to do. Hence, it's
left as a home work problem.


Red-black Trees (rbtree) in Linux
January 18, 2007
Rob Landley <rob@landley.net>
=============================

What are red-black trees, and what are they for?
------------------------------------------------

Red-black trees are a type of self-balancing binary search tree, used for
storing sortable key/value data pairs.  This differs from radix trees (which
are used to efficiently store sparse arrays and thus use long integer indexes
to insert/access/delete nodes) and hash tables (which are not kept sorted to
be easily traversed in order, and must be tuned for a specific size and
hash function where rbtrees scale gracefully storing arbitrary keys).

Red-black trees are similar to AVL trees, but provide faster real-time bounded
worst case performance for insertion and deletion (at most two rotations and
three rotations, respectively, to balance the tree), with slightly slower
(but still O(log n)) lookup time.

To quote Linux Weekly News:

    There are a number of red-black trees in use in the kernel.
    The deadline and CFQ I/O schedulers employ rbtrees to
    track requests; the packet CD/DVD driver does the same.
    The high-resolution timer code uses an rbtree to organize outstanding
    timer requests.  The ext3 filesystem tracks directory entries in a
    red-black tree.  Virtual memory areas (VMAs) are tracked with red-black
    trees, as are epoll file descriptors, cryptographic keys, and network
    packets in the "hierarchical token bucket" scheduler.

This document covers use of the Linux rbtree implementation.  For more
information on the nature and implementation of Red Black Trees,  see:

  Linux Weekly News article on red-black trees
    http://lwn.net/Articles/184495/

  Wikipedia entry on red-black trees
    http://en.wikipedia.org/wiki/Red-black_tree

Linux implementation of red-black trees
---------------------------------------

Linux's rbtree implementation lives in the file "lib/rbtree.c".  To use it,
"#include <linux/rbtree.h>".

The Linux rbtree implementation is optimized for speed, and thus has one
less layer of indirection (and better cache locality) than more traditional
tree implementations.  Instead of using pointers to separate rb_node and data
structures, each instance of struct rb_node is embedded in the data structure
it organizes.  And instead of using a comparison callback function pointer,
users are expected to write their own tree search and insert functions
which call the provided rbtree functions.  Locking is also left up to the
user of the rbtree code.

Creating a new rbtree
---------------------

Data nodes in an rbtree tree are structures containing a struct rb_node member:

  struct mytype {
  	struct rb_node node;
  	char *keystring;
  };

When dealing with a pointer to the embedded struct rb_node, the containing data
structure may be accessed with the standard container_of() macro.  In addition,
individual members may be accessed directly via rb_entry(node, type, member).

At the root of each rbtree is an rb_root structure, which is initialized to be
empty via:

  struct rb_root mytree = RB_ROOT;

Searching for a value in an rbtree
----------------------------------

Writing a search function for your tree is fairly straightforward: start at the
root, compare each value, and follow the left or right branch as necessary.

Example:

  struct mytype *my_search(struct rb_root *root, char *string)
  {
  	struct rb_node *node = root->rb_node;

  	while (node) {
  		struct mytype *data = container_of(node, struct mytype, node);
		int result;

		result = strcmp(string, data->keystring);

		if (result < 0)
  			node = node->rb_left;
		else if (result > 0)
  			node = node->rb_right;
		else
  			return data;
	}
	return NULL;
  }

Inserting data into an rbtree
-----------------------------

Inserting data in the tree involves first searching for the place to insert the
new node, then inserting the node and rebalancing ("recoloring") the tree.

The search for insertion differs from the previous search by finding the
location of the pointer on which to graft the new node.  The new node also
needs a link to its parent node for rebalancing purposes.

Example:

  int my_insert(struct rb_root *root, struct mytype *data)
  {
  	struct rb_node **new = &(root->rb_node), *parent = NULL;

  	/* Figure out where to put new node */
  	while (*new) {
  		struct mytype *this = container_of(*new, struct mytype, node);
  		int result = strcmp(data->keystring, this->keystring);

		parent = *new;
  		if (result < 0)
  			new = &((*new)->rb_left);
  		else if (result > 0)
  			new = &((*new)->rb_right);
  		else
  			return FALSE;
  	}

  	/* Add new node and rebalance tree. */
  	rb_link_node(&data->node, parent, new);
  	rb_insert_color(&data->node, root);

	return TRUE;
  }

Removing or replacing existing data in an rbtree
------------------------------------------------

To remove an existing node from a tree, call:

  void rb_erase(struct rb_node *victim, struct rb_root *tree);

Example:

  struct mytype *data = mysearch(&mytree, "walrus");

  if (data) {
  	rb_erase(&data->node, &mytree);
  	myfree(data);
  }

To replace an existing node in a tree with a new one with the same key, call:

  void rb_replace_node(struct rb_node *old, struct rb_node *new,
  			struct rb_root *tree);

Replacing a node this way does not re-sort the tree: If the new node doesn't
have the same key as the old node, the rbtree will probably become corrupted.

Iterating through the elements stored in an rbtree (in sort order)
------------------------------------------------------------------

Four functions are provided for iterating through an rbtree's contents in
sorted order.  These work on arbitrary trees, and should not need to be
modified or wrapped (except for locking purposes):

  struct rb_node *rb_first(struct rb_root *tree);
  struct rb_node *rb_last(struct rb_root *tree);
  struct rb_node *rb_next(struct rb_node *node);
  struct rb_node *rb_prev(struct rb_node *node);

To start iterating, call rb_first() or rb_last() with a pointer to the root
of the tree, which will return a pointer to the node structure contained in
the first or last element in the tree.  To continue, fetch the next or previous
node by calling rb_next() or rb_prev() on the current node.  This will return
NULL when there are no more nodes left.

The iterator functions return a pointer to the embedded struct rb_node, from
which the containing data structure may be accessed with the container_of()
macro, and individual members may be accessed directly via
rb_entry(node, type, member).

Example:

  struct rb_node *node;
  for (node = rb_first(&mytree); node; node = rb_next(node))
	printk("key=%s\n", rb_entry(node, struct mytype, node)->keystring);

Support for Augmented rbtrees
-----------------------------

Augmented rbtree is an rbtree with "some" additional data stored in each node.
This data can be used to augment some new functionality to rbtree.
Augmented rbtree is an optional feature built on top of basic rbtree
infrastructure. rbtree user who wants this feature will have an augment
callback function in rb_root initialized.

This callback function will be called from rbtree core routines whenever
a node has a change in one or both of its children. It is the responsibility
of the callback function to recalculate the additional data that is in the
rb node using new children information. Note that if this new additional
data affects the parent node's additional data, then callback function has
to handle it and do the recursive updates.


Interval tree is an example of augmented rb tree. Reference -
"Introduction to Algorithms" by Cormen, Leiserson, Rivest and Stein.
More details about interval trees:

Classical rbtree has a single key and it cannot be directly used to store
interval ranges like [lo:hi] and do a quick lookup for any overlap with a new
lo:hi or to find whether there is an exact match for a new lo:hi.

However, rbtree can be augmented to store such interval ranges in a structured
way making it possible to do efficient lookup and exact match.

This "extra information" stored in each node is the maximum hi
(max_hi) value among all the nodes that are its descendents. This
information can be maintained at each node just be looking at the node
and its immediate children. And this will be used in O(log n) lookup
for lowest match (lowest start address among all possible matches)
with something like:

find_lowest_match(lo, hi, node)
{
	lowest_match = NULL;
	while (node) {
		if (max_hi(node->left) > lo) {
			// Lowest overlap if any must be on left side
			node = node->left;
		} else if (overlap(lo, hi, node)) {
			lowest_match = node;
			break;
		} else if (lo > node->lo) {
			// Lowest overlap if any must be on right side
			node = node->right;
		} else {
			break;
		}
	}
	return lowest_match;
}

Finding exact match will be to first find lowest match and then to follow
successor nodes looking for exact match, until the start of a node is beyond
the hi value we are looking for.
rfkill - RF kill switch support
===============================

1. Introduction
2. Implementation details
3. Kernel API
4. Userspace support


1. Introduction

The rfkill subsystem provides a generic interface to disabling any radio
transmitter in the system. When a transmitter is blocked, it shall not
radiate any power.

The subsystem also provides the ability to react on button presses and
disable all transmitters of a certain type (or all). This is intended for
situations where transmitters need to be turned off, for example on
aircraft.

The rfkill subsystem has a concept of "hard" and "soft" block, which
differ little in their meaning (block == transmitters off) but rather in
whether they can be changed or not:
 - hard block: read-only radio block that cannot be overriden by software
 - soft block: writable radio block (need not be readable) that is set by
               the system software.


2. Implementation details

The rfkill subsystem is composed of three main components:
 * the rfkill core,
 * the deprecated rfkill-input module (an input layer handler, being
   replaced by userspace policy code) and
 * the rfkill drivers.

The rfkill core provides API for kernel drivers to register their radio
transmitter with the kernel, methods for turning it on and off and, letting
the system know about hardware-disabled states that may be implemented on
the device.

The rfkill core code also notifies userspace of state changes, and provides
ways for userspace to query the current states. See the "Userspace support"
section below.

When the device is hard-blocked (either by a call to rfkill_set_hw_state()
or from query_hw_block) set_block() will be invoked for additional software
block, but drivers can ignore the method call since they can use the return
value of the function rfkill_set_hw_state() to sync the software state
instead of keeping track of calls to set_block(). In fact, drivers should
use the return value of rfkill_set_hw_state() unless the hardware actually
keeps track of soft and hard block separately.


3. Kernel API


Drivers for radio transmitters normally implement an rfkill driver.

Platform drivers might implement input devices if the rfkill button is just
that, a button. If that button influences the hardware then you need to
implement an rfkill driver instead. This also applies if the platform provides
a way to turn on/off the transmitter(s).

For some platforms, it is possible that the hardware state changes during
suspend/hibernation, in which case it will be necessary to update the rfkill
core with the current state is at resume time.

To create an rfkill driver, driver's Kconfig needs to have

	depends on RFKILL || !RFKILL

to ensure the driver cannot be built-in when rfkill is modular. The !RFKILL
case allows the driver to be built when rfkill is not configured, which which
case all rfkill API can still be used but will be provided by static inlines
which compile to almost nothing.

Calling rfkill_set_hw_state() when a state change happens is required from
rfkill drivers that control devices that can be hard-blocked unless they also
assign the poll_hw_block() callback (then the rfkill core will poll the
device). Don't do this unless you cannot get the event in any other way.



5. Userspace support

The recommended userspace interface to use is /dev/rfkill, which is a misc
character device that allows userspace to obtain and set the state of rfkill
devices and sets of devices. It also notifies userspace about device addition
and removal. The API is a simple read/write API that is defined in
linux/rfkill.h, with one ioctl that allows turning off the deprecated input
handler in the kernel for the transition period.

Except for the one ioctl, communication with the kernel is done via read()
and write() of instances of 'struct rfkill_event'. In this structure, the
soft and hard block are properly separated (unlike sysfs, see below) and
userspace is able to get a consistent snapshot of all rfkill devices in the
system. Also, it is possible to switch all rfkill drivers (or all drivers of
a specified type) into a state which also updates the default state for
hotplugged devices.

After an application opens /dev/rfkill, it can read the current state of all
devices. Changes can be either obtained by either polling the descriptor for
hotplug or state change events or by listening for uevents emitted by the
rfkill core framework.

Additionally, each rfkill device is registered in sysfs and emits uevents.

rfkill devices issue uevents (with an action of "change"), with the following
environment variables set:

RFKILL_NAME
RFKILL_STATE
RFKILL_TYPE

The contents of these variables corresponds to the "name", "state" and
"type" sysfs files explained above.


For further details consult Documentation/ABI/stable/dev-rfkill and
Documentation/ABI/stable/sysfs-class-rfkill.
Started by Paul Jackson <pj@sgi.com>

The robust futex ABI
--------------------

Robust_futexes provide a mechanism that is used in addition to normal
futexes, for kernel assist of cleanup of held locks on task exit.

The interesting data as to what futexes a thread is holding is kept on a
linked list in user space, where it can be updated efficiently as locks
are taken and dropped, without kernel intervention.  The only additional
kernel intervention required for robust_futexes above and beyond what is
required for futexes is:

 1) a one time call, per thread, to tell the kernel where its list of
    held robust_futexes begins, and
 2) internal kernel code at exit, to handle any listed locks held
    by the exiting thread.

The existing normal futexes already provide a "Fast Userspace Locking"
mechanism, which handles uncontested locking without needing a system
call, and handles contested locking by maintaining a list of waiting
threads in the kernel.  Options on the sys_futex(2) system call support
waiting on a particular futex, and waking up the next waiter on a
particular futex.

For robust_futexes to work, the user code (typically in a library such
as glibc linked with the application) has to manage and place the
necessary list elements exactly as the kernel expects them.  If it fails
to do so, then improperly listed locks will not be cleaned up on exit,
probably causing deadlock or other such failure of the other threads
waiting on the same locks.

A thread that anticipates possibly using robust_futexes should first
issue the system call:

    asmlinkage long
    sys_set_robust_list(struct robust_list_head __user *head, size_t len);

The pointer 'head' points to a structure in the threads address space
consisting of three words.  Each word is 32 bits on 32 bit arch's, or 64
bits on 64 bit arch's, and local byte order.  Each thread should have
its own thread private 'head'.

If a thread is running in 32 bit compatibility mode on a 64 native arch
kernel, then it can actually have two such structures - one using 32 bit
words for 32 bit compatibility mode, and one using 64 bit words for 64
bit native mode.  The kernel, if it is a 64 bit kernel supporting 32 bit
compatibility mode, will attempt to process both lists on each task
exit, if the corresponding sys_set_robust_list() call has been made to
setup that list.

  The first word in the memory structure at 'head' contains a
  pointer to a single linked list of 'lock entries', one per lock,
  as described below.  If the list is empty, the pointer will point
  to itself, 'head'.  The last 'lock entry' points back to the 'head'.

  The second word, called 'offset', specifies the offset from the
  address of the associated 'lock entry', plus or minus, of what will
  be called the 'lock word', from that 'lock entry'.  The 'lock word'
  is always a 32 bit word, unlike the other words above.  The 'lock
  word' holds 3 flag bits in the upper 3 bits, and the thread id (TID)
  of the thread holding the lock in the bottom 29 bits.  See further
  below for a description of the flag bits.

  The third word, called 'list_op_pending', contains transient copy of
  the address of the 'lock entry', during list insertion and removal,
  and is needed to correctly resolve races should a thread exit while
  in the middle of a locking or unlocking operation.

Each 'lock entry' on the single linked list starting at 'head' consists
of just a single word, pointing to the next 'lock entry', or back to
'head' if there are no more entries.  In addition, nearby to each 'lock
entry', at an offset from the 'lock entry' specified by the 'offset'
word, is one 'lock word'.

The 'lock word' is always 32 bits, and is intended to be the same 32 bit
lock variable used by the futex mechanism, in conjunction with
robust_futexes.  The kernel will only be able to wakeup the next thread
waiting for a lock on a threads exit if that next thread used the futex
mechanism to register the address of that 'lock word' with the kernel.

For each futex lock currently held by a thread, if it wants this
robust_futex support for exit cleanup of that lock, it should have one
'lock entry' on this list, with its associated 'lock word' at the
specified 'offset'.  Should a thread die while holding any such locks,
the kernel will walk this list, mark any such locks with a bit
indicating their holder died, and wakeup the next thread waiting for
that lock using the futex mechanism.

When a thread has invoked the above system call to indicate it
anticipates using robust_futexes, the kernel stores the passed in 'head'
pointer for that task.  The task may retrieve that value later on by
using the system call:

    asmlinkage long
    sys_get_robust_list(int pid, struct robust_list_head __user **head_ptr,
                        size_t __user *len_ptr);

It is anticipated that threads will use robust_futexes embedded in
larger, user level locking structures, one per lock.  The kernel
robust_futex mechanism doesn't care what else is in that structure, so
long as the 'offset' to the 'lock word' is the same for all
robust_futexes used by that thread.  The thread should link those locks
it currently holds using the 'lock entry' pointers.  It may also have
other links between the locks, such as the reverse side of a double
linked list, but that doesn't matter to the kernel.

By keeping its locks linked this way, on a list starting with a 'head'
pointer known to the kernel, the kernel can provide to a thread the
essential service available for robust_futexes, which is to help clean
up locks held at the time of (a perhaps unexpectedly) exit.

Actual locking and unlocking, during normal operations, is handled
entirely by user level code in the contending threads, and by the
existing futex mechanism to wait for, and wakeup, locks.  The kernels
only essential involvement in robust_futexes is to remember where the
list 'head' is, and to walk the list on thread exit, handling locks
still held by the departing thread, as described below.

There may exist thousands of futex lock structures in a threads shared
memory, on various data structures, at a given point in time. Only those
lock structures for locks currently held by that thread should be on
that thread's robust_futex linked lock list a given time.

A given futex lock structure in a user shared memory region may be held
at different times by any of the threads with access to that region. The
thread currently holding such a lock, if any, is marked with the threads
TID in the lower 29 bits of the 'lock word'.

When adding or removing a lock from its list of held locks, in order for
the kernel to correctly handle lock cleanup regardless of when the task
exits (perhaps it gets an unexpected signal 9 in the middle of
manipulating this list), the user code must observe the following
protocol on 'lock entry' insertion and removal:

On insertion:
 1) set the 'list_op_pending' word to the address of the 'lock entry'
    to be inserted,
 2) acquire the futex lock,
 3) add the lock entry, with its thread id (TID) in the bottom 29 bits
    of the 'lock word', to the linked list starting at 'head', and
 4) clear the 'list_op_pending' word.

On removal:
 1) set the 'list_op_pending' word to the address of the 'lock entry'
    to be removed,
 2) remove the lock entry for this lock from the 'head' list,
 2) release the futex lock, and
 2) clear the 'lock_op_pending' word.

On exit, the kernel will consider the address stored in
'list_op_pending' and the address of each 'lock word' found by walking
the list starting at 'head'.  For each such address, if the bottom 29
bits of the 'lock word' at offset 'offset' from that address equals the
exiting threads TID, then the kernel will do two things:

 1) if bit 31 (0x80000000) is set in that word, then attempt a futex
    wakeup on that address, which will waken the next thread that has
    used to the futex mechanism to wait on that address, and
 2) atomically set  bit 30 (0x40000000) in the 'lock word'.

In the above, bit 31 was set by futex waiters on that lock to indicate
they were waiting, and bit 30 is set by the kernel to indicate that the
lock owner died holding the lock.

The kernel exit code will silently stop scanning the list further if at
any point:

 1) the 'head' pointer or an subsequent linked list pointer
    is not a valid address of a user space word
 2) the calculated location of the 'lock word' (address plus
    'offset') is not the valid address of a 32 bit user space
    word
 3) if the list contains more than 1 million (subject to
    future kernel configuration changes) elements.

When the kernel sees a list entry whose 'lock word' doesn't have the
current threads TID in the lower 29 bits, it does nothing with that
entry, and goes on to the next entry.

Bit 29 (0x20000000) of the 'lock word' is reserved for future use.
Started by: Ingo Molnar <mingo@redhat.com>

Background
----------

what are robust futexes? To answer that, we first need to understand
what futexes are: normal futexes are special types of locks that in the
noncontended case can be acquired/released from userspace without having
to enter the kernel.

A futex is in essence a user-space address, e.g. a 32-bit lock variable
field. If userspace notices contention (the lock is already owned and
someone else wants to grab it too) then the lock is marked with a value
that says "there's a waiter pending", and the sys_futex(FUTEX_WAIT)
syscall is used to wait for the other guy to release it. The kernel
creates a 'futex queue' internally, so that it can later on match up the
waiter with the waker - without them having to know about each other.
When the owner thread releases the futex, it notices (via the variable
value) that there were waiter(s) pending, and does the
sys_futex(FUTEX_WAKE) syscall to wake them up.  Once all waiters have
taken and released the lock, the futex is again back to 'uncontended'
state, and there's no in-kernel state associated with it. The kernel
completely forgets that there ever was a futex at that address. This
method makes futexes very lightweight and scalable.

"Robustness" is about dealing with crashes while holding a lock: if a
process exits prematurely while holding a pthread_mutex_t lock that is
also shared with some other process (e.g. yum segfaults while holding a
pthread_mutex_t, or yum is kill -9-ed), then waiters for that lock need
to be notified that the last owner of the lock exited in some irregular
way.

To solve such types of problems, "robust mutex" userspace APIs were
created: pthread_mutex_lock() returns an error value if the owner exits
prematurely - and the new owner can decide whether the data protected by
the lock can be recovered safely.

There is a big conceptual problem with futex based mutexes though: it is
the kernel that destroys the owner task (e.g. due to a SEGFAULT), but
the kernel cannot help with the cleanup: if there is no 'futex queue'
(and in most cases there is none, futexes being fast lightweight locks)
then the kernel has no information to clean up after the held lock!
Userspace has no chance to clean up after the lock either - userspace is
the one that crashes, so it has no opportunity to clean up. Catch-22.

In practice, when e.g. yum is kill -9-ed (or segfaults), a system reboot
is needed to release that futex based lock. This is one of the leading
bugreports against yum.

To solve this problem, the traditional approach was to extend the vma
(virtual memory area descriptor) concept to have a notion of 'pending
robust futexes attached to this area'. This approach requires 3 new
syscall variants to sys_futex(): FUTEX_REGISTER, FUTEX_DEREGISTER and
FUTEX_RECOVER. At do_exit() time, all vmas are searched to see whether
they have a robust_head set. This approach has two fundamental problems
left:

 - it has quite complex locking and race scenarios. The vma-based
   approach had been pending for years, but they are still not completely
   reliable.

 - they have to scan _every_ vma at sys_exit() time, per thread!

The second disadvantage is a real killer: pthread_exit() takes around 1
microsecond on Linux, but with thousands (or tens of thousands) of vmas
every pthread_exit() takes a millisecond or more, also totally
destroying the CPU's L1 and L2 caches!

This is very much noticeable even for normal process sys_exit_group()
calls: the kernel has to do the vma scanning unconditionally! (this is
because the kernel has no knowledge about how many robust futexes there
are to be cleaned up, because a robust futex might have been registered
in another task, and the futex variable might have been simply mmap()-ed
into this process's address space).

This huge overhead forced the creation of CONFIG_FUTEX_ROBUST so that
normal kernels can turn it off, but worse than that: the overhead makes
robust futexes impractical for any type of generic Linux distribution.

So something had to be done.

New approach to robust futexes
------------------------------

At the heart of this new approach there is a per-thread private list of
robust locks that userspace is holding (maintained by glibc) - which
userspace list is registered with the kernel via a new syscall [this
registration happens at most once per thread lifetime]. At do_exit()
time, the kernel checks this user-space list: are there any robust futex
locks to be cleaned up?

In the common case, at do_exit() time, there is no list registered, so
the cost of robust futexes is just a simple current->robust_list != NULL
comparison. If the thread has registered a list, then normally the list
is empty. If the thread/process crashed or terminated in some incorrect
way then the list might be non-empty: in this case the kernel carefully
walks the list [not trusting it], and marks all locks that are owned by
this thread with the FUTEX_OWNER_DIED bit, and wakes up one waiter (if
any).

The list is guaranteed to be private and per-thread at do_exit() time,
so it can be accessed by the kernel in a lockless way.

There is one race possible though: since adding to and removing from the
list is done after the futex is acquired by glibc, there is a few
instructions window for the thread (or process) to die there, leaving
the futex hung. To protect against this possibility, userspace (glibc)
also maintains a simple per-thread 'list_op_pending' field, to allow the
kernel to clean up if the thread dies after acquiring the lock, but just
before it could have added itself to the list. Glibc sets this
list_op_pending field before it tries to acquire the futex, and clears
it after the list-add (or list-remove) has finished.

That's all that is needed - all the rest of robust-futex cleanup is done
in userspace [just like with the previous patches].

Ulrich Drepper has implemented the necessary glibc support for this new
mechanism, which fully enables robust mutexes.

Key differences of this userspace-list based approach, compared to the
vma based method:

 - it's much, much faster: at thread exit time, there's no need to loop
   over every vma (!), which the VM-based method has to do. Only a very
   simple 'is the list empty' op is done.

 - no VM changes are needed - 'struct address_space' is left alone.

 - no registration of individual locks is needed: robust mutexes dont
   need any extra per-lock syscalls. Robust mutexes thus become a very
   lightweight primitive - so they dont force the application designer
   to do a hard choice between performance and robustness - robust
   mutexes are just as fast.

 - no per-lock kernel allocation happens.

 - no resource limits are needed.

 - no kernel-space recovery call (FUTEX_RECOVER) is needed.

 - the implementation and the locking is "obvious", and there are no
   interactions with the VM.

Performance
-----------

I have benchmarked the time needed for the kernel to process a list of 1
million (!) held locks, using the new method [on a 2GHz CPU]:

 - with FUTEX_WAIT set [contended mutex]: 130 msecs
 - without FUTEX_WAIT set [uncontended mutex]: 30 msecs

I have also measured an approach where glibc does the lock notification
[which it currently does for !pshared robust mutexes], and that took 256
msecs - clearly slower, due to the 1 million FUTEX_WAKE syscalls
userspace had to do.

(1 million held locks are unheard of - we expect at most a handful of
locks to be held at a time. Nevertheless it's nice to know that this
approach scales nicely.)

Implementation details
----------------------

The patch adds two new syscalls: one to register the userspace list, and
one to query the registered list pointer:

 asmlinkage long
 sys_set_robust_list(struct robust_list_head __user *head,
                     size_t len);

 asmlinkage long
 sys_get_robust_list(int pid, struct robust_list_head __user **head_ptr,
                     size_t __user *len_ptr);

List registration is very fast: the pointer is simply stored in
current->robust_list. [Note that in the future, if robust futexes become
widespread, we could extend sys_clone() to register a robust-list head
for new threads, without the need of another syscall.]

So there is virtually zero overhead for tasks not using robust futexes,
and even for robust futex users, there is only one extra syscall per
thread lifetime, and the cleanup operation, if it happens, is fast and
straightforward. The kernel doesn't have any internal distinction between
robust and normal futexes.

If a futex is found to be held at exit time, the kernel sets the
following bit of the futex word:

	#define FUTEX_OWNER_DIED        0x40000000

and wakes up the next futex waiter (if any). User-space does the rest of
the cleanup.

Otherwise, robust futexes are acquired by glibc by putting the TID into
the futex field atomically. Waiters set the FUTEX_WAITERS bit:

	#define FUTEX_WAITERS           0x80000000

and the remaining bits are for the TID.

Testing, architecture support
-----------------------------

i've tested the new syscalls on x86 and x86_64, and have made sure the
parsing of the userspace list is robust [ ;-) ] even if the list is
deliberately corrupted.

i386 and x86_64 syscalls are wired up at the moment, and Ulrich has
tested the new glibc code (on x86_64 and i386), and it works for his
robust-mutex testcases.

All other architectures should build just fine too - but they wont have
the new syscalls yet.

Architectures need to implement the new futex_atomic_cmpxchg_inatomic()
inline function before writing up the syscalls (that function returns
-ENOSYS right now).

	Real Time Clock (RTC) Drivers for Linux
	=======================================

When Linux developers talk about a "Real Time Clock", they usually mean
something that tracks wall clock time and is battery backed so that it
works even with system power off.  Such clocks will normally not track
the local time zone or daylight savings time -- unless they dual boot
with MS-Windows -- but will instead be set to Coordinated Universal Time
(UTC, formerly "Greenwich Mean Time").

The newest non-PC hardware tends to just count seconds, like the time(2)
system call reports, but RTCs also very commonly represent time using
the Gregorian calendar and 24 hour time, as reported by gmtime(3).

Linux has two largely-compatible userspace RTC API families you may
need to know about:

    *	/dev/rtc ... is the RTC provided by PC compatible systems,
	so it's not very portable to non-x86 systems.

    *	/dev/rtc0, /dev/rtc1 ... are part of a framework that's
	supported by a wide variety of RTC chips on all systems.

Programmers need to understand that the PC/AT functionality is not
always available, and some systems can do much more.  That is, the
RTCs use the same API to make requests in both RTC frameworks (using
different filenames of course), but the hardware may not offer the
same functionality.  For example, not every RTC is hooked up to an
IRQ, so they can't all issue alarms; and where standard PC RTCs can
only issue an alarm up to 24 hours in the future, other hardware may
be able to schedule one any time in the upcoming century.


	Old PC/AT-Compatible driver:  /dev/rtc
	--------------------------------------

All PCs (even Alpha machines) have a Real Time Clock built into them.
Usually they are built into the chipset of the computer, but some may
actually have a Motorola MC146818 (or clone) on the board. This is the
clock that keeps the date and time while your computer is turned off.

ACPI has standardized that MC146818 functionality, and extended it in
a few ways (enabling longer alarm periods, and wake-from-hibernate).
That functionality is NOT exposed in the old driver.

However it can also be used to generate signals from a slow 2Hz to a
relatively fast 8192Hz, in increments of powers of two. These signals
are reported by interrupt number 8. (Oh! So *that* is what IRQ 8 is
for...) It can also function as a 24hr alarm, raising IRQ 8 when the
alarm goes off. The alarm can also be programmed to only check any
subset of the three programmable values, meaning that it could be set to
ring on the 30th second of the 30th minute of every hour, for example.
The clock can also be set to generate an interrupt upon every clock
update, thus generating a 1Hz signal.

The interrupts are reported via /dev/rtc (major 10, minor 135, read only
character device) in the form of an unsigned long. The low byte contains
the type of interrupt (update-done, alarm-rang, or periodic) that was
raised, and the remaining bytes contain the number of interrupts since
the last read.  Status information is reported through the pseudo-file
/proc/driver/rtc if the /proc filesystem was enabled.  The driver has
built in locking so that only one process is allowed to have the /dev/rtc
interface open at a time.

A user process can monitor these interrupts by doing a read(2) or a
select(2) on /dev/rtc -- either will block/stop the user process until
the next interrupt is received. This is useful for things like
reasonably high frequency data acquisition where one doesn't want to
burn up 100% CPU by polling gettimeofday etc. etc.

At high frequencies, or under high loads, the user process should check
the number of interrupts received since the last read to determine if
there has been any interrupt "pileup" so to speak. Just for reference, a
typical 486-33 running a tight read loop on /dev/rtc will start to suffer
occasional interrupt pileup (i.e. > 1 IRQ event since last read) for
frequencies above 1024Hz. So you really should check the high bytes
of the value you read, especially at frequencies above that of the
normal timer interrupt, which is 100Hz.

Programming and/or enabling interrupt frequencies greater than 64Hz is
only allowed by root. This is perhaps a bit conservative, but we don't want
an evil user generating lots of IRQs on a slow 386sx-16, where it might have
a negative impact on performance. This 64Hz limit can be changed by writing
a different value to /proc/sys/dev/rtc/max-user-freq. Note that the
interrupt handler is only a few lines of code to minimize any possibility
of this effect.

Also, if the kernel time is synchronized with an external source, the 
kernel will write the time back to the CMOS clock every 11 minutes. In 
the process of doing this, the kernel briefly turns off RTC periodic 
interrupts, so be aware of this if you are doing serious work. If you
don't synchronize the kernel time with an external source (via ntp or
whatever) then the kernel will keep its hands off the RTC, allowing you
exclusive access to the device for your applications.

The alarm and/or interrupt frequency are programmed into the RTC via
various ioctl(2) calls as listed in ./include/linux/rtc.h
Rather than write 50 pages describing the ioctl() and so on, it is
perhaps more useful to include a small test program that demonstrates
how to use them, and demonstrates the features of the driver. This is
probably a lot more useful to people interested in writing applications
that will be using this driver.  See the code at the end of this document.

(The original /dev/rtc driver was written by Paul Gortmaker.)


	New portable "RTC Class" drivers:  /dev/rtcN
	--------------------------------------------

Because Linux supports many non-ACPI and non-PC platforms, some of which
have more than one RTC style clock, it needed a more portable solution
than expecting a single battery-backed MC146818 clone on every system.
Accordingly, a new "RTC Class" framework has been defined.  It offers
three different userspace interfaces:

    *	/dev/rtcN ... much the same as the older /dev/rtc interface

    *	/sys/class/rtc/rtcN ... sysfs attributes support readonly
	access to some RTC attributes.

    *	/proc/driver/rtc ... the first RTC (rtc0) may expose itself
	using a procfs interface.  More information is (currently) shown
	here than through sysfs.

The RTC Class framework supports a wide variety of RTCs, ranging from those
integrated into embeddable system-on-chip (SOC) processors to discrete chips
using I2C, SPI, or some other bus to communicate with the host CPU.  There's
even support for PC-style RTCs ... including the features exposed on newer PCs
through ACPI.

The new framework also removes the "one RTC per system" restriction.  For
example, maybe the low-power battery-backed RTC is a discrete I2C chip, but
a high functionality RTC is integrated into the SOC.  That system might read
the system clock from the discrete RTC, but use the integrated one for all
other tasks, because of its greater functionality.

SYSFS INTERFACE
---------------

The sysfs interface under /sys/class/rtc/rtcN provides access to various
rtc attributes without requiring the use of ioctls. All dates and times
are in the RTC's timezone, rather than in system time.

date:  	   	 RTC-provided date
hctosys:   	 1 if the RTC provided the system time at boot via the
		 CONFIG_RTC_HCTOSYS kernel option, 0 otherwise
max_user_freq:	 The maximum interrupt rate an unprivileged user may request
		 from this RTC.
name:		 The name of the RTC corresponding to this sysfs directory
since_epoch:	 The number of seconds since the epoch according to the RTC
time:		 RTC-provided time
wakealarm:	 The time at which the clock will generate a system wakeup
		 event. This is a one shot wakeup event, so must be reset
		 after wake if a daily wakeup is required. Format is either
		 seconds since the epoch or, if there's a leading +, seconds
		 in the future.

IOCTL INTERFACE
---------------

The ioctl() calls supported by /dev/rtc are also supported by the RTC class
framework.  However, because the chips and systems are not standardized,
some PC/AT functionality might not be provided.  And in the same way, some
newer features -- including those enabled by ACPI -- are exposed by the
RTC class framework, but can't be supported by the older driver.

    *	RTC_RD_TIME, RTC_SET_TIME ... every RTC supports at least reading
	time, returning the result as a Gregorian calendar date and 24 hour
	wall clock time.  To be most useful, this time may also be updated.

    *	RTC_AIE_ON, RTC_AIE_OFF, RTC_ALM_SET, RTC_ALM_READ ... when the RTC
	is connected to an IRQ line, it can often issue an alarm IRQ up to
	24 hours in the future.  (Use RTC_WKALM_* by preference.)

    *	RTC_WKALM_SET, RTC_WKALM_RD ... RTCs that can issue alarms beyond
	the next 24 hours use a slightly more powerful API, which supports
	setting the longer alarm time and enabling its IRQ using a single
	request (using the same model as EFI firmware).

    *	RTC_UIE_ON, RTC_UIE_OFF ... if the RTC offers IRQs, the RTC framework
	will emulate this mechanism.

    *	RTC_PIE_ON, RTC_PIE_OFF, RTC_IRQP_SET, RTC_IRQP_READ ... these icotls
	are emulated via a kernel hrtimer.

In many cases, the RTC alarm can be a system wake event, used to force
Linux out of a low power sleep state (or hibernation) back to a fully
operational state.  For example, a system could enter a deep power saving
state until it's time to execute some scheduled tasks.

Note that many of these ioctls are handled by the common rtc-dev interface.
Some common examples:

    *	RTC_RD_TIME, RTC_SET_TIME: the read_time/set_time functions will be
	called with appropriate values.

    *	RTC_ALM_SET, RTC_ALM_READ, RTC_WKALM_SET, RTC_WKALM_RD: gets or sets
	the alarm rtc_timer. May call the set_alarm driver function.

    *	RTC_IRQP_SET, RTC_IRQP_READ: These are emulated by the generic code.

    *	RTC_PIE_ON, RTC_PIE_OFF: These are also emulated by the generic code.

If all else fails, check out the rtc-test.c driver!


-------------------- 8< ---------------- 8< -----------------------------

/*
 *      Real Time Clock Driver Test/Example Program
 *
 *      Compile with:
 *		     gcc -s -Wall -Wstrict-prototypes rtctest.c -o rtctest
 *
 *      Copyright (C) 1996, Paul Gortmaker.
 *
 *      Released under the GNU General Public License, version 2,
 *      included herein by reference.
 *
 */

#include <stdio.h>
#include <linux/rtc.h>
#include <sys/ioctl.h>
#include <sys/time.h>
#include <sys/types.h>
#include <fcntl.h>
#include <unistd.h>
#include <stdlib.h>
#include <errno.h>


/*
 * This expects the new RTC class driver framework, working with
 * clocks that will often not be clones of what the PC-AT had.
 * Use the command line to specify another RTC if you need one.
 */
static const char default_rtc[] = "/dev/rtc0";


int main(int argc, char **argv)
{
	int i, fd, retval, irqcount = 0;
	unsigned long tmp, data;
	struct rtc_time rtc_tm;
	const char *rtc = default_rtc;

	switch (argc) {
	case 2:
		rtc = argv[1];
		/* FALLTHROUGH */
	case 1:
		break;
	default:
		fprintf(stderr, "usage:  rtctest [rtcdev]\n");
		return 1;
	}

	fd = open(rtc, O_RDONLY);

	if (fd ==  -1) {
		perror(rtc);
		exit(errno);
	}

	fprintf(stderr, "\n\t\t\tRTC Driver Test Example.\n\n");

	/* Turn on update interrupts (one per second) */
	retval = ioctl(fd, RTC_UIE_ON, 0);
	if (retval == -1) {
		if (errno == ENOTTY) {
			fprintf(stderr,
				"\n...Update IRQs not supported.\n");
			goto test_READ;
		}
		perror("RTC_UIE_ON ioctl");
		exit(errno);
	}

	fprintf(stderr, "Counting 5 update (1/sec) interrupts from reading %s:",
			rtc);
	fflush(stderr);
	for (i=1; i<6; i++) {
		/* This read will block */
		retval = read(fd, &data, sizeof(unsigned long));
		if (retval == -1) {
			perror("read");
			exit(errno);
		}
		fprintf(stderr, " %d",i);
		fflush(stderr);
		irqcount++;
	}

	fprintf(stderr, "\nAgain, from using select(2) on /dev/rtc:");
	fflush(stderr);
	for (i=1; i<6; i++) {
		struct timeval tv = {5, 0};     /* 5 second timeout on select */
		fd_set readfds;

		FD_ZERO(&readfds);
		FD_SET(fd, &readfds);
		/* The select will wait until an RTC interrupt happens. */
		retval = select(fd+1, &readfds, NULL, NULL, &tv);
		if (retval == -1) {
		        perror("select");
		        exit(errno);
		}
		/* This read won't block unlike the select-less case above. */
		retval = read(fd, &data, sizeof(unsigned long));
		if (retval == -1) {
		        perror("read");
		        exit(errno);
		}
		fprintf(stderr, " %d",i);
		fflush(stderr);
		irqcount++;
	}

	/* Turn off update interrupts */
	retval = ioctl(fd, RTC_UIE_OFF, 0);
	if (retval == -1) {
		perror("RTC_UIE_OFF ioctl");
		exit(errno);
	}

test_READ:
	/* Read the RTC time/date */
	retval = ioctl(fd, RTC_RD_TIME, &rtc_tm);
	if (retval == -1) {
		perror("RTC_RD_TIME ioctl");
		exit(errno);
	}

	fprintf(stderr, "\n\nCurrent RTC date/time is %d-%d-%d, %02d:%02d:%02d.\n",
		rtc_tm.tm_mday, rtc_tm.tm_mon + 1, rtc_tm.tm_year + 1900,
		rtc_tm.tm_hour, rtc_tm.tm_min, rtc_tm.tm_sec);

	/* Set the alarm to 5 sec in the future, and check for rollover */
	rtc_tm.tm_sec += 5;
	if (rtc_tm.tm_sec >= 60) {
		rtc_tm.tm_sec %= 60;
		rtc_tm.tm_min++;
	}
	if (rtc_tm.tm_min == 60) {
		rtc_tm.tm_min = 0;
		rtc_tm.tm_hour++;
	}
	if (rtc_tm.tm_hour == 24)
		rtc_tm.tm_hour = 0;

	retval = ioctl(fd, RTC_ALM_SET, &rtc_tm);
	if (retval == -1) {
		if (errno == ENOTTY) {
			fprintf(stderr,
				"\n...Alarm IRQs not supported.\n");
			goto test_PIE;
		}
		perror("RTC_ALM_SET ioctl");
		exit(errno);
	}

	/* Read the current alarm settings */
	retval = ioctl(fd, RTC_ALM_READ, &rtc_tm);
	if (retval == -1) {
		perror("RTC_ALM_READ ioctl");
		exit(errno);
	}

	fprintf(stderr, "Alarm time now set to %02d:%02d:%02d.\n",
		rtc_tm.tm_hour, rtc_tm.tm_min, rtc_tm.tm_sec);

	/* Enable alarm interrupts */
	retval = ioctl(fd, RTC_AIE_ON, 0);
	if (retval == -1) {
		perror("RTC_AIE_ON ioctl");
		exit(errno);
	}

	fprintf(stderr, "Waiting 5 seconds for alarm...");
	fflush(stderr);
	/* This blocks until the alarm ring causes an interrupt */
	retval = read(fd, &data, sizeof(unsigned long));
	if (retval == -1) {
		perror("read");
		exit(errno);
	}
	irqcount++;
	fprintf(stderr, " okay. Alarm rang.\n");

	/* Disable alarm interrupts */
	retval = ioctl(fd, RTC_AIE_OFF, 0);
	if (retval == -1) {
		perror("RTC_AIE_OFF ioctl");
		exit(errno);
	}

test_PIE:
	/* Read periodic IRQ rate */
	retval = ioctl(fd, RTC_IRQP_READ, &tmp);
	if (retval == -1) {
		/* not all RTCs support periodic IRQs */
		if (errno == ENOTTY) {
			fprintf(stderr, "\nNo periodic IRQ support\n");
			goto done;
		}
		perror("RTC_IRQP_READ ioctl");
		exit(errno);
	}
	fprintf(stderr, "\nPeriodic IRQ rate is %ldHz.\n", tmp);

	fprintf(stderr, "Counting 20 interrupts at:");
	fflush(stderr);

	/* The frequencies 128Hz, 256Hz, ... 8192Hz are only allowed for root. */
	for (tmp=2; tmp<=64; tmp*=2) {

		retval = ioctl(fd, RTC_IRQP_SET, tmp);
		if (retval == -1) {
			/* not all RTCs can change their periodic IRQ rate */
			if (errno == ENOTTY) {
				fprintf(stderr,
					"\n...Periodic IRQ rate is fixed\n");
				goto done;
			}
			perror("RTC_IRQP_SET ioctl");
			exit(errno);
		}

		fprintf(stderr, "\n%ldHz:\t", tmp);
		fflush(stderr);

		/* Enable periodic interrupts */
		retval = ioctl(fd, RTC_PIE_ON, 0);
		if (retval == -1) {
			perror("RTC_PIE_ON ioctl");
			exit(errno);
		}

		for (i=1; i<21; i++) {
			/* This blocks */
			retval = read(fd, &data, sizeof(unsigned long));
			if (retval == -1) {
				perror("read");
				exit(errno);
			}
			fprintf(stderr, " %d",i);
			fflush(stderr);
			irqcount++;
		}

		/* Disable periodic interrupts */
		retval = ioctl(fd, RTC_PIE_OFF, 0);
		if (retval == -1) {
			perror("RTC_PIE_OFF ioctl");
			exit(errno);
		}
	}

done:
	fprintf(stderr, "\n\n\t\t\t *** Test complete ***\n");

	close(fd);

	return 0;
}
RT-mutex subsystem with PI support
----------------------------------

RT-mutexes with priority inheritance are used to support PI-futexes,
which enable pthread_mutex_t priority inheritance attributes
(PTHREAD_PRIO_INHERIT). [See Documentation/pi-futex.txt for more details
about PI-futexes.]

This technology was developed in the -rt tree and streamlined for
pthread_mutex support.

Basic principles:
-----------------

RT-mutexes extend the semantics of simple mutexes by the priority
inheritance protocol.

A low priority owner of a rt-mutex inherits the priority of a higher
priority waiter until the rt-mutex is released. If the temporarily
boosted owner blocks on a rt-mutex itself it propagates the priority
boosting to the owner of the other rt_mutex it gets blocked on. The
priority boosting is immediately removed once the rt_mutex has been
unlocked.

This approach allows us to shorten the block of high-prio tasks on
mutexes which protect shared resources. Priority inheritance is not a
magic bullet for poorly designed applications, but it allows
well-designed applications to use userspace locks in critical parts of
an high priority thread, without losing determinism.

The enqueueing of the waiters into the rtmutex waiter list is done in
priority order. For same priorities FIFO order is chosen. For each
rtmutex, only the top priority waiter is enqueued into the owner's
priority waiters list. This list too queues in priority order. Whenever
the top priority waiter of a task changes (for example it timed out or
got a signal), the priority of the owner task is readjusted. [The
priority enqueueing is handled by "plists", see include/linux/plist.h
for more details.]

RT-mutexes are optimized for fastpath operations and have no internal
locking overhead when locking an uncontended mutex or unlocking a mutex
without waiters. The optimized fastpath operations require cmpxchg
support. [If that is not available then the rt-mutex internal spinlock
is used]

The state of the rt-mutex is tracked via the owner field of the rt-mutex
structure:

rt_mutex->owner holds the task_struct pointer of the owner. Bit 0 and 1
are used to keep track of the "owner is pending" and "rtmutex has
waiters" state.

 owner		bit1	bit0
 NULL		0	0	mutex is free (fast acquire possible)
 NULL		0	1	invalid state
 NULL		1	0	Transitional state*
 NULL		1	1	invalid state
 taskpointer	0	0	mutex is held (fast release possible)
 taskpointer	0	1	task is pending owner
 taskpointer	1	0	mutex is held and has waiters
 taskpointer	1	1	task is pending owner and mutex has waiters

Pending-ownership handling is a performance optimization:
pending-ownership is assigned to the first (highest priority) waiter of
the mutex, when the mutex is released. The thread is woken up and once
it starts executing it can acquire the mutex. Until the mutex is taken
by it (bit 0 is cleared) a competing higher priority thread can "steal"
the mutex which puts the woken up thread back on the waiters list.

The pending-ownership optimization is especially important for the
uninterrupted workflow of high-prio tasks which repeatedly
takes/releases locks that have lower-prio waiters. Without this
optimization the higher-prio thread would ping-pong to the lower-prio
task [because at unlock time we always assign a new owner].

(*) The "mutex has waiters" bit gets set to take the lock. If the lock
doesn't already have an owner, this bit is quickly cleared if there are
no waiters.  So this is a transitional state to synchronize with looking
at the owner field of the mutex and the mutex owner releasing the lock.
Linux 2.4.2 Secure Attention Key (SAK) handling
18 March 2001, Andrew Morton

An operating system's Secure Attention Key is a security tool which is
provided as protection against trojan password capturing programs.  It
is an undefeatable way of killing all programs which could be
masquerading as login applications.  Users need to be taught to enter
this key sequence before they log in to the system.

From the PC keyboard, Linux has two similar but different ways of
providing SAK.  One is the ALT-SYSRQ-K sequence.  You shouldn't use
this sequence.  It is only available if the kernel was compiled with
sysrq support.

The proper way of generating a SAK is to define the key sequence using
`loadkeys'.  This will work whether or not sysrq support is compiled
into the kernel.

SAK works correctly when the keyboard is in raw mode.  This means that
once defined, SAK will kill a running X server.  If the system is in
run level 5, the X server will restart.  This is what you want to
happen.

What key sequence should you use? Well, CTRL-ALT-DEL is used to reboot
the machine.  CTRL-ALT-BACKSPACE is magical to the X server.  We'll
choose CTRL-ALT-PAUSE.

In your rc.sysinit (or rc.local) file, add the command

	echo "control alt keycode 101 = SAK" | /bin/loadkeys

And that's it!  Only the superuser may reprogram the SAK key.


NOTES
=====

1: Linux SAK is said to be not a "true SAK" as is required by
   systems which implement C2 level security.  This author does not
   know why.


2: On the PC keyboard, SAK kills all applications which have
   /dev/console opened.

   Unfortunately this includes a number of things which you don't
   actually want killed.  This is because these applications are
   incorrectly holding /dev/console open.  Be sure to complain to your
   Linux distributor about this!

   You can identify processes which will be killed by SAK with the
   command

	# ls -l /proc/[0-9]*/fd/* | grep console
	l-wx------    1 root     root           64 Mar 18 00:46 /proc/579/fd/0 -> /dev/console

   Then:

	# ps aux|grep 579
	root       579  0.0  0.1  1088  436 ?        S    00:43   0:00 gpm -t ps/2

   So `gpm' will be killed by SAK.  This is a bug in gpm.  It should
   be closing standard input.  You can work around this by finding the
   initscript which launches gpm and changing it thusly:

   Old:

	daemon gpm

   New:

	daemon gpm < /dev/null

   Vixie cron also seems to have this problem, and needs the same treatment.

   Also, one prominent Linux distribution has the following three
   lines in its rc.sysinit and rc scripts:

	exec 3<&0
	exec 4>&1
	exec 5>&2

   These commands cause *all* daemons which are launched by the
   initscripts to have file descriptors 3, 4 and 5 attached to
   /dev/console.  So SAK kills them all.  A workaround is to simply
   delete these lines, but this may cause system management
   applications to malfunction - test everything well.

Linux kernel developers take security very seriously.  As such, we'd
like to know when a security bug is found so that it can be fixed and
disclosed as quickly as possible.  Please report security bugs to the
Linux kernel security team.

1) Contact

The Linux kernel security team can be contacted by email at
<security@kernel.org>.  This is a private list of security officers
who will help verify the bug report and develop and release a fix.
It is possible that the security team will bring in extra help from
area maintainers to understand and fix the security vulnerability.

As it is with any bug, the more information provided the easier it
will be to diagnose and fix.  Please review the procedure outlined in
REPORTING-BUGS if you are unclear about what information is helpful.
Any exploit code is very helpful and will not be released without
consent from the reporter unless it has already been made public.

2) Disclosure

The goal of the Linux kernel security team is to work with the
bug submitter to bug resolution as well as disclosure.  We prefer
to fully disclose the bug as soon as possible.  It is reasonable to
delay disclosure when the bug or the fix is not yet fully understood,
the solution is not well-tested or for vendor coordination.  However, we
expect these delays to be short, measurable in days, not weeks or months.
A disclosure date is negotiated by the security team working with the
bug submitter as well as vendors.  However, the kernel security team
holds the final say when setting a disclosure date.  The timeframe for
disclosure is from immediate (esp. if it's already publicly known)
to a few weeks.  As a basic default policy, we expect report date to
disclosure date to be on the order of 7 days.

3) Non-disclosure agreements

The Linux kernel security team is not a formal body and therefore unable
to enter any non-disclosure agreements.
                       Linux Serial Console

To use a serial port as console you need to compile the support into your
kernel - by default it is not compiled in. For PC style serial ports
it's the config option next to "Standard/generic (dumb) serial support".
You must compile serial support into the kernel and not as a module.

It is possible to specify multiple devices for console output. You can
define a new kernel command line option to select which device(s) to
use for console output.

The format of this option is:

	console=device,options

	device:		tty0 for the foreground virtual console
			ttyX for any other virtual console
			ttySx for a serial port
			lp0 for the first parallel port
			ttyUSB0 for the first USB serial device

	options:	depend on the driver. For the serial port this
			defines the baudrate/parity/bits/flow control of
			the port, in the format BBBBPNF, where BBBB is the
			speed, P is parity (n/o/e), N is number of bits,
			and F is flow control ('r' for RTS). Default is
			9600n8. The maximum baudrate is 115200.

You can specify multiple console= options on the kernel command line.
Output will appear on all of them. The last device will be used when
you open /dev/console. So, for example:

	console=ttyS1,9600 console=tty0

defines that opening /dev/console will get you the current foreground
virtual console, and kernel messages will appear on both the VGA
console and the 2nd serial port (ttyS1 or COM2) at 9600 baud.

Note that you can only define one console per device type (serial, video).

If no console device is specified, the first device found capable of
acting as a system console will be used. At this time, the system
first looks for a VGA card and then for a serial port. So if you don't
have a VGA card in your system the first serial port will automatically
become the console.

You will need to create a new device to use /dev/console. The official
/dev/console is now character device 5,1.

(You can also use a network device as a console.  See
Documentation/networking/netconsole.txt for information on that.)

Here's an example that will use /dev/ttyS1 (COM2) as the console.
Replace the sample values as needed.

1. Create /dev/console (real console) and /dev/tty0 (master virtual
   console):

   cd /dev
   rm -f console tty0
   mknod -m 622 console c 5 1
   mknod -m 622 tty0 c 4 0

2. LILO can also take input from a serial device. This is a very
   useful option. To tell LILO to use the serial port:
   In lilo.conf (global section): 

   serial  = 1,9600n8 (ttyS1, 9600 bd, no parity, 8 bits)

3. Adjust to kernel flags for the new kernel,
   again in lilo.conf (kernel section)

   append = "console=ttyS1,9600" 

4. Make sure a getty runs on the serial port so that you can login to
   it once the system is done booting. This is done by adding a line
   like this to /etc/inittab (exact syntax depends on your getty):

   S1:23:respawn:/sbin/getty -L ttyS1 9600 vt100

5. Init and /etc/ioctl.save

   Sysvinit remembers its stty settings in a file in /etc, called
   `/etc/ioctl.save'. REMOVE THIS FILE before using the serial
   console for the first time, because otherwise init will probably
   set the baudrate to 38400 (baudrate of the virtual console).

6. /dev/console and X
   Programs that want to do something with the virtual console usually
   open /dev/console. If you have created the new /dev/console device,
   and your console is NOT the virtual console some programs will fail.
   Those are programs that want to access the VT interface, and use
   /dev/console instead of /dev/tty0. Some of those programs are:

   Xfree86, svgalib, gpm, SVGATextMode

   It should be fixed in modern versions of these programs though.

   Note that if you boot without a console= option (or with
   console=/dev/tty0), /dev/console is the same as /dev/tty0. In that
   case everything will still work.

7. Thanks

   Thanks to Geert Uytterhoeven <geert@linux-m68k.org>
   for porting the patches from 2.1.4x to 2.1.6x for taking care of
   the integration of these patches into m68k, ppc and alpha.

Miquel van Smoorenburg <miquels@cistron.nl>, 11-Jun-2000
The SGI IOC4 PCI device is a bit of a strange beast, so some notes on
it are in order.

First, even though the IOC4 performs multiple functions, such as an
IDE controller, a serial controller, a PS/2 keyboard/mouse controller,
and an external interrupt mechanism, it's not implemented as a
multifunction device.  The consequence of this from a software
standpoint is that all these functions share a single IRQ, and
they can't all register to own the same PCI device ID.  To make
matters a bit worse, some of the register blocks (and even registers
themselves) present in IOC4 are mixed-purpose between these several
functions, meaning that there's no clear "owning" device driver.

The solution is to organize the IOC4 driver into several independent
drivers, "ioc4", "sgiioc4", and "ioc4_serial".  Note that there is no
PS/2 controller driver as this functionality has never been wired up
on a shipping IO card.

ioc4
====
This is the core (or shim) driver for IOC4.  It is responsible for
initializing the basic functionality of the chip, and allocating
the PCI resources that are shared between the IOC4 functions.

This driver also provides registration functions that the other
IOC4 drivers can call to make their presence known.  Each driver
needs to provide a probe and remove function, which are invoked
by the core driver at appropriate times.  The interface of these
IOC4 function probe and remove operations isn't precisely the same
as PCI device probe and remove operations, but is logically the
same operation.

sgiioc4
=======
This is the IDE driver for IOC4.  Its name isn't very descriptive
simply for historical reasons (it used to be the only IOC4 driver
component).  There's not much to say about it other than it hooks
up to the ioc4 driver via the appropriate registration, probe, and
remove functions.

ioc4_serial
===========
This is the serial driver for IOC4.  There's not much to say about it
other than it hooks up to the ioc4 driver via the appropriate registration,
probe, and remove functions.

The SGI Visual Workstations (models 320 and 540) are based around
the Cobalt, Lithium, and Arsenic ASICs.  The Cobalt ASIC is the
main system ASIC which interfaces the 1-4 IA32 cpus, the memory
system, and the I/O system in the Lithium ASIC.  The Cobalt ASIC
also contains the 3D gfx rendering engine which renders to main
system memory -- part of which is used as the frame buffer which
is DMA'ed to a video connector using the Arsenic ASIC.  A PIIX4
chip and NS87307 are used to provide legacy device support (IDE,
serial, floppy, and parallel).

The Visual Workstation chipset largely conforms to the PC architecture
with some notable exceptions such as interrupt handling.
			SM501 Driver
			============

Copyright 2006, 2007 Simtec Electronics

The Silicon Motion SM501 multimedia companion chip is a multifunction device
which may provide numerous interfaces including USB host controller USB gadget,
asynchronous serial ports, audio functions, and a dual display video interface.
The device may be connected by PCI or local bus with varying functions enabled.

Core
----

The core driver in drivers/mfd provides common services for the
drivers which manage the specific hardware blocks. These services
include locking for common registers, clock control and resource
management.

The core registers drivers for both PCI and generic bus based
chips via the platform device and driver system.

On detection of a device, the core initialises the chip (which may
be specified by the platform data) and then exports the selected
peripheral set as platform devices for the specific drivers.

The core re-uses the platform device system as the platform device
system provides enough features to support the drivers without the
need to create a new bus-type and the associated code to go with it.


Resources
---------

Each peripheral has a view of the device which is implicitly narrowed to
the specific set of resources that peripheral requires in order to
function correctly.

The centralised memory allocation allows the driver to ensure that the
maximum possible resource allocation can be made to the video subsystem
as this is by-far the most resource-sensitive of the on-chip functions.

The primary issue with memory allocation is that of moving the video
buffers once a display mode is chosen. Indeed when a video mode change
occurs the memory footprint of the video subsystem changes.

Since video memory is difficult to move without changing the display
(unless sufficient contiguous memory can be provided for the old and new
modes simultaneously) the video driver fully utilises the memory area
given to it by aligning fb0 to the start of the area and fb1 to the end
of it. Any memory left over in the middle is used for the acceleration
functions, which are transient and thus their location is less critical
as it can be moved.


Configuration
-------------

The platform device driver uses a set of platform data to pass
configurations through to the core and the subsidiary drivers
so that there can be support for more than one system carrying
an SM501 built into a single kernel image.

The PCI driver assumes that the PCI card behaves as per the Silicon
Motion reference design.

There is an errata (AB-5) affecting the selection of the
of the M1XCLK and M1CLK frequencies. These two clocks
must be sourced from the same PLL, although they can then
be divided down individually. If this is not set, then SM501 may
lock and hang the whole system. The driver will refuse to
attach if the PLL selection is different.
Copyright 2004 Linus Torvalds
Copyright 2004 Pavel Machek <pavel@ucw.cz>
Copyright 2006 Bob Copeland <me@bobcopeland.com>

Using sparse for typechecking
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

"__bitwise" is a type attribute, so you have to do something like this:

        typedef int __bitwise pm_request_t;

        enum pm_request {
                PM_SUSPEND = (__force pm_request_t) 1,
                PM_RESUME = (__force pm_request_t) 2
        };

which makes PM_SUSPEND and PM_RESUME "bitwise" integers (the "__force" is
there because sparse will complain about casting to/from a bitwise type,
but in this case we really _do_ want to force the conversion). And because
the enum values are all the same type, now "enum pm_request" will be that
type too.

And with gcc, all the __bitwise/__force stuff goes away, and it all ends
up looking just like integers to gcc.

Quite frankly, you don't need the enum there. The above all really just
boils down to one special "int __bitwise" type.

So the simpler way is to just do

        typedef int __bitwise pm_request_t;

        #define PM_SUSPEND ((__force pm_request_t) 1)
        #define PM_RESUME ((__force pm_request_t) 2)

and you now have all the infrastructure needed for strict typechecking.

One small note: the constant integer "0" is special. You can use a
constant zero as a bitwise integer type without sparse ever complaining.
This is because "bitwise" (as the name implies) was designed for making
sure that bitwise types don't get mixed up (little-endian vs big-endian
vs cpu-endian vs whatever), and there the constant "0" really _is_
special.

__bitwise__ - to be used for relatively compact stuff (gfp_t, etc.) that
is mostly warning-free and is supposed to stay that way.  Warnings will
be generated without __CHECK_ENDIAN__.

__bitwise - noisy stuff; in particular, __le*/__be* are that.  We really
don't want to drown in noise unless we'd explicitly asked for it.


Getting sparse
~~~~~~~~~~~~~~

You can get latest released versions from the Sparse homepage at
https://sparse.wiki.kernel.org/index.php/Main_Page

Alternatively, you can get snapshots of the latest development version
of sparse using git to clone..

        git://git.kernel.org/pub/scm/devel/sparse/sparse.git

DaveJ has hourly generated tarballs of the git tree available at..

        http://www.codemonkey.org.uk/projects/git-snapshots/sparse/


Once you have it, just do

        make
        make install

as a regular user, and it will install sparse in your ~/bin directory.

Using sparse
~~~~~~~~~~~~

Do a kernel make with "make C=1" to run sparse on all the C files that get
recompiled, or use "make C=2" to run sparse on the files whether they need to
be recompiled or not.  The latter is a fast way to check the whole tree if you
have already built it.

The optional make variable CF can be used to pass arguments to sparse.  The
build system passes -Wbitwise to sparse automatically.  To perform endianness
checks, you may define __CHECK_ENDIAN__:

        make C=2 CF="-D__CHECK_ENDIAN__"

These checks are disabled by default as they generate a host of warnings.
Lesson 1: Spin locks

The most basic primitive for locking is spinlock.

static DEFINE_SPINLOCK(xxx_lock);

	unsigned long flags;

	spin_lock_irqsave(&xxx_lock, flags);
	... critical section here ..
	spin_unlock_irqrestore(&xxx_lock, flags);

The above is always safe. It will disable interrupts _locally_, but the
spinlock itself will guarantee the global lock, so it will guarantee that
there is only one thread-of-control within the region(s) protected by that
lock. This works well even under UP also, so the code does _not_ need to
worry about UP vs SMP issues: the spinlocks work correctly under both.

   NOTE! Implications of spin_locks for memory are further described in:

     Documentation/memory-barriers.txt
       (5) LOCK operations.
       (6) UNLOCK operations.

The above is usually pretty simple (you usually need and want only one
spinlock for most things - using more than one spinlock can make things a
lot more complex and even slower and is usually worth it only for
sequences that you _know_ need to be split up: avoid it at all cost if you
aren't sure).

This is really the only really hard part about spinlocks: once you start
using spinlocks they tend to expand to areas you might not have noticed
before, because you have to make sure the spinlocks correctly protect the
shared data structures _everywhere_ they are used. The spinlocks are most
easily added to places that are completely independent of other code (for
example, internal driver data structures that nobody else ever touches).

   NOTE! The spin-lock is safe only when you _also_ use the lock itself
   to do locking across CPU's, which implies that EVERYTHING that
   touches a shared variable has to agree about the spinlock they want
   to use.

----

Lesson 2: reader-writer spinlocks.

If your data accesses have a very natural pattern where you usually tend
to mostly read from the shared variables, the reader-writer locks
(rw_lock) versions of the spinlocks are sometimes useful. They allow multiple
readers to be in the same critical region at once, but if somebody wants
to change the variables it has to get an exclusive write lock.

   NOTE! reader-writer locks require more atomic memory operations than
   simple spinlocks.  Unless the reader critical section is long, you
   are better off just using spinlocks.

The routines look the same as above:

   rwlock_t xxx_lock = __RW_LOCK_UNLOCKED(xxx_lock);

	unsigned long flags;

	read_lock_irqsave(&xxx_lock, flags);
	.. critical section that only reads the info ...
	read_unlock_irqrestore(&xxx_lock, flags);

	write_lock_irqsave(&xxx_lock, flags);
	.. read and write exclusive access to the info ...
	write_unlock_irqrestore(&xxx_lock, flags);

The above kind of lock may be useful for complex data structures like
linked lists, especially searching for entries without changing the list
itself.  The read lock allows many concurrent readers.  Anything that
_changes_ the list will have to get the write lock.

   NOTE! RCU is better for list traversal, but requires careful
   attention to design detail (see Documentation/RCU/listRCU.txt).

Also, you cannot "upgrade" a read-lock to a write-lock, so if you at _any_
time need to do any changes (even if you don't do it every time), you have
to get the write-lock at the very beginning.

   NOTE! We are working hard to remove reader-writer spinlocks in most
   cases, so please don't add a new one without consensus.  (Instead, see
   Documentation/RCU/rcu.txt for complete information.)

----

Lesson 3: spinlocks revisited.

The single spin-lock primitives above are by no means the only ones. They
are the most safe ones, and the ones that work under all circumstances,
but partly _because_ they are safe they are also fairly slow. They are slower
than they'd need to be, because they do have to disable interrupts
(which is just a single instruction on a x86, but it's an expensive one -
and on other architectures it can be worse).

If you have a case where you have to protect a data structure across
several CPU's and you want to use spinlocks you can potentially use
cheaper versions of the spinlocks. IFF you know that the spinlocks are
never used in interrupt handlers, you can use the non-irq versions:

	spin_lock(&lock);
	...
	spin_unlock(&lock);

(and the equivalent read-write versions too, of course). The spinlock will
guarantee the same kind of exclusive access, and it will be much faster. 
This is useful if you know that the data in question is only ever
manipulated from a "process context", ie no interrupts involved. 

The reasons you mustn't use these versions if you have interrupts that
play with the spinlock is that you can get deadlocks:

	spin_lock(&lock);
	...
		<- interrupt comes in:
			spin_lock(&lock);

where an interrupt tries to lock an already locked variable. This is ok if
the other interrupt happens on another CPU, but it is _not_ ok if the
interrupt happens on the same CPU that already holds the lock, because the
lock will obviously never be released (because the interrupt is waiting
for the lock, and the lock-holder is interrupted by the interrupt and will
not continue until the interrupt has been processed). 

(This is also the reason why the irq-versions of the spinlocks only need
to disable the _local_ interrupts - it's ok to use spinlocks in interrupts
on other CPU's, because an interrupt on another CPU doesn't interrupt the
CPU that holds the lock, so the lock-holder can continue and eventually
releases the lock). 

Note that you can be clever with read-write locks and interrupts. For
example, if you know that the interrupt only ever gets a read-lock, then
you can use a non-irq version of read locks everywhere - because they
don't block on each other (and thus there is no dead-lock wrt interrupts. 
But when you do the write-lock, you have to use the irq-safe version. 

For an example of being clever with rw-locks, see the "waitqueue_lock" 
handling in kernel/sched.c - nothing ever _changes_ a wait-queue from
within an interrupt, they only read the queue in order to know whom to
wake up. So read-locks are safe (which is good: they are very common
indeed), while write-locks need to protect themselves against interrupts.

		Linus

----

Reference information:

For dynamic initialization, use spin_lock_init() or rwlock_init() as
appropriate:

   spinlock_t xxx_lock;
   rwlock_t xxx_rw_lock;

   static int __init xxx_init(void)
   {
	spin_lock_init(&xxx_lock);
	rwlock_init(&xxx_rw_lock);
	...
   }

   module_init(xxx_init);

For static initialization, use DEFINE_SPINLOCK() / DEFINE_RWLOCK() or
__SPIN_LOCK_UNLOCKED() / __RW_LOCK_UNLOCKED() as appropriate.
Everything you ever wanted to know about Linux 2.6 -stable releases.

Rules on what kind of patches are accepted, and which ones are not, into the
"-stable" tree:

 - It must be obviously correct and tested.
 - It cannot be bigger than 100 lines, with context.
 - It must fix only one thing.
 - It must fix a real bug that bothers people (not a, "This could be a
   problem..." type thing).
 - It must fix a problem that causes a build error (but not for things
   marked CONFIG_BROKEN), an oops, a hang, data corruption, a real
   security issue, or some "oh, that's not good" issue.  In short, something
   critical.
 - New device IDs and quirks are also accepted.
 - No "theoretical race condition" issues, unless an explanation of how the
   race can be exploited is also provided.
 - It cannot contain any "trivial" fixes in it (spelling changes,
   whitespace cleanups, etc).
 - It must follow the Documentation/SubmittingPatches rules.
 - It or an equivalent fix must already exist in Linus' tree (upstream).


Procedure for submitting patches to the -stable tree:

 - Send the patch, after verifying that it follows the above rules, to
   stable@kernel.org.  You must note the upstream commit ID in the changelog
   of your submission.
 - To have the patch automatically included in the stable tree, add the tag
     Cc: stable@kernel.org
   in the sign-off area. Once the patch is merged it will be applied to
   the stable tree without anything else needing to be done by the author
   or subsystem maintainer.
 - If the patch requires other patches as prerequisites which can be
   cherry-picked than this can be specified in the following format in
   the sign-off area:

     Cc: <stable@kernel.org> # .32.x: a1f84a3: sched: Check for idle
     Cc: <stable@kernel.org> # .32.x: 1b9508f: sched: Rate-limit newidle
     Cc: <stable@kernel.org> # .32.x: fd21073: sched: Fix affinity logic
     Cc: <stable@kernel.org> # .32.x
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

   The tag sequence has the meaning of:
     git cherry-pick a1f84a3
     git cherry-pick 1b9508f
     git cherry-pick fd21073
     git cherry-pick <this commit>

 - The sender will receive an ACK when the patch has been accepted into the
   queue, or a NAK if the patch is rejected.  This response might take a few
   days, according to the developer's schedules.
 - If accepted, the patch will be added to the -stable queue, for review by
   other developers and by the relevant subsystem maintainer.
 - Security patches should not be sent to this alias, but instead to the
   documented security@kernel.org address.


Review cycle:

 - When the -stable maintainers decide for a review cycle, the patches will be
   sent to the review committee, and the maintainer of the affected area of
   the patch (unless the submitter is the maintainer of the area) and CC: to
   the linux-kernel mailing list.
 - The review committee has 48 hours in which to ACK or NAK the patch.
 - If the patch is rejected by a member of the committee, or linux-kernel
   members object to the patch, bringing up issues that the maintainers and
   members did not realize, the patch will be dropped from the queue.
 - At the end of the review cycle, the ACKed patches will be added to the
   latest -stable release, and a new -stable release will happen.
 - Security patches will be accepted into the -stable tree directly from the
   security kernel team, and not go through the normal review cycle.
   Contact the kernel security team for more details on this procedure.


Review committee:

 - This is made up of a number of kernel developers who have volunteered for
   this task, and a few that haven't.
Submitting Drivers For The Linux Kernel
---------------------------------------

This document is intended to explain how to submit device drivers to the
various kernel trees. Note that if you are interested in video card drivers
you should probably talk to XFree86 (http://www.xfree86.org/) and/or X.Org
(http://x.org/) instead.

Also read the Documentation/SubmittingPatches document.


Allocating Device Numbers
-------------------------

Major and minor numbers for block and character devices are allocated
by the Linux assigned name and number authority (currently this is
Torben Mathiasen). The site is http://www.lanana.org/. This
also deals with allocating numbers for devices that are not going to
be submitted to the mainstream kernel.
See Documentation/devices.txt for more information on this.

If you don't use assigned numbers then when your device is submitted it will
be given an assigned number even if that is different from values you may
have shipped to customers before.

Who To Submit Drivers To
------------------------

Linux 2.0:
	No new drivers are accepted for this kernel tree.

Linux 2.2:
	No new drivers are accepted for this kernel tree.

Linux 2.4:
	If the code area has a general maintainer then please submit it to
	the maintainer listed in MAINTAINERS in the kernel file. If the
	maintainer does not respond or you cannot find the appropriate
	maintainer then please contact Willy Tarreau <w@1wt.eu>.

Linux 2.6:
	The same rules apply as 2.4 except that you should follow linux-kernel
	to track changes in API's. The final contact point for Linux 2.6
	submissions is Andrew Morton.

What Criteria Determine Acceptance
----------------------------------

Licensing:	The code must be released to us under the
		GNU General Public License. We don't insist on any kind
		of exclusive GPL licensing, and if you wish the driver
		to be useful to other communities such as BSD you may well
		wish to release under multiple licenses.
		See accepted licenses at include/linux/module.h

Copyright:	The copyright owner must agree to use of GPL.
		It's best if the submitter and copyright owner
		are the same person/entity. If not, the name of
		the person/entity authorizing use of GPL should be
		listed in case it's necessary to verify the will of
		the copyright owner.

Interfaces:	If your driver uses existing interfaces and behaves like
		other drivers in the same class it will be much more likely
		to be accepted than if it invents gratuitous new ones.
		If you need to implement a common API over Linux and NT
		drivers do it in userspace.

Code:		Please use the Linux style of code formatting as documented
		in Documentation/CodingStyle. If you have sections of code
		that need to be in other formats, for example because they
		are shared with a windows driver kit and you want to
		maintain them just once separate them out nicely and note
		this fact.

Portability:	Pointers are not always 32bits, not all computers are little
		endian, people do not all have floating point and you
		shouldn't use inline x86 assembler in your driver without
		careful thought. Pure x86 drivers generally are not popular.
		If you only have x86 hardware it is hard to test portability
		but it is easy to make sure the code can easily be made
		portable.

Clarity:	It helps if anyone can see how to fix the driver. It helps
		you because you get patches not bug reports. If you submit a
		driver that intentionally obfuscates how the hardware works
		it will go in the bitbucket.

PM support:	Since Linux is used on many portable and desktop systems, your
		driver is likely to be used on such a system and therefore it
		should support basic power management by implementing, if
		necessary, the .suspend and .resume methods used during the
		system-wide suspend and resume transitions.  You should verify
		that your driver correctly handles the suspend and resume, but
		if you are unable to ensure that, please at least define the
		.suspend method returning the -ENOSYS ("Function not
		implemented") error.  You should also try to make sure that your
		driver uses as little power as possible when it's not doing
		anything.  For the driver testing instructions see
		Documentation/power/drivers-testing.txt and for a relatively
		complete overview of the power management issues related to
		drivers see Documentation/power/devices.txt .

Control:	In general if there is active maintenance of a driver by
		the author then patches will be redirected to them unless
		they are totally obvious and without need of checking.
		If you want to be the contact and update point for the
		driver it is a good idea to state this in the comments,
		and include an entry in MAINTAINERS for your driver.

What Criteria Do Not Determine Acceptance
-----------------------------------------

Vendor:		Being the hardware vendor and maintaining the driver is
		often a good thing. If there is a stable working driver from
		other people already in the tree don't expect 'we are the
		vendor' to get your driver chosen. Ideally work with the
		existing driver author to build a single perfect driver.

Author:		It doesn't matter if a large Linux company wrote the driver,
		or you did. Nobody has any special access to the kernel
		tree. Anyone who tells you otherwise isn't telling the
		whole story.


Resources
---------

Linux kernel master tree:
	ftp.??.kernel.org:/pub/linux/kernel/...
	?? == your country code, such as "us", "uk", "fr", etc.

	http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git

Linux kernel mailing list:
	linux-kernel@vger.kernel.org
	[mail majordomo@vger.kernel.org to subscribe]

Linux Device Drivers, Third Edition (covers 2.6.10):
	http://lwn.net/Kernel/LDD3/  (free version)

LWN.net:
	Weekly summary of kernel development activity - http://lwn.net/
	2.6 API changes:
		http://lwn.net/Articles/2.6-kernel-api/
	Porting drivers from prior kernels to 2.6:
		http://lwn.net/Articles/driver-porting/

KernelTrap:
	Occasional Linux kernel articles and developer interviews
	http://kerneltrap.org/

KernelNewbies:
	Documentation and assistance for new kernel programmers
	http://kernelnewbies.org/

Linux USB project:
	http://www.linux-usb.org/

How to NOT write kernel driver by Arjan van de Ven:
	http://www.fenrus.org/how-to-not-write-a-device-driver-paper.pdf

Kernel Janitor:
	http://kernelnewbies.org/KernelJanitors

GIT, Fast Version Control System:
	http://git-scm.com/

	How to Get Your Change Into the Linux Kernel
		or
	Care And Operation Of Your Linus Torvalds



For a person or company who wishes to submit a change to the Linux
kernel, the process can sometimes be daunting if you're not familiar
with "the system."  This text is a collection of suggestions which
can greatly increase the chances of your change being accepted.

Read Documentation/SubmitChecklist for a list of items to check
before submitting code.  If you are submitting a driver, also read
Documentation/SubmittingDrivers.



--------------------------------------------
SECTION 1 - CREATING AND SENDING YOUR CHANGE
--------------------------------------------



1) "diff -up"
------------

Use "diff -up" or "diff -uprN" to create patches.

All changes to the Linux kernel occur in the form of patches, as
generated by diff(1).  When creating your patch, make sure to create it
in "unified diff" format, as supplied by the '-u' argument to diff(1).
Also, please use the '-p' argument which shows which C function each
change is in - that makes the resultant diff a lot easier to read.
Patches should be based in the root kernel source directory,
not in any lower subdirectory.

To create a patch for a single file, it is often sufficient to do:

	SRCTREE= linux-2.6
	MYFILE=  drivers/net/mydriver.c

	cd $SRCTREE
	cp $MYFILE $MYFILE.orig
	vi $MYFILE	# make your change
	cd ..
	diff -up $SRCTREE/$MYFILE{.orig,} > /tmp/patch

To create a patch for multiple files, you should unpack a "vanilla",
or unmodified kernel source tree, and generate a diff against your
own source tree.  For example:

	MYSRC= /devel/linux-2.6

	tar xvfz linux-2.6.12.tar.gz
	mv linux-2.6.12 linux-2.6.12-vanilla
	diff -uprN -X linux-2.6.12-vanilla/Documentation/dontdiff \
		linux-2.6.12-vanilla $MYSRC > /tmp/patch

"dontdiff" is a list of files which are generated by the kernel during
the build process, and should be ignored in any diff(1)-generated
patch.  The "dontdiff" file is included in the kernel tree in
2.6.12 and later.  For earlier kernel versions, you can get it
from <http://www.xenotime.net/linux/doc/dontdiff>.

Make sure your patch does not include any extra files which do not
belong in a patch submission.  Make sure to review your patch -after-
generated it with diff(1), to ensure accuracy.

If your changes produce a lot of deltas, you may want to look into
splitting them into individual patches which modify things in
logical stages.  This will facilitate easier reviewing by other
kernel developers, very important if you want your patch accepted.
There are a number of scripts which can aid in this:

Quilt:
http://savannah.nongnu.org/projects/quilt

Andrew Morton's patch scripts:
http://userweb.kernel.org/~akpm/stuff/patch-scripts.tar.gz
Instead of these scripts, quilt is the recommended patch management
tool (see above).



2) Describe your changes.

Describe the technical detail of the change(s) your patch includes.

Be as specific as possible.  The WORST descriptions possible include
things like "update driver X", "bug fix for driver X", or "this patch
includes updates for subsystem X.  Please apply."

The maintainer will thank you if you write your patch description in a
form which can be easily pulled into Linux's source code management
system, git, as a "commit log".  See #15, below.

If your description starts to get long, that's a sign that you probably
need to split up your patch.  See #3, next.

When you submit or resubmit a patch or patch series, include the
complete patch description and justification for it.  Don't just
say that this is version N of the patch (series).  Don't expect the
patch merger to refer back to earlier patch versions or referenced
URLs to find the patch description and put that into the patch.
I.e., the patch (series) and its description should be self-contained.
This benefits both the patch merger(s) and reviewers.  Some reviewers
probably didn't even receive earlier versions of the patch.

If the patch fixes a logged bug entry, refer to that bug entry by
number and URL.


3) Separate your changes.

Separate _logical changes_ into a single patch file.

For example, if your changes include both bug fixes and performance
enhancements for a single driver, separate those changes into two
or more patches.  If your changes include an API update, and a new
driver which uses that new API, separate those into two patches.

On the other hand, if you make a single change to numerous files,
group those changes into a single patch.  Thus a single logical change
is contained within a single patch.

If one patch depends on another patch in order for a change to be
complete, that is OK.  Simply note "this patch depends on patch X"
in your patch description.

If you cannot condense your patch set into a smaller set of patches,
then only post say 15 or so at a time and wait for review and integration.



4) Style check your changes.

Check your patch for basic style violations, details of which can be
found in Documentation/CodingStyle.  Failure to do so simply wastes
the reviewers time and will get your patch rejected, probably
without even being read.

At a minimum you should check your patches with the patch style
checker prior to submission (scripts/checkpatch.pl).  You should
be able to justify all violations that remain in your patch.



5) Select e-mail destination.

Look through the MAINTAINERS file and the source code, and determine
if your change applies to a specific subsystem of the kernel, with
an assigned maintainer.  If so, e-mail that person.

If no maintainer is listed, or the maintainer does not respond, send
your patch to the primary Linux kernel developer's mailing list,
linux-kernel@vger.kernel.org.  Most kernel developers monitor this
e-mail list, and can comment on your changes.


Do not send more than 15 patches at once to the vger mailing lists!!!


Linus Torvalds is the final arbiter of all changes accepted into the
Linux kernel.  His e-mail address is <torvalds@linux-foundation.org>. 
He gets a lot of e-mail, so typically you should do your best to -avoid-
sending him e-mail. 

Patches which are bug fixes, are "obvious" changes, or similarly
require little discussion should be sent or CC'd to Linus.  Patches
which require discussion or do not have a clear advantage should
usually be sent first to linux-kernel.  Only after the patch is
discussed should the patch then be submitted to Linus.



6) Select your CC (e-mail carbon copy) list.

Unless you have a reason NOT to do so, CC linux-kernel@vger.kernel.org.

Other kernel developers besides Linus need to be aware of your change,
so that they may comment on it and offer code review and suggestions.
linux-kernel is the primary Linux kernel developer mailing list.
Other mailing lists are available for specific subsystems, such as
USB, framebuffer devices, the VFS, the SCSI subsystem, etc.  See the
MAINTAINERS file for a mailing list that relates specifically to
your change.

Majordomo lists of VGER.KERNEL.ORG at:
	<http://vger.kernel.org/vger-lists.html>

If changes affect userland-kernel interfaces, please send
the MAN-PAGES maintainer (as listed in the MAINTAINERS file)
a man-pages patch, or at least a notification of the change,
so that some information makes its way into the manual pages.

Even if the maintainer did not respond in step #5, make sure to ALWAYS
copy the maintainer when you change their code.

For small patches you may want to CC the Trivial Patch Monkey
trivial@kernel.org which collects "trivial" patches. Have a look
into the MAINTAINERS file for its current manager.
Trivial patches must qualify for one of the following rules:
 Spelling fixes in documentation
 Spelling fixes which could break grep(1)
 Warning fixes (cluttering with useless warnings is bad)
 Compilation fixes (only if they are actually correct)
 Runtime fixes (only if they actually fix things)
 Removing use of deprecated functions/macros (eg. check_region)
 Contact detail and documentation fixes
 Non-portable code replaced by portable code (even in arch-specific,
 since people copy, as long as it's trivial)
 Any fix by the author/maintainer of the file (ie. patch monkey
 in re-transmission mode)



7) No MIME, no links, no compression, no attachments.  Just plain text.

Linus and other kernel developers need to be able to read and comment
on the changes you are submitting.  It is important for a kernel
developer to be able to "quote" your changes, using standard e-mail
tools, so that they may comment on specific portions of your code.

For this reason, all patches should be submitting e-mail "inline".
WARNING:  Be wary of your editor's word-wrap corrupting your patch,
if you choose to cut-n-paste your patch.

Do not attach the patch as a MIME attachment, compressed or not.
Many popular e-mail applications will not always transmit a MIME
attachment as plain text, making it impossible to comment on your
code.  A MIME attachment also takes Linus a bit more time to process,
decreasing the likelihood of your MIME-attached change being accepted.

Exception:  If your mailer is mangling patches then someone may ask
you to re-send them using MIME.

See Documentation/email-clients.txt for hints about configuring
your e-mail client so that it sends your patches untouched.

8) E-mail size.

When sending patches to Linus, always follow step #7.

Large changes are not appropriate for mailing lists, and some
maintainers.  If your patch, uncompressed, exceeds 300 kB in size,
it is preferred that you store your patch on an Internet-accessible
server, and provide instead a URL (link) pointing to your patch.



9) Name your kernel version.

It is important to note, either in the subject line or in the patch
description, the kernel version to which this patch applies.

If the patch does not apply cleanly to the latest kernel version,
Linus will not apply it.



10) Don't get discouraged.  Re-submit.

After you have submitted your change, be patient and wait.  If Linus
likes your change and applies it, it will appear in the next version
of the kernel that he releases.

However, if your change doesn't appear in the next version of the
kernel, there could be any number of reasons.  It's YOUR job to
narrow down those reasons, correct what was wrong, and submit your
updated change.

It is quite common for Linus to "drop" your patch without comment.
That's the nature of the system.  If he drops your patch, it could be
due to
* Your patch did not apply cleanly to the latest kernel version.
* Your patch was not sufficiently discussed on linux-kernel.
* A style issue (see section 2).
* An e-mail formatting issue (re-read this section).
* A technical problem with your change.
* He gets tons of e-mail, and yours got lost in the shuffle.
* You are being annoying.

When in doubt, solicit comments on linux-kernel mailing list.



11) Include PATCH in the subject

Due to high e-mail traffic to Linus, and to linux-kernel, it is common
convention to prefix your subject line with [PATCH].  This lets Linus
and other kernel developers more easily distinguish patches from other
e-mail discussions.



12) Sign your work

To improve tracking of who did what, especially with patches that can
percolate to their final resting place in the kernel through several
layers of maintainers, we've introduced a "sign-off" procedure on
patches that are being emailed around.

The sign-off is a simple line at the end of the explanation for the
patch, which certifies that you wrote it or otherwise have the right to
pass it on as a open-source patch.  The rules are pretty simple: if you
can certify the below:

        Developer's Certificate of Origin 1.1

        By making a contribution to this project, I certify that:

        (a) The contribution was created in whole or in part by me and I
            have the right to submit it under the open source license
            indicated in the file; or

        (b) The contribution is based upon previous work that, to the best
            of my knowledge, is covered under an appropriate open source
            license and I have the right under that license to submit that
            work with modifications, whether created in whole or in part
            by me, under the same open source license (unless I am
            permitted to submit under a different license), as indicated
            in the file; or

        (c) The contribution was provided directly to me by some other
            person who certified (a), (b) or (c) and I have not modified
            it.

	(d) I understand and agree that this project and the contribution
	    are public and that a record of the contribution (including all
	    personal information I submit with it, including my sign-off) is
	    maintained indefinitely and may be redistributed consistent with
	    this project or the open source license(s) involved.

then you just add a line saying

	Signed-off-by: Random J Developer <random@developer.example.org>

using your real name (sorry, no pseudonyms or anonymous contributions.)

Some people also put extra tags at the end.  They'll just be ignored for
now, but you can do this to mark internal company procedures or just
point out some special detail about the sign-off. 

If you are a subsystem or branch maintainer, sometimes you need to slightly
modify patches you receive in order to merge them, because the code is not
exactly the same in your tree and the submitters'. If you stick strictly to
rule (c), you should ask the submitter to rediff, but this is a totally
counter-productive waste of time and energy. Rule (b) allows you to adjust
the code, but then it is very impolite to change one submitter's code and
make him endorse your bugs. To solve this problem, it is recommended that
you add a line between the last Signed-off-by header and yours, indicating
the nature of your changes. While there is nothing mandatory about this, it
seems like prepending the description with your mail and/or name, all
enclosed in square brackets, is noticeable enough to make it obvious that
you are responsible for last-minute changes. Example :

	Signed-off-by: Random J Developer <random@developer.example.org>
	[lucky@maintainer.example.org: struct foo moved from foo.c to foo.h]
	Signed-off-by: Lucky K Maintainer <lucky@maintainer.example.org>

This practise is particularly helpful if you maintain a stable branch and
want at the same time to credit the author, track changes, merge the fix,
and protect the submitter from complaints. Note that under no circumstances
can you change the author's identity (the From header), as it is the one
which appears in the changelog.

Special note to back-porters: It seems to be a common and useful practise
to insert an indication of the origin of a patch at the top of the commit
message (just after the subject line) to facilitate tracking. For instance,
here's what we see in 2.6-stable :

    Date:   Tue May 13 19:10:30 2008 +0000

        SCSI: libiscsi regression in 2.6.25: fix nop timer handling

        commit 4cf1043593db6a337f10e006c23c69e5fc93e722 upstream

And here's what appears in 2.4 :

    Date:   Tue May 13 22:12:27 2008 +0200

        wireless, airo: waitbusy() won't delay

        [backport of 2.6 commit b7acbdfbd1f277c1eb23f344f899cfa4cd0bf36a]

Whatever the format, this information provides a valuable help to people
tracking your trees, and to people trying to trouble-shoot bugs in your
tree.


13) When to use Acked-by: and Cc:

The Signed-off-by: tag indicates that the signer was involved in the
development of the patch, or that he/she was in the patch's delivery path.

If a person was not directly involved in the preparation or handling of a
patch but wishes to signify and record their approval of it then they can
arrange to have an Acked-by: line added to the patch's changelog.

Acked-by: is often used by the maintainer of the affected code when that
maintainer neither contributed to nor forwarded the patch.

Acked-by: is not as formal as Signed-off-by:.  It is a record that the acker
has at least reviewed the patch and has indicated acceptance.  Hence patch
mergers will sometimes manually convert an acker's "yep, looks good to me"
into an Acked-by:.

Acked-by: does not necessarily indicate acknowledgement of the entire patch.
For example, if a patch affects multiple subsystems and has an Acked-by: from
one subsystem maintainer then this usually indicates acknowledgement of just
the part which affects that maintainer's code.  Judgement should be used here.
When in doubt people should refer to the original discussion in the mailing
list archives.

If a person has had the opportunity to comment on a patch, but has not
provided such comments, you may optionally add a "Cc:" tag to the patch.
This is the only tag which might be added without an explicit action by the
person it names.  This tag documents that potentially interested parties
have been included in the discussion


14) Using Reported-by:, Tested-by: and Reviewed-by:

If this patch fixes a problem reported by somebody else, consider adding a
Reported-by: tag to credit the reporter for their contribution.  Please
note that this tag should not be added without the reporter's permission,
especially if the problem was not reported in a public forum.  That said,
if we diligently credit our bug reporters, they will, hopefully, be
inspired to help us again in the future.

A Tested-by: tag indicates that the patch has been successfully tested (in
some environment) by the person named.  This tag informs maintainers that
some testing has been performed, provides a means to locate testers for
future patches, and ensures credit for the testers.

Reviewed-by:, instead, indicates that the patch has been reviewed and found
acceptable according to the Reviewer's Statement:

	Reviewer's statement of oversight

	By offering my Reviewed-by: tag, I state that:

 	 (a) I have carried out a technical review of this patch to
	     evaluate its appropriateness and readiness for inclusion into
	     the mainline kernel.

	 (b) Any problems, concerns, or questions relating to the patch
	     have been communicated back to the submitter.  I am satisfied
	     with the submitter's response to my comments.

	 (c) While there may be things that could be improved with this
	     submission, I believe that it is, at this time, (1) a
	     worthwhile modification to the kernel, and (2) free of known
	     issues which would argue against its inclusion.

	 (d) While I have reviewed the patch and believe it to be sound, I
	     do not (unless explicitly stated elsewhere) make any
	     warranties or guarantees that it will achieve its stated
	     purpose or function properly in any given situation.

A Reviewed-by tag is a statement of opinion that the patch is an
appropriate modification of the kernel without any remaining serious
technical issues.  Any interested reviewer (who has done the work) can
offer a Reviewed-by tag for a patch.  This tag serves to give credit to
reviewers and to inform maintainers of the degree of review which has been
done on the patch.  Reviewed-by: tags, when supplied by reviewers known to
understand the subject area and to perform thorough reviews, will normally
increase the likelihood of your patch getting into the kernel.


15) The canonical patch format

The canonical patch subject line is:

    Subject: [PATCH 001/123] subsystem: summary phrase

The canonical patch message body contains the following:

  - A "from" line specifying the patch author.

  - An empty line.

  - The body of the explanation, which will be copied to the
    permanent changelog to describe this patch.

  - The "Signed-off-by:" lines, described above, which will
    also go in the changelog.

  - A marker line containing simply "---".

  - Any additional comments not suitable for the changelog.

  - The actual patch (diff output).

The Subject line format makes it very easy to sort the emails
alphabetically by subject line - pretty much any email reader will
support that - since because the sequence number is zero-padded,
the numerical and alphabetic sort is the same.

The "subsystem" in the email's Subject should identify which
area or subsystem of the kernel is being patched.

The "summary phrase" in the email's Subject should concisely
describe the patch which that email contains.  The "summary
phrase" should not be a filename.  Do not use the same "summary
phrase" for every patch in a whole patch series (where a "patch
series" is an ordered sequence of multiple, related patches).

Bear in mind that the "summary phrase" of your email becomes a
globally-unique identifier for that patch.  It propagates all the way
into the git changelog.  The "summary phrase" may later be used in
developer discussions which refer to the patch.  People will want to
google for the "summary phrase" to read discussion regarding that
patch.  It will also be the only thing that people may quickly see
when, two or three months later, they are going through perhaps
thousands of patches using tools such as "gitk" or "git log
--oneline".

For these reasons, the "summary" must be no more than 70-75
characters, and it must describe both what the patch changes, as well
as why the patch might be necessary.  It is challenging to be both
succinct and descriptive, but that is what a well-written summary
should do.

The "summary phrase" may be prefixed by tags enclosed in square
brackets: "Subject: [PATCH tag] <summary phrase>".  The tags are not
considered part of the summary phrase, but describe how the patch
should be treated.  Common tags might include a version descriptor if
the multiple versions of the patch have been sent out in response to
comments (i.e., "v1, v2, v3"), or "RFC" to indicate a request for
comments.  If there are four patches in a patch series the individual
patches may be numbered like this: 1/4, 2/4, 3/4, 4/4.  This assures
that developers understand the order in which the patches should be
applied and that they have reviewed or applied all of the patches in
the patch series.

A couple of example Subjects:

    Subject: [patch 2/5] ext2: improve scalability of bitmap searching
    Subject: [PATCHv2 001/207] x86: fix eflags tracking

The "from" line must be the very first line in the message body,
and has the form:

        From: Original Author <author@example.com>

The "from" line specifies who will be credited as the author of the
patch in the permanent changelog.  If the "from" line is missing,
then the "From:" line from the email header will be used to determine
the patch author in the changelog.

The explanation body will be committed to the permanent source
changelog, so should make sense to a competent reader who has long
since forgotten the immediate details of the discussion that might
have led to this patch.  Including symptoms of the failure which the
patch addresses (kernel log messages, oops messages, etc.) is
especially useful for people who might be searching the commit logs
looking for the applicable patch.  If a patch fixes a compile failure,
it may not be necessary to include _all_ of the compile failures; just
enough that it is likely that someone searching for the patch can find
it.  As in the "summary phrase", it is important to be both succinct as
well as descriptive.

The "---" marker line serves the essential purpose of marking for patch
handling tools where the changelog message ends.

One good use for the additional comments after the "---" marker is for
a diffstat, to show what files have changed, and the number of
inserted and deleted lines per file.  A diffstat is especially useful
on bigger patches.  Other comments relevant only to the moment or the
maintainer, not suitable for the permanent changelog, should also go
here.  A good example of such comments might be "patch changelogs"
which describe what has changed between the v1 and v2 version of the
patch.

If you are going to include a diffstat after the "---" marker, please
use diffstat options "-p 1 -w 70" so that filenames are listed from
the top of the kernel source tree and don't use too much horizontal
space (easily fit in 80 columns, maybe with some indentation).

See more details on the proper patch format in the following
references.


16) Sending "git pull" requests  (from Linus emails)

Please write the git repo address and branch name alone on the same line
so that I can't even by mistake pull from the wrong branch, and so
that a triple-click just selects the whole thing.

So the proper format is something along the lines of:

	"Please pull from

		git://jdelvare.pck.nerim.net/jdelvare-2.6 i2c-for-linus

	 to get these changes:"

so that I don't have to hunt-and-peck for the address and inevitably
get it wrong (actually, I've only gotten it wrong a few times, and
checking against the diffstat tells me when I get it wrong, but I'm
just a lot more comfortable when I don't have to "look for" the right
thing to pull, and double-check that I have the right branch-name).


Please use "git diff -M --stat --summary" to generate the diffstat:
the -M enables rename detection, and the summary enables a summary of
new/deleted or renamed files.

With rename detection, the statistics are rather different [...]
because git will notice that a fair number of the changes are renames.

-----------------------------------
SECTION 2 - HINTS, TIPS, AND TRICKS
-----------------------------------

This section lists many of the common "rules" associated with code
submitted to the kernel.  There are always exceptions... but you must
have a really good reason for doing so.  You could probably call this
section Linus Computer Science 101.



1) Read Documentation/CodingStyle

Nuff said.  If your code deviates too much from this, it is likely
to be rejected without further review, and without comment.

One significant exception is when moving code from one file to
another -- in this case you should not modify the moved code at all in
the same patch which moves it.  This clearly delineates the act of
moving the code and your changes.  This greatly aids review of the
actual differences and allows tools to better track the history of
the code itself.

Check your patches with the patch style checker prior to submission
(scripts/checkpatch.pl).  The style checker should be viewed as
a guide not as the final word.  If your code looks better with
a violation then its probably best left alone.

The checker reports at three levels:
 - ERROR: things that are very likely to be wrong
 - WARNING: things requiring careful review
 - CHECK: things requiring thought

You should be able to justify all violations that remain in your
patch.



2) #ifdefs are ugly

Code cluttered with ifdefs is difficult to read and maintain.  Don't do
it.  Instead, put your ifdefs in a header, and conditionally define
'static inline' functions, or macros, which are used in the code.
Let the compiler optimize away the "no-op" case.

Simple example, of poor code:

	dev = alloc_etherdev (sizeof(struct funky_private));
	if (!dev)
		return -ENODEV;
	#ifdef CONFIG_NET_FUNKINESS
	init_funky_net(dev);
	#endif

Cleaned-up example:

(in header)
	#ifndef CONFIG_NET_FUNKINESS
	static inline void init_funky_net (struct net_device *d) {}
	#endif

(in the code itself)
	dev = alloc_etherdev (sizeof(struct funky_private));
	if (!dev)
		return -ENODEV;
	init_funky_net(dev);



3) 'static inline' is better than a macro

Static inline functions are greatly preferred over macros.
They provide type safety, have no length limitations, no formatting
limitations, and under gcc they are as cheap as macros.

Macros should only be used for cases where a static inline is clearly
suboptimal [there are a few, isolated cases of this in fast paths],
or where it is impossible to use a static inline function [such as
string-izing].

'static inline' is preferred over 'static __inline__', 'extern inline',
and 'extern __inline__'.



4) Don't over-design.

Don't try to anticipate nebulous future cases which may or may not
be useful:  "Make it as simple as you can, and no simpler."



----------------------
SECTION 3 - REFERENCES
----------------------

Andrew Morton, "The perfect patch" (tpp).
  <http://userweb.kernel.org/~akpm/stuff/tpp.txt>

Jeff Garzik, "Linux kernel patch submission format".
  <http://linux.yyz.us/patch-format.html>

Greg Kroah-Hartman, "How to piss off a kernel subsystem maintainer".
  <http://www.kroah.com/log/linux/maintainer.html>
  <http://www.kroah.com/log/linux/maintainer-02.html>
  <http://www.kroah.com/log/linux/maintainer-03.html>
  <http://www.kroah.com/log/linux/maintainer-04.html>
  <http://www.kroah.com/log/linux/maintainer-05.html>

NO!!!! No more huge patch bombs to linux-kernel@vger.kernel.org people!
  <http://marc.theaimsgroup.com/?l=linux-kernel&m=112112749912944&w=2>

Kernel Documentation/CodingStyle:
  <http://users.sosdg.org/~qiyong/lxr/source/Documentation/CodingStyle>

Linus Torvalds's mail on the canonical patch format:
  <http://lkml.org/lkml/2005/4/7/183>

Andi Kleen, "On submitting kernel patches"
  Some strategies to get difficult or controversial changes in.
  http://halobates.de/on-submitting-patches.pdf

--
		       Video Mode Selection Support 2.13
		    (c) 1995--1999 Martin Mares, <mj@ucw.cz>
--------------------------------------------------------------------------------

1. Intro
~~~~~~~~
   This small document describes the "Video Mode Selection" feature which
allows the use of various special video modes supported by the video BIOS. Due
to usage of the BIOS, the selection is limited to boot time (before the
kernel decompression starts) and works only on 80X86 machines.

   **  Short intro for the impatient: Just use vga=ask for the first time,
   **  enter `scan' on the video mode prompt, pick the mode you want to use,
   **  remember its mode ID (the four-digit hexadecimal number) and then
   **  set the vga parameter to this number (converted to decimal first).

   The video mode to be used is selected by a kernel parameter which can be
specified in the kernel Makefile (the SVGA_MODE=... line) or by the "vga=..."
option of LILO (or some other boot loader you use) or by the "vidmode" utility
(present in standard Linux utility packages). You can use the following values
of this parameter:

   NORMAL_VGA - Standard 80x25 mode available on all display adapters.

   EXTENDED_VGA	- Standard 8-pixel font mode: 80x43 on EGA, 80x50 on VGA.

   ASK_VGA - Display a video mode menu upon startup (see below).

   0..35 - Menu item number (when you have used the menu to view the list of
      modes available on your adapter, you can specify the menu item you want
      to use). 0..9 correspond to "0".."9", 10..35 to "a".."z". Warning: the
      mode list displayed may vary as the kernel version changes, because the
      modes are listed in a "first detected -- first displayed" manner. It's
      better to use absolute mode numbers instead.

   0x.... - Hexadecimal video mode ID (also displayed on the menu, see below
      for exact meaning of the ID). Warning: rdev and LILO don't support
      hexadecimal numbers -- you have to convert it to decimal manually.

2. Menu
~~~~~~~
   The ASK_VGA mode causes the kernel to offer a video mode menu upon
bootup. It displays a "Press <RETURN> to see video modes available, <SPACE>
to continue or wait 30 secs" message. If you press <RETURN>, you enter the
menu, if you press <SPACE> or wait 30 seconds, the kernel will boot up in
the standard 80x25 mode.

   The menu looks like:

Video adapter: <name-of-detected-video-adapter>
Mode:    COLSxROWS:
0  0F00  80x25
1  0F01  80x50
2  0F02  80x43
3  0F03  80x26
....
Enter mode number or `scan': <flashing-cursor-here>

   <name-of-detected-video-adapter> tells what video adapter did Linux detect
-- it's either a generic adapter name (MDA, CGA, HGC, EGA, VGA, VESA VGA [a VGA
with VESA-compliant BIOS]) or a chipset name (e.g., Trident). Direct detection
of chipsets is turned off by default (see CONFIG_VIDEO_SVGA in chapter 4 to see
how to enable it if you really want) as it's inherently unreliable due to
absolutely insane PC design.

   "0  0F00  80x25" means that the first menu item (the menu items are numbered
from "0" to "9" and from "a" to "z") is a 80x25 mode with ID=0x0f00 (see the
next section for a description of mode IDs).

   <flashing-cursor-here> encourages you to enter the item number or mode ID
you wish to set and press <RETURN>. If the computer complains something about
"Unknown mode ID", it is trying to tell you that it isn't possible to set such
a mode. It's also possible to press only <RETURN> which leaves the current mode.

   The mode list usually contains a few basic modes and some VESA modes.  In
case your chipset has been detected, some chipset-specific modes are shown as
well (some of these might be missing or unusable on your machine as different
BIOSes are often shipped with the same card and the mode numbers depend purely
on the VGA BIOS).

   The modes displayed on the menu are partially sorted: The list starts with
the standard modes (80x25 and 80x50) followed by "special" modes (80x28 and
80x43), local modes (if the local modes feature is enabled), VESA modes and
finally SVGA modes for the auto-detected adapter.

   If you are not happy with the mode list offered (e.g., if you think your card
is able to do more), you can enter "scan" instead of item number / mode ID.  The
program will try to ask the BIOS for all possible video mode numbers and test
what happens then. The screen will be probably flashing wildly for some time and
strange noises will be heard from inside the monitor and so on and then, really
all consistent video modes supported by your BIOS will appear (plus maybe some
`ghost modes'). If you are afraid this could damage your monitor, don't use this
function.

   After scanning, the mode ordering is a bit different: the auto-detected SVGA
modes are not listed at all and the modes revealed by `scan' are shown before
all VESA modes.

3. Mode IDs
~~~~~~~~~~~
   Because of the complexity of all the video stuff, the video mode IDs
used here are also a bit complex. A video mode ID is a 16-bit number usually
expressed in a hexadecimal notation (starting with "0x"). You can set a mode
by entering its mode directly if you know it even if it isn't shown on the menu.

The ID numbers can be divided to three regions:

   0x0000 to 0x00ff - menu item references. 0x0000 is the first item. Don't use
	outside the menu as this can change from boot to boot (especially if you
	have used the `scan' feature).

   0x0100 to 0x017f - standard BIOS modes. The ID is a BIOS video mode number
	(as presented to INT 10, function 00) increased by 0x0100.

   0x0200 to 0x08ff - VESA BIOS modes. The ID is a VESA mode ID increased by
	0x0100. All VESA modes should be autodetected and shown on the menu.

   0x0900 to 0x09ff - Video7 special modes. Set by calling INT 0x10, AX=0x6f05.
	(Usually 940=80x43, 941=132x25, 942=132x44, 943=80x60, 944=100x60,
	945=132x28 for the standard Video7 BIOS)

   0x0f00 to 0x0fff - special modes (they are set by various tricks -- usually
	by modifying one of the standard modes). Currently available:
	0x0f00	standard 80x25, don't reset mode if already set (=FFFF)
	0x0f01	standard with 8-point font: 80x43 on EGA, 80x50 on VGA
	0x0f02	VGA 80x43 (VGA switched to 350 scanlines with a 8-point font)
	0x0f03	VGA 80x28 (standard VGA scans, but 14-point font)
	0x0f04	leave current video mode
	0x0f05	VGA 80x30 (480 scans, 16-point font)
	0x0f06	VGA 80x34 (480 scans, 14-point font)
	0x0f07	VGA 80x60 (480 scans, 8-point font)
	0x0f08	Graphics hack (see the CONFIG_VIDEO_HACK paragraph below)

   0x1000 to 0x7fff - modes specified by resolution. The code has a "0xRRCC"
	form where RR is a number of rows and CC is a number of columns.
	E.g., 0x1950 corresponds to a 80x25 mode, 0x2b84 to 132x43 etc.
	This is the only fully portable way to refer to a non-standard mode,
	but it relies on the mode being found and displayed on the menu
	(remember that mode scanning is not done automatically).

   0xff00 to 0xffff - aliases for backward compatibility:
	0xffff	equivalent to 0x0f00 (standard 80x25)
	0xfffe	equivalent to 0x0f01 (EGA 80x43 or VGA 80x50)

   If you add 0x8000 to the mode ID, the program will try to recalculate
vertical display timing according to mode parameters, which can be used to
eliminate some annoying bugs of certain VGA BIOSes (usually those used for
cards with S3 chipsets and old Cirrus Logic BIOSes) -- mainly extra lines at the
end of the display.

4. Options
~~~~~~~~~~
   Some options can be set in the source text (in arch/i386/boot/video.S).
All of them are simple #define's -- change them to #undef's when you want to
switch them off. Currently supported:

   CONFIG_VIDEO_SVGA - enables autodetection of SVGA cards. This is switched
off by default as it's a bit unreliable due to terribly bad PC design. If you
really want to have the adapter autodetected (maybe in case the `scan' feature
doesn't work on your machine), switch this on and don't cry if the results
are not completely sane. In case you really need this feature, please drop me
a mail as I think of removing it some day.

   CONFIG_VIDEO_VESA - enables autodetection of VESA modes. If it doesn't work
on your machine (or displays a "Error: Scanning of VESA modes failed" message),
you can switch it off and report as a bug.

   CONFIG_VIDEO_COMPACT - enables compacting of the video mode list. If there
are more modes with the same screen size, only the first one is kept (see above
for more info on mode ordering). However, in very strange cases it's possible
that the first "version" of the mode doesn't work although some of the others
do -- in this case turn this switch off to see the rest.

   CONFIG_VIDEO_RETAIN - enables retaining of screen contents when switching
video modes. Works only with some boot loaders which leave enough room for the
buffer. (If you have old LILO, you can adjust heap_end_ptr and loadflags
in setup.S, but it's better to upgrade the boot loader...)

   CONFIG_VIDEO_LOCAL - enables inclusion of "local modes" in the list. The
local modes are added automatically to the beginning of the list not depending
on hardware configuration. The local modes are listed in the source text after
the "local_mode_table:" line. The comment before this line describes the format
of the table (which also includes a video card name to be displayed on the
top of the menu).

   CONFIG_VIDEO_400_HACK - force setting of 400 scan lines for standard VGA
modes. This option is intended to be used on certain buggy BIOSes which draw
some useless logo using font download and then fail to reset the correct mode.
Don't use unless needed as it forces resetting the video card.

   CONFIG_VIDEO_GFX_HACK - includes special hack for setting of graphics modes
to be used later by special drivers (e.g., 800x600 on IBM ThinkPad -- see
ftp://ftp.phys.keio.ac.jp/pub/XFree86/800x600/XF86Configs/XF86Config.IBM_TP560).
Allows to set _any_ BIOS mode including graphic ones and forcing specific
text screen resolution instead of peeking it from BIOS variables. Don't use
unless you think you know what you're doing. To activate this setup, use
mode number 0x0f08 (see section 3).

5. Still doesn't work?
~~~~~~~~~~~~~~~~~~~~~~
   When the mode detection doesn't work (e.g., the mode list is incorrect or
the machine hangs instead of displaying the menu), try to switch off some of
the configuration options listed in section 4. If it fails, you can still use
your kernel with the video mode set directly via the kernel parameter.

   In either case, please send me a bug report containing what _exactly_
happens and how do the configuration switches affect the behaviour of the bug.

   If you start Linux from M$-DOS, you might also use some DOS tools for
video mode setting. In this case, you must specify the 0x0f04 mode ("leave
current settings") to Linux, because if you don't and you use any non-standard
mode, Linux will switch to 80x25 automatically.

   If you set some extended mode and there's one or more extra lines on the
bottom of the display containing already scrolled-out text, your VGA BIOS
contains the most common video BIOS bug called "incorrect vertical display
end setting". Adding 0x8000 to the mode ID might fix the problem. Unfortunately,
this must be done manually -- no autodetection mechanisms are available.

   If you have a VGA card and your display still looks as on EGA, your BIOS
is probably broken and you need to set the CONFIG_VIDEO_400_HACK switch to
force setting of the correct mode.

6. History
~~~~~~~~~~
1.0 (??-Nov-95)	First version supporting all adapters supported by the old
		setup.S + Cirrus Logic 54XX. Present in some 1.3.4? kernels
		and then removed due to instability on some machines.
2.0 (28-Jan-96)	Rewritten from scratch. Cirrus Logic 64XX support added, almost
		everything is configurable, the VESA support should be much more
		stable, explicit mode numbering allowed, "scan" implemented etc.
2.1 (30-Jan-96) VESA modes moved to 0x200-0x3ff. Mode selection by resolution
		supported. Few bugs fixed. VESA modes are listed prior to
		modes supplied by SVGA autodetection as they are more reliable.
		CLGD autodetect works better. Doesn't depend on 80x25 being
		active when started. Scanning fixed. 80x43 (any VGA) added.
		Code cleaned up.
2.2 (01-Feb-96)	EGA 80x43 fixed. VESA extended to 0x200-0x4ff (non-standard 02XX
		VESA modes work now). Display end bug workaround supported.
		Special modes renumbered to allow adding of the "recalculate"
		flag, 0xffff and 0xfffe became aliases instead of real IDs.
		Screen contents retained during mode changes.
2.3 (15-Mar-96)	Changed to work with 1.3.74 kernel.
2.4 (18-Mar-96)	Added patches by Hans Lermen fixing a memory overwrite problem
		with some boot loaders. Memory management rewritten to reflect
		these changes. Unfortunately, screen contents retaining works
		only with some loaders now.
		Added a Tseng 132x60 mode.
2.5 (19-Mar-96)	Fixed a VESA mode scanning bug introduced in 2.4.
2.6 (25-Mar-96)	Some VESA BIOS errors not reported -- it fixes error reports on
		several cards with broken VESA code (e.g., ATI VGA).
2.7 (09-Apr-96)	- Accepted all VESA modes in range 0x100 to 0x7ff, because some
		  cards use very strange mode numbers.
		- Added Realtek VGA modes (thanks to Gonzalo Tornaria).
		- Hardware testing order slightly changed, tests based on ROM
		  contents done as first.
		- Added support for special Video7 mode switching functions
		  (thanks to Tom Vander Aa).
		- Added 480-scanline modes (especially useful for notebooks,
		  original version written by hhanemaa@cs.ruu.nl, patched by
		  Jeff Chua, rewritten by me).
		- Screen store/restore fixed.
2.8 (14-Apr-96)	- Previous release was not compilable without CONFIG_VIDEO_SVGA.
		- Better recognition of text modes during mode scan.
2.9 (12-May-96)	- Ignored VESA modes 0x80 - 0xff (more VESA BIOS bugs!)
2.10 (11-Nov-96)- The whole thing made optional.
		- Added the CONFIG_VIDEO_400_HACK switch.
		- Added the CONFIG_VIDEO_GFX_HACK switch.
		- Code cleanup.
2.11 (03-May-97)- Yet another cleanup, now including also the documentation.
		- Direct testing of SVGA adapters turned off by default, `scan'
		  offered explicitly on the prompt line.
		- Removed the doc section describing adding of new probing
		  functions as I try to get rid of _all_ hardware probing here.
2.12 (25-May-98)- Added support for VESA frame buffer graphics.
2.13 (14-May-99)- Minor documentation fixes.
Rules on how to access information in the Linux kernel sysfs

The kernel-exported sysfs exports internal kernel implementation details
and depends on internal kernel structures and layout. It is agreed upon
by the kernel developers that the Linux kernel does not provide a stable
internal API. Therefore, there are aspects of the sysfs interface that
may not be stable across kernel releases.

To minimize the risk of breaking users of sysfs, which are in most cases
low-level userspace applications, with a new kernel release, the users
of sysfs must follow some rules to use an as-abstract-as-possible way to
access this filesystem. The current udev and HAL programs already
implement this and users are encouraged to plug, if possible, into the
abstractions these programs provide instead of accessing sysfs directly.

But if you really do want or need to access sysfs directly, please follow
the following rules and then your programs should work with future
versions of the sysfs interface.

- Do not use libsysfs
  It makes assumptions about sysfs which are not true. Its API does not
  offer any abstraction, it exposes all the kernel driver-core
  implementation details in its own API. Therefore it is not better than
  reading directories and opening the files yourself.
  Also, it is not actively maintained, in the sense of reflecting the
  current kernel development. The goal of providing a stable interface
  to sysfs has failed; it causes more problems than it solves. It
  violates many of the rules in this document.

- sysfs is always at /sys
  Parsing /proc/mounts is a waste of time. Other mount points are a
  system configuration bug you should not try to solve. For test cases,
  possibly support a SYSFS_PATH environment variable to overwrite the
  application's behavior, but never try to search for sysfs. Never try
  to mount it, if you are not an early boot script.

- devices are only "devices"
  There is no such thing like class-, bus-, physical devices,
  interfaces, and such that you can rely on in userspace. Everything is
  just simply a "device". Class-, bus-, physical, ... types are just
  kernel implementation details which should not be expected by
  applications that look for devices in sysfs.

  The properties of a device are:
    o devpath (/devices/pci0000:00/0000:00:1d.1/usb2/2-2/2-2:1.0)
      - identical to the DEVPATH value in the event sent from the kernel
        at device creation and removal
      - the unique key to the device at that point in time
      - the kernel's path to the device directory without the leading
        /sys, and always starting with with a slash
      - all elements of a devpath must be real directories. Symlinks
        pointing to /sys/devices must always be resolved to their real
        target and the target path must be used to access the device.
        That way the devpath to the device matches the devpath of the
        kernel used at event time.
      - using or exposing symlink values as elements in a devpath string
        is a bug in the application

    o kernel name (sda, tty, 0000:00:1f.2, ...)
      - a directory name, identical to the last element of the devpath
      - applications need to handle spaces and characters like '!' in
        the name

    o subsystem (block, tty, pci, ...)
      - simple string, never a path or a link
      - retrieved by reading the "subsystem"-link and using only the
        last element of the target path

    o driver (tg3, ata_piix, uhci_hcd)
      - a simple string, which may contain spaces, never a path or a
        link
      - it is retrieved by reading the "driver"-link and using only the
        last element of the target path
      - devices which do not have "driver"-link just do not have a
        driver; copying the driver value in a child device context is a
        bug in the application

    o attributes
      - the files in the device directory or files below subdirectories
        of the same device directory
      - accessing attributes reached by a symlink pointing to another device,
        like the "device"-link, is a bug in the application

  Everything else is just a kernel driver-core implementation detail
  that should not be assumed to be stable across kernel releases.

- Properties of parent devices never belong into a child device.
  Always look at the parent devices themselves for determining device
  context properties. If the device 'eth0' or 'sda' does not have a
  "driver"-link, then this device does not have a driver. Its value is empty.
  Never copy any property of the parent-device into a child-device. Parent
  device properties may change dynamically without any notice to the
  child device.

- Hierarchy in a single device tree
  There is only one valid place in sysfs where hierarchy can be examined
  and this is below: /sys/devices.
  It is planned that all device directories will end up in the tree
  below this directory.

- Classification by subsystem
  There are currently three places for classification of devices:
  /sys/block, /sys/class and /sys/bus. It is planned that these will
  not contain any device directories themselves, but only flat lists of
  symlinks pointing to the unified /sys/devices tree.
  All three places have completely different rules on how to access
  device information. It is planned to merge all three
  classification directories into one place at /sys/subsystem,
  following the layout of the bus directories. All buses and
  classes, including the converted block subsystem, will show up
  there.
  The devices belonging to a subsystem will create a symlink in the
  "devices" directory at /sys/subsystem/<name>/devices.

  If /sys/subsystem exists, /sys/bus, /sys/class and /sys/block can be
  ignored. If it does not exist, you always have to scan all three
  places, as the kernel is free to move a subsystem from one place to
  the other, as long as the devices are still reachable by the same
  subsystem name.

  Assuming /sys/class/<subsystem> and /sys/bus/<subsystem>, or
  /sys/block and /sys/class/block are not interchangeable is a bug in
  the application.

- Block
  The converted block subsystem at /sys/class/block or
  /sys/subsystem/block will contain the links for disks and partitions
  at the same level, never in a hierarchy. Assuming the block subsystem to
  contain only disks and not partition devices in the same flat list is
  a bug in the application.

- "device"-link and <subsystem>:<kernel name>-links
  Never depend on the "device"-link. The "device"-link is a workaround
  for the old layout, where class devices are not created in
  /sys/devices/ like the bus devices. If the link-resolving of a
  device directory does not end in /sys/devices/, you can use the
  "device"-link to find the parent devices in /sys/devices/. That is the
  single valid use of the "device"-link; it must never appear in any
  path as an element. Assuming the existence of the "device"-link for
  a device in /sys/devices/ is a bug in the application.
  Accessing /sys/class/net/eth0/device is a bug in the application.

  Never depend on the class-specific links back to the /sys/class
  directory.  These links are also a workaround for the design mistake
  that class devices are not created in /sys/devices. If a device
  directory does not contain directories for child devices, these links
  may be used to find the child devices in /sys/class. That is the single
  valid use of these links; they must never appear in any path as an
  element. Assuming the existence of these links for devices which are
  real child device directories in the /sys/devices tree is a bug in
  the application.

  It is planned to remove all these links when all class device
  directories live in /sys/devices.

- Position of devices along device chain can change.
  Never depend on a specific parent device position in the devpath,
  or the chain of parent devices. The kernel is free to insert devices into
  the chain. You must always request the parent device you are looking for
  by its subsystem value. You need to walk up the chain until you find
  the device that matches the expected subsystem. Depending on a specific
  position of a parent device or exposing relative paths using "../" to
  access the chain of parents is a bug in the application.
Linux Magic System Request Key Hacks
Documentation for sysrq.c

*  What is the magic SysRq key?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
It is a 'magical' key combo you can hit which the kernel will respond to
regardless of whatever else it is doing, unless it is completely locked up.

*  How do I enable the magic SysRq key?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
You need to say "yes" to 'Magic SysRq key (CONFIG_MAGIC_SYSRQ)' when
configuring the kernel. When running a kernel with SysRq compiled in,
/proc/sys/kernel/sysrq controls the functions allowed to be invoked via
the SysRq key. By default the file contains 1 which means that every
possible SysRq request is allowed (in older versions SysRq was disabled
by default, and you were required to specifically enable it at run-time
but this is not the case any more). Here is the list of possible values
in /proc/sys/kernel/sysrq:
   0 - disable sysrq completely
   1 - enable all functions of sysrq
  >1 - bitmask of allowed sysrq functions (see below for detailed function
       description):
          2 - enable control of console logging level
          4 - enable control of keyboard (SAK, unraw)
          8 - enable debugging dumps of processes etc.
         16 - enable sync command
         32 - enable remount read-only
         64 - enable signalling of processes (term, kill, oom-kill)
        128 - allow reboot/poweroff
        256 - allow nicing of all RT tasks

You can set the value in the file by the following command:
    echo "number" >/proc/sys/kernel/sysrq

Note that the value of /proc/sys/kernel/sysrq influences only the invocation
via a keyboard. Invocation of any operation via /proc/sysrq-trigger is always
allowed (by a user with admin privileges).

*  How do I use the magic SysRq key?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
On x86   - You press the key combo 'ALT-SysRq-<command key>'. Note - Some
           keyboards may not have a key labeled 'SysRq'. The 'SysRq' key is
           also known as the 'Print Screen' key. Also some keyboards cannot
	   handle so many keys being pressed at the same time, so you might
	   have better luck with "press Alt", "press SysRq", "release SysRq",
	   "press <command key>", release everything.

On SPARC - You press 'ALT-STOP-<command key>', I believe.

On the serial console (PC style standard serial ports only) -
           You send a BREAK, then within 5 seconds a command key. Sending
           BREAK twice is interpreted as a normal BREAK.

On PowerPC - Press 'ALT - Print Screen (or F13) - <command key>,  
             Print Screen (or F13) - <command key> may suffice.

On other - If you know of the key combos for other architectures, please
           let me know so I can add them to this section.

On all -  write a character to /proc/sysrq-trigger.  e.g.:

		echo t > /proc/sysrq-trigger

*  What are the 'command' keys?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
'b'     - Will immediately reboot the system without syncing or unmounting
          your disks.

'c'	- Will perform a system crash by a NULL pointer dereference.
          A crashdump will be taken if configured.

'd'	- Shows all locks that are held.

'e'     - Send a SIGTERM to all processes, except for init.

'f'	- Will call oom_kill to kill a memory hog process.

'g'	- Used by kgdb (kernel debugger)

'h'     - Will display help (actually any other key than those listed
          here will display help. but 'h' is easy to remember :-)

'i'     - Send a SIGKILL to all processes, except for init.

'j'     - Forcibly "Just thaw it" - filesystems frozen by the FIFREEZE ioctl.

'k'     - Secure Access Key (SAK) Kills all programs on the current virtual
          console. NOTE: See important comments below in SAK section.

'l'     - Shows a stack backtrace for all active CPUs.

'm'     - Will dump current memory info to your console.

'n'	- Used to make RT tasks nice-able

'o'     - Will shut your system off (if configured and supported).

'p'     - Will dump the current registers and flags to your console.

'q'     - Will dump per CPU lists of all armed hrtimers (but NOT regular
          timer_list timers) and detailed information about all
          clockevent devices.

'r'     - Turns off keyboard raw mode and sets it to XLATE.

's'     - Will attempt to sync all mounted filesystems.

't'     - Will dump a list of current tasks and their information to your
          console.

'u'     - Will attempt to remount all mounted filesystems read-only.

'v'	- Forcefully restores framebuffer console
'v'	- Causes ETM buffer dump [ARM-specific]

'w'	- Dumps tasks that are in uninterruptable (blocked) state.

'x'	- Used by xmon interface on ppc/powerpc platforms.

'y'	- Show global CPU Registers [SPARC-64 specific]

'z'	- Dump the ftrace buffer

'0'-'9' - Sets the console log level, controlling which kernel messages
          will be printed to your console. ('0', for example would make
          it so that only emergency messages like PANICs or OOPSes would
          make it to your console.)

*  Okay, so what can I use them for?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Well, un'R'aw is very handy when your X server or a svgalib program crashes.

sa'K' (Secure Access Key) is useful when you want to be sure there is no
trojan program running at console which could grab your password
when you would try to login. It will kill all programs on given console,
thus letting you make sure that the login prompt you see is actually
the one from init, not some trojan program.
IMPORTANT: In its true form it is not a true SAK like the one in a :IMPORTANT
IMPORTANT: c2 compliant system, and it should not be mistaken as   :IMPORTANT
IMPORTANT: such.                                                   :IMPORTANT
       It seems others find it useful as (System Attention Key) which is
useful when you want to exit a program that will not let you switch consoles.
(For example, X or a svgalib program.)

re'B'oot is good when you're unable to shut down. But you should also 'S'ync
and 'U'mount first.

'C'rash can be used to manually trigger a crashdump when the system is hung.
Note that this just triggers a crash if there is no dump mechanism available.

'S'ync is great when your system is locked up, it allows you to sync your
disks and will certainly lessen the chance of data loss and fscking. Note
that the sync hasn't taken place until you see the "OK" and "Done" appear
on the screen. (If the kernel is really in strife, you may not ever get the
OK or Done message...)

'U'mount is basically useful in the same ways as 'S'ync. I generally 'S'ync,
'U'mount, then re'B'oot when my system locks. It's saved me many a fsck.
Again, the unmount (remount read-only) hasn't taken place until you see the
"OK" and "Done" message appear on the screen.

The loglevels '0'-'9' are useful when your console is being flooded with
kernel messages you do not want to see. Selecting '0' will prevent all but
the most urgent kernel messages from reaching your console. (They will
still be logged if syslogd/klogd are alive, though.)

t'E'rm and k'I'll are useful if you have some sort of runaway process you
are unable to kill any other way, especially if it's spawning other
processes.

"'J'ust thaw it" is useful if your system becomes unresponsive due to a frozen
(probably root) filesystem via the FIFREEZE ioctl.

*  Sometimes SysRq seems to get 'stuck' after using it, what can I do?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
That happens to me, also. I've found that tapping shift, alt, and control
on both sides of the keyboard, and hitting an invalid sysrq sequence again
will fix the problem. (i.e., something like alt-sysrq-z). Switching to another
virtual console (ALT+Fn) and then back again should also help.

*  I hit SysRq, but nothing seems to happen, what's wrong?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
There are some keyboards that produce a different keycode for SysRq than the
pre-defined value of 99 (see KEY_SYSRQ in include/linux/input.h), or which
don't have a SysRq key at all. In these cases, run 'showkey -s' to find an
appropriate scancode sequence, and use 'setkeycodes <sequence> 99' to map
this sequence to the usual SysRq code (e.g., 'setkeycodes e05b 99'). It's
probably best to put this command in a boot script. Oh, and by the way, you
exit 'showkey' by not typing anything for ten seconds.

*  I want to add SysRQ key events to a module, how does it work?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In order to register a basic function with the table, you must first include
the header 'include/linux/sysrq.h', this will define everything else you need.
Next, you must create a sysrq_key_op struct, and populate it with A) the key
handler function you will use, B) a help_msg string, that will print when SysRQ
prints help, and C) an action_msg string, that will print right before your
handler is called. Your handler must conform to the prototype in 'sysrq.h'.

After the sysrq_key_op is created, you can call the kernel function
register_sysrq_key(int key, struct sysrq_key_op *op_p); this will
register the operation pointed to by 'op_p' at table key 'key',
if that slot in the table is blank. At module unload time, you must call
the function unregister_sysrq_key(int key, struct sysrq_key_op *op_p), which
will remove the key op pointed to by 'op_p' from the key 'key', if and only if
it is currently registered in that slot. This is in case the slot has been
overwritten since you registered it.

The Magic SysRQ system works by registering key operations against a key op
lookup table, which is defined in 'drivers/char/sysrq.c'. This key table has
a number of operations registered into it at compile time, but is mutable,
and 2 functions are exported for interface to it:
	register_sysrq_key and unregister_sysrq_key.
Of course, never ever leave an invalid pointer in the table. I.e., when
your module that called register_sysrq_key() exits, it must call
unregister_sysrq_key() to clean up the sysrq key table entry that it used.
Null pointers in the table are always safe. :)

If for some reason you feel the need to call the handle_sysrq function from
within a function called by handle_sysrq, you must be aware that you are in
a lock (you are also in an interrupt handler, which means don't sleep!), so
you must call __handle_sysrq_nolock instead.

*  When I hit a SysRq key combination only the header appears on the console?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Sysrq output is subject to the same console loglevel control as all
other console output.  This means that if the kernel was booted 'quiet'
as is common on distro kernels the output may not appear on the actual
console, even though it will appear in the dmesg buffer, and be accessible
via the dmesg command and to the consumers of /proc/kmsg.  As a specific
exception the header line from the sysrq command is passed to all console
consumers as if the current loglevel was maximum.  If only the header
is emitted it is almost certain that the kernel loglevel is too low.
Should you require the output on the console channel then you will need
to temporarily up the console loglevel using alt-sysrq-8 or:

    echo 8 > /proc/sysrq-trigger

Remember to return the loglevel to normal after triggering the sysrq
command you are interested in.

*  I have more questions, who can I ask?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
And I'll answer any questions about the registration system you got, also
responding as soon as possible.
 -Crutcher

*  Credits
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Written by Mydraal <vulpyne@vulpyne.net>
Updated by Adam Sulmicki <adam@cfar.umd.edu>
Updated by Jeremy M. Dolan <jmd@turbogeek.org> 2001/01/28 10:15:59
Added to by Crutcher Dunnavant <crutcher+kernel@datastacks.com>
UNALIGNED MEMORY ACCESSES
=========================

Linux runs on a wide variety of architectures which have varying behaviour
when it comes to memory access. This document presents some details about
unaligned accesses, why you need to write code that doesn't cause them,
and how to write such code!


The definition of an unaligned access
=====================================

Unaligned memory accesses occur when you try to read N bytes of data starting
from an address that is not evenly divisible by N (i.e. addr % N != 0).
For example, reading 4 bytes of data from address 0x10004 is fine, but
reading 4 bytes of data from address 0x10005 would be an unaligned memory
access.

The above may seem a little vague, as memory access can happen in different
ways. The context here is at the machine code level: certain instructions read
or write a number of bytes to or from memory (e.g. movb, movw, movl in x86
assembly). As will become clear, it is relatively easy to spot C statements
which will compile to multiple-byte memory access instructions, namely when
dealing with types such as u16, u32 and u64.


Natural alignment
=================

The rule mentioned above forms what we refer to as natural alignment:
When accessing N bytes of memory, the base memory address must be evenly
divisible by N, i.e. addr % N == 0.

When writing code, assume the target architecture has natural alignment
requirements.

In reality, only a few architectures require natural alignment on all sizes
of memory access. However, we must consider ALL supported architectures;
writing code that satisfies natural alignment requirements is the easiest way
to achieve full portability.


Why unaligned access is bad
===========================

The effects of performing an unaligned memory access vary from architecture
to architecture. It would be easy to write a whole document on the differences
here; a summary of the common scenarios is presented below:

 - Some architectures are able to perform unaligned memory accesses
   transparently, but there is usually a significant performance cost.
 - Some architectures raise processor exceptions when unaligned accesses
   happen. The exception handler is able to correct the unaligned access,
   at significant cost to performance.
 - Some architectures raise processor exceptions when unaligned accesses
   happen, but the exceptions do not contain enough information for the
   unaligned access to be corrected.
 - Some architectures are not capable of unaligned memory access, but will
   silently perform a different memory access to the one that was requested,
   resulting in a subtle code bug that is hard to detect!

It should be obvious from the above that if your code causes unaligned
memory accesses to happen, your code will not work correctly on certain
platforms and will cause performance problems on others.


Code that does not cause unaligned access
=========================================

At first, the concepts above may seem a little hard to relate to actual
coding practice. After all, you don't have a great deal of control over
memory addresses of certain variables, etc.

Fortunately things are not too complex, as in most cases, the compiler
ensures that things will work for you. For example, take the following
structure:

	struct foo {
		u16 field1;
		u32 field2;
		u8 field3;
	};

Let us assume that an instance of the above structure resides in memory
starting at address 0x10000. With a basic level of understanding, it would
not be unreasonable to expect that accessing field2 would cause an unaligned
access. You'd be expecting field2 to be located at offset 2 bytes into the
structure, i.e. address 0x10002, but that address is not evenly divisible
by 4 (remember, we're reading a 4 byte value here).

Fortunately, the compiler understands the alignment constraints, so in the
above case it would insert 2 bytes of padding in between field1 and field2.
Therefore, for standard structure types you can always rely on the compiler
to pad structures so that accesses to fields are suitably aligned (assuming
you do not cast the field to a type of different length).

Similarly, you can also rely on the compiler to align variables and function
parameters to a naturally aligned scheme, based on the size of the type of
the variable.

At this point, it should be clear that accessing a single byte (u8 or char)
will never cause an unaligned access, because all memory addresses are evenly
divisible by one.

On a related topic, with the above considerations in mind you may observe
that you could reorder the fields in the structure in order to place fields
where padding would otherwise be inserted, and hence reduce the overall
resident memory size of structure instances. The optimal layout of the
above example is:

	struct foo {
		u32 field2;
		u16 field1;
		u8 field3;
	};

For a natural alignment scheme, the compiler would only have to add a single
byte of padding at the end of the structure. This padding is added in order
to satisfy alignment constraints for arrays of these structures.

Another point worth mentioning is the use of __attribute__((packed)) on a
structure type. This GCC-specific attribute tells the compiler never to
insert any padding within structures, useful when you want to use a C struct
to represent some data that comes in a fixed arrangement 'off the wire'.

You might be inclined to believe that usage of this attribute can easily
lead to unaligned accesses when accessing fields that do not satisfy
architectural alignment requirements. However, again, the compiler is aware
of the alignment constraints and will generate extra instructions to perform
the memory access in a way that does not cause unaligned access. Of course,
the extra instructions obviously cause a loss in performance compared to the
non-packed case, so the packed attribute should only be used when avoiding
structure padding is of importance.


Code that causes unaligned access
=================================

With the above in mind, let's move onto a real life example of a function
that can cause an unaligned memory access. The following function adapted
from include/linux/etherdevice.h is an optimized routine to compare two
ethernet MAC addresses for equality.

unsigned int compare_ether_addr(const u8 *addr1, const u8 *addr2)
{
	const u16 *a = (const u16 *) addr1;
	const u16 *b = (const u16 *) addr2;
	return ((a[0] ^ b[0]) | (a[1] ^ b[1]) | (a[2] ^ b[2])) != 0;
}

In the above function, the reference to a[0] causes 2 bytes (16 bits) to
be read from memory starting at address addr1. Think about what would happen
if addr1 was an odd address such as 0x10003. (Hint: it'd be an unaligned
access.)

Despite the potential unaligned access problems with the above function, it
is included in the kernel anyway but is understood to only work on
16-bit-aligned addresses. It is up to the caller to ensure this alignment or
not use this function at all. This alignment-unsafe function is still useful
as it is a decent optimization for the cases when you can ensure alignment,
which is true almost all of the time in ethernet networking context.


Here is another example of some code that could cause unaligned accesses:
	void myfunc(u8 *data, u32 value)
	{
		[...]
		*((u32 *) data) = cpu_to_le32(value);
		[...]
	}

This code will cause unaligned accesses every time the data parameter points
to an address that is not evenly divisible by 4.

In summary, the 2 main scenarios where you may run into unaligned access
problems involve:
 1. Casting variables to types of different lengths
 2. Pointer arithmetic followed by access to at least 2 bytes of data


Avoiding unaligned accesses
===========================

The easiest way to avoid unaligned access is to use the get_unaligned() and
put_unaligned() macros provided by the <asm/unaligned.h> header file.

Going back to an earlier example of code that potentially causes unaligned
access:

	void myfunc(u8 *data, u32 value)
	{
		[...]
		*((u32 *) data) = cpu_to_le32(value);
		[...]
	}

To avoid the unaligned memory access, you would rewrite it as follows:

	void myfunc(u8 *data, u32 value)
	{
		[...]
		value = cpu_to_le32(value);
		put_unaligned(value, (u32 *) data);
		[...]
	}

The get_unaligned() macro works similarly. Assuming 'data' is a pointer to
memory and you wish to avoid unaligned access, its usage is as follows:

	u32 value = get_unaligned((u32 *) data);

These macros work for memory accesses of any length (not just 32 bits as
in the examples above). Be aware that when compared to standard access of
aligned memory, using these macros to access unaligned memory can be costly in
terms of performance.

If use of such macros is not convenient, another option is to use memcpy(),
where the source or destination (or both) are of type u8* or unsigned char*.
Due to the byte-wise nature of this operation, unaligned accesses are avoided.


Alignment vs. Networking
========================

On architectures that require aligned loads, networking requires that the IP
header is aligned on a four-byte boundary to optimise the IP stack. For
regular ethernet hardware, the constant NET_IP_ALIGN is used. On most
architectures this constant has the value 2 because the normal ethernet
header is 14 bytes long, so in order to get proper alignment one needs to
DMA to an address which can be expressed as 4*n + 2. One notable exception
here is powerpc which defines NET_IP_ALIGN to 0 because DMA to unaligned
addresses can be very expensive and dwarf the cost of unaligned loads.

For some ethernet hardware that cannot DMA to unaligned addresses like
4*n+2 or non-ethernet hardware, this can be a problem, and it is then
required to copy the incoming frame into an aligned buffer. Because this is
unnecessary on architectures that can do unaligned accesses, the code can be
made dependent on CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS like so:

#ifdef CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS
	skb = original skb
#else
	skb = copy skb
#endif

--
Authors: Daniel Drake <dsd@gentoo.org>,
         Johannes Berg <johannes@sipsolutions.net>
With help from: Alan Cox, Avuton Olrich, Heikki Orsila, Jan Engelhardt,
Kyle McMartin, Kyle Moffett, Randy Dunlap, Robert Hancock, Uli Kunitz,
Vadim Lobanov

		 Last update: 2005-01-17, version 1.4

This file is maintained by H. Peter Anvin <unicode@lanana.org> as part
of the Linux Assigned Names And Numbers Authority (LANANA) project.
The current version can be found at:

	    http://www.lanana.org/docs/unicode/unicode.txt

		       ------------------------

The Linux kernel code has been rewritten to use Unicode to map
characters to fonts.  By downloading a single Unicode-to-font table,
both the eight-bit character sets and UTF-8 mode are changed to use
the font as indicated.

This changes the semantics of the eight-bit character tables subtly.
The four character tables are now:

Map symbol	Map name			Escape code (G0)

LAT1_MAP	Latin-1 (ISO 8859-1)		ESC ( B
GRAF_MAP	DEC VT100 pseudographics	ESC ( 0
IBMPC_MAP	IBM code page 437		ESC ( U
USER_MAP	User defined			ESC ( K

In particular, ESC ( U is no longer "straight to font", since the font
might be completely different than the IBM character set.  This
permits for example the use of block graphics even with a Latin-1 font
loaded.

Note that although these codes are similar to ISO 2022, neither the
codes nor their uses match ISO 2022; Linux has two 8-bit codes (G0 and
G1), whereas ISO 2022 has four 7-bit codes (G0-G3).

In accordance with the Unicode standard/ISO 10646 the range U+F000 to
U+F8FF has been reserved for OS-wide allocation (the Unicode Standard
refers to this as a "Corporate Zone", since this is inaccurate for
Linux we call it the "Linux Zone").  U+F000 was picked as the starting
point since it lets the direct-mapping area start on a large power of
two (in case 1024- or 2048-character fonts ever become necessary).
This leaves U+E000 to U+EFFF as End User Zone.

[v1.2]: The Unicodes range from U+F000 and up to U+F7FF have been
hard-coded to map directly to the loaded font, bypassing the
translation table.  The user-defined map now defaults to U+F000 to
U+F0FF, emulating the previous behaviour.  In practice, this range
might be shorter; for example, vgacon can only handle 256-character
(U+F000..U+F0FF) or 512-character (U+F000..U+F1FF) fonts.


Actual characters assigned in the Linux Zone
--------------------------------------------

In addition, the following characters not present in Unicode 1.1.4
have been defined; these are used by the DEC VT graphics map.  [v1.2]
THIS USE IS OBSOLETE AND SHOULD NO LONGER BE USED; PLEASE SEE BELOW.

U+F800 DEC VT GRAPHICS HORIZONTAL LINE SCAN 1
U+F801 DEC VT GRAPHICS HORIZONTAL LINE SCAN 3
U+F803 DEC VT GRAPHICS HORIZONTAL LINE SCAN 7
U+F804 DEC VT GRAPHICS HORIZONTAL LINE SCAN 9

The DEC VT220 uses a 6x10 character matrix, and these characters form
a smooth progression in the DEC VT graphics character set.  I have
omitted the scan 5 line, since it is also used as a block-graphics
character, and hence has been coded as U+2500 FORMS LIGHT HORIZONTAL.

[v1.3]: These characters have been officially added to Unicode 3.2.0;
they are added at U+23BA, U+23BB, U+23BC, U+23BD.  Linux now uses the
new values.

[v1.2]: The following characters have been added to represent common
keyboard symbols that are unlikely to ever be added to Unicode proper
since they are horribly vendor-specific.  This, of course, is an
excellent example of horrible design.

U+F810 KEYBOARD SYMBOL FLYING FLAG
U+F811 KEYBOARD SYMBOL PULLDOWN MENU
U+F812 KEYBOARD SYMBOL OPEN APPLE
U+F813 KEYBOARD SYMBOL SOLID APPLE

Klingon language support
------------------------

In 1996, Linux was the first operating system in the world to add
support for the artificial language Klingon, created by Marc Okrand
for the "Star Trek" television series.	This encoding was later
adopted by the ConScript Unicode Registry and proposed (but ultimately
rejected) for inclusion in Unicode Plane 1.  Thus, it remains as a
Linux/CSUR private assignment in the Linux Zone.

This encoding has been endorsed by the Klingon Language Institute.
For more information, contact them at:

	http://www.kli.org/

Since the characters in the beginning of the Linux CZ have been more
of the dingbats/symbols/forms type and this is a language, I have
located it at the end, on a 16-cell boundary in keeping with standard
Unicode practice.

NOTE: This range is now officially managed by the ConScript Unicode
Registry.  The normative reference is at:

	http://www.evertype.com/standards/csur/klingon.html

Klingon has an alphabet of 26 characters, a positional numeric writing
system with 10 digits, and is written left-to-right, top-to-bottom.

Several glyph forms for the Klingon alphabet have been proposed.
However, since the set of symbols appear to be consistent throughout,
with only the actual shapes being different, in keeping with standard
Unicode practice these differences are considered font variants.

U+F8D0	KLINGON LETTER A
U+F8D1	KLINGON LETTER B
U+F8D2	KLINGON LETTER CH
U+F8D3	KLINGON LETTER D
U+F8D4	KLINGON LETTER E
U+F8D5	KLINGON LETTER GH
U+F8D6	KLINGON LETTER H
U+F8D7	KLINGON LETTER I
U+F8D8	KLINGON LETTER J
U+F8D9	KLINGON LETTER L
U+F8DA	KLINGON LETTER M
U+F8DB	KLINGON LETTER N
U+F8DC	KLINGON LETTER NG
U+F8DD	KLINGON LETTER O
U+F8DE	KLINGON LETTER P
U+F8DF	KLINGON LETTER Q
	- Written <q> in standard Okrand Latin transliteration
U+F8E0	KLINGON LETTER QH
	- Written <Q> in standard Okrand Latin transliteration
U+F8E1	KLINGON LETTER R
U+F8E2	KLINGON LETTER S
U+F8E3	KLINGON LETTER T
U+F8E4	KLINGON LETTER TLH
U+F8E5	KLINGON LETTER U
U+F8E6	KLINGON LETTER V
U+F8E7	KLINGON LETTER W
U+F8E8	KLINGON LETTER Y
U+F8E9	KLINGON LETTER GLOTTAL STOP

U+F8F0	KLINGON DIGIT ZERO
U+F8F1	KLINGON DIGIT ONE
U+F8F2	KLINGON DIGIT TWO
U+F8F3	KLINGON DIGIT THREE
U+F8F4	KLINGON DIGIT FOUR
U+F8F5	KLINGON DIGIT FIVE
U+F8F6	KLINGON DIGIT SIX
U+F8F7	KLINGON DIGIT SEVEN
U+F8F8	KLINGON DIGIT EIGHT
U+F8F9	KLINGON DIGIT NINE

U+F8FD	KLINGON COMMA
U+F8FE	KLINGON FULL STOP
U+F8FF	KLINGON SYMBOL FOR EMPIRE

Other Fictional and Artificial Scripts
--------------------------------------

Since the assignment of the Klingon Linux Unicode block, a registry of
fictional and artificial scripts has been established by John Cowan
<jcowan@reutershealth.com> and Michael Everson <everson@evertype.com>.
The ConScript Unicode Registry is accessible at:

	  http://www.evertype.com/standards/csur/

The ranges used fall at the low end of the End User Zone and can hence
not be normatively assigned, but it is recommended that people who
wish to encode fictional scripts use these codes, in the interest of
interoperability.  For Klingon, CSUR has adopted the Linux encoding.
The CSUR people are driving adding Tengwar and Cirth into Unicode
Plane 1; the addition of Klingon to Unicode Plane 1 has been rejected
and so the above encoding remains official.

unshare system call:
--------------------
This document describes the new system call, unshare. The document
provides an overview of the feature, why it is needed, how it can
be used, its interface specification, design, implementation and
how it can be tested.

Change Log:
-----------
version 0.1  Initial document, Janak Desai (janak@us.ibm.com), Jan 11, 2006

Contents:
---------
	1) Overview
	2) Benefits
	3) Cost
	4) Requirements
	5) Functional Specification
	6) High Level Design
	7) Low Level Design
	8) Test Specification
	9) Future Work

1) Overview
-----------
Most legacy operating system kernels support an abstraction of threads
as multiple execution contexts within a process. These kernels provide
special resources and mechanisms to maintain these "threads". The Linux
kernel, in a clever and simple manner, does not make distinction
between processes and "threads". The kernel allows processes to share
resources and thus they can achieve legacy "threads" behavior without
requiring additional data structures and mechanisms in the kernel. The
power of implementing threads in this manner comes not only from
its simplicity but also from allowing application programmers to work
outside the confinement of all-or-nothing shared resources of legacy
threads. On Linux, at the time of thread creation using the clone system
call, applications can selectively choose which resources to share
between threads.

unshare system call adds a primitive to the Linux thread model that
allows threads to selectively 'unshare' any resources that were being
shared at the time of their creation. unshare was conceptualized by
Al Viro in the August of 2000, on the Linux-Kernel mailing list, as part
of the discussion on POSIX threads on Linux.  unshare augments the
usefulness of Linux threads for applications that would like to control
shared resources without creating a new process. unshare is a natural
addition to the set of available primitives on Linux that implement
the concept of process/thread as a virtual machine.

2) Benefits
-----------
unshare would be useful to large application frameworks such as PAM
where creating a new process to control sharing/unsharing of process
resources is not possible. Since namespaces are shared by default
when creating a new process using fork or clone, unshare can benefit
even non-threaded applications if they have a need to disassociate
from default shared namespace. The following lists two use-cases
where unshare can be used.

2.1 Per-security context namespaces
-----------------------------------
unshare can be used to implement polyinstantiated directories using
the kernel's per-process namespace mechanism. Polyinstantiated directories,
such as per-user and/or per-security context instance of /tmp, /var/tmp or
per-security context instance of a user's home directory, isolate user
processes when working with these directories. Using unshare, a PAM
module can easily setup a private namespace for a user at login.
Polyinstantiated directories are required for Common Criteria certification
with Labeled System Protection Profile, however, with the availability
of shared-tree feature in the Linux kernel, even regular Linux systems
can benefit from setting up private namespaces at login and
polyinstantiating /tmp, /var/tmp and other directories deemed
appropriate by system administrators.

2.2 unsharing of virtual memory and/or open files
-------------------------------------------------
Consider a client/server application where the server is processing
client requests by creating processes that share resources such as
virtual memory and open files. Without unshare, the server has to
decide what needs to be shared at the time of creating the process
which services the request. unshare allows the server an ability to
disassociate parts of the context during the servicing of the
request. For large and complex middleware application frameworks, this
ability to unshare after the process was created can be very
useful.

3) Cost
-------
In order to not duplicate code and to handle the fact that unshare
works on an active task (as opposed to clone/fork working on a newly
allocated inactive task) unshare had to make minor reorganizational
changes to copy_* functions utilized by clone/fork system call.
There is a cost associated with altering existing, well tested and
stable code to implement a new feature that may not get exercised
extensively in the beginning. However, with proper design and code
review of the changes and creation of an unshare test for the LTP
the benefits of this new feature can exceed its cost.

4) Requirements
---------------
unshare reverses sharing that was done using clone(2) system call,
so unshare should have a similar interface as clone(2). That is,
since flags in clone(int flags, void *stack) specifies what should
be shared, similar flags in unshare(int flags) should specify
what should be unshared. Unfortunately, this may appear to invert
the meaning of the flags from the way they are used in clone(2).
However, there was no easy solution that was less confusing and that
allowed incremental context unsharing in future without an ABI change.

unshare interface should accommodate possible future addition of
new context flags without requiring a rebuild of old applications.
If and when new context flags are added, unshare design should allow
incremental unsharing of those resources on an as needed basis.

5) Functional Specification
---------------------------
NAME
	unshare - disassociate parts of the process execution context

SYNOPSIS
	#include <sched.h>

	int unshare(int flags);

DESCRIPTION
	unshare allows a process to disassociate parts of its execution
	context that are currently being shared with other processes. Part
	of execution context, such as the namespace, is shared by default
	when a new process is created using fork(2), while other parts,
	such as the virtual memory, open file descriptors, etc, may be
	shared by explicit request to share them when creating a process
	using clone(2).

	The main use of unshare is to allow a process to control its
	shared execution context without creating a new process.

	The flags argument specifies one or bitwise-or'ed of several of
	the following constants.

	CLONE_FS
		If CLONE_FS is set, file system information of the caller
		is disassociated from the shared file system information.

	CLONE_FILES
		If CLONE_FILES is set, the file descriptor table of the
		caller is disassociated from the shared file descriptor
		table.

	CLONE_NEWNS
		If CLONE_NEWNS is set, the namespace of the caller is
		disassociated from the shared namespace.

	CLONE_VM
		If CLONE_VM is set, the virtual memory of the caller is
		disassociated from the shared virtual memory.

RETURN VALUE
	On success, zero returned. On failure, -1 is returned and errno is

ERRORS
	EPERM	CLONE_NEWNS was specified by a non-root process (process
		without CAP_SYS_ADMIN).

	ENOMEM	Cannot allocate sufficient memory to copy parts of caller's
		context that need to be unshared.

	EINVAL	Invalid flag was specified as an argument.

CONFORMING TO
	The unshare() call is Linux-specific and  should  not be used
	in programs intended to be portable.

SEE ALSO
	clone(2), fork(2)

6) High Level Design
--------------------
Depending on the flags argument, the unshare system call allocates
appropriate process context structures, populates it with values from
the current shared version, associates newly duplicated structures
with the current task structure and releases corresponding shared
versions. Helper functions of clone (copy_*) could not be used
directly by unshare because of the following two reasons.
  1) clone operates on a newly allocated not-yet-active task
     structure, where as unshare operates on the current active
     task. Therefore unshare has to take appropriate task_lock()
     before associating newly duplicated context structures
  2) unshare has to allocate and duplicate all context structures
     that are being unshared, before associating them with the
     current task and releasing older shared structures. Failure
     do so will create race conditions and/or oops when trying
     to backout due to an error. Consider the case of unsharing
     both virtual memory and namespace. After successfully unsharing
     vm, if the system call encounters an error while allocating
     new namespace structure, the error return code will have to
     reverse the unsharing of vm. As part of the reversal the
     system call will have to go back to older, shared, vm
     structure, which may not exist anymore.

Therefore code from copy_* functions that allocated and duplicated
current context structure was moved into new dup_* functions. Now,
copy_* functions call dup_* functions to allocate and duplicate
appropriate context structures and then associate them with the
task structure that is being constructed. unshare system call on
the other hand performs the following:
  1) Check flags to force missing, but implied, flags
  2) For each context structure, call the corresponding unshare
     helper function to allocate and duplicate a new context
     structure, if the appropriate bit is set in the flags argument.
  3) If there is no error in allocation and duplication and there
     are new context structures then lock the current task structure,
     associate new context structures with the current task structure,
     and release the lock on the current task structure.
  4) Appropriately release older, shared, context structures.

7) Low Level Design
-------------------
Implementation of unshare can be grouped in the following 4 different
items:
  a) Reorganization of existing copy_* functions
  b) unshare system call service function
  c) unshare helper functions for each different process context
  d) Registration of system call number for different architectures

  7.1) Reorganization of copy_* functions
       Each copy function such as copy_mm, copy_namespace, copy_files,
       etc, had roughly two components. The first component allocated
       and duplicated the appropriate structure and the second component
       linked it to the task structure passed in as an argument to the copy
       function. The first component was split into its own function.
       These dup_* functions allocated and duplicated the appropriate
       context structure. The reorganized copy_* functions invoked
       their corresponding dup_* functions and then linked the newly
       duplicated structures to the task structure with which the
       copy function was called.

  7.2) unshare system call service function
       * Check flags
	 Force implied flags. If CLONE_THREAD is set force CLONE_VM.
	 If CLONE_VM is set, force CLONE_SIGHAND. If CLONE_SIGHAND is
	 set and signals are also being shared, force CLONE_THREAD. If
	 CLONE_NEWNS is set, force CLONE_FS.
       * For each context flag, invoke the corresponding unshare_*
	 helper routine with flags passed into the system call and a
	 reference to pointer pointing the new unshared structure
       * If any new structures are created by unshare_* helper
	 functions, take the task_lock() on the current task,
	 modify appropriate context pointers, and release the
         task lock.
       * For all newly unshared structures, release the corresponding
         older, shared, structures.

  7.3) unshare_* helper functions
       For unshare_* helpers corresponding to CLONE_SYSVSEM, CLONE_SIGHAND,
       and CLONE_THREAD, return -EINVAL since they are not implemented yet.
       For others, check the flag value to see if the unsharing is
       required for that structure. If it is, invoke the corresponding
       dup_* function to allocate and duplicate the structure and return
       a pointer to it.

  7.4) Appropriately modify architecture specific code to register the
       new system call.

8) Test Specification
---------------------
The test for unshare should test the following:
  1) Valid flags: Test to check that clone flags for signal and
	signal handlers, for which unsharing is not implemented
	yet, return -EINVAL.
  2) Missing/implied flags: Test to make sure that if unsharing
	namespace without specifying unsharing of filesystem, correctly
	unshares both namespace and filesystem information.
  3) For each of the four (namespace, filesystem, files and vm)
	supported unsharing, verify that the system call correctly
	unshares the appropriate structure. Verify that unsharing
	them individually as well as in combination with each
	other works as expected.
  4) Concurrent execution: Use shared memory segments and futex on
	an address in the shm segment to synchronize execution of
	about 10 threads. Have a couple of threads execute execve,
	a couple _exit and the rest unshare with different combination
	of flags. Verify that unsharing is performed as expected and
	that there are no oops or hangs.

9) Future Work
--------------
The current implementation of unshare does not allow unsharing of
signals and signal handlers. Signals are complex to begin with and
to unshare signals and/or signal handlers of a currently running
process is even more complex. If in the future there is a specific
need to allow unsharing of signals and/or signal handlers, it can
be incrementally added to unshare without affecting legacy
applications using unshare.

Software cursor for VGA    by Pavel Machek <pavel@atrey.karlin.mff.cuni.cz>
=======================    and Martin Mares <mj@atrey.karlin.mff.cuni.cz>

   Linux now has some ability to manipulate cursor appearance. Normally, you
can set the size of hardware cursor (and also work around some ugly bugs in
those miserable Trident cards--see #define TRIDENT_GLITCH in drivers/video/
vgacon.c). You can now play a few new tricks:  you can make your cursor look
like a non-blinking red block, make it inverse background of the character it's
over or to highlight that character and still choose whether the original
hardware cursor should remain visible or not.  There may be other things I have
never thought of.

   The cursor appearance is controlled by a "<ESC>[?1;2;3c" escape sequence
where 1, 2 and 3 are parameters described below. If you omit any of them,
they will default to zeroes.

   Parameter 1 specifies cursor size (0=default, 1=invisible, 2=underline, ...,
8=full block) + 16 if you want the software cursor to be applied + 32 if you
want to always change the background color + 64 if you dislike having the
background the same as the foreground.  Highlights are ignored for the last two
flags.

   The second parameter selects character attribute bits you want to change
(by simply XORing them with the value of this parameter). On standard VGA,
the high four bits specify background and the low four the foreground. In both
groups, low three bits set color (as in normal color codes used by the console)
and the most significant one turns on highlight (or sometimes blinking--it
depends on the configuration of your VGA).

   The third parameter consists of character attribute bits you want to set.
Bit setting takes place before bit toggling, so you can simply clear a bit by 
including it in both the set mask and the toggle mask.

Examples:
=========

To get normal blinking underline, use: echo -e '\033[?2c'
To get blinking block, use:            echo -e '\033[?6c'
To get red non-blinking block, use:    echo -e '\033[?17;0;64c'

Concurrency Managed Workqueue (cmwq)

September, 2010		Tejun Heo <tj@kernel.org>
			Florian Mickler <florian@mickler.org>

CONTENTS

1. Introduction
2. Why cmwq?
3. The Design
4. Application Programming Interface (API)
5. Example Execution Scenarios
6. Guidelines
7. Debugging


1. Introduction

There are many cases where an asynchronous process execution context
is needed and the workqueue (wq) API is the most commonly used
mechanism for such cases.

When such an asynchronous execution context is needed, a work item
describing which function to execute is put on a queue.  An
independent thread serves as the asynchronous execution context.  The
queue is called workqueue and the thread is called worker.

While there are work items on the workqueue the worker executes the
functions associated with the work items one after the other.  When
there is no work item left on the workqueue the worker becomes idle.
When a new work item gets queued, the worker begins executing again.


2. Why cmwq?

In the original wq implementation, a multi threaded (MT) wq had one
worker thread per CPU and a single threaded (ST) wq had one worker
thread system-wide.  A single MT wq needed to keep around the same
number of workers as the number of CPUs.  The kernel grew a lot of MT
wq users over the years and with the number of CPU cores continuously
rising, some systems saturated the default 32k PID space just booting
up.

Although MT wq wasted a lot of resource, the level of concurrency
provided was unsatisfactory.  The limitation was common to both ST and
MT wq albeit less severe on MT.  Each wq maintained its own separate
worker pool.  A MT wq could provide only one execution context per CPU
while a ST wq one for the whole system.  Work items had to compete for
those very limited execution contexts leading to various problems
including proneness to deadlocks around the single execution context.

The tension between the provided level of concurrency and resource
usage also forced its users to make unnecessary tradeoffs like libata
choosing to use ST wq for polling PIOs and accepting an unnecessary
limitation that no two polling PIOs can progress at the same time.  As
MT wq don't provide much better concurrency, users which require
higher level of concurrency, like async or fscache, had to implement
their own thread pool.

Concurrency Managed Workqueue (cmwq) is a reimplementation of wq with
focus on the following goals.

* Maintain compatibility with the original workqueue API.

* Use per-CPU unified worker pools shared by all wq to provide
  flexible level of concurrency on demand without wasting a lot of
  resource.

* Automatically regulate worker pool and level of concurrency so that
  the API users don't need to worry about such details.


3. The Design

In order to ease the asynchronous execution of functions a new
abstraction, the work item, is introduced.

A work item is a simple struct that holds a pointer to the function
that is to be executed asynchronously.  Whenever a driver or subsystem
wants a function to be executed asynchronously it has to set up a work
item pointing to that function and queue that work item on a
workqueue.

Special purpose threads, called worker threads, execute the functions
off of the queue, one after the other.  If no work is queued, the
worker threads become idle.  These worker threads are managed in so
called thread-pools.

The cmwq design differentiates between the user-facing workqueues that
subsystems and drivers queue work items on and the backend mechanism
which manages thread-pool and processes the queued work items.

The backend is called gcwq.  There is one gcwq for each possible CPU
and one gcwq to serve work items queued on unbound workqueues.

Subsystems and drivers can create and queue work items through special
workqueue API functions as they see fit. They can influence some
aspects of the way the work items are executed by setting flags on the
workqueue they are putting the work item on. These flags include
things like CPU locality, reentrancy, concurrency limits and more. To
get a detailed overview refer to the API description of
alloc_workqueue() below.

When a work item is queued to a workqueue, the target gcwq is
determined according to the queue parameters and workqueue attributes
and appended on the shared worklist of the gcwq.  For example, unless
specifically overridden, a work item of a bound workqueue will be
queued on the worklist of exactly that gcwq that is associated to the
CPU the issuer is running on.

For any worker pool implementation, managing the concurrency level
(how many execution contexts are active) is an important issue.  cmwq
tries to keep the concurrency at a minimal but sufficient level.
Minimal to save resources and sufficient in that the system is used at
its full capacity.

Each gcwq bound to an actual CPU implements concurrency management by
hooking into the scheduler.  The gcwq is notified whenever an active
worker wakes up or sleeps and keeps track of the number of the
currently runnable workers.  Generally, work items are not expected to
hog a CPU and consume many cycles.  That means maintaining just enough
concurrency to prevent work processing from stalling should be
optimal.  As long as there are one or more runnable workers on the
CPU, the gcwq doesn't start execution of a new work, but, when the
last running worker goes to sleep, it immediately schedules a new
worker so that the CPU doesn't sit idle while there are pending work
items.  This allows using a minimal number of workers without losing
execution bandwidth.

Keeping idle workers around doesn't cost other than the memory space
for kthreads, so cmwq holds onto idle ones for a while before killing
them.

For an unbound wq, the above concurrency management doesn't apply and
the gcwq for the pseudo unbound CPU tries to start executing all work
items as soon as possible.  The responsibility of regulating
concurrency level is on the users.  There is also a flag to mark a
bound wq to ignore the concurrency management.  Please refer to the
API section for details.

Forward progress guarantee relies on that workers can be created when
more execution contexts are necessary, which in turn is guaranteed
through the use of rescue workers.  All work items which might be used
on code paths that handle memory reclaim are required to be queued on
wq's that have a rescue-worker reserved for execution under memory
pressure.  Else it is possible that the thread-pool deadlocks waiting
for execution contexts to free up.


4. Application Programming Interface (API)

alloc_workqueue() allocates a wq.  The original create_*workqueue()
functions are deprecated and scheduled for removal.  alloc_workqueue()
takes three arguments - @name, @flags and @max_active.  @name is the
name of the wq and also used as the name of the rescuer thread if
there is one.

A wq no longer manages execution resources but serves as a domain for
forward progress guarantee, flush and work item attributes.  @flags
and @max_active control how work items are assigned execution
resources, scheduled and executed.

@flags:

  WQ_NON_REENTRANT

	By default, a wq guarantees non-reentrance only on the same
	CPU.  A work item may not be executed concurrently on the same
	CPU by multiple workers but is allowed to be executed
	concurrently on multiple CPUs.  This flag makes sure
	non-reentrance is enforced across all CPUs.  Work items queued
	to a non-reentrant wq are guaranteed to be executed by at most
	one worker system-wide at any given time.

  WQ_UNBOUND

	Work items queued to an unbound wq are served by a special
	gcwq which hosts workers which are not bound to any specific
	CPU.  This makes the wq behave as a simple execution context
	provider without concurrency management.  The unbound gcwq
	tries to start execution of work items as soon as possible.
	Unbound wq sacrifices locality but is useful for the following
	cases.

	* Wide fluctuation in the concurrency level requirement is
	  expected and using bound wq may end up creating large number
	  of mostly unused workers across different CPUs as the issuer
	  hops through different CPUs.

	* Long running CPU intensive workloads which can be better
	  managed by the system scheduler.

  WQ_FREEZABLE

	A freezable wq participates in the freeze phase of the system
	suspend operations.  Work items on the wq are drained and no
	new work item starts execution until thawed.

  WQ_MEM_RECLAIM

	All wq which might be used in the memory reclaim paths _MUST_
	have this flag set.  The wq is guaranteed to have at least one
	execution context regardless of memory pressure.

  WQ_HIGHPRI

	Work items of a highpri wq are queued at the head of the
	worklist of the target gcwq and start execution regardless of
	the current concurrency level.  In other words, highpri work
	items will always start execution as soon as execution
	resource is available.

	Ordering among highpri work items is preserved - a highpri
	work item queued after another highpri work item will start
	execution after the earlier highpri work item starts.

	Although highpri work items are not held back by other
	runnable work items, they still contribute to the concurrency
	level.  Highpri work items in runnable state will prevent
	non-highpri work items from starting execution.

	This flag is meaningless for unbound wq.

  WQ_CPU_INTENSIVE

	Work items of a CPU intensive wq do not contribute to the
	concurrency level.  In other words, runnable CPU intensive
	work items will not prevent other work items from starting
	execution.  This is useful for bound work items which are
	expected to hog CPU cycles so that their execution is
	regulated by the system scheduler.

	Although CPU intensive work items don't contribute to the
	concurrency level, start of their executions is still
	regulated by the concurrency management and runnable
	non-CPU-intensive work items can delay execution of CPU
	intensive work items.

	This flag is meaningless for unbound wq.

  WQ_HIGHPRI | WQ_CPU_INTENSIVE

	This combination makes the wq avoid interaction with
	concurrency management completely and behave as a simple
	per-CPU execution context provider.  Work items queued on a
	highpri CPU-intensive wq start execution as soon as resources
	are available and don't affect execution of other work items.

@max_active:

@max_active determines the maximum number of execution contexts per
CPU which can be assigned to the work items of a wq.  For example,
with @max_active of 16, at most 16 work items of the wq can be
executing at the same time per CPU.

Currently, for a bound wq, the maximum limit for @max_active is 512
and the default value used when 0 is specified is 256.  For an unbound
wq, the limit is higher of 512 and 4 * num_possible_cpus().  These
values are chosen sufficiently high such that they are not the
limiting factor while providing protection in runaway cases.

The number of active work items of a wq is usually regulated by the
users of the wq, more specifically, by how many work items the users
may queue at the same time.  Unless there is a specific need for
throttling the number of active work items, specifying '0' is
recommended.

Some users depend on the strict execution ordering of ST wq.  The
combination of @max_active of 1 and WQ_UNBOUND is used to achieve this
behavior.  Work items on such wq are always queued to the unbound gcwq
and only one work item can be active at any given time thus achieving
the same ordering property as ST wq.


5. Example Execution Scenarios

The following example execution scenarios try to illustrate how cmwq
behave under different configurations.

 Work items w0, w1, w2 are queued to a bound wq q0 on the same CPU.
 w0 burns CPU for 5ms then sleeps for 10ms then burns CPU for 5ms
 again before finishing.  w1 and w2 burn CPU for 5ms then sleep for
 10ms.

Ignoring all other tasks, works and processing overhead, and assuming
simple FIFO scheduling, the following is one highly simplified version
of possible sequences of events with the original wq.

 TIME IN MSECS	EVENT
 0		w0 starts and burns CPU
 5		w0 sleeps
 15		w0 wakes up and burns CPU
 20		w0 finishes
 20		w1 starts and burns CPU
 25		w1 sleeps
 35		w1 wakes up and finishes
 35		w2 starts and burns CPU
 40		w2 sleeps
 50		w2 wakes up and finishes

And with cmwq with @max_active >= 3,

 TIME IN MSECS	EVENT
 0		w0 starts and burns CPU
 5		w0 sleeps
 5		w1 starts and burns CPU
 10		w1 sleeps
 10		w2 starts and burns CPU
 15		w2 sleeps
 15		w0 wakes up and burns CPU
 20		w0 finishes
 20		w1 wakes up and finishes
 25		w2 wakes up and finishes

If @max_active == 2,

 TIME IN MSECS	EVENT
 0		w0 starts and burns CPU
 5		w0 sleeps
 5		w1 starts and burns CPU
 10		w1 sleeps
 15		w0 wakes up and burns CPU
 20		w0 finishes
 20		w1 wakes up and finishes
 20		w2 starts and burns CPU
 25		w2 sleeps
 35		w2 wakes up and finishes

Now, let's assume w1 and w2 are queued to a different wq q1 which has
WQ_HIGHPRI set,

 TIME IN MSECS	EVENT
 0		w1 and w2 start and burn CPU
 5		w1 sleeps
 10		w2 sleeps
 10		w0 starts and burns CPU
 15		w0 sleeps
 15		w1 wakes up and finishes
 20		w2 wakes up and finishes
 25		w0 wakes up and burns CPU
 30		w0 finishes

If q1 has WQ_CPU_INTENSIVE set,

 TIME IN MSECS	EVENT
 0		w0 starts and burns CPU
 5		w0 sleeps
 5		w1 and w2 start and burn CPU
 10		w1 sleeps
 15		w2 sleeps
 15		w0 wakes up and burns CPU
 20		w0 finishes
 20		w1 wakes up and finishes
 25		w2 wakes up and finishes


6. Guidelines

* Do not forget to use WQ_MEM_RECLAIM if a wq may process work items
  which are used during memory reclaim.  Each wq with WQ_MEM_RECLAIM
  set has an execution context reserved for it.  If there is
  dependency among multiple work items used during memory reclaim,
  they should be queued to separate wq each with WQ_MEM_RECLAIM.

* Unless strict ordering is required, there is no need to use ST wq.

* Unless there is a specific need, using 0 for @max_active is
  recommended.  In most use cases, concurrency level usually stays
  well under the default limit.

* A wq serves as a domain for forward progress guarantee
  (WQ_MEM_RECLAIM, flush and work item attributes.  Work items which
  are not involved in memory reclaim and don't need to be flushed as a
  part of a group of work items, and don't require any special
  attribute, can use one of the system wq.  There is no difference in
  execution characteristics between using a dedicated wq and a system
  wq.

* Unless work items are expected to consume a huge amount of CPU
  cycles, using a bound wq is usually beneficial due to the increased
  level of locality in wq operations and work item execution.


7. Debugging

Because the work functions are executed by generic worker threads
there are a few tricks needed to shed some light on misbehaving
workqueue users.

Worker threads show up in the process list as:

root      5671  0.0  0.0      0     0 ?        S    12:07   0:00 [kworker/0:1]
root      5672  0.0  0.0      0     0 ?        S    12:07   0:00 [kworker/1:2]
root      5673  0.0  0.0      0     0 ?        S    12:12   0:00 [kworker/0:0]
root      5674  0.0  0.0      0     0 ?        S    12:13   0:00 [kworker/1:0]

If kworkers are going crazy (using too much cpu), there are two types
of possible problems:

	1. Something beeing scheduled in rapid succession
	2. A single work item that consumes lots of cpu cycles

The first one can be tracked using tracing:

	$ echo workqueue:workqueue_queue_work > /sys/kernel/debug/tracing/set_event
	$ cat /sys/kernel/debug/tracing/trace_pipe > out.txt
	(wait a few secs)
	^C

If something is busy looping on work queueing, it would be dominating
the output and the offender can be determined with the work item
function.

For the second type of problems it should be possible to just check
the stack trace of the offending worker thread.

	$ cat /proc/THE_OFFENDING_KWORKER/stack

The work item's function should be trivially visible in the stack
trace.

XZ data compression in Linux
============================

Introduction

    XZ is a general purpose data compression format with high compression
    ratio and relatively fast decompression. The primary compression
    algorithm (filter) is LZMA2. Additional filters can be used to improve
    compression ratio even further. E.g. Branch/Call/Jump (BCJ) filters
    improve compression ratio of executable data.

    The XZ decompressor in Linux is called XZ Embedded. It supports
    the LZMA2 filter and optionally also BCJ filters. CRC32 is supported
    for integrity checking. The home page of XZ Embedded is at
    <http://tukaani.org/xz/embedded.html>, where you can find the
    latest version and also information about using the code outside
    the Linux kernel.

    For userspace, XZ Utils provide a zlib-like compression library
    and a gzip-like command line tool. XZ Utils can be downloaded from
    <http://tukaani.org/xz/>.

XZ related components in the kernel

    The xz_dec module provides XZ decompressor with single-call (buffer
    to buffer) and multi-call (stateful) APIs. The usage of the xz_dec
    module is documented in include/linux/xz.h.

    The xz_dec_test module is for testing xz_dec. xz_dec_test is not
    useful unless you are hacking the XZ decompressor. xz_dec_test
    allocates a char device major dynamically to which one can write
    .xz files from userspace. The decompressed output is thrown away.
    Keep an eye on dmesg to see diagnostics printed by xz_dec_test.
    See the xz_dec_test source code for the details.

    For decompressing the kernel image, initramfs, and initrd, there
    is a wrapper function in lib/decompress_unxz.c. Its API is the
    same as in other decompress_*.c files, which is defined in
    include/linux/decompress/generic.h.

    scripts/xz_wrap.sh is a wrapper for the xz command line tool found
    from XZ Utils. The wrapper sets compression options to values suitable
    for compressing the kernel image.

    For kernel makefiles, two commands are provided for use with
    $(call if_needed). The kernel image should be compressed with
    $(call if_needed,xzkern) which will use a BCJ filter and a big LZMA2
    dictionary. It will also append a four-byte trailer containing the
    uncompressed size of the file, which is needed by the boot code.
    Other things should be compressed with $(call if_needed,xzmisc)
    which will use no BCJ filter and 1 MiB LZMA2 dictionary.

Notes on compression options

    Since the XZ Embedded supports only streams with no integrity check or
    CRC32, make sure that you don't use some other integrity check type
    when encoding files that are supposed to be decoded by the kernel. With
    liblzma, you need to use either LZMA_CHECK_NONE or LZMA_CHECK_CRC32
    when encoding. With the xz command line tool, use --check=none or
    --check=crc32.

    Using CRC32 is strongly recommended unless there is some other layer
    which will verify the integrity of the uncompressed data anyway.
    Double checking the integrity would probably be waste of CPU cycles.
    Note that the headers will always have a CRC32 which will be validated
    by the decoder; you can only change the integrity check type (or
    disable it) for the actual uncompressed data.

    In userspace, LZMA2 is typically used with dictionary sizes of several
    megabytes. The decoder needs to have the dictionary in RAM, thus big
    dictionaries cannot be used for files that are intended to be decoded
    by the kernel. 1 MiB is probably the maximum reasonable dictionary
    size for in-kernel use (maybe more is OK for initramfs). The presets
    in XZ Utils may not be optimal when creating files for the kernel,
    so don't hesitate to use custom settings. Example:

        xz --check=crc32 --lzma2=dict=512KiB inputfile

    An exception to above dictionary size limitation is when the decoder
    is used in single-call mode. Decompressing the kernel itself is an
    example of this situation. In single-call mode, the memory usage
    doesn't depend on the dictionary size, and it is perfectly fine to
    use a big dictionary: for maximum compression, the dictionary should
    be at least as big as the uncompressed data itself.

Future plans

    Creating a limited XZ encoder may be considered if people think it is
    useful. LZMA2 is slower to compress than e.g. Deflate or LZO even at
    the fastest settings, so it isn't clear if LZMA2 encoder is wanted
    into the kernel.

    Support for limited random-access reading is planned for the
    decompression code. I don't know if it could have any use in the
    kernel, but I know that it would be useful in some embedded projects
    outside the Linux kernel.

Conformance to the .xz file format specification

    There are a couple of corner cases where things have been simplified
    at expense of detecting errors as early as possible. These should not
    matter in practice all, since they don't cause security issues. But
    it is good to know this if testing the code e.g. with the test files
    from XZ Utils.

Reporting bugs

    Before reporting a bug, please check that it's not fixed already
    at upstream. See <http://tukaani.org/xz/embedded.html> to get the
    latest code.

    Report bugs to <lasse.collin@tukaani.org> or visit #tukaani on
    Freenode and talk to Larhzu. I don't actively read LKML or other
    kernel-related mailing lists, so if there's something I should know,
    you should email to me personally or use IRC.

    Don't bother Igor Pavlov with questions about the XZ implementation
    in the kernel or about XZ Utils. While these two implementations
    include essential code that is directly based on Igor Pavlov's code,
    these implementations aren't maintained nor supported by him.
		Writing Device Drivers for Zorro Devices
		----------------------------------------

Written by Geert Uytterhoeven <geert@linux-m68k.org>
Last revised: September 5, 2003


1. Introduction
---------------

The Zorro bus is the bus used in the Amiga family of computers. Thanks to
AutoConfig(tm), it's 100% Plug-and-Play.

There are two types of Zorro busses, Zorro II and Zorro III:

  - The Zorro II address space is 24-bit and lies within the first 16 MB of the
    Amiga's address map.

  - Zorro III is a 32-bit extension of Zorro II, which is backwards compatible
    with Zorro II. The Zorro III address space lies outside the first 16 MB.


2. Probing for Zorro Devices
----------------------------

Zorro devices are found by calling `zorro_find_device()', which returns a
pointer to the `next' Zorro device with the specified Zorro ID. A probe loop
for the board with Zorro ID `ZORRO_PROD_xxx' looks like:

    struct zorro_dev *z = NULL;

    while ((z = zorro_find_device(ZORRO_PROD_xxx, z))) {
	if (!zorro_request_region(z->resource.start+MY_START, MY_SIZE,
				  "My explanation"))
	...
    }

`ZORRO_WILDCARD' acts as a wildcard and finds any Zorro device. If your driver
supports different types of boards, you can use a construct like:

    struct zorro_dev *z = NULL;

    while ((z = zorro_find_device(ZORRO_WILDCARD, z))) {
	if (z->id != ZORRO_PROD_xxx1 && z->id != ZORRO_PROD_xxx2 && ...)
	    continue;
	if (!zorro_request_region(z->resource.start+MY_START, MY_SIZE,
				  "My explanation"))
	...
    }


3. Zorro Resources
------------------

Before you can access a Zorro device's registers, you have to make sure it's
not yet in use. This is done using the I/O memory space resource management
functions:

    request_mem_region()
    release_mem_region()

Shortcuts to claim the whole device's address space are provided as well:

    zorro_request_device
    zorro_release_device


4. Accessing the Zorro Address Space
------------------------------------

The address regions in the Zorro device resources are Zorro bus address
regions. Due to the identity bus-physical address mapping on the Zorro bus,
they are CPU physical addresses as well.

The treatment of these regions depends on the type of Zorro space:

  - Zorro II address space is always mapped and does not have to be mapped
    explicitly using z_ioremap().
    
    Conversion from bus/physical Zorro II addresses to kernel virtual addresses
    and vice versa is done using:

	virt_addr = ZTWO_VADDR(bus_addr);
	bus_addr = ZTWO_PADDR(virt_addr);

  - Zorro III address space must be mapped explicitly using z_ioremap() first
    before it can be accessed:
 
	virt_addr = z_ioremap(bus_addr, size);
	...
	z_iounmap(virt_addr);


5. References
-------------

linux/include/linux/zorro.h
linux/include/asm-{m68k,ppc}/zorro.h
linux/include/linux/zorro_ids.h
linux/drivers/zorro
/proc/bus/zorro

